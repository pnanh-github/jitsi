(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else if(typeof exports === 'object')
		exports["JitsiMeetJS"] = factory();
	else
		root["JitsiMeetJS"] = factory();
})(window, function() {
return /******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./index.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./JitsiConference.js":
/*!****************************!*\
  !*** ./JitsiConference.js ***!
  \****************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JitsiConference; });
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! lodash.isequal */ "./node_modules/lodash.isequal/index.js");
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(lodash_isequal__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./JitsiConferenceErrors */ "./JitsiConferenceErrors.js");
/* harmony import */ var _JitsiConferenceEventManager__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./JitsiConferenceEventManager */ "./JitsiConferenceEventManager.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _JitsiParticipant__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./JitsiParticipant */ "./JitsiParticipant.js");
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./JitsiTrackError */ "./JitsiTrackError.js");
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./JitsiTrackErrors */ "./JitsiTrackErrors.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./JitsiTrackEvents */ "./JitsiTrackEvents.js");
/* harmony import */ var _authenticateAndUpgradeRole__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./authenticateAndUpgradeRole */ "./authenticateAndUpgradeRole.js");
/* harmony import */ var _modules_detection_P2PDominantSpeakerDetection__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./modules/detection/P2PDominantSpeakerDetection */ "./modules/detection/P2PDominantSpeakerDetection.js");
/* harmony import */ var _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./modules/RTC/RTC */ "./modules/RTC/RTC.js");
/* harmony import */ var _modules_detection_TalkMutedDetection__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./modules/detection/TalkMutedDetection */ "./modules/detection/TalkMutedDetection.js");
/* harmony import */ var _modules_detection_VADTalkMutedDetection__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./modules/detection/VADTalkMutedDetection */ "./modules/detection/VADTalkMutedDetection.js");
/* harmony import */ var _modules_detection_VADNoiseDetection__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./modules/detection/VADNoiseDetection */ "./modules/detection/VADNoiseDetection.js");
/* harmony import */ var _modules_detection_VADAudioAnalyser__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./modules/detection/VADAudioAnalyser */ "./modules/detection/VADAudioAnalyser.js");
/* harmony import */ var _modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./modules/detection/DetectionEvents */ "./modules/detection/DetectionEvents.js");
/* harmony import */ var _modules_detection_NoAudioSignalDetection__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./modules/detection/NoAudioSignalDetection */ "./modules/detection/NoAudioSignalDetection.js");
/* harmony import */ var _modules_browser__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./modules/browser */ "./modules/browser/index.js");
/* harmony import */ var _modules_connectivity_ConnectionQuality__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./modules/connectivity/ConnectionQuality */ "./modules/connectivity/ConnectionQuality.js");
/* harmony import */ var _modules_connectivity_IceFailedNotification__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./modules/connectivity/IceFailedNotification */ "./modules/connectivity/IceFailedNotification.js");
/* harmony import */ var _modules_connectivity_ParticipantConnectionStatus__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./modules/connectivity/ParticipantConnectionStatus */ "./modules/connectivity/ParticipantConnectionStatus.js");
/* harmony import */ var _modules_e2ee_E2EEContext__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./modules/e2ee/E2EEContext */ "./modules/e2ee/E2EEContext.js");
/* harmony import */ var _modules_e2eping_e2eping__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./modules/e2eping/e2eping */ "./modules/e2eping/e2eping.js");
/* harmony import */ var _modules_event_Jvb121EventGenerator__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./modules/event/Jvb121EventGenerator */ "./modules/event/Jvb121EventGenerator.js");
/* harmony import */ var _modules_recording_RecordingManager__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./modules/recording/RecordingManager */ "./modules/recording/RecordingManager.js");
/* harmony import */ var _modules_rttmonitor_rttmonitor__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./modules/rttmonitor/rttmonitor */ "./modules/rttmonitor/rttmonitor.js");
/* harmony import */ var _modules_settings_Settings__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./modules/settings/Settings */ "./modules/settings/Settings.js");
/* harmony import */ var _modules_statistics_AvgRTPStatsReporter__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./modules/statistics/AvgRTPStatsReporter */ "./modules/statistics/AvgRTPStatsReporter.js");
/* harmony import */ var _modules_statistics_AudioOutputProblemDetector__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./modules/statistics/AudioOutputProblemDetector */ "./modules/statistics/AudioOutputProblemDetector.js");
/* harmony import */ var _modules_statistics_SpeakerStatsCollector__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./modules/statistics/SpeakerStatsCollector */ "./modules/statistics/SpeakerStatsCollector.js");
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _modules_transcription_transcriber__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./modules/transcription/transcriber */ "./modules/transcription/transcriber.js");
/* harmony import */ var _modules_transcription_transcriber__WEBPACK_IMPORTED_MODULE_34___default = /*#__PURE__*/__webpack_require__.n(_modules_transcription_transcriber__WEBPACK_IMPORTED_MODULE_34__);
/* harmony import */ var _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./modules/util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_35___default = /*#__PURE__*/__webpack_require__.n(_modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_35__);
/* harmony import */ var _modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./modules/util/RandomUtil */ "./modules/util/RandomUtil.js");
/* harmony import */ var _modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_36___default = /*#__PURE__*/__webpack_require__.n(_modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_36__);
/* harmony import */ var _modules_version_ComponentsVersions__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./modules/version/ComponentsVersions */ "./modules/version/ComponentsVersions.js");
/* harmony import */ var _modules_videosipgw_VideoSIPGW__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./modules/videosipgw/VideoSIPGW */ "./modules/videosipgw/VideoSIPGW.js");
/* harmony import */ var _modules_videosipgw_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./modules/videosipgw/VideoSIPGWConstants */ "./modules/videosipgw/VideoSIPGWConstants.js");
/* harmony import */ var _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./modules/xmpp/xmpp */ "./modules/xmpp/xmpp.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_42___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_42__);
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./service/RTC/VideoType */ "./service/RTC/VideoType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_43___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_43__);
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__);
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

/* global __filename, $, Promise */














































const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__["getLogger"])(__filename);
/**
 * How long since Jicofo is supposed to send a session-initiate, before
 * {@link ACTION_JINGLE_SI_TIMEOUT} analytics event is sent (in ms).
 * @type {number}
 */

const JINGLE_SI_TIMEOUT = 5000;
/**
 * Creates a JitsiConference object with the given name and properties.
 * Note: this constructor is not a part of the public API (objects should be
 * created using JitsiConnection.createConference).
 * @param options.config properties / settings related to the conference that
 * will be created.
 * @param options.name the name of the conference
 * @param options.connection the JitsiConnection object for this
 * JitsiConference.
 * @param {number} [options.config.avgRtpStatsN=15] how many samples are to be
 * collected by {@link AvgRTPStatsReporter}, before arithmetic mean is
 * calculated and submitted to the analytics module.
 * @param {boolean} [options.config.p2p.enabled] when set to <tt>true</tt>
 * the peer to peer mode will be enabled. It means that when there are only 2
 * participants in the conference an attempt to make direct connection will be
 * made. If the connection succeeds the conference will stop sending data
 * through the JVB connection and will use the direct one instead.
 * @param {number} [options.config.p2p.backToP2PDelay=5] a delay given in
 * seconds, before the conference switches back to P2P, after the 3rd
 * participant has left the room.
 * @param {number} [options.config.channelLastN=-1] The requested amount of
 * videos are going to be delivered after the value is in effect. Set to -1 for
 * unlimited or all available videos.
 * @param {number} [options.config.forceJVB121Ratio]
 * "Math.random() < forceJVB121Ratio" will determine whether a 2 people
 * conference should be moved to the JVB instead of P2P. The decision is made on
 * the responder side, after ICE succeeds on the P2P connection.
 * @param {*} [options.config.openBridgeChannel] Which kind of communication to
 * open with the videobridge. Values can be "datachannel", "websocket", true
 * (treat it as "datachannel"), undefined (treat it as "datachannel") and false
 * (don't open any channel).
 * @constructor
 *
 * FIXME Make all methods which are called from lib-internal classes
 *       to non-public (use _). To name a few:
 *       {@link JitsiConference.onLocalRoleChanged}
 *       {@link JitsiConference.onUserRoleChanged}
 *       {@link JitsiConference.onMemberLeft}
 *       and so on...
 */

function JitsiConference(options) {
  if (!options.name || options.name.toLowerCase() !== options.name) {
    const errmsg = 'Invalid conference name (no conference name passed or it ' + 'contains invalid characters like capital letters)!';
    logger.error(errmsg);
    throw new Error(errmsg);
  }

  this.eventEmitter = new events__WEBPACK_IMPORTED_MODULE_1___default.a();
  this.options = options;
  this.eventManager = new _JitsiConferenceEventManager__WEBPACK_IMPORTED_MODULE_5__["default"](this);
  this.participants = {};

  this._init(options);

  this.componentsVersions = new _modules_version_ComponentsVersions__WEBPACK_IMPORTED_MODULE_37__["default"](this);
  /**
   * Jingle session instance for the JVB connection.
   * @type {JingleSessionPC}
   */

  this.jvbJingleSession = null;
  this.lastDominantSpeaker = null;
  this.dtmfManager = null;
  this.somebodySupportsDTMF = false;
  this.authEnabled = false;
  this.startAudioMuted = false;
  this.startVideoMuted = false;
  this.startMutedPolicy = {
    audio: false,
    video: false
  };
  this.isMutedByFocus = false; // when muted by focus we receive the jid of the initiator of the mute

  this.mutedByFocusActor = null; // Flag indicates if the 'onCallEnded' method was ever called on this
  // instance. Used to log extra analytics event for debugging purpose.
  // We need to know if the potential issue happened before or after
  // the restart.

  this.wasStopped = false; // Conference properties, maintained by jicofo.

  this.properties = {};
  /**
   * The object which monitors local and remote connection statistics (e.g.
   * sending bitrate) and calculates a number which represents the connection
   * quality.
   */

  this.connectionQuality = new _modules_connectivity_ConnectionQuality__WEBPACK_IMPORTED_MODULE_21__["default"](this, this.eventEmitter, options);
  /**
   * Reports average RTP statistics to the analytics module.
   * @type {AvgRTPStatsReporter}
   */

  this.avgRtpStatsReporter = new _modules_statistics_AvgRTPStatsReporter__WEBPACK_IMPORTED_MODULE_30__["default"](this, options.config.avgRtpStatsN || 15);
  /**
   * Detects issues with the audio of remote participants.
   * @type {AudioOutputProblemDetector}
   */

  this._audioOutputProblemDetector = new _modules_statistics_AudioOutputProblemDetector__WEBPACK_IMPORTED_MODULE_31__["default"](this);
  /**
   * Indicates whether the connection is interrupted or not.
   */

  this.isJvbConnectionInterrupted = false;
  /**
   * The object which tracks active speaker times
   */

  this.speakerStatsCollector = new _modules_statistics_SpeakerStatsCollector__WEBPACK_IMPORTED_MODULE_32__["default"](this);
  /* P2P related fields below: */

  /**
   * Stores reference to deferred start P2P task. It's created when 3rd
   * participant leaves the room in order to avoid ping pong effect (it
   * could be just a page reload).
   * @type {number|null}
   */

  this.deferredStartP2PTask = null;
  const delay = parseInt(options.config.p2p && options.config.p2p.backToP2PDelay, 10);
  /**
   * A delay given in seconds, before the conference switches back to P2P
   * after the 3rd participant has left.
   * @type {number}
   */

  this.backToP2PDelay = isNaN(delay) ? 5 : delay;
  logger.info(`backToP2PDelay: ${this.backToP2PDelay}`);
  /**
   * If set to <tt>true</tt> it means the P2P ICE is no longer connected.
   * When <tt>false</tt> it means that P2P ICE (media) connection is up
   * and running.
   * @type {boolean}
   */

  this.isP2PConnectionInterrupted = false;
  /**
   * Flag set to <tt>true</tt> when P2P session has been established
   * (ICE has been connected) and this conference is currently in the peer to
   * peer mode (P2P connection is the active one).
   * @type {boolean}
   */

  this.p2p = false;
  /**
   * A JingleSession for the direct peer to peer connection.
   * @type {JingleSessionPC}
   */

  this.p2pJingleSession = null;
  this.videoSIPGWHandler = new _modules_videosipgw_VideoSIPGW__WEBPACK_IMPORTED_MODULE_38__["default"](this.room);
  this.recordingManager = new _modules_recording_RecordingManager__WEBPACK_IMPORTED_MODULE_27__["default"](this.room);
  this._conferenceJoinAnalyticsEventSent = false;

  if (_modules_browser__WEBPACK_IMPORTED_MODULE_20__["default"].supportsInsertableStreams()) {
    this._e2eeCtx = new _modules_e2ee_E2EEContext__WEBPACK_IMPORTED_MODULE_24__["default"]({
      salt: this.options.name
    });
  }
} // FIXME convert JitsiConference to ES6 - ASAP !

JitsiConference.prototype.constructor = JitsiConference;
/**
 * Create a resource for the a jid. We use the room nickname (the resource part
 * of the occupant JID, see XEP-0045) as the endpoint ID in colibri. We require
 * endpoint IDs to be 8 hex digits because in some cases they get serialized
 * into a 32bit field.
 *
 * @param {string} jid - The id set onto the XMPP connection.
 * @param {boolean} isAuthenticatedUser - Whether or not the user has connected
 * to the XMPP service with a password.
 * @returns {string}
 * @static
 */

JitsiConference.resourceCreator = function (jid, isAuthenticatedUser) {
  let mucNickname;

  if (isAuthenticatedUser) {
    // For authenticated users generate a random ID.
    mucNickname = _modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_36___default.a.randomHexString(8).toLowerCase();
  } else {
    // We try to use the first part of the node (which for anonymous users
    // on prosody is a UUID) to match the previous behavior (and maybe make
    // debugging easier).
    mucNickname = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getNodeFromJid(jid).substr(0, 8).toLowerCase(); // But if this doesn't have the required format we just generate a new
    // random nickname.

    const re = /[0-9a-f]{8}/g;

    if (!re.test(mucNickname)) {
      mucNickname = _modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_36___default.a.randomHexString(8).toLowerCase();
    }
  }

  return mucNickname;
};
/**
 * Initializes the conference object properties
 * @param options {object}
 * @param options.connection {JitsiConnection} overrides this.connection
 */


JitsiConference.prototype._init = function (options = {}) {
  // Override connection and xmpp properties (Useful if the connection
  // reloaded)
  if (options.connection) {
    this.connection = options.connection;
    this.xmpp = this.connection.xmpp; // Setup XMPP events only if we have new connection object.

    this.eventManager.setupXMPPListeners();
  }

  const {
    config
  } = this.options;
  this._statsCurrentId = config.statisticsId ? config.statisticsId : _modules_settings_Settings__WEBPACK_IMPORTED_MODULE_29__["default"].callStatsUserName;
  this.room = this.xmpp.createRoom(this.options.name, _objectSpread({}, config, {
    statsId: this._statsCurrentId
  }), JitsiConference.resourceCreator); // Connection interrupted/restored listeners

  this._onIceConnectionInterrupted = this._onIceConnectionInterrupted.bind(this);
  this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["CONNECTION_INTERRUPTED"], this._onIceConnectionInterrupted);
  this._onIceConnectionRestored = this._onIceConnectionRestored.bind(this);
  this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["CONNECTION_RESTORED"], this._onIceConnectionRestored);
  this._onIceConnectionEstablished = this._onIceConnectionEstablished.bind(this);
  this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["CONNECTION_ESTABLISHED"], this._onIceConnectionEstablished);
  this._updateProperties = this._updateProperties.bind(this);
  this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["CONFERENCE_PROPERTIES_CHANGED"], this._updateProperties);
  this._sendConferenceJoinAnalyticsEvent = this._sendConferenceJoinAnalyticsEvent.bind(this);
  this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["MEETING_ID_SET"], this._sendConferenceJoinAnalyticsEvent);
  this.rttMonitor = new _modules_rttmonitor_rttmonitor__WEBPACK_IMPORTED_MODULE_28__["default"](config.rttMonitor || {});
  this.e2eping = new _modules_e2eping_e2eping__WEBPACK_IMPORTED_MODULE_25__["default"](this, config, (message, to) => {
    try {
      this.sendMessage(message, to, true
      /* sendThroughVideobridge */
      );
    } catch (error) {
      logger.warn('Failed to send E2E ping request or response.', error && error.msg);
    }
  });

  if (!this.rtc) {
    this.rtc = new _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_13__["default"](this, options);
    this.eventManager.setupRTCListeners();
  }

  this.participantConnectionStatus = new _modules_connectivity_ParticipantConnectionStatus__WEBPACK_IMPORTED_MODULE_23__["default"](this.rtc, this, {
    // Both these options are not public API, leaving it here only
    // as an entry point through config for tuning up purposes.
    // Default values should be adjusted as soon as optimal values
    // are discovered.
    rtcMuteTimeout: config._peerConnStatusRtcMuteTimeout,
    outOfLastNTimeout: config._peerConnStatusOutOfLastNTimeout
  });
  this.participantConnectionStatus.init();

  if (!this.statistics) {
    this.statistics = new _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"](this.xmpp, {
      aliasName: this._statsCurrentId,
      userName: config.statisticsDisplayName ? config.statisticsDisplayName : this.myUserId(),
      callStatsConfIDNamespace: this.connection.options.hosts.domain,
      confID: config.confID || `${this.connection.options.hosts.domain}/${this.options.name}`,
      customScriptUrl: config.callStatsCustomScriptUrl,
      callStatsID: config.callStatsID,
      callStatsSecret: config.callStatsSecret,
      callStatsApplicationLogsDisabled: config.callStatsApplicationLogsDisabled,
      roomName: this.options.name,
      applicationName: config.applicationName,
      getWiFiStatsMethod: config.getWiFiStatsMethod
    });
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].analytics.addPermanentProperties({
      'callstats_name': this._statsCurrentId
    });
  }

  this.eventManager.setupChatRoomListeners(); // Always add listeners because on reload we are executing leave and the
  // listeners are removed from statistics module.

  this.eventManager.setupStatisticsListeners();

  if (config.enableTalkWhileMuted) {
    // If VAD processor factory method is provided uses VAD based detection, otherwise fallback to audio level
    // based detection.
    if (config.createVADProcessor) {
      logger.info('Using VAD detection for generating talk while muted events');

      if (!this._audioAnalyser) {
        this._audioAnalyser = new _modules_detection_VADAudioAnalyser__WEBPACK_IMPORTED_MODULE_17__["default"](this, config.createVADProcessor);
      }

      const vadTalkMutedDetection = new _modules_detection_VADTalkMutedDetection__WEBPACK_IMPORTED_MODULE_15__["default"]();
      vadTalkMutedDetection.on(_modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_18__["VAD_TALK_WHILE_MUTED"], () => this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TALK_WHILE_MUTED"]));

      this._audioAnalyser.addVADDetectionService(vadTalkMutedDetection);
    } else {
      logger.info('Using audio level based detection for generating talk while muted events');
      this._talkWhileMutedDetection = new _modules_detection_TalkMutedDetection__WEBPACK_IMPORTED_MODULE_14__["default"](this, () => this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TALK_WHILE_MUTED"]));
    }
  }

  if (config.enableNoisyMicDetection) {
    if (config.createVADProcessor) {
      if (!this._audioAnalyser) {
        this._audioAnalyser = new _modules_detection_VADAudioAnalyser__WEBPACK_IMPORTED_MODULE_17__["default"](this, config.createVADProcessor);
      }

      const vadNoiseDetection = new _modules_detection_VADNoiseDetection__WEBPACK_IMPORTED_MODULE_16__["default"]();
      vadNoiseDetection.on(_modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_18__["VAD_NOISY_DEVICE"], () => this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["NOISY_MIC"]));

      this._audioAnalyser.addVADDetectionService(vadNoiseDetection);
    } else {
      logger.warn('No VAD Processor was provided. Noisy microphone detection service was not initialized!');
    }
  } // Generates events based on no audio input detector.


  if (config.enableNoAudioDetection) {
    this._noAudioSignalDetection = new _modules_detection_NoAudioSignalDetection__WEBPACK_IMPORTED_MODULE_19__["default"](this);

    this._noAudioSignalDetection.on(_modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_18__["NO_AUDIO_INPUT"], () => {
      this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["NO_AUDIO_INPUT"]);
    });

    this._noAudioSignalDetection.on(_modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_18__["AUDIO_INPUT_STATE_CHANGE"], hasAudioSignal => {
      this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["AUDIO_INPUT_STATE_CHANGE"], hasAudioSignal);
    });
  }

  if ('channelLastN' in config) {
    this.setLastN(config.channelLastN);
  }
  /**
   * Emits {@link JitsiConferenceEvents.JVB121_STATUS}.
   * @type {Jvb121EventGenerator}
   */


  this.jvb121Status = new _modules_event_Jvb121EventGenerator__WEBPACK_IMPORTED_MODULE_26__["default"](this); // creates dominant speaker detection that works only in p2p mode

  this.p2pDominantSpeakerDetection = new _modules_detection_P2PDominantSpeakerDetection__WEBPACK_IMPORTED_MODULE_12__["default"](this);

  if (config && config.deploymentInfo && config.deploymentInfo.userRegion) {
    this.setLocalParticipantProperty('region', config.deploymentInfo.userRegion);
  }
};
/**
 * Joins the conference.
 * @param password {string} the password
 */


JitsiConference.prototype.join = function (password) {
  if (this.room) {
    this.room.join(password).then(() => this._maybeSetSITimeout());
  }
};
/**
 * Authenticates and upgrades the role of the local participant/user.
 *
 * @returns {Object} A <tt>thenable</tt> which (1) settles when the process of
 * authenticating and upgrading the role of the local participant/user finishes
 * and (2) has a <tt>cancel</tt> method that allows the caller to interrupt the
 * process.
 */


JitsiConference.prototype.authenticateAndUpgradeRole = function (options) {
  return _authenticateAndUpgradeRole__WEBPACK_IMPORTED_MODULE_11__["default"].call(this, _objectSpread({}, options, {
    onCreateResource: JitsiConference.resourceCreator
  }));
};
/**
 * Check if joined to the conference.
 */


JitsiConference.prototype.isJoined = function () {
  return this.room && this.room.joined;
};
/**
 * Tells whether or not the P2P mode is enabled in the configuration.
 * @return {boolean}
 */


JitsiConference.prototype.isP2PEnabled = function () {
  return Boolean(this.options.config.p2p && this.options.config.p2p.enabled) // FIXME: remove once we have a default config template. -saghul
  || typeof this.options.config.p2p === 'undefined';
};
/**
 * When in P2P test mode, the conference will not automatically switch to P2P
 * when there 2 participants.
 * @return {boolean}
 */


JitsiConference.prototype.isP2PTestModeEnabled = function () {
  return Boolean(this.options.config.testing && this.options.config.testing.p2pTestMode);
};
/**
 * Leaves the conference.
 * @returns {Promise}
 */


JitsiConference.prototype.leave = function () {
  if (this.participantConnectionStatus) {
    this.participantConnectionStatus.dispose();
    this.participantConnectionStatus = null;
  }

  if (this.avgRtpStatsReporter) {
    this.avgRtpStatsReporter.dispose();
    this.avgRtpStatsReporter = null;
  }

  if (this._audioOutputProblemDetector) {
    this._audioOutputProblemDetector.dispose();

    this._audioOutputProblemDetector = null;
  }

  if (this.rttMonitor) {
    this.rttMonitor.stop();
    this.rttMonitor = null;
  }

  if (this.e2eping) {
    this.e2eping.stop();
    this.e2eping = null;
  }

  this.getLocalTracks().forEach(track => this.onLocalTrackRemoved(track));
  this.rtc.closeBridgeChannel();

  if (this.statistics) {
    this.statistics.dispose();
  }

  this._delayedIceFailed && this._delayedIceFailed.cancel(); // Close both JVb and P2P JingleSessions

  if (this.jvbJingleSession) {
    this.jvbJingleSession.close();
    this.jvbJingleSession = null;
  }

  if (this.p2pJingleSession) {
    this.p2pJingleSession.close();
    this.p2pJingleSession = null;
  } // leave the conference


  if (this.room) {
    const room = this.room; // Unregister connection state listeners

    room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["CONNECTION_INTERRUPTED"], this._onIceConnectionInterrupted);
    room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["CONNECTION_RESTORED"], this._onIceConnectionRestored);
    room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["CONNECTION_ESTABLISHED"], this._onIceConnectionEstablished);
    room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["CONFERENCE_PROPERTIES_CHANGED"], this._updateProperties);
    room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_45__["MEETING_ID_SET"], this._sendConferenceJoinAnalyticsEvent);
    this.eventManager.removeXMPPListeners();
    this.room = null;
    return room.leave().then(() => {
      if (this.rtc) {
        this.rtc.destroy();
      }
    }).catch(error => {
      // remove all participants because currently the conference
      // won't be usable anyway. This is done on success automatically
      // by the ChatRoom instance.
      this.getParticipants().forEach(participant => this.onMemberLeft(participant.getJid()));
      throw error;
    });
  } // If this.room == null we are calling second time leave().


  return Promise.reject(new Error('The conference is has been already left'));
};
/**
 * Returns name of this conference.
 */


JitsiConference.prototype.getName = function () {
  return this.options.name;
};
/**
 * Returns the {@link JitsiConnection} used by this this conference.
 */


JitsiConference.prototype.getConnection = function () {
  return this.connection;
};
/**
 * Check if authentication is enabled for this conference.
 */


JitsiConference.prototype.isAuthEnabled = function () {
  return this.authEnabled;
};
/**
 * Check if user is logged in.
 */


JitsiConference.prototype.isLoggedIn = function () {
  return Boolean(this.authIdentity);
};
/**
 * Get authorized login.
 */


JitsiConference.prototype.getAuthLogin = function () {
  return this.authIdentity;
};
/**
 * Check if external authentication is enabled for this conference.
 */


JitsiConference.prototype.isExternalAuthEnabled = function () {
  return this.room && this.room.moderator.isExternalAuthEnabled();
};
/**
 * Get url for external authentication.
 * @param {boolean} [urlForPopup] if true then return url for login popup,
 *                                else url of login page.
 * @returns {Promise}
 */


JitsiConference.prototype.getExternalAuthUrl = function (urlForPopup) {
  return new Promise((resolve, reject) => {
    if (!this.isExternalAuthEnabled()) {
      reject();
      return;
    }

    if (urlForPopup) {
      this.room.moderator.getPopupLoginUrl(resolve, reject);
    } else {
      this.room.moderator.getLoginUrl(resolve, reject);
    }
  });
};
/**
 * Returns the local tracks of the given media type, or all local tracks if no
 * specific type is given.
 * @param {MediaType} [mediaType] Optional media type (audio or video).
 */


JitsiConference.prototype.getLocalTracks = function (mediaType) {
  let tracks = [];

  if (this.rtc) {
    tracks = this.rtc.getLocalTracks(mediaType);
  }

  return tracks;
};
/**
 * Obtains local audio track.
 * @return {JitsiLocalTrack|null}
 */


JitsiConference.prototype.getLocalAudioTrack = function () {
  return this.rtc ? this.rtc.getLocalAudioTrack() : null;
};
/**
 * Obtains local video track.
 * @return {JitsiLocalTrack|null}
 */


JitsiConference.prototype.getLocalVideoTrack = function () {
  return this.rtc ? this.rtc.getLocalVideoTrack() : null;
};
/**
 * Attaches a handler for events(For example - "participant joined".) in the
 * conference. All possible event are defined in JitsiConferenceEvents.
 * @param eventId the event ID.
 * @param handler handler for the event.
 *
 * Note: consider adding eventing functionality by extending an EventEmitter
 * impl, instead of rolling ourselves
 */


JitsiConference.prototype.on = function (eventId, handler) {
  if (this.eventEmitter) {
    this.eventEmitter.on(eventId, handler);
  }
};
/**
 * Removes event listener
 * @param eventId the event ID.
 * @param [handler] optional, the specific handler to unbind
 *
 * Note: consider adding eventing functionality by extending an EventEmitter
 * impl, instead of rolling ourselves
 */


JitsiConference.prototype.off = function (eventId, handler) {
  if (this.eventEmitter) {
    this.eventEmitter.removeListener(eventId, handler);
  }
}; // Common aliases for event emitter


JitsiConference.prototype.addEventListener = JitsiConference.prototype.on;
JitsiConference.prototype.removeEventListener = JitsiConference.prototype.off;
/**
 * Receives notifications from other participants about commands / custom events
 * (sent by sendCommand or sendCommandOnce methods).
 * @param command {String} the name of the command
 * @param handler {Function} handler for the command
 */

JitsiConference.prototype.addCommandListener = function (command, handler) {
  if (this.room) {
    this.room.addPresenceListener(command, handler);
  }
};
/**
  * Removes command  listener
  * @param command {String} the name of the command
  * @param handler {Function} handler to remove for the command
  */


JitsiConference.prototype.removeCommandListener = function (command, handler) {
  if (this.room) {
    this.room.removePresenceListener(command, handler);
  }
};
/**
 * Sends text message to the other participants in the conference
 * @param message the text message.
 * @param elementName the element name to encapsulate the message.
 * @deprecated Use 'sendMessage' instead. TODO: this should be private.
 */


JitsiConference.prototype.sendTextMessage = function (message, elementName = 'body') {
  if (this.room) {
    const displayName = (this.room.getFromPresence('nick') || {}).value;
    this.room.sendMessage(message, elementName, displayName);
  }
};
/**
 * Send private text message to another participant of the conference
 * @param id the id of the participant to send a private message.
 * @param message the text message.
 * @param elementName the element name to encapsulate the message.
 * @deprecated Use 'sendMessage' instead. TODO: this should be private.
 */


JitsiConference.prototype.sendPrivateTextMessage = function (id, message, elementName = 'body') {
  if (this.room) {
    this.room.sendPrivateMessage(id, message, elementName);
  }
};
/**
 * Send presence command.
 * @param name {String} the name of the command.
 * @param values {Object} with keys and values that will be sent.
 **/


JitsiConference.prototype.sendCommand = function (name, values) {
  if (this.room) {
    this.room.addToPresence(name, values);
    this.room.sendPresence();
  } else {
    logger.warn('Not sending a command, room not initialized.');
  }
};
/**
 * Send presence command one time.
 * @param name {String} the name of the command.
 * @param values {Object} with keys and values that will be sent.
 **/


JitsiConference.prototype.sendCommandOnce = function (name, values) {
  this.sendCommand(name, values);
  this.removeCommand(name);
};
/**
 * Removes presence command.
 * @param name {String} the name of the command.
 **/


JitsiConference.prototype.removeCommand = function (name) {
  if (this.room) {
    this.room.removeFromPresence(name);
  }
};
/**
 * Sets the display name for this conference.
 * @param name the display name to set
 */


JitsiConference.prototype.setDisplayName = function (name) {
  if (this.room) {
    // remove previously set nickname
    this.room.removeFromPresence('nick');
    this.room.addToPresence('nick', {
      attributes: {
        xmlns: 'http://jabber.org/protocol/nick'
      },
      value: name
    });
    this.room.sendPresence();
  }
};
/**
 * Set new subject for this conference. (available only for moderator)
 * @param {string} subject new subject
 */


JitsiConference.prototype.setSubject = function (subject) {
  if (this.room && this.isModerator()) {
    this.room.setSubject(subject);
  }
};
/**
 * Get a transcriber object for all current participants in this conference
 * @return {Transcriber} the transcriber object
 */


JitsiConference.prototype.getTranscriber = function () {
  if (this.transcriber === undefined) {
    this.transcriber = new _modules_transcription_transcriber__WEBPACK_IMPORTED_MODULE_34___default.a(); // add all existing local audio tracks to the transcriber

    const localAudioTracks = this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_41__["AUDIO"]);

    for (const localAudio of localAudioTracks) {
      this.transcriber.addTrack(localAudio);
    } // and all remote audio tracks


    const remoteAudioTracks = this.rtc.getRemoteTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_41__["AUDIO"]);

    for (const remoteTrack of remoteAudioTracks) {
      this.transcriber.addTrack(remoteTrack);
    }
  }

  return this.transcriber;
};
/**
 * Returns the transcription status.
 *
 * @returns {String} "on" or "off".
 */


JitsiConference.prototype.getTranscriptionStatus = function () {
  return this.room.transcriptionStatus;
};
/**
 * Adds JitsiLocalTrack object to the conference.
 * @param track the JitsiLocalTrack object.
 * @returns {Promise<JitsiLocalTrack>}
 * @throws {Error} if the specified track is a video track and there is already
 * another video track in the conference.
 */


JitsiConference.prototype.addTrack = function (track) {
  if (track.isVideoTrack()) {
    // Ensure there's exactly 1 local video track in the conference.
    const localVideoTrack = this.rtc.getLocalVideoTrack();

    if (localVideoTrack) {
      // Don't be excessively harsh and severe if the API client happens
      // to attempt to add the same local video track twice.
      if (track === localVideoTrack) {
        return Promise.resolve(track);
      }

      return Promise.reject(new Error('cannot add second video track to the conference'));
    }
  }

  return this.replaceTrack(null, track);
};
/**
 * Fires TRACK_AUDIO_LEVEL_CHANGED change conference event (for local tracks).
 * @param {number} audioLevel the audio level
 * @param {TraceablePeerConnection} [tpc]
 */


JitsiConference.prototype._fireAudioLevelChangeEvent = function (audioLevel, tpc) {
  const activeTpc = this.getActivePeerConnection(); // There will be no TraceablePeerConnection if audio levels do not come from
  // a peerconnection. LocalStatsCollector.js measures audio levels using Web
  // Audio Analyser API and emits local audio levels events through
  // JitsiTrack.setAudioLevel, but does not provide TPC instance which is
  // optional.

  if (!tpc || activeTpc === tpc) {
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_AUDIO_LEVEL_CHANGED"], this.myUserId(), audioLevel);
  }
};
/**
 * Fires TRACK_MUTE_CHANGED change conference event.
 * @param track the JitsiTrack object related to the event.
 */


JitsiConference.prototype._fireMuteChangeEvent = function (track) {
  // check if track was muted by focus and now is unmuted by user
  if (this.isMutedByFocus && track.isAudioTrack() && !track.isMuted()) {
    this.isMutedByFocus = false; // unmute local user on server

    this.room.muteParticipant(this.room.myroomjid, false);
  }

  let actorParticipant;

  if (this.mutedByFocusActor) {
    const actorId = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(this.mutedByFocusActor);
    actorParticipant = this.participants[actorId];
  }

  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_MUTE_CHANGED"], track, actorParticipant);
};
/**
 * Clear JitsiLocalTrack properties and listeners.
 * @param track the JitsiLocalTrack object.
 */


JitsiConference.prototype.onLocalTrackRemoved = function (track) {
  track._setConference(null);

  this.rtc.removeLocalTrack(track);
  track.removeEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_10__["TRACK_MUTE_CHANGED"], track.muteHandler);
  track.removeEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_10__["TRACK_AUDIO_LEVEL_CHANGED"], track.audioLevelHandler); // send event for stopping screen sharing
  // FIXME: we assume we have only one screen sharing track
  // if we change this we need to fix this check

  if (track.isVideoTrack() && track.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_43___default.a.DESKTOP) {
    this.statistics.sendScreenSharingEvent(false);
  }

  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_REMOVED"], track);
};
/**
 * Removes JitsiLocalTrack from the conference and performs
 * a new offer/answer cycle.
 * @param {JitsiLocalTrack} track
 * @returns {Promise}
 */


JitsiConference.prototype.removeTrack = function (track) {
  return this.replaceTrack(track, null);
};
/**
 * Replaces oldTrack with newTrack and performs a single offer/answer
 *  cycle after both operations are done.  Either oldTrack or newTrack
 *  can be null; replacing a valid 'oldTrack' with a null 'newTrack'
 *  effectively just removes 'oldTrack'
 * @param {JitsiLocalTrack} oldTrack the current stream in use to be replaced
 * @param {JitsiLocalTrack} newTrack the new stream to use
 * @returns {Promise} resolves when the replacement is finished
 */


JitsiConference.prototype.replaceTrack = function (oldTrack, newTrack) {
  // First do the removal of the oldTrack at the JitsiConference level
  if (oldTrack) {
    if (oldTrack.disposed) {
      return Promise.reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_8__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_9__["TRACK_IS_DISPOSED"]));
    }
  }

  if (newTrack) {
    if (newTrack.disposed) {
      return Promise.reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_8__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_9__["TRACK_IS_DISPOSED"]));
    }
  } // Now replace the stream at the lower levels


  return this._doReplaceTrack(oldTrack, newTrack).then(() => {
    if (oldTrack) {
      this.onLocalTrackRemoved(oldTrack);
    }

    if (newTrack) {
      // Now handle the addition of the newTrack at the
      // JitsiConference level
      this._setupNewTrack(newTrack);
    }

    return Promise.resolve();
  }, error => Promise.reject(new Error(error)));
};
/**
 * Replaces the tracks at the lower level by going through the Jingle session
 * and WebRTC peer connection. The method will resolve immediately if there is
 * currently no JingleSession started.
 * @param {JitsiLocalTrack|null} oldTrack the track to be removed during
 * the process or <tt>null</t> if the method should act as "add track"
 * @param {JitsiLocalTrack|null} newTrack the new track to be added or
 * <tt>null</tt> if the method should act as "remove track"
 * @return {Promise} resolved when the process is done or rejected with a string
 * which describes the error.
 * @private
 */


JitsiConference.prototype._doReplaceTrack = function (oldTrack, newTrack) {
  const replaceTrackPromises = [];

  if (this.jvbJingleSession) {
    replaceTrackPromises.push(this.jvbJingleSession.replaceTrack(oldTrack, newTrack));
  } else {
    logger.info('_doReplaceTrack - no JVB JingleSession');
  }

  if (this.p2pJingleSession) {
    replaceTrackPromises.push(this.p2pJingleSession.replaceTrack(oldTrack, newTrack));
  } else {
    logger.info('_doReplaceTrack - no P2P JingleSession');
  }

  return Promise.all(replaceTrackPromises);
};
/**
 * Operations related to creating a new track
 * @param {JitsiLocalTrack} newTrack the new track being created
 */


JitsiConference.prototype._setupNewTrack = function (newTrack) {
  if (newTrack.isAudioTrack() || newTrack.isVideoTrack() && newTrack.videoType !== _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_43___default.a.DESKTOP) {
    // Report active device to statistics
    const devices = _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_13__["default"].getCurrentlyAvailableMediaDevices();
    const device = devices.find(d => d.kind === `${newTrack.getTrack().kind}input` && d.label === newTrack.getTrack().label);

    if (device) {
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendActiveDeviceListEvent(_modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_13__["default"].getEventDataForActiveDevice(device));
    }
  }

  if (newTrack.isVideoTrack()) {
    this.removeCommand('videoType');
    this.sendCommand('videoType', {
      value: newTrack.videoType,
      attributes: {
        xmlns: 'http://jitsi.org/jitmeet/video'
      }
    });
  }

  this.rtc.addLocalTrack(newTrack); // ensure that we're sharing proper "is muted" state

  if (newTrack.isAudioTrack()) {
    this.room.setAudioMute(newTrack.isMuted());
  } else {
    this.room.setVideoMute(newTrack.isMuted());
  }

  newTrack.muteHandler = this._fireMuteChangeEvent.bind(this, newTrack);
  newTrack.audioLevelHandler = this._fireAudioLevelChangeEvent.bind(this);
  newTrack.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_10__["TRACK_MUTE_CHANGED"], newTrack.muteHandler);
  newTrack.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_10__["TRACK_AUDIO_LEVEL_CHANGED"], newTrack.audioLevelHandler);

  newTrack._setConference(this);

  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_ADDED"], newTrack);
};
/**
 * Method called by the {@link JitsiLocalTrack} (a video one) in order to add
 * back the underlying WebRTC MediaStream to the PeerConnection (which has
 * removed on video mute).
 * @param {JitsiLocalTrack} track the local track that will be added as part of
 * the unmute operation.
 * @return {Promise} resolved when the process is done or rejected with a string
 * which describes the error.
 */


JitsiConference.prototype._addLocalTrackAsUnmute = function (track) {
  const addAsUnmutePromises = [];

  if (this.jvbJingleSession) {
    addAsUnmutePromises.push(this.jvbJingleSession.addTrackAsUnmute(track));
  } else {
    logger.info('Add local MediaStream as unmute -' + ' no JVB Jingle session started yet');
  }

  if (this.p2pJingleSession) {
    addAsUnmutePromises.push(this.p2pJingleSession.addTrackAsUnmute(track));
  } else {
    logger.info('Add local MediaStream as unmute -' + ' no P2P Jingle session started yet');
  }

  return Promise.all(addAsUnmutePromises);
};
/**
 * Method called by the {@link JitsiLocalTrack} (a video one) in order to remove
 * the underlying WebRTC MediaStream from the PeerConnection. The purpose of
 * that is to stop sending any data and turn off the HW camera device.
 * @param {JitsiLocalTrack} track the local track that will be removed.
 * @return {Promise}
 */


JitsiConference.prototype._removeLocalTrackAsMute = function (track) {
  const removeAsMutePromises = [];

  if (this.jvbJingleSession) {
    removeAsMutePromises.push(this.jvbJingleSession.removeTrackAsMute(track));
  } else {
    logger.info('Remove local MediaStream - no JVB JingleSession started yet');
  }

  if (this.p2pJingleSession) {
    removeAsMutePromises.push(this.p2pJingleSession.removeTrackAsMute(track));
  } else {
    logger.info('Remove local MediaStream - no P2P JingleSession started yet');
  }

  return Promise.all(removeAsMutePromises);
};
/**
 * Get role of the local user.
 * @returns {string} user role: 'moderator' or 'none'
 */


JitsiConference.prototype.getRole = function () {
  return this.room.role;
};
/**
 * Returns whether or not the current conference has been joined as a hidden
 * user.
 *
 * @returns {boolean|null} True if hidden, false otherwise. Will return null if
 * no connection is active.
 */


JitsiConference.prototype.isHidden = function () {
  if (!this.connection) {
    return null;
  }

  return strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getDomainFromJid(this.connection.getJid()) === this.options.config.hiddenDomain;
};
/**
 * Check if local user is moderator.
 * @returns {boolean|null} true if local user is moderator, false otherwise. If
 * we're no longer in the conference room then <tt>null</tt> is returned.
 */


JitsiConference.prototype.isModerator = function () {
  return this.room ? this.room.isModerator() : null;
};
/**
 * Set password for the room.
 * @param {string} password new password for the room.
 * @returns {Promise}
 */


JitsiConference.prototype.lock = function (password) {
  if (!this.isModerator()) {
    return Promise.reject(new Error('You are not moderator.'));
  }

  return new Promise((resolve, reject) => {
    this.room.lockRoom(password || '', () => resolve(), err => reject(err), () => reject(_JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_4__["PASSWORD_NOT_SUPPORTED"]));
  });
};
/**
 * Remove password from the room.
 * @returns {Promise}
 */


JitsiConference.prototype.unlock = function () {
  return this.lock();
};
/**
 * Elects the participant with the given id to be the selected participant in
 * order to receive higher video quality (if simulcast is enabled).
 * Or cache it if channel is not created and send it once channel is available.
 * @param participantId the identifier of the participant
 * @throws NetworkError or InvalidStateError or Error if the operation fails.
 * @returns {void}
 */


JitsiConference.prototype.selectParticipant = function (participantId) {
  this.selectParticipants([participantId]);
};
/*
 * Elects participants with given ids to be the selected participants in order
 * to receive higher video quality (if simulcast is enabled). The argument
 * should be an array of participant id strings or an empty array; an error will
 * be thrown if a non-array is passed in. The error is thrown as a layer of
 * protection against passing an invalid argument, as the error will happen in
 * the bridge and may not be visible in the client.
 *
 * @param {Array<strings>} participantIds - An array of identifiers for
 * participants.
 * @returns {void}
 */


JitsiConference.prototype.selectParticipants = function (participantIds) {
  if (!Array.isArray(participantIds)) {
    throw new Error('Invalid argument; participantIds must be an array.');
  }

  this.rtc.selectEndpoints(participantIds);
};
/**
 * Elects the participant with the given id to be the pinned participant in
 * order to always receive video for this participant (even when last n is
 * enabled).
 * @param participantId the identifier of the participant
 * @throws NetworkError or InvalidStateError or Error if the operation fails.
 */


JitsiConference.prototype.pinParticipant = function (participantId) {
  this.rtc.pinEndpoint(participantId);
};
/**
 * Obtains the current value for "lastN". See {@link setLastN} for more info.
 * @returns {number}
 */


JitsiConference.prototype.getLastN = function () {
  return this.rtc.getLastN();
};
/**
 * Selects a new value for "lastN". The requested amount of videos are going
 * to be delivered after the value is in effect. Set to -1 for unlimited or
 * all available videos.
 * @param lastN the new number of videos the user would like to receive.
 * @throws Error or RangeError if the given value is not a number or is smaller
 * than -1.
 */


JitsiConference.prototype.setLastN = function (lastN) {
  if (!Number.isInteger(lastN) && !Number.parseInt(lastN, 10)) {
    throw new Error(`Invalid value for lastN: ${lastN}`);
  }

  const n = Number(lastN);

  if (n < -1) {
    throw new RangeError('lastN cannot be smaller than -1');
  }

  this.rtc.setLastN(n); // If the P2P session is not fully established yet, we wait until it gets
  // established.

  if (this.p2pJingleSession) {
    const isVideoActive = n !== 0;
    this.p2pJingleSession.setMediaTransferActive(true, isVideoActive).catch(error => {
      logger.error(`Failed to adjust video transfer status (${isVideoActive})`, error);
    });
  }
};
/**
 * Checks if the participant given by participantId is currently included in
 * the last N.
 * @param {string} participantId the identifier of the participant we would
 * like to check.
 * @return {boolean} true if the participant with id is in the last N set or
 * if there's no last N set, false otherwise.
 * @deprecated this method should never be used to figure out the UI, but
 * {@link ParticipantConnectionStatus} should be used instead.
 */


JitsiConference.prototype.isInLastN = function (participantId) {
  return this.rtc.isInLastN(participantId);
};
/**
 * @return Array<JitsiParticipant> an array of all participants in this
 * conference.
 */


JitsiConference.prototype.getParticipants = function () {
  return Object.keys(this.participants).map(function (key) {
    return this.participants[key];
  }, this);
};
/**
 * Returns the number of participants in the conference, including the local
 * participant.
 * @param countHidden {boolean} Whether or not to include hidden participants
 * in the count. Default: false.
 **/


JitsiConference.prototype.getParticipantCount = function (countHidden = false) {
  let participants = this.getParticipants();

  if (!countHidden) {
    participants = participants.filter(p => !p.isHidden());
  } // Add one for the local participant.


  return participants.length + 1;
};
/**
 * @returns {JitsiParticipant} the participant in this conference with the
 * specified id (or undefined if there isn't one).
 * @param id the id of the participant.
 */


JitsiConference.prototype.getParticipantById = function (id) {
  return this.participants[id];
};
/**
 * Kick participant from this conference.
 * @param {string} id id of the participant to kick
 */


JitsiConference.prototype.kickParticipant = function (id) {
  const participant = this.getParticipantById(id);

  if (!participant) {
    return;
  }

  this.room.kick(participant.getJid());
};
/**
 * Maybe clears the timeout which emits {@link ACTION_JINGLE_SI_TIMEOUT}
 * analytics event.
 * @private
 */


JitsiConference.prototype._maybeClearSITimeout = function () {
  if (this._sessionInitiateTimeout && (this.jvbJingleSession || this.getParticipantCount() < 2)) {
    window.clearTimeout(this._sessionInitiateTimeout);
    this._sessionInitiateTimeout = null;
  }
};
/**
 * Sets a timeout which will emit {@link ACTION_JINGLE_SI_TIMEOUT} analytics
 * event.
 * @private
 */


JitsiConference.prototype._maybeSetSITimeout = function () {
  // Jicofo is supposed to invite if there are at least 2 participants
  if (!this.jvbJingleSession && this.getParticipantCount() >= 2 && !this._sessionInitiateTimeout) {
    this._sessionInitiateTimeout = window.setTimeout(() => {
      this._sessionInitiateTimeout = null;
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["createJingleEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["ACTION_JINGLE_SI_TIMEOUT"], {
        p2p: false,
        value: JINGLE_SI_TIMEOUT
      }));
    }, JINGLE_SI_TIMEOUT);
  }
};
/**
 * Mutes a participant.
 * @param {string} id The id of the participant to mute.
 */


JitsiConference.prototype.muteParticipant = function (id) {
  const participant = this.getParticipantById(id);

  if (!participant) {
    return;
  }

  this.room.muteParticipant(participant.getJid(), true);
};
/* eslint-disable max-params */

/**
 * Notifies this JitsiConference that a new member has joined its chat room.
 *
 * FIXME This should NOT be exposed!
 *
 * @param jid the jid of the participant in the MUC
 * @param nick the display name of the participant
 * @param role the role of the participant in the MUC
 * @param isHidden indicates if this is a hidden participant (system
 * participant for example a recorder).
 * @param statsID the participant statsID (optional)
 * @param status the initial status if any
 * @param identity the member identity, if any
 * @param botType the member botType, if any
 */


JitsiConference.prototype.onMemberJoined = function (jid, nick, role, isHidden, statsID, status, identity, botType) {
  const id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);

  if (id === 'focus' || this.myUserId() === id) {
    return;
  }

  const participant = new _JitsiParticipant__WEBPACK_IMPORTED_MODULE_7__["default"](jid, this, nick, isHidden, statsID, status, identity);
  participant._role = role;
  participant._botType = botType;
  this.participants[id] = participant;
  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["USER_JOINED"], id, participant);

  this._updateFeatures(participant);

  this._maybeStartOrStopP2P();

  this._maybeSetSITimeout();
};
/* eslint-enable max-params */

/**
 * Updates features for a participant.
 * @param {JitsiParticipant} participant - The participant to query for features.
 * @returns {void}
 * @private
 */


JitsiConference.prototype._updateFeatures = function (participant) {
  participant.getFeatures().then(features => {
    participant._supportsDTMF = features.has('urn:xmpp:jingle:dtmf:0');
    this.updateDTMFSupport();

    if (features.has('http://jitsi.org/protocol/jigasi')) {
      participant.setProperty('features_jigasi', true);
    }

    if (features.has('https://jitsi.org/meet/e2ee')) {
      participant.setProperty('features_e2ee', true);
    }
  }).catch(() => false);
};
/**
 * Get notified when member bot type had changed.
 * @param jid the member jid
 * @param botType the new botType value
 * @private
 */


JitsiConference.prototype._onMemberBotTypeChanged = function (jid, botType) {
  // find the participant and mark it as non bot, as the real one will join
  // in a moment
  const peers = this.getParticipants();
  const botParticipant = peers.find(p => p.getJid() === jid);

  if (botParticipant) {
    botParticipant._botType = botType;
    const id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["BOT_TYPE_CHANGED"], id, botType);
  } // if botType changed to undefined, botType was removed, in case of
  // poltergeist mode this is the moment when the poltergeist had exited and
  // the real participant had already replaced it.
  // In this case we can check and try p2p


  if (!botParticipant._botType) {
    this._maybeStartOrStopP2P();
  }
};

JitsiConference.prototype.onMemberLeft = function (jid) {
  const id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);

  if (id === 'focus' || this.myUserId() === id) {
    return;
  }

  const participant = this.participants[id];
  delete this.participants[id];
  const removedTracks = this.rtc.removeRemoteTracks(id);
  removedTracks.forEach(track => this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_REMOVED"], track)); // there can be no participant in case the member that left is focus

  if (participant) {
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["USER_LEFT"], id, participant);
  }

  this._maybeStartOrStopP2P(true
  /* triggered by user left event */
  );

  this._maybeClearSITimeout();
};
/**
 * Designates an event indicating that we were kicked from the XMPP MUC.
 * @param {boolean} isSelfPresence - whether it is for local participant
 * or another participant.
 * @param {string} actorId - the id of the participant who was initiator
 * of the kick.
 * @param {string?} kickedParticipantId - when it is not a kick for local participant,
 * this is the id of the participant which was kicked.
 */


JitsiConference.prototype.onMemberKicked = function (isSelfPresence, actorId, kickedParticipantId) {
  const actorParticipant = this.participants[actorId];

  if (isSelfPresence) {
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["KICKED"], actorParticipant);
    this.leave();
    return;
  }

  const kickedParticipant = this.participants[kickedParticipantId];
  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["PARTICIPANT_KICKED"], actorParticipant, kickedParticipant);
};
/**
 * Method called on local MUC role change.
 * @param {string} role the name of new user's role as defined by XMPP MUC.
 */


JitsiConference.prototype.onLocalRoleChanged = function (role) {
  // Emit role changed for local  JID
  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["USER_ROLE_CHANGED"], this.myUserId(), role);
};

JitsiConference.prototype.onUserRoleChanged = function (jid, role) {
  const id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);
  const participant = this.getParticipantById(id);

  if (!participant) {
    return;
  }

  participant._role = role;
  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["USER_ROLE_CHANGED"], id, role);
};

JitsiConference.prototype.onDisplayNameChanged = function (jid, displayName) {
  const id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);
  const participant = this.getParticipantById(id);

  if (!participant) {
    return;
  }

  if (participant._displayName === displayName) {
    return;
  }

  participant._displayName = displayName;
  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["DISPLAY_NAME_CHANGED"], id, displayName);
};
/**
 * Notifies this JitsiConference that a JitsiRemoteTrack was added into
 * the conference.
 *
 * @param {JitsiRemoteTrack} track the JitsiRemoteTrack which was added to this
 * JitsiConference
 */


JitsiConference.prototype.onRemoteTrackAdded = function (track) {
  if (track.isP2P && !this.isP2PActive()) {
    logger.info('Trying to add remote P2P track, when not in P2P - IGNORED');
    return;
  } else if (!track.isP2P && this.isP2PActive()) {
    logger.info('Trying to add remote JVB track, when in P2P - IGNORED');
    return;
  } // Setup E2EE handling, if supported.


  this._setupReceiverE2EEForTrack(track);

  const id = track.getParticipantId();
  const participant = this.getParticipantById(id);

  if (!participant) {
    logger.error(`No participant found for id: ${id}`);
    return;
  } // Add track to JitsiParticipant.


  participant._tracks.push(track);

  if (this.transcriber) {
    this.transcriber.addTrack(track);
  }

  const emitter = this.eventEmitter;
  track.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_10__["TRACK_MUTE_CHANGED"], () => emitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_MUTE_CHANGED"], track));
  track.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_10__["TRACK_AUDIO_LEVEL_CHANGED"], (audioLevel, tpc) => {
    const activeTPC = this.getActivePeerConnection();

    if (activeTPC === tpc) {
      emitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_AUDIO_LEVEL_CHANGED"], id, audioLevel);
    }
  });
  emitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_ADDED"], track);
};
/**
 * Callback called by the Jingle plugin when 'session-answer' is received.
 * @param {JingleSessionPC} session the Jingle session for which an answer was
 * received.
 * @param {jQuery} answer a jQuery selector pointing to 'jingle' IQ element
 */
// eslint-disable-next-line no-unused-vars


JitsiConference.prototype.onCallAccepted = function (session, answer) {
  if (this.p2pJingleSession === session) {
    logger.info('P2P setAnswer'); // Setup E2EE.

    const localTracks = this.getLocalTracks();

    for (const track of localTracks) {
      this._setupSenderE2EEForTrack(session, track);
    }

    this.p2pJingleSession.setAnswer(answer);
  }
};
/**
 * Callback called by the Jingle plugin when 'transport-info' is received.
 * @param {JingleSessionPC} session the Jingle session for which the IQ was
 * received
 * @param {jQuery} transportInfo a jQuery selector pointing to 'jingle' IQ
 * element
 */
// eslint-disable-next-line no-unused-vars


JitsiConference.prototype.onTransportInfo = function (session, transportInfo) {
  if (this.p2pJingleSession === session) {
    logger.info('P2P addIceCandidates');
    this.p2pJingleSession.addIceCandidates(transportInfo);
  }
};
/**
 * Notifies this JitsiConference that a JitsiRemoteTrack was removed from
 * the conference.
 *
 * @param {JitsiRemoteTrack} removedTrack
 */


JitsiConference.prototype.onRemoteTrackRemoved = function (removedTrack) {
  this.getParticipants().forEach(participant => {
    const tracks = participant.getTracks();

    for (let i = 0; i < tracks.length; i++) {
      if (tracks[i] === removedTrack) {
        // Since the tracks have been compared and are
        // considered equal the result of splice can be ignored.
        participant._tracks.splice(i, 1);

        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_REMOVED"], removedTrack);

        if (this.transcriber) {
          this.transcriber.removeTrack(removedTrack);
        }

        break;
      }
    }
  }, this);
};
/**
 * Handles an incoming call event for the P2P jingle session.
 */


JitsiConference.prototype._onIncomingCallP2P = function (jingleSession, jingleOffer) {
  let rejectReason;

  if (!_modules_browser__WEBPACK_IMPORTED_MODULE_20__["default"].supportsP2P()) {
    rejectReason = {
      reason: 'unsupported-applications',
      reasonDescription: 'P2P not supported',
      errorMsg: 'This client does not support P2P connections'
    };
  } else if (!this.isP2PEnabled() && !this.isP2PTestModeEnabled()) {
    rejectReason = {
      reason: 'decline',
      reasonDescription: 'P2P disabled',
      errorMsg: 'P2P mode disabled in the configuration'
    };
  } else if (this.p2pJingleSession) {
    // Reject incoming P2P call (already in progress)
    rejectReason = {
      reason: 'busy',
      reasonDescription: 'P2P already in progress',
      errorMsg: 'Duplicated P2P "session-initiate"'
    };
  } else if (!this._shouldBeInP2PMode()) {
    rejectReason = {
      reason: 'decline',
      reasonDescription: 'P2P requirements not met',
      errorMsg: 'Received P2P "session-initiate" when should not be in P2P mode'
    };
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["createJingleEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["ACTION_P2P_DECLINED"]));
  }

  if (rejectReason) {
    this._rejectIncomingCall(jingleSession, rejectReason);
  } else {
    this._acceptP2PIncomingCall(jingleSession, jingleOffer);
  }
};
/**
 * Handles an incoming call event.
 */


JitsiConference.prototype.onIncomingCall = function (jingleSession, jingleOffer, now) {
  // Handle incoming P2P call
  if (jingleSession.isP2P) {
    this._onIncomingCallP2P(jingleSession, jingleOffer);
  } else {
    if (!this.room.isFocus(jingleSession.remoteJid)) {
      const description = 'Rejecting session-initiate from non-focus.';

      this._rejectIncomingCall(jingleSession, {
        reason: 'security-error',
        reasonDescription: description,
        errorMsg: description
      });

      return;
    }

    this._acceptJvbIncomingCall(jingleSession, jingleOffer, now);
  }
};
/**
 * Accepts an incoming call event for the JVB jingle session.
 */


JitsiConference.prototype._acceptJvbIncomingCall = function (jingleSession, jingleOffer, now) {
  // Accept incoming call
  this.jvbJingleSession = jingleSession;
  this.room.connectionTimes['session.initiate'] = now;

  this._sendConferenceJoinAnalyticsEvent();

  if (this.wasStopped) {
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalyticsAndLog(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["createJingleEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["ACTION_JINGLE_RESTART"], {
      p2p: false
    }));
  }

  const serverRegion = $(jingleOffer).find('>bridge-session[xmlns="http://jitsi.org/protocol/focus"]').attr('region');
  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["SERVER_REGION_CHANGED"], serverRegion);

  this._maybeClearSITimeout();

  _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["createJingleEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["ACTION_JINGLE_SI_RECEIVED"], {
    p2p: false,
    value: now
  }));

  try {
    jingleSession.initialize(this.room, this.rtc, this.options.config);
  } catch (error) {
    _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_35___default.a.callErrorHandler(error);
  } // Open a channel with the videobridge.


  this._setBridgeChannel(jingleOffer, jingleSession.peerconnection); // Add local tracks to the session


  const localTracks = this.getLocalTracks();

  try {
    jingleSession.acceptOffer(jingleOffer, () => {
      // If for any reason invite for the JVB session arrived after
      // the P2P has been established already the media transfer needs
      // to be turned off here.
      if (this.isP2PActive() && this.jvbJingleSession) {
        this._suspendMediaTransferForJvbConnection();
      } // Setup E2EE.


      for (const track of localTracks) {
        this._setupSenderE2EEForTrack(jingleSession, track);
      }
    }, error => {
      _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_35___default.a.callErrorHandler(error);
      logger.error('Failed to accept incoming Jingle session', error);
    }, localTracks); // Start callstats as soon as peerconnection is initialized,
    // do not wait for XMPPEvents.PEERCONNECTION_READY, as it may never
    // happen in case if user doesn't have or denied permission to
    // both camera and microphone.

    logger.info('Starting CallStats for JVB connection...');
    this.statistics.startCallStats(this.jvbJingleSession.peerconnection, 'jitsi'
    /* Remote user ID for JVB is 'jitsi' */
    );
    this.statistics.startRemoteStats(this.jvbJingleSession.peerconnection);
  } catch (e) {
    _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_35___default.a.callErrorHandler(e);
    logger.error(e);
  }
};
/**
 * Sets the BridgeChannel.
 *
 * @param {jQuery} offerIq a jQuery selector pointing to the jingle element of
 * the offer IQ which may carry the WebSocket URL for the 'websocket'
 * BridgeChannel mode.
 * @param {TraceablePeerConnection} pc the peer connection which will be used
 * to listen for new WebRTC Data Channels (in the 'datachannel' mode).
 */


JitsiConference.prototype._setBridgeChannel = function (offerIq, pc) {
  let wsUrl = null;
  const webSocket = $(offerIq).find('>content>transport>web-socket').first();

  if (webSocket.length === 1) {
    wsUrl = webSocket[0].getAttribute('url');
  }

  let bridgeChannelType;

  switch (this.options.config.openBridgeChannel) {
    case 'datachannel':
    case true:
    case undefined:
      bridgeChannelType = 'datachannel';
      break;

    case 'websocket':
      bridgeChannelType = 'websocket';
      break;
  }

  if (bridgeChannelType === 'datachannel') {
    this.rtc.initializeBridgeChannel(pc, null);
  } else if (bridgeChannelType === 'websocket' && wsUrl) {
    this.rtc.initializeBridgeChannel(null, wsUrl);
  }
};
/**
 * Rejects incoming Jingle call.
 * @param {JingleSessionPC} jingleSession the session instance to be rejected.
 * @param {object} [options]
 * @param {string} options.reason the name of the reason element as defined
 * by Jingle
 * @param {string} options.reasonDescription the reason description which will
 * be included in Jingle 'session-terminate' message.
 * @param {string} options.errorMsg an error message to be logged on global
 * error handler
 * @private
 */


JitsiConference.prototype._rejectIncomingCall = function (jingleSession, options) {
  if (options && options.errorMsg) {
    _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_35___default.a.callErrorHandler(new Error(options.errorMsg));
  } // Terminate the jingle session with a reason


  jingleSession.terminate(null
  /* success callback => we don't care */
  , error => {
    logger.warn('An error occurred while trying to terminate' + ' invalid Jingle session', error);
  }, {
    reason: options && options.reason,
    reasonDescription: options && options.reasonDescription,
    sendSessionTerminate: true
  });
};
/**
 * Handles the call ended event.
 * XXX is this due to the remote side terminating the Jingle session?
 *
 * @param {JingleSessionPC} jingleSession the jingle session which has been
 * terminated.
 * @param {String} reasonCondition the Jingle reason condition.
 * @param {String|null} reasonText human readable reason text which may provide
 * more details about why the call has been terminated.
 */


JitsiConference.prototype.onCallEnded = function (jingleSession, reasonCondition, reasonText) {
  logger.info(`Call ended: ${reasonCondition} - ${reasonText} P2P ?${jingleSession.isP2P}`);

  if (jingleSession === this.jvbJingleSession) {
    this.wasStopped = true;
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["createJingleEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["ACTION_JINGLE_TERMINATE"], {
      p2p: false
    })); // Stop the stats

    if (this.statistics) {
      this.statistics.stopRemoteStats(this.jvbJingleSession.peerconnection);
      logger.info('Stopping JVB CallStats');
      this.statistics.stopCallStats(this.jvbJingleSession.peerconnection);
    } // Current JVB JingleSession is no longer valid, so set it to null


    this.jvbJingleSession = null; // Let the RTC service do any cleanups

    this.rtc.onCallEnded();
  } else if (jingleSession === this.p2pJingleSession) {
    // It's the responder who decides to enforce JVB mode, so that both
    // initiator and responder are aware if it was intentional.
    if (reasonCondition === 'decline' && reasonText === 'force JVB121') {
      logger.info('In forced JVB 121 mode...');
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].analytics.addPermanentProperties({
        forceJvb121: true
      });
    } else if (reasonCondition === 'connectivity-error' && reasonText === 'ICE FAILED') {
      // It can happen that the other peer detects ICE failed and
      // terminates the session, before we get the event on our side.
      // But we are able to parse the reason and mark it here.
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].analytics.addPermanentProperties({
        p2pFailed: true
      });
    }

    this._stopP2PSession();
  } else {
    logger.error('Received onCallEnded for invalid session', jingleSession.sid, jingleSession.remoteJid, reasonCondition, reasonText);
  }
};
/**
 * Handles the suspend detected event. Leaves the room and fires suspended.
 * @param {JingleSessionPC} jingleSession
 */


JitsiConference.prototype.onSuspendDetected = function (jingleSession) {
  if (!jingleSession.isP2P) {
    this.leave();
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["SUSPEND_DETECTED"]);
  }
};

JitsiConference.prototype.updateDTMFSupport = function () {
  let somebodySupportsDTMF = false;
  const participants = this.getParticipants(); // check if at least 1 participant supports DTMF

  for (let i = 0; i < participants.length; i += 1) {
    if (participants[i].supportsDTMF()) {
      somebodySupportsDTMF = true;
      break;
    }
  }

  if (somebodySupportsDTMF !== this.somebodySupportsDTMF) {
    this.somebodySupportsDTMF = somebodySupportsDTMF;
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["DTMF_SUPPORT_CHANGED"], somebodySupportsDTMF);
  }
};
/**
 * Allows to check if there is at least one user in the conference
 * that supports DTMF.
 * @returns {boolean} true if somebody supports DTMF, false otherwise
 */


JitsiConference.prototype.isDTMFSupported = function () {
  return this.somebodySupportsDTMF;
};
/**
 * Returns the local user's ID
 * @return {string} local user's ID
 */


JitsiConference.prototype.myUserId = function () {
  return this.room && this.room.myroomjid ? strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(this.room.myroomjid) : null;
};

JitsiConference.prototype.sendTones = function (tones, duration, pause) {
  const peerConnection = this.getActivePeerConnection();

  if (peerConnection) {
    peerConnection.sendTones(tones, duration, pause);
  } else {
    logger.warn('cannot sendTones: no peer connection');
  }
};
/**
 * Starts recording the current conference.
 *
 * @param {Object} options - Configuration for the recording. See
 * {@link Chatroom#startRecording} for more info.
 * @returns {Promise} See {@link Chatroom#startRecording} for more info.
 */


JitsiConference.prototype.startRecording = function (options) {
  if (this.room) {
    return this.recordingManager.startRecording(options);
  }

  return Promise.reject(new Error('The conference is not created yet!'));
};
/**
 * Stop a recording session.
 *
 * @param {string} sessionID - The ID of the recording session that
 * should be stopped.
 * @returns {Promise} See {@link Chatroom#stopRecording} for more info.
 */


JitsiConference.prototype.stopRecording = function (sessionID) {
  if (this.room) {
    return this.recordingManager.stopRecording(sessionID);
  }

  return Promise.reject(new Error('The conference is not created yet!'));
};
/**
 * Returns true if the SIP calls are supported and false otherwise
 */


JitsiConference.prototype.isSIPCallingSupported = function () {
  if (this.room) {
    return this.room.isSIPCallingSupported();
  }

  return false;
};
/**
 * Dials a number.
 * @param number the number
 */


JitsiConference.prototype.dial = function (number) {
  if (this.room) {
    return this.room.dial(number);
  }

  return new Promise((resolve, reject) => {
    reject(new Error('The conference is not created yet!'));
  });
};
/**
 * Hangup an existing call
 */


JitsiConference.prototype.hangup = function () {
  if (this.room) {
    return this.room.hangup();
  }

  return new Promise((resolve, reject) => {
    reject(new Error('The conference is not created yet!'));
  });
};
/**
 * Starts the transcription service.
 */


JitsiConference.prototype.startTranscriber = function () {
  return this.dial('jitsi_meet_transcribe');
};
/**
 * Stops the transcription service.
 */


JitsiConference.prototype.stopTranscriber = JitsiConference.prototype.hangup;
/**
 * Returns the phone number for joining the conference.
 */

JitsiConference.prototype.getPhoneNumber = function () {
  if (this.room) {
    return this.room.getPhoneNumber();
  }

  return null;
};
/**
 * Returns the pin for joining the conference with phone.
 */


JitsiConference.prototype.getPhonePin = function () {
  if (this.room) {
    return this.room.getPhonePin();
  }

  return null;
};
/**
 * Returns the meeting unique ID if any.
 *
 * @returns {string|undefined}
 */


JitsiConference.prototype.getMeetingUniqueId = function () {
  if (this.room) {
    return this.room.getMeetingId();
  }
};
/**
 * Will return P2P or JVB <tt>TraceablePeerConnection</tt> depending on
 * which connection is currently active.
 *
 * @return {TraceablePeerConnection|null} null if there isn't any active
 * <tt>TraceablePeerConnection</tt> currently available.
 * @public (FIXME how to make package local ?)
 */


JitsiConference.prototype.getActivePeerConnection = function () {
  if (this.isP2PActive()) {
    return this.p2pJingleSession.peerconnection;
  }

  return this.jvbJingleSession ? this.jvbJingleSession.peerconnection : null;
};
/**
 * Returns the connection state for the current room. Its ice connection state
 * for its session.
 * NOTE that "completed" ICE state which can appear on the P2P connection will
 * be converted to "connected".
 * @return {string|null} ICE state name or <tt>null</tt> if there is no active
 * peer connection at this time.
 */


JitsiConference.prototype.getConnectionState = function () {
  const peerConnection = this.getActivePeerConnection();
  return peerConnection ? peerConnection.getConnectionState() : null;
};
/**
 * Make all new participants mute their audio/video on join.
 * @param policy {Object} object with 2 boolean properties for video and audio:
 * @param {boolean} audio if audio should be muted.
 * @param {boolean} video if video should be muted.
 */


JitsiConference.prototype.setStartMutedPolicy = function (policy) {
  if (!this.isModerator()) {
    return;
  }

  this.startMutedPolicy = policy;
  this.room.removeFromPresence('startmuted');
  this.room.addToPresence('startmuted', {
    attributes: {
      audio: policy.audio,
      video: policy.video,
      xmlns: 'http://jitsi.org/jitmeet/start-muted'
    }
  });
  this.room.sendPresence();
};
/**
 * Returns current start muted policy
 * @returns {Object} with 2 properties - audio and video.
 */


JitsiConference.prototype.getStartMutedPolicy = function () {
  return this.startMutedPolicy;
};
/**
 * Check if audio is muted on join.
 */


JitsiConference.prototype.isStartAudioMuted = function () {
  return this.startAudioMuted;
};
/**
 * Check if video is muted on join.
 */


JitsiConference.prototype.isStartVideoMuted = function () {
  return this.startVideoMuted;
};
/**
 * Get object with internal logs.
 */


JitsiConference.prototype.getLogs = function () {
  const data = this.xmpp.getJingleLog();
  const metadata = {};
  metadata.time = new Date();
  metadata.url = window.location.href;
  metadata.ua = navigator.userAgent;
  const log = this.xmpp.getXmppLog();

  if (log) {
    metadata.xmpp = log;
  }

  data.metadata = metadata;
  return data;
};
/**
 * Returns measured connectionTimes.
 */


JitsiConference.prototype.getConnectionTimes = function () {
  return this.room.connectionTimes;
};
/**
 * Sets a property for the local participant.
 */


JitsiConference.prototype.setLocalParticipantProperty = function (name, value) {
  this.sendCommand(`jitsi_participant_${name}`, {
    value
  });
};
/**
 *  Removes a property for the local participant and sends the updated presence.
 */


JitsiConference.prototype.removeLocalParticipantProperty = function (name) {
  this.removeCommand(`jitsi_participant_${name}`);
  this.room.sendPresence();
};
/**
 * Gets a local participant property.
 *
 * @return value of the local participant property if the tagName exists in the
 * list of properties, otherwise returns undefined.
 */


JitsiConference.prototype.getLocalParticipantProperty = function (name) {
  const property = this.room.presMap.nodes.find(prop => prop.tagName === `jitsi_participant_${name}`);
  return property ? property.value : undefined;
};
/**
 * Sends the given feedback through CallStats if enabled.
 *
 * @param overallFeedback an integer between 1 and 5 indicating the
 * user feedback
 * @param detailedFeedback detailed feedback from the user. Not yet used
 * @returns {Promise} Resolves if feedback is submitted successfully.
 */


JitsiConference.prototype.sendFeedback = function (overallFeedback, detailedFeedback) {
  return this.statistics.sendFeedback(overallFeedback, detailedFeedback);
};
/**
 * Returns true if the callstats integration is enabled, otherwise returns
 * false.
 *
 * @returns true if the callstats integration is enabled, otherwise returns
 * false.
 */


JitsiConference.prototype.isCallstatsEnabled = function () {
  return this.statistics.isCallstatsEnabled();
};
/**
 * Handles track attached to container (Calls associateStreamWithVideoTag method
 * from statistics module)
 * @param {JitsiLocalTrack|JitsiRemoteTrack} track the track
 * @param container the container
 */


JitsiConference.prototype._onTrackAttach = function (track, container) {
  const isLocal = track.isLocal();
  let ssrc = null;
  const isP2P = track.isP2P;
  const remoteUserId = isP2P ? track.getParticipantId() : 'jitsi';
  const peerConnection = isP2P ? this.p2pJingleSession && this.p2pJingleSession.peerconnection : this.jvbJingleSession && this.jvbJingleSession.peerconnection;

  if (isLocal) {
    // Local tracks have SSRC stored on per peer connection basis
    if (peerConnection) {
      ssrc = peerConnection.getLocalSSRC(track);
    }
  } else {
    ssrc = track.getSSRC();
  }

  if (!container.id || !ssrc || !peerConnection) {
    return;
  }

  this.statistics.associateStreamWithVideoTag(peerConnection, ssrc, isLocal, remoteUserId, track.getUsageLabel(), container.id);
};
/**
 * Logs an "application log" message.
 * @param message {string} The message to log. Note that while this can be a
 * generic string, the convention used by lib-jitsi-meet and jitsi-meet is to
 * log valid JSON strings, with an "id" field used for distinguishing between
 * message types. E.g.: {id: "recorder_status", status: "off"}
 */


JitsiConference.prototype.sendApplicationLog = function (message) {
  _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendLog(message);
};
/**
 * Checks if the user identified by given <tt>mucJid</tt> is the conference
 * focus.
 * @param mucJid the full MUC address of the user to be checked.
 * @returns {boolean|null} <tt>true</tt> if MUC user is the conference focus,
 * <tt>false</tt> when is not. <tt>null</tt> if we're not in the MUC anymore and
 * are unable to figure out the status or if given <tt>mucJid</tt> is invalid.
 */


JitsiConference.prototype._isFocus = function (mucJid) {
  return this.room ? this.room.isFocus(mucJid) : null;
};
/**
 * Fires CONFERENCE_FAILED event with INCOMPATIBLE_SERVER_VERSIONS parameter
 */


JitsiConference.prototype._fireIncompatibleVersionsEvent = function () {
  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_4__["INCOMPATIBLE_SERVER_VERSIONS"]);
};
/**
 * Sends a message via the data channel.
 * @param to {string} the id of the endpoint that should receive the message.
 * If "" the message will be sent to all participants.
 * @param payload {object} the payload of the message.
 * @throws NetworkError or InvalidStateError or Error if the operation fails.
 * @deprecated Use 'sendMessage' instead. TODO: this should be private.
 */


JitsiConference.prototype.sendEndpointMessage = function (to, payload) {
  this.rtc.sendChannelMessage(to, payload);
};
/**
 * Sends a broadcast message via the data channel.
 * @param payload {object} the payload of the message.
 * @throws NetworkError or InvalidStateError or Error if the operation fails.
 * @deprecated Use 'sendMessage' instead. TODO: this should be private.
 */


JitsiConference.prototype.broadcastEndpointMessage = function (payload) {
  this.sendEndpointMessage('', payload);
};
/**
 * Sends a message to a given endpoint (if 'to' is a non-empty string), or
 * broadcasts it to all endpoints in the conference.
 * @param {string} to The ID of the endpoint/participant which is to receive
 * the message, or '' to broadcast the message to all endpoints in the
 * conference.
 * @param {string|object} message the message to send. If this is of type
 * 'string' it will be sent as a chat message. If it is of type 'object', it
 * will be encapsulated in a format recognized by jitsi-meet and converted to
 * JSON before being sent.
 * @param {boolean} sendThroughVideobridge Whether to send the message through
 * jitsi-videobridge (via the COLIBRI data channel or web socket), or through
 * the XMPP MUC. Currently only objects can be sent through jitsi-videobridge.
 */


JitsiConference.prototype.sendMessage = function (message, to = '', sendThroughVideobridge = false) {
  const messageType = typeof message; // Through videobridge we support only objects. Through XMPP we support
  // objects (encapsulated in a specific JSON format) and strings (i.e.
  // regular chat messages).

  if (messageType !== 'object' && (sendThroughVideobridge || messageType !== 'string')) {
    logger.error(`Can not send a message of type ${messageType}`);
    return;
  }

  if (sendThroughVideobridge) {
    this.sendEndpointMessage(to, message);
  } else {
    let messageToSend = message; // Name of packet extension of message stanza to send the required
    // message in.

    let elementName = 'body';

    if (messageType === 'object') {
      elementName = 'json-message'; // Mark as valid JSON message if not already

      if (!messageToSend.hasOwnProperty(_modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_40__["JITSI_MEET_MUC_TYPE"])) {
        messageToSend[_modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_40__["JITSI_MEET_MUC_TYPE"]] = '';
      }

      try {
        messageToSend = JSON.stringify(messageToSend);
      } catch (e) {
        logger.error('Can not send a message, stringify failed: ', e);
        return;
      }
    }

    if (to) {
      this.sendPrivateTextMessage(to, messageToSend, elementName);
    } else {
      // Broadcast
      this.sendTextMessage(messageToSend, elementName);
    }
  }
};

JitsiConference.prototype.isConnectionInterrupted = function () {
  return this.isP2PActive() ? this.isP2PConnectionInterrupted : this.isJvbConnectionInterrupted;
};
/**
 * Handles {@link XMPPEvents.CONNECTION_INTERRUPTED}
 * @param {JingleSessionPC} session
 * @private
 */


JitsiConference.prototype._onIceConnectionInterrupted = function (session) {
  if (session.isP2P) {
    this.isP2PConnectionInterrupted = true;
  } else {
    this.isJvbConnectionInterrupted = true;
  }

  if (session.isP2P === this.isP2PActive()) {
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONNECTION_INTERRUPTED"]);
  }
};
/**
 * Handles {@link XMPPEvents.CONNECTION_ICE_FAILED}
 * @param {JingleSessionPC} session
 * @private
 */


JitsiConference.prototype._onIceConnectionFailed = function (session) {
  // We do nothing for the JVB connection, because it's up to the Jicofo to
  // eventually come up with the new offer (at least for the time being).
  if (session.isP2P) {
    // Add p2pFailed property to analytics to distinguish, between "good"
    // and "bad" connection
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].analytics.addPermanentProperties({
      p2pFailed: true
    });

    if (this.p2pJingleSession) {
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalyticsAndLog(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["createP2PEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["ACTION_P2P_FAILED"], {
        initiator: this.p2pJingleSession.isInitiator
      }));
    }

    this._stopP2PSession('connectivity-error', 'ICE FAILED');
  } else if (session && this.jvbJingleSession === session) {
    if (this.xmpp.isPingSupported()) {
      this._delayedIceFailed = new _modules_connectivity_IceFailedNotification__WEBPACK_IMPORTED_MODULE_22__["default"](this);

      this._delayedIceFailed.start(session);
    } else {
      // Let Jicofo know that the JVB's ICE connection has failed
      logger.info('PING not supported - sending ICE failed immediately');
      session.sendIceFailedNotification();
    }
  }
};
/**
 * Handles {@link XMPPEvents.CONNECTION_RESTORED}
 * @param {JingleSessionPC} session
 * @private
 */


JitsiConference.prototype._onIceConnectionRestored = function (session) {
  if (session.isP2P) {
    this.isP2PConnectionInterrupted = false;
  } else {
    this.isJvbConnectionInterrupted = false;
    this._delayedIceFailed && this._delayedIceFailed.cancel();
  }

  if (session.isP2P === this.isP2PActive()) {
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONNECTION_RESTORED"]);
  }
};
/**
 * Accept incoming P2P Jingle call.
 * @param {JingleSessionPC} jingleSession the session instance
 * @param {jQuery} jingleOffer a jQuery selector pointing to 'jingle' IQ element
 * @private
 */


JitsiConference.prototype._acceptP2PIncomingCall = function (jingleSession, jingleOffer) {
  this.isP2PConnectionInterrupted = false; // Accept the offer

  this.p2pJingleSession = jingleSession;

  this._sendConferenceJoinAnalyticsEvent();

  this.p2pJingleSession.initialize(this.room, this.rtc, this.options.config);
  logger.info('Starting CallStats for P2P connection...');
  let remoteID = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(this.p2pJingleSession.remoteJid);
  const participant = this.participants[remoteID];

  if (participant) {
    remoteID = participant.getStatsID() || remoteID;
  }

  this.statistics.startCallStats(this.p2pJingleSession.peerconnection, remoteID);
  const localTracks = this.getLocalTracks();
  this.p2pJingleSession.acceptOffer(jingleOffer, () => {
    logger.debug('Got RESULT for P2P "session-accept"'); // Setup E2EE.

    for (const track of localTracks) {
      this._setupSenderE2EEForTrack(jingleSession, track);
    }
  }, error => {
    logger.error('Failed to accept incoming P2P Jingle session', error);
  }, localTracks);
};
/**
 * Adds remote tracks to the conference associated with the JVB session.
 * @private
 */


JitsiConference.prototype._addRemoteJVBTracks = function () {
  this._addRemoteTracks('JVB', this.jvbJingleSession.peerconnection.getRemoteTracks());
};
/**
 * Adds remote tracks to the conference associated with the P2P session.
 * @private
 */


JitsiConference.prototype._addRemoteP2PTracks = function () {
  this._addRemoteTracks('P2P', this.p2pJingleSession.peerconnection.getRemoteTracks());
};
/**
 * Generates fake "remote track added" events for given Jingle session.
 * @param {string} logName the session's nickname which will appear in log
 * messages.
 * @param {Array<JitsiRemoteTrack>} remoteTracks the tracks that will be added
 * @private
 */


JitsiConference.prototype._addRemoteTracks = function (logName, remoteTracks) {
  for (const track of remoteTracks) {
    logger.info(`Adding remote ${logName} track: ${track}`);
    this.rtc.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_42__["REMOTE_TRACK_ADDED"], track);
  }
};
/**
 * Called when {@link XMPPEvents.CONNECTION_ESTABLISHED} event is
 * triggered for a {@link JingleSessionPC}. Switches the conference to use
 * the P2P connection if the event comes from the P2P session.
 * @param {JingleSessionPC} jingleSession the session instance.
 * @private
 */


JitsiConference.prototype._onIceConnectionEstablished = function (jingleSession) {
  if (this.p2pJingleSession !== null) {
    // store the establishment time of the p2p session as a field of the
    // JitsiConference because the p2pJingleSession might get disposed (thus
    // the value is lost).
    this.p2pEstablishmentDuration = this.p2pJingleSession.establishmentDuration;
  }

  if (this.jvbJingleSession !== null) {
    this.jvbEstablishmentDuration = this.jvbJingleSession.establishmentDuration;
  }

  let done = false;
  const forceJVB121Ratio = this.options.config.forceJVB121Ratio; // We don't care about the JVB case, there's nothing to be done

  if (!jingleSession.isP2P) {
    done = true;
  } else if (this.p2pJingleSession !== jingleSession) {
    logger.error('CONNECTION_ESTABLISHED - wrong P2P session instance ?!');
    done = true;
  } else if (!jingleSession.isInitiator && typeof forceJVB121Ratio === 'number' && Math.random() < forceJVB121Ratio) {
    logger.info(`Forcing JVB 121 mode (ratio=${forceJVB121Ratio})...`);
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].analytics.addPermanentProperties({
      forceJvb121: true
    });

    this._stopP2PSession('decline', 'force JVB121');

    done = true;
  }

  if (!isNaN(this.p2pEstablishmentDuration) && !isNaN(this.jvbEstablishmentDuration)) {
    const establishmentDurationDiff = this.p2pEstablishmentDuration - this.jvbEstablishmentDuration;
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["ICE_ESTABLISHMENT_DURATION_DIFF"], {
      value: establishmentDurationDiff
    });
  }

  if (jingleSession.isP2P === this.isP2PActive()) {
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONNECTION_ESTABLISHED"]);
  }

  if (done) {
    return;
  } // Update P2P status and emit events


  this._setP2PStatus(true); // Remove remote tracks


  if (this.jvbJingleSession) {
    this._removeRemoteJVBTracks();
  } else {
    logger.info('Not removing remote JVB tracks - no session yet');
  }

  this._addRemoteP2PTracks(); // Stop media transfer over the JVB connection


  if (this.jvbJingleSession) {
    this._suspendMediaTransferForJvbConnection();
  }

  logger.info('Starting remote stats with p2p connection');
  this.statistics.startRemoteStats(this.p2pJingleSession.peerconnection);
  _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalyticsAndLog(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["createP2PEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["ACTION_P2P_ESTABLISHED"], {
    initiator: this.p2pJingleSession.isInitiator
  }));
};
/**
 * Called when the chat room reads a new list of properties from jicofo's
 * presence. The properties may have changed, but they don't have to.
 *
 * @param {Object} properties - The properties keyed by the property name
 * ('key').
 * @private
 */


JitsiConference.prototype._updateProperties = function (properties = {}) {
  const changed = !lodash_isequal__WEBPACK_IMPORTED_MODULE_3___default()(properties, this.properties);
  this.properties = properties;

  if (changed) {
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["PROPERTIES_CHANGED"], this.properties); // Some of the properties need to be added to analytics events.

    const analyticsKeys = [// The number of jitsi-videobridge instances currently used for the
    // conference.
    'bridge-count', // The conference creation time (set by jicofo).
    'created-ms', 'octo-enabled'];
    analyticsKeys.forEach(key => {
      if (properties[key] !== undefined) {
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].analytics.addPermanentProperties({
          [key.replace('-', '_')]: properties[key]
        });
      }
    });
  }
};
/**
 * Gets a conference property with a given key.
 *
 * @param {string} key - The key.
 * @returns {*} The value
 */


JitsiConference.prototype.getProperty = function (key) {
  return this.properties[key];
};
/**
 * Clears the deferred start P2P task if it has been scheduled.
 * @private
 */


JitsiConference.prototype._maybeClearDeferredStartP2P = function () {
  if (this.deferredStartP2PTask) {
    logger.info('Cleared deferred start P2P task');
    clearTimeout(this.deferredStartP2PTask);
    this.deferredStartP2PTask = null;
  }
};
/**
 * Removes from the conference remote tracks associated with the JVB
 * connection.
 * @private
 */


JitsiConference.prototype._removeRemoteJVBTracks = function () {
  this._removeRemoteTracks('JVB', this.jvbJingleSession.peerconnection.getRemoteTracks());
};
/**
 * Removes from the conference remote tracks associated with the P2P
 * connection.
 * @private
 */


JitsiConference.prototype._removeRemoteP2PTracks = function () {
  this._removeRemoteTracks('P2P', this.p2pJingleSession.peerconnection.getRemoteTracks());
};
/**
 * Generates fake "remote track removed" events for given Jingle session.
 * @param {string} sessionNickname the session's nickname which will appear in
 * log messages.
 * @param {Array<JitsiRemoteTrack>} remoteTracks the tracks that will be removed
 * @private
 */


JitsiConference.prototype._removeRemoteTracks = function (sessionNickname, remoteTracks) {
  for (const track of remoteTracks) {
    logger.info(`Removing remote ${sessionNickname} track: ${track}`);
    this.rtc.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_42__["REMOTE_TRACK_REMOVED"], track);
  }
};
/**
 * Resumes media transfer over the JVB connection.
 * @private
 */


JitsiConference.prototype._resumeMediaTransferForJvbConnection = function () {
  logger.info('Resuming media transfer over the JVB connection...');
  this.jvbJingleSession.setMediaTransferActive(true, true).then(() => {
    logger.info('Resumed media transfer over the JVB connection!');
  }, error => {
    logger.error('Failed to resume media transfer over the JVB connection:', error);
  });
};
/**
 * Sets new P2P status and updates some events/states hijacked from
 * the <tt>JitsiConference</tt>.
 * @param {boolean} newStatus the new P2P status value, <tt>true</tt> means that
 * P2P is now in use, <tt>false</tt> means that the JVB connection is now in use
 * @private
 */


JitsiConference.prototype._setP2PStatus = function (newStatus) {
  if (this.p2p === newStatus) {
    logger.debug(`Called _setP2PStatus with the same status: ${newStatus}`);
    return;
  }

  this.p2p = newStatus;

  if (newStatus) {
    logger.info('Peer to peer connection established!'); // When we end up in a valid P2P session need to reset the properties
    // in case they have persisted, after session with another peer.

    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].analytics.addPermanentProperties({
      p2pFailed: false,
      forceJvb121: false
    }); // Sync up video transfer active in case p2pJingleSession not existed
    // when the lastN value was being adjusted.

    const isVideoActive = this.rtc.getLastN() !== 0;
    this.p2pJingleSession.setMediaTransferActive(true, isVideoActive).catch(error => {
      logger.error('Failed to sync up P2P video transfer status' + `(${isVideoActive})`, error);
    });
  } else {
    logger.info('Peer to peer connection closed!');
  } // Put the JVB connection on hold/resume


  if (this.jvbJingleSession) {
    this.statistics.sendConnectionResumeOrHoldEvent(this.jvbJingleSession.peerconnection, !newStatus);
  } // Clear dtmfManager, so that it can be recreated with new connection


  this.dtmfManager = null; // Update P2P status

  this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["P2P_STATUS"], this, this.p2p); // Refresh connection interrupted/restored

  this.eventEmitter.emit(this.isConnectionInterrupted() ? _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONNECTION_INTERRUPTED"] : _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONNECTION_RESTORED"]);
};
/**
 * Starts new P2P session.
 * @param {string} remoteJid the JID of the remote participant
 * @private
 */


JitsiConference.prototype._startP2PSession = function (remoteJid) {
  this._maybeClearDeferredStartP2P();

  if (this.p2pJingleSession) {
    logger.error('P2P session already started!');
    return;
  }

  this.isP2PConnectionInterrupted = false;
  this.p2pJingleSession = this.xmpp.connection.jingle.newP2PJingleSession(this.room.myroomjid, remoteJid);
  logger.info('Created new P2P JingleSession', this.room.myroomjid, remoteJid);

  this._sendConferenceJoinAnalyticsEvent();

  this.p2pJingleSession.initialize(this.room, this.rtc, this.options.config);
  logger.info('Starting CallStats for P2P connection...');
  let remoteID = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(this.p2pJingleSession.remoteJid);
  const participant = this.participants[remoteID];

  if (participant) {
    remoteID = participant.getStatsID() || remoteID;
  }

  this.statistics.startCallStats(this.p2pJingleSession.peerconnection, remoteID); // NOTE one may consider to start P2P with the local tracks detached,
  // but no data will be sent until ICE succeeds anyway. And we switch
  // immediately once the P2P ICE connects.

  const localTracks = this.getLocalTracks();
  this.p2pJingleSession.invite(localTracks);
};
/**
 * Suspends media transfer over the JVB connection.
 * @private
 */


JitsiConference.prototype._suspendMediaTransferForJvbConnection = function () {
  logger.info('Suspending media transfer over the JVB connection...');
  this.jvbJingleSession.setMediaTransferActive(false, false).then(() => {
    logger.info('Suspended media transfer over the JVB connection !');
  }, error => {
    logger.error('Failed to suspend media transfer over the JVB connection:', error);
  });
};
/**
 * Method when called will decide whether it's the time to start or stop
 * the P2P session.
 * @param {boolean} userLeftEvent if <tt>true</tt> it means that the call
 * originates from the user left event.
 * @private
 */


JitsiConference.prototype._maybeStartOrStopP2P = function (userLeftEvent) {
  if (!_modules_browser__WEBPACK_IMPORTED_MODULE_20__["default"].supportsP2P() || !this.isP2PEnabled() || this.isP2PTestModeEnabled()) {
    logger.info('Auto P2P disabled');
    return;
  }

  const peers = this.getParticipants();
  const peerCount = peers.length; // FIXME 1 peer and it must *support* P2P switching

  const shouldBeInP2P = this._shouldBeInP2PMode(); // Clear deferred "start P2P" task


  if (!shouldBeInP2P && this.deferredStartP2PTask) {
    this._maybeClearDeferredStartP2P();
  } // Start peer to peer session


  if (!this.p2pJingleSession && shouldBeInP2P) {
    const peer = peerCount && peers[0];
    const myId = this.myUserId();
    const peersId = peer.getId();

    if (myId > peersId) {
      logger.debug('I\'m the bigger peersId - ' + 'the other peer should start P2P', myId, peersId);
      return;
    } else if (myId === peersId) {
      logger.error('The same IDs ? ', myId, peersId);
      return;
    }

    const jid = peer.getJid();

    if (userLeftEvent) {
      if (this.deferredStartP2PTask) {
        logger.error('Deferred start P2P task\'s been set already!');
        return;
      }

      logger.info(`Will start P2P with: ${jid} after ${this.backToP2PDelay} seconds...`);
      this.deferredStartP2PTask = setTimeout(this._startP2PSession.bind(this, jid), this.backToP2PDelay * 1000);
    } else {
      logger.info(`Will start P2P with: ${jid}`);

      this._startP2PSession(jid);
    }
  } else if (this.p2pJingleSession && !shouldBeInP2P) {
    logger.info(`Will stop P2P with: ${this.p2pJingleSession.remoteJid}`); // Log that there will be a switch back to the JVB connection

    if (this.p2pJingleSession.isInitiator && peerCount > 1) {
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalyticsAndLog(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["createP2PEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["ACTION_P2P_SWITCH_TO_JVB"]));
    }

    this._stopP2PSession();
  }
};
/**
 * Tells whether or not this conference should be currently in the P2P mode.
 *
 * @private
 * @returns {boolean}
 */


JitsiConference.prototype._shouldBeInP2PMode = function () {
  const peers = this.getParticipants();
  const peerCount = peers.length;
  const hasBotPeer = peers.find(p => p._botType === 'poltergeist') !== undefined;
  const shouldBeInP2P = peerCount === 1 && !hasBotPeer;
  logger.debug(`P2P? peerCount: ${peerCount}, hasBotPeer: ${hasBotPeer} => ${shouldBeInP2P}`);
  return shouldBeInP2P;
};
/**
 * Stops the current P2P session.
 * @param {string} [reason="success"] one of the Jingle "reason" element
 * names as defined by https://xmpp.org/extensions/xep-0166.html#def-reason
 * @param {string} [reasonDescription="Turing off P2P session"] text
 * description that will be included in the session terminate message
 * @private
 */


JitsiConference.prototype._stopP2PSession = function (reason, reasonDescription) {
  if (!this.p2pJingleSession) {
    logger.error('No P2P session to be stopped!');
    return;
  }

  const wasP2PEstablished = this.isP2PActive(); // Swap remote tracks, but only if the P2P has been fully established

  if (wasP2PEstablished) {
    if (this.jvbJingleSession) {
      this._resumeMediaTransferForJvbConnection();
    } // Remove remote P2P tracks


    this._removeRemoteP2PTracks();
  } // Stop P2P stats


  logger.info('Stopping remote stats for P2P connection');
  this.statistics.stopRemoteStats(this.p2pJingleSession.peerconnection);
  logger.info('Stopping CallStats for P2P connection');
  this.statistics.stopCallStats(this.p2pJingleSession.peerconnection);
  this.p2pJingleSession.terminate(() => {
    logger.info('P2P session terminate RESULT');
  }, error => {
    // Because both initiator and responder are simultaneously
    // terminating their JingleSessions in case of the 'to JVB switch'
    // when 3rd participant joins, both will dispose their sessions and
    // reply with 'item-not-found' (see strophe.jingle.js). We don't
    // want to log this as an error since it's expected behaviour.
    //
    // We want them both to terminate, because in case of initiator's
    // crash the responder would stay in P2P mode until ICE fails which
    // could take up to 20 seconds.
    //
    // NOTE lack of 'reason' is considered as graceful session terminate
    // where both initiator and responder terminate their sessions
    // simultaneously.
    if (reason) {
      logger.error('An error occurred while trying to terminate' + ' P2P Jingle session', error);
    }
  }, {
    reason: reason ? reason : 'success',
    reasonDescription: reasonDescription ? reasonDescription : 'Turing off P2P session',
    sendSessionTerminate: this.room && this.getParticipantById(strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(this.p2pJingleSession.remoteJid))
  });
  this.p2pJingleSession = null; // Update P2P status and other affected events/states

  this._setP2PStatus(false);

  if (wasP2PEstablished) {
    // Add back remote JVB tracks
    if (this.jvbJingleSession) {
      this._addRemoteJVBTracks();
    } else {
      logger.info('Not adding remote JVB tracks - no session yet');
    }
  }
};
/**
 * Checks whether or not the conference is currently in the peer to peer mode.
 * Being in peer to peer mode means that the direct connection has been
 * established and the P2P connection is being used for media transmission.
 * @return {boolean} <tt>true</tt> if in P2P mode or <tt>false</tt> otherwise.
 */


JitsiConference.prototype.isP2PActive = function () {
  return this.p2p;
};
/**
 * Returns the current ICE state of the P2P connection.
 * NOTE: method is used by the jitsi-meet-torture tests.
 * @return {string|null} an ICE state or <tt>null</tt> if there's currently
 * no P2P connection.
 */


JitsiConference.prototype.getP2PConnectionState = function () {
  if (this.isP2PActive()) {
    return this.p2pJingleSession.peerconnection.getConnectionState();
  }

  return null;
};
/**
 * Manually starts new P2P session (should be used only in the tests).
 */


JitsiConference.prototype.startP2PSession = function () {
  const peers = this.getParticipants(); // Start peer to peer session

  if (peers.length === 1) {
    const peerJid = peers[0].getJid();

    this._startP2PSession(peerJid);
  } else {
    throw new Error('There must be exactly 1 participant to start the P2P session !');
  }
};
/**
 * Manually stops the current P2P session (should be used only in the tests)
 */


JitsiConference.prototype.stopP2PSession = function () {
  this._stopP2PSession();
};
/**
 * Get a summary of how long current participants have been the dominant speaker
 * @returns {object}
 */


JitsiConference.prototype.getSpeakerStats = function () {
  return this.speakerStatsCollector.getStats();
};
/**
 * Sets the maximum video size the local participant should receive from remote
 * participants.
 *
 * @param {number} maxFrameHeightPixels the maximum frame height, in pixels,
 * this receiver is willing to receive.
 * @returns {void}
 */


JitsiConference.prototype.setReceiverVideoConstraint = function (maxFrameHeight) {
  this.rtc.setReceiverVideoConstraint(maxFrameHeight);
};
/**
 * Creates a video SIP GW session and returns it if service is enabled. Before
 * creating a session one need to check whether video SIP GW service is
 * available in the system {@link JitsiConference.isVideoSIPGWAvailable}. Even
 * if there are available nodes to serve this request, after creating the
 * session those nodes can be taken and the request about using the
 * created session can fail.
 *
 * @param {string} sipAddress - The sip address to be used.
 * @param {string} displayName - The display name to be used for this session.
 * @returns {JitsiVideoSIPGWSession|Error} Returns null if conference is not
 * initialised and there is no room.
 */


JitsiConference.prototype.createVideoSIPGWSession = function (sipAddress, displayName) {
  if (!this.room) {
    return new Error(_modules_videosipgw_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_39__["ERROR_NO_CONNECTION"]);
  }

  return this.videoSIPGWHandler.createVideoSIPGWSession(sipAddress, displayName);
};
/**
 * Sends a conference.join analytics event.
 *
 * @returns {void}
 */


JitsiConference.prototype._sendConferenceJoinAnalyticsEvent = function () {
  const meetingId = this.getMeetingUniqueId();

  if (this._conferenceJoinAnalyticsEventSent || !meetingId || this.getActivePeerConnection() === null) {
    return;
  }

  _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_33__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_44__["createConferenceEvent"])('joined', {
    meetingId,
    participantId: `${meetingId}.${this._statsCurrentId}`
  }));
  this._conferenceJoinAnalyticsEventSent = true;
};
/**
 * Returns whether End-To-End encryption is supported. Note that not all participants
 * in the conference may support it.
 *
 * @returns {boolean}
 */


JitsiConference.prototype.isE2EESupported = function () {
  return Boolean(this._e2eeCtx);
};
/**
 * Sets the key to be used for End-To-End encryption.
 *
 * @param {string} key the key to be used.
 * @returns {void}
 */


JitsiConference.prototype.setE2EEKey = function (key) {
  if (!this._e2eeCtx) {
    logger.warn('Cannot set E2EE key: there is no defined context, platform is likely unsupported.');
    return;
  }

  this._e2eeCtx.setKey(key);
};
/**
 * Setup E2EE for the sending side, if supported.
 * Note that this is only done for the JVB Peer Connecction.
 *
 * @returns {void}
 */


JitsiConference.prototype._setupSenderE2EEForTrack = function (session, track) {
  if (!this._e2eeCtx) {
    return;
  }

  const pc = session.peerconnection;
  const sender = pc.findSenderForTrack(track.track);

  if (sender) {
    this._e2eeCtx.handleSender(sender, track.getType());
  } else {
    logger.warn(`Could not handle E2EE for local ${track.getType()} track: sender not found`);
  }
};
/**
 * Setup E2EE for the receiving side, if supported.
 * Note that this is only done for the JVB Peer Connecction.
 *
 * @returns {void}
 */


JitsiConference.prototype._setupReceiverE2EEForTrack = function (track) {
  if (!this._e2eeCtx) {
    return;
  }

  const session = track.isP2P ? this.p2pJingleSession : this.jvbJingleSession;
  const pc = session && session.peerconnection;

  if (pc) {
    const receiver = pc.findReceiverForTrack(track.track);

    if (receiver) {
      this._e2eeCtx.handleReceiver(receiver, track.getType());
    } else {
      logger.warn(`Could not handle E2EE for remote ${track.getType()} track: receiver not found`);
    }
  }
};
/* WEBPACK VAR INJECTION */}.call(this, "JitsiConference.js"))

/***/ }),

/***/ "./JitsiConferenceErrors.js":
/*!**********************************!*\
  !*** ./JitsiConferenceErrors.js ***!
  \**********************************/
/*! exports provided: AUTHENTICATION_REQUIRED, CHAT_ERROR, CONFERENCE_DESTROYED, CONFERENCE_MAX_USERS, CONNECTION_ERROR, NOT_ALLOWED_ERROR, FOCUS_DISCONNECTED, FOCUS_LEFT, GRACEFUL_SHUTDOWN, INCOMPATIBLE_SERVER_VERSIONS, OFFER_ANSWER_FAILED, PASSWORD_NOT_SUPPORTED, PASSWORD_REQUIRED, RESERVATION_ERROR, SETUP_FAILED, VIDEOBRIDGE_NOT_AVAILABLE */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AUTHENTICATION_REQUIRED", function() { return AUTHENTICATION_REQUIRED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CHAT_ERROR", function() { return CHAT_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONFERENCE_DESTROYED", function() { return CONFERENCE_DESTROYED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONFERENCE_MAX_USERS", function() { return CONFERENCE_MAX_USERS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_ERROR", function() { return CONNECTION_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NOT_ALLOWED_ERROR", function() { return NOT_ALLOWED_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "FOCUS_DISCONNECTED", function() { return FOCUS_DISCONNECTED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "FOCUS_LEFT", function() { return FOCUS_LEFT; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "GRACEFUL_SHUTDOWN", function() { return GRACEFUL_SHUTDOWN; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "INCOMPATIBLE_SERVER_VERSIONS", function() { return INCOMPATIBLE_SERVER_VERSIONS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OFFER_ANSWER_FAILED", function() { return OFFER_ANSWER_FAILED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PASSWORD_NOT_SUPPORTED", function() { return PASSWORD_NOT_SUPPORTED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PASSWORD_REQUIRED", function() { return PASSWORD_REQUIRED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RESERVATION_ERROR", function() { return RESERVATION_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SETUP_FAILED", function() { return SETUP_FAILED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VIDEOBRIDGE_NOT_AVAILABLE", function() { return VIDEOBRIDGE_NOT_AVAILABLE; });
/**
 * The errors for the conference.
 */

/**
 * Indicates that client must be authenticated to create the conference.
 */
const AUTHENTICATION_REQUIRED = 'conference.authenticationRequired';
/**
 * Indicates that chat error occurred.
 */

const CHAT_ERROR = 'conference.chatError';
/**
 * Indicates that conference has been destroyed.
 */

const CONFERENCE_DESTROYED = 'conference.destroyed';
/**
 * Indicates that max users limit has been reached.
 */

const CONFERENCE_MAX_USERS = 'conference.max_users';
/**
 * Indicates that a connection error occurred when trying to join a conference.
 */

const CONNECTION_ERROR = 'conference.connectionError';
/**
 * Indicates that a connection error is due to not allowed,
 * occurred when trying to join a conference.
 */

const NOT_ALLOWED_ERROR = 'conference.connectionError.notAllowed';
/**
 * Indicates that focus error happened.
 */

const FOCUS_DISCONNECTED = 'conference.focusDisconnected';
/**
 * Indicates that focus left the conference.
 */

const FOCUS_LEFT = 'conference.focusLeft';
/**
 * Indicates that graceful shutdown happened.
 */

const GRACEFUL_SHUTDOWN = 'conference.gracefulShutdown';
/**
 * Indicates that the versions of the server side components are incompatible
 * with the client side.
 */

const INCOMPATIBLE_SERVER_VERSIONS = 'conference.incompatible_server_versions';
/**
 * Indicates that offer/answer had failed.
 */

const OFFER_ANSWER_FAILED = 'conference.offerAnswerFailed';
/**
 * Indicates that password cannot be set for this conference.
 */

const PASSWORD_NOT_SUPPORTED = 'conference.passwordNotSupported';
/**
 * Indicates that a password is required in order to join the conference.
 */

const PASSWORD_REQUIRED = 'conference.passwordRequired';
/**
 * Indicates that reservation system returned error.
 */

const RESERVATION_ERROR = 'conference.reservationError';
/**
 * Indicates that the conference setup failed.
 */

const SETUP_FAILED = 'conference.setup_failed';
/**
 * Indicates that there is no available videobridge.
 */

const VIDEOBRIDGE_NOT_AVAILABLE = 'conference.videobridgeNotAvailable';

/***/ }),

/***/ "./JitsiConferenceEventManager.js":
/*!****************************************!*\
  !*** ./JitsiConferenceEventManager.js ***!
  \****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JitsiConferenceEventManager; });
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _service_authentication_AuthenticationEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./service/authentication/AuthenticationEvents */ "./service/authentication/AuthenticationEvents.js");
/* harmony import */ var _service_authentication_AuthenticationEvents__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_service_authentication_AuthenticationEvents__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _modules_util_EventEmitterForwarder__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./modules/util/EventEmitterForwarder */ "./modules/util/EventEmitterForwarder.js");
/* harmony import */ var _modules_util_EventEmitterForwarder__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_modules_util_EventEmitterForwarder__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_4__);
/* harmony import */ var _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./JitsiConferenceErrors */ "./JitsiConferenceErrors.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8__);
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./service/RTC/VideoType */ "./service/RTC/VideoType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__);
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11__);
/* global __filename */












const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_4__["getLogger"])(__filename);
/**
 * Setups all event listeners related to conference
 * @param conference {JitsiConference} the conference
 */

function JitsiConferenceEventManager(conference) {
  this.conference = conference;
  this.xmppListeners = {}; // Listeners related to the conference only

  conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRACK_MUTE_CHANGED"], track => {
    if (!track.isLocal() || !conference.statistics) {
      return;
    }

    const session = track.isP2P ? conference.p2pJingleSession : conference.jvbJingleSession; // TPC will be null, before the conference starts, but the event
    // still should be queued

    const tpc = session && session.peerconnection || null;
    conference.statistics.sendMuteEvent(tpc, track.isMuted(), track.getType());
  });
}
/**
 * Setups event listeners related to conference.chatRoom
 */

JitsiConferenceEventManager.prototype.setupChatRoomListeners = function () {
  const conference = this.conference;
  const chatRoom = conference.room;
  this.chatRoomForwarder = new _modules_util_EventEmitterForwarder__WEBPACK_IMPORTED_MODULE_3___default.a(chatRoom, this.conference.eventEmitter);
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.ICE_RESTARTING, jingleSession => {
    if (!jingleSession.isP2P) {
      // If using DataChannel as bridge channel, it must be closed
      // before ICE restart, otherwise Chrome will not trigger "opened"
      // event for the channel established with the new bridge.
      // TODO: This may be bypassed when using a WebSocket as bridge
      // channel.
      conference.rtc.closeBridgeChannel();
    } // else: there are no DataChannels in P2P session (at least for now)

  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.ICE_RESTART_SUCCESS, (jingleSession, offerIq) => {
    // The JVB data chanel needs to be reopened in case the conference
    // has been moved to a new bridge.
    !jingleSession.isP2P && conference._setBridgeChannel(offerIq, jingleSession.peerconnection);
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.AUDIO_MUTED_BY_FOCUS, actor => {
    // TODO: Add a way to differentiate between commands which caused
    // us to mute and those that did not change our state (i.e. we were
    // already muted).
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createRemotelyMutedEvent"])());
    conference.mutedByFocusActor = actor; // set isMutedByFocus when setAudioMute Promise ends

    conference.rtc.setAudioMute(true).then(() => {
      conference.isMutedByFocus = true;
      conference.mutedByFocusActor = null;
    }).catch(error => {
      conference.mutedByFocusActor = null;
      logger.warn('Error while audio muting due to focus request', error);
    });
  });
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.SUBJECT_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["SUBJECT_CHANGED"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MUC_JOINED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_JOINED"]); // send some analytics events

  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MUC_JOINED, () => {
    this.conference.isJvbConnectionInterrupted = false; // TODO: Move all of the 'connectionTimes' logic to its own module.

    Object.keys(chatRoom.connectionTimes).forEach(key => {
      const event = Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createConnectionStageReachedEvent"])(`conference_${key}`, {
        value: chatRoom.connectionTimes[key]
      });
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendAnalytics(event);
    }); // TODO: Move all of the 'connectionTimes' logic to its own module.

    Object.keys(chatRoom.xmpp.connectionTimes).forEach(key => {
      const event = Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createConnectionStageReachedEvent"])(`xmpp_${key}`, {
        value: chatRoom.xmpp.connectionTimes[key]
      });
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendAnalytics(event);
    });
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.RENEGOTIATION_FAILED, (e, session) => {
    if (!session.isP2P) {
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["OFFER_ANSWER_FAILED"], e);
    }
  });
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.ROOM_JOIN_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_ERROR"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.ROOM_CONNECT_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_ERROR"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.ROOM_CONNECT_NOT_ALLOWED_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["NOT_ALLOWED_ERROR"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.ROOM_MAX_USERS_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["CONFERENCE_MAX_USERS"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.PASSWORD_REQUIRED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["PASSWORD_REQUIRED"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.AUTHENTICATION_REQUIRED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["AUTHENTICATION_REQUIRED"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.BRIDGE_DOWN, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["VIDEOBRIDGE_NOT_AVAILABLE"]);
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.BRIDGE_DOWN, () => _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createBridgeDownEvent"])()));
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.RESERVATION_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["RESERVATION_ERROR"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.GRACEFUL_SHUTDOWN, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["GRACEFUL_SHUTDOWN"]);
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.CONNECTION_ICE_FAILED, jingleSession => {
    conference._onIceConnectionFailed(jingleSession);
  });
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MUC_DESTROYED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["CONFERENCE_DESTROYED"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.CHAT_ERROR_RECEIVED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_ERROR"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["CHAT_ERROR"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.FOCUS_DISCONNECTED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["FOCUS_DISCONNECTED"]);
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.FOCUS_LEFT, () => {
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createFocusLeftEvent"])());
    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["FOCUS_LEFT"]);
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.SESSION_ACCEPT_TIMEOUT, jingleSession => {
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendAnalyticsAndLog(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createJingleEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["ACTION_JINGLE_SA_TIMEOUT"], {
      p2p: jingleSession.isP2P
    }));
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.RECORDER_STATE_CHANGED, (session, jid) => {
    if (jid) {
      const participant = conference.getParticipantById(strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid));

      if (session.getStatus() === 'off') {
        session.setTerminator(participant);
      } else if (session.getStatus() === 'on') {
        session.setInitiator(participant);
      }
    }

    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["RECORDER_STATE_CHANGED"], session);
  });
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.TRANSCRIPTION_STATUS_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["TRANSCRIPTION_STATUS_CHANGED"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.VIDEO_SIP_GW_AVAILABILITY_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["VIDEO_SIP_GW_AVAILABILITY_CHANGED"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.VIDEO_SIP_GW_SESSION_STATE_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["VIDEO_SIP_GW_SESSION_STATE_CHANGED"]);
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.PHONE_NUMBER_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["PHONE_NUMBER_CHANGED"]);
  chatRoom.setParticipantPropertyListener((node, from) => {
    const participant = conference.getParticipantById(from);

    if (!participant) {
      return;
    }

    participant.setProperty(node.tagName.substring('jitsi_participant_'.length), node.value);
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.KICKED, conference.onMemberKicked.bind(conference));
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.SUSPEND_DETECTED, conference.onSuspendDetected.bind(conference));
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MUC_LOCK_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["LOCK_STATE_CHANGED"]);
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MUC_MEMBER_JOINED, conference.onMemberJoined.bind(conference));
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MUC_MEMBER_BOT_TYPE_CHANGED, conference._onMemberBotTypeChanged.bind(conference));
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MUC_MEMBER_LEFT, conference.onMemberLeft.bind(conference));
  this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MUC_LEFT, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_LEFT"]);
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.DISPLAY_NAME_CHANGED, conference.onDisplayNameChanged.bind(conference));
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.LOCAL_ROLE_CHANGED, role => {
    conference.onLocalRoleChanged(role); // log all events for the recorder operated by the moderator

    if (conference.statistics && conference.isModerator()) {
      conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["RECORDER_STATE_CHANGED"], recorderSession => {
        const logObject = {
          error: recorderSession.getError(),
          id: 'recorder_status',
          status: recorderSession.getStatus()
        };
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendLog(JSON.stringify(logObject));
      });
    }
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MUC_ROLE_CHANGED, conference.onUserRoleChanged.bind(conference));
  chatRoom.addListener(_service_authentication_AuthenticationEvents__WEBPACK_IMPORTED_MODULE_2___default.a.IDENTITY_UPDATED, (authEnabled, authIdentity) => {
    conference.authEnabled = authEnabled;
    conference.authIdentity = authIdentity;
    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["AUTH_STATUS_CHANGED"], authEnabled, authIdentity);
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.MESSAGE_RECEIVED, // eslint-disable-next-line max-params
  (jid, displayName, txt, myJid, ts) => {
    const id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);
    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["MESSAGE_RECEIVED"], id, txt, ts, displayName);
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.PRIVATE_MESSAGE_RECEIVED, // eslint-disable-next-line max-params
  (jid, displayName, txt, myJid, ts) => {
    const id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);
    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["PRIVATE_MESSAGE_RECEIVED"], id, txt, ts);
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.PRESENCE_STATUS, (jid, status) => {
    const id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);
    const participant = conference.getParticipantById(id);

    if (!participant || participant._status === status) {
      return;
    }

    participant._status = status;
    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["USER_STATUS_CHANGED"], id, status);
  });
  chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.JSON_MESSAGE_RECEIVED, (from, payload) => {
    const id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(from);
    const participant = conference.getParticipantById(id);

    if (participant) {
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["ENDPOINT_MESSAGE_RECEIVED"], participant, payload);
    } else {
      logger.warn('Ignored XMPPEvents.JSON_MESSAGE_RECEIVED for not existing ' + `participant: ${from}`, payload);
    }
  });
  chatRoom.addPresenceListener('startmuted', (data, from) => {
    let isModerator = false;

    if (conference.myUserId() === from && conference.isModerator()) {
      isModerator = true;
    } else {
      const participant = conference.getParticipantById(from);

      if (participant && participant.isModerator()) {
        isModerator = true;
      }
    }

    if (!isModerator) {
      return;
    }

    const startAudioMuted = data.attributes.audio === 'true';
    const startVideoMuted = data.attributes.video === 'true';
    let updated = false;

    if (startAudioMuted !== conference.startMutedPolicy.audio) {
      conference.startMutedPolicy.audio = startAudioMuted;
      updated = true;
    }

    if (startVideoMuted !== conference.startMutedPolicy.video) {
      conference.startMutedPolicy.video = startVideoMuted;
      updated = true;
    }

    if (updated) {
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["START_MUTED_POLICY_CHANGED"], conference.startMutedPolicy);
    }
  });

  if (conference.statistics) {
    // FIXME ICE related events should end up in RTCEvents eventually
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.CONNECTION_ICE_FAILED, session => {
      conference.statistics.sendIceConnectionFailedEvent(session.peerconnection);
    }); // FIXME XMPPEvents.ADD_ICE_CANDIDATE_FAILED is never emitted

    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.ADD_ICE_CANDIDATE_FAILED, (e, pc) => {
      conference.statistics.sendAddIceCandidateFailed(e, pc);
    });
  }
};
/**
 * Setups event listeners related to conference.rtc
 */


JitsiConferenceEventManager.prototype.setupRTCListeners = function () {
  const conference = this.conference;
  const rtc = conference.rtc;
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.REMOTE_TRACK_ADDED, conference.onRemoteTrackAdded.bind(conference));
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.REMOTE_TRACK_REMOVED, conference.onRemoteTrackRemoved.bind(conference));
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.DOMINANT_SPEAKER_CHANGED, id => {
    if (conference.lastDominantSpeaker !== id && conference.room) {
      conference.lastDominantSpeaker = id;
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["DOMINANT_SPEAKER_CHANGED"], id);

      if (conference.statistics && conference.myUserId() === id) {
        // We are the new dominant speaker.
        conference.statistics.sendDominantSpeakerEvent(conference.room.roomjid);
      }
    }
  });
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.DATA_CHANNEL_OPEN, () => {
    const now = window.performance.now();
    const key = 'data.channel.opened'; // TODO: Move all of the 'connectionTimes' logic to its own module.

    logger.log(`(TIME) ${key}:\t`, now);
    conference.room.connectionTimes[key] = now;
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createConnectionStageReachedEvent"])(key, {
      value: now
    }));
    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["DATA_CHANNEL_OPENED"]);
  });
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.ENDPOINT_MESSAGE_RECEIVED, (from, payload) => {
    const participant = conference.getParticipantById(from);

    if (participant) {
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["ENDPOINT_MESSAGE_RECEIVED"], participant, payload);
    } else {
      logger.warn('Ignored ENDPOINT_MESSAGE_RECEIVED for not existing ' + `participant: ${from}`, payload);
    }
  });
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.LOCAL_UFRAG_CHANGED, (tpc, ufrag) => {
    if (!tpc.isP2P) {
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendLog(JSON.stringify({
        id: 'local_ufrag',
        value: ufrag
      }));
    }
  });
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.REMOTE_UFRAG_CHANGED, (tpc, ufrag) => {
    if (!tpc.isP2P) {
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendLog(JSON.stringify({
        id: 'remote_ufrag',
        value: ufrag
      }));
    }
  });
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.CREATE_ANSWER_FAILED, (e, tpc) => {
    conference.statistics.sendCreateAnswerFailed(e, tpc);

    if (!tpc.isP2P) {
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["OFFER_ANSWER_FAILED"], e);
    }
  });
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.CREATE_OFFER_FAILED, (e, tpc) => {
    conference.statistics.sendCreateOfferFailed(e, tpc);

    if (!tpc.isP2P) {
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["OFFER_ANSWER_FAILED"], e);
    }
  });
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.SET_LOCAL_DESCRIPTION_FAILED, (e, tpc) => {
    conference.statistics.sendSetLocalDescFailed(e, tpc);

    if (!tpc.isP2P) {
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["OFFER_ANSWER_FAILED"], e);
    }
  });
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.SET_REMOTE_DESCRIPTION_FAILED, (e, tpc) => {
    conference.statistics.sendSetRemoteDescFailed(e, tpc);

    if (!tpc.isP2P) {
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_FAILED"], _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__["OFFER_ANSWER_FAILED"], e);
    }
  });
  rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_8___default.a.LOCAL_TRACK_SSRC_UPDATED, (track, ssrc) => {
    // when starting screen sharing, the track is created and when
    // we do set local description and we process the ssrc we
    // will be notified for it and we will report it with the event
    // for screen sharing
    if (track.isVideoTrack() && track.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9___default.a.DESKTOP) {
      conference.statistics.sendScreenSharingEvent(true, ssrc);
    }
  });
};
/**
 * Removes event listeners related to conference.xmpp
 */


JitsiConferenceEventManager.prototype.removeXMPPListeners = function () {
  const conference = this.conference;
  conference.xmpp.caps.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.PARTCIPANT_FEATURES_CHANGED, this.xmppListeners[_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.PARTCIPANT_FEATURES_CHANGED]);
  delete this.xmppListeners[_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.PARTCIPANT_FEATURES_CHANGED];
  Object.keys(this.xmppListeners).forEach(eventName => {
    conference.xmpp.removeListener(eventName, this.xmppListeners[eventName]);
  });
  this.xmppListeners = {};
};
/**
 * Setups event listeners related to conference.xmpp
 */


JitsiConferenceEventManager.prototype.setupXMPPListeners = function () {
  const conference = this.conference;

  const featuresChangedListener = from => {
    const participant = conference.getParticipantById(strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(from));

    if (participant) {
      conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["PARTCIPANT_FEATURES_CHANGED"], participant);
    }
  };

  conference.xmpp.caps.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.PARTCIPANT_FEATURES_CHANGED, featuresChangedListener);
  this.xmppListeners[_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.PARTCIPANT_FEATURES_CHANGED] = featuresChangedListener;

  this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.CALL_INCOMING, conference.onIncomingCall.bind(conference));

  this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.CALL_ACCEPTED, conference.onCallAccepted.bind(conference));

  this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.TRANSPORT_INFO, conference.onTransportInfo.bind(conference));

  this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.CALL_ENDED, conference.onCallEnded.bind(conference));

  this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.START_MUTED_FROM_FOCUS, (audioMuted, videoMuted) => {
    if (conference.options.config.ignoreStartMuted) {
      return;
    }

    conference.startAudioMuted = audioMuted;
    conference.startVideoMuted = videoMuted; // mute existing local tracks because this is initial mute from
    // Jicofo

    conference.getLocalTracks().forEach(track => {
      switch (track.getType()) {
        case _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["AUDIO"]:
          conference.startAudioMuted && track.mute();
          break;

        case _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["VIDEO"]:
          conference.startVideoMuted && track.mute();
          break;
      }
    });
    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["STARTED_MUTED"]);
  });

  this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_11___default.a.CONFERENCE_TIMESTAMP_RECEIVED, createdTimestamp => {
    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["CONFERENCE_CREATED_TIMESTAMP"], createdTimestamp);
  });
};
/**
 * Add XMPP listener and save its reference for remove on leave conference.
 */


JitsiConferenceEventManager.prototype._addConferenceXMPPListener = function (eventName, listener) {
  this.xmppListeners[eventName] = listener;
  this.conference.xmpp.addListener(eventName, listener);
};
/**
 * Setups event listeners related to conference.statistics
 */


JitsiConferenceEventManager.prototype.setupStatisticsListeners = function () {
  const conference = this.conference;

  if (!conference.statistics) {
    return;
  }
  /* eslint-disable max-params */


  conference.statistics.addAudioLevelListener((tpc, ssrc, level, isLocal) => {
    conference.rtc.setAudioLevel(tpc, ssrc, level, isLocal);
  });
  /* eslint-enable max-params */
  // Forward the "before stats disposed" event

  conference.statistics.addBeforeDisposedListener(() => {
    conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_6__["BEFORE_STATISTICS_DISPOSED"]);
  }); // if we are in startSilent mode we will not be sending/receiving so nothing to detect

  if (!conference.options.config.startSilent) {
    conference.statistics.addByteSentStatsListener((tpc, stats) => {
      conference.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["AUDIO"]).forEach(track => {
        const ssrc = tpc.getLocalSSRC(track);

        if (!ssrc || !stats.hasOwnProperty(ssrc)) {
          return;
        }

        track._onByteSentStatsReceived(tpc, stats[ssrc]);
      });
    });
  }
};
/* WEBPACK VAR INJECTION */}.call(this, "JitsiConferenceEventManager.js"))

/***/ }),

/***/ "./JitsiConferenceEvents.js":
/*!**********************************!*\
  !*** ./JitsiConferenceEvents.js ***!
  \**********************************/
/*! exports provided: AUDIO_INPUT_STATE_CHANGE, AUTH_STATUS_CHANGED, AVATAR_CHANGED, BEFORE_STATISTICS_DISPOSED, CONFERENCE_ERROR, CONFERENCE_FAILED, CONFERENCE_JOINED, CONFERENCE_LEFT, CONNECTION_ESTABLISHED, CONNECTION_INTERRUPTED, CONNECTION_RESTORED, DATA_CHANNEL_OPENED, DISPLAY_NAME_CHANGED, DOMINANT_SPEAKER_CHANGED, CONFERENCE_CREATED_TIMESTAMP, DTMF_SUPPORT_CHANGED, ENDPOINT_MESSAGE_RECEIVED, JVB121_STATUS, KICKED, PARTICIPANT_KICKED, LAST_N_ENDPOINTS_CHANGED, LOCK_STATE_CHANGED, SERVER_REGION_CHANGED, MESSAGE_RECEIVED, NO_AUDIO_INPUT, NOISY_MIC, PRIVATE_MESSAGE_RECEIVED, PARTICIPANT_CONN_STATUS_CHANGED, PARTCIPANT_FEATURES_CHANGED, PARTICIPANT_PROPERTY_CHANGED, P2P_STATUS, PHONE_NUMBER_CHANGED, PROPERTIES_CHANGED, RECORDER_STATE_CHANGED, VIDEO_SIP_GW_AVAILABILITY_CHANGED, VIDEO_SIP_GW_SESSION_STATE_CHANGED, START_MUTED_POLICY_CHANGED, STARTED_MUTED, SUBJECT_CHANGED, SUSPEND_DETECTED, TALK_WHILE_MUTED, TRACK_ADDED, TRACK_AUDIO_LEVEL_CHANGED, TRACK_MUTE_CHANGED, TRACK_REMOVED, TRANSCRIPTION_STATUS_CHANGED, USER_JOINED, USER_LEFT, USER_ROLE_CHANGED, USER_STATUS_CHANGED, BOT_TYPE_CHANGED */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AUDIO_INPUT_STATE_CHANGE", function() { return AUDIO_INPUT_STATE_CHANGE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AUTH_STATUS_CHANGED", function() { return AUTH_STATUS_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AVATAR_CHANGED", function() { return AVATAR_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "BEFORE_STATISTICS_DISPOSED", function() { return BEFORE_STATISTICS_DISPOSED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONFERENCE_ERROR", function() { return CONFERENCE_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONFERENCE_FAILED", function() { return CONFERENCE_FAILED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONFERENCE_JOINED", function() { return CONFERENCE_JOINED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONFERENCE_LEFT", function() { return CONFERENCE_LEFT; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_ESTABLISHED", function() { return CONNECTION_ESTABLISHED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_INTERRUPTED", function() { return CONNECTION_INTERRUPTED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_RESTORED", function() { return CONNECTION_RESTORED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DATA_CHANNEL_OPENED", function() { return DATA_CHANNEL_OPENED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DISPLAY_NAME_CHANGED", function() { return DISPLAY_NAME_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DOMINANT_SPEAKER_CHANGED", function() { return DOMINANT_SPEAKER_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONFERENCE_CREATED_TIMESTAMP", function() { return CONFERENCE_CREATED_TIMESTAMP; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DTMF_SUPPORT_CHANGED", function() { return DTMF_SUPPORT_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ENDPOINT_MESSAGE_RECEIVED", function() { return ENDPOINT_MESSAGE_RECEIVED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "JVB121_STATUS", function() { return JVB121_STATUS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "KICKED", function() { return KICKED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PARTICIPANT_KICKED", function() { return PARTICIPANT_KICKED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LAST_N_ENDPOINTS_CHANGED", function() { return LAST_N_ENDPOINTS_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LOCK_STATE_CHANGED", function() { return LOCK_STATE_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SERVER_REGION_CHANGED", function() { return SERVER_REGION_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MESSAGE_RECEIVED", function() { return MESSAGE_RECEIVED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NO_AUDIO_INPUT", function() { return NO_AUDIO_INPUT; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NOISY_MIC", function() { return NOISY_MIC; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PRIVATE_MESSAGE_RECEIVED", function() { return PRIVATE_MESSAGE_RECEIVED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PARTICIPANT_CONN_STATUS_CHANGED", function() { return PARTICIPANT_CONN_STATUS_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PARTCIPANT_FEATURES_CHANGED", function() { return PARTCIPANT_FEATURES_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PARTICIPANT_PROPERTY_CHANGED", function() { return PARTICIPANT_PROPERTY_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "P2P_STATUS", function() { return P2P_STATUS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PHONE_NUMBER_CHANGED", function() { return PHONE_NUMBER_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PROPERTIES_CHANGED", function() { return PROPERTIES_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RECORDER_STATE_CHANGED", function() { return RECORDER_STATE_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VIDEO_SIP_GW_AVAILABILITY_CHANGED", function() { return VIDEO_SIP_GW_AVAILABILITY_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VIDEO_SIP_GW_SESSION_STATE_CHANGED", function() { return VIDEO_SIP_GW_SESSION_STATE_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "START_MUTED_POLICY_CHANGED", function() { return START_MUTED_POLICY_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STARTED_MUTED", function() { return STARTED_MUTED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SUBJECT_CHANGED", function() { return SUBJECT_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SUSPEND_DETECTED", function() { return SUSPEND_DETECTED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TALK_WHILE_MUTED", function() { return TALK_WHILE_MUTED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_ADDED", function() { return TRACK_ADDED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_AUDIO_LEVEL_CHANGED", function() { return TRACK_AUDIO_LEVEL_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_MUTE_CHANGED", function() { return TRACK_MUTE_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_REMOVED", function() { return TRACK_REMOVED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRANSCRIPTION_STATUS_CHANGED", function() { return TRANSCRIPTION_STATUS_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "USER_JOINED", function() { return USER_JOINED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "USER_LEFT", function() { return USER_LEFT; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "USER_ROLE_CHANGED", function() { return USER_ROLE_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "USER_STATUS_CHANGED", function() { return USER_STATUS_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "BOT_TYPE_CHANGED", function() { return BOT_TYPE_CHANGED; });
/**
 * The events for the conference.
 */

/**
 * Event indicates that the current conference audio input switched between audio
 * input states,i.e. with or without audio input.
 */
const AUDIO_INPUT_STATE_CHANGE = 'conference.audio_input_state_changed';
/**
 * Indicates that authentication status changed.
 */

const AUTH_STATUS_CHANGED = 'conference.auth_status_changed';
/**
 * A participant avatar has changed.
 */

const AVATAR_CHANGED = 'conference.avatarChanged';
/**
 * Fired just before the statistics module is disposed and it's the last chance
 * to submit some logs to the statistics service (ex. CallStats if enabled),
 * before it's disconnected.
 */

const BEFORE_STATISTICS_DISPOSED = 'conference.beforeStatisticsDisposed';
/**
 * Indicates that an error occured.
 */

const CONFERENCE_ERROR = 'conference.error';
/**
 * Indicates that conference failed.
 */

const CONFERENCE_FAILED = 'conference.failed';
/**
 * Indicates that conference has been joined. The event does NOT provide any
 * parameters to its listeners.
 */

const CONFERENCE_JOINED = 'conference.joined';
/**
 * Indicates that conference has been left.
 */

const CONFERENCE_LEFT = 'conference.left';
/**
 * Indicates that the connection to the conference has been established
 * XXX This is currently fired whenVthe *ICE* connection enters 'connected'
 * state for the first time.
 */

const CONNECTION_ESTABLISHED = 'conference.connectionEstablished';
/**
 * Indicates that the connection to the conference has been interrupted for some
 * reason.
 * XXX This is currently fired when the *ICE* connection is interrupted.
 */

const CONNECTION_INTERRUPTED = 'conference.connectionInterrupted';
/**
 * Indicates that the connection to the conference has been restored.
 * XXX This is currently fired when the *ICE* connection is restored.
 */

const CONNECTION_RESTORED = 'conference.connectionRestored';
/**
 * A connection to the video bridge's data channel has been established.
 */

const DATA_CHANNEL_OPENED = 'conference.dataChannelOpened';
/**
 * A user has changed it display name
 */

const DISPLAY_NAME_CHANGED = 'conference.displayNameChanged';
/**
 * The dominant speaker was changed.
 */

const DOMINANT_SPEAKER_CHANGED = 'conference.dominantSpeaker';
/**
 * UTC conference timestamp when first participant joined.
 */

const CONFERENCE_CREATED_TIMESTAMP = 'conference.createdTimestamp';
/**
 * Indicates that DTMF support changed.
 */

const DTMF_SUPPORT_CHANGED = 'conference.dtmfSupportChanged';
/**
 * Indicates that a message from another participant is received on data
 * channel.
 */

const ENDPOINT_MESSAGE_RECEIVED = 'conference.endpoint_message_received';
/**
 * NOTE This is lib-jitsi-meet internal event and can be removed at any time !
 *
 * Event emitted when conference transits, between one to one and multiparty JVB
 * conference. If the conference switches to P2P it's neither one to one nor
 * a multiparty JVB conference, but P2P (the status argument of this event will
 * be <tt>false</tt>).
 *
 * The first argument is a boolean which carries the previous value and
 * the seconds argument is a boolean with the new status. The event is emitted
 * only if the previous and the new values are different.
 *
 * @type {string}
 */

const JVB121_STATUS = 'conference.jvb121Status';
/**
 * You are kicked from the conference.
 * @param {JitsiParticipant} the participant that initiated the kick.
 */

const KICKED = 'conference.kicked';
/**
 * Participant was kicked from the conference.
 * @param {JitsiParticipant} the participant that initiated the kick.
 * @param {JitsiParticipant} the participant that was kicked.
 */

const PARTICIPANT_KICKED = 'conference.participant_kicked';
/**
 * The Last N set is changed.
 *
 * @param {Array<string>|null} leavingEndpointIds the ids of all the endpoints
 * which are leaving Last N
 * @param {Array<string>|null} enteringEndpointIds the ids of all the endpoints
 * which are entering Last N
 */

const LAST_N_ENDPOINTS_CHANGED = 'conference.lastNEndpointsChanged';
/**
 * Indicates that the room has been locked or unlocked.
 */

const LOCK_STATE_CHANGED = 'conference.lock_state_changed';
/**
 * Indicates that the region of the media server (jitsi-videobridge) that we
 * are connected to changed (or was initially set).
 * @type {string} the region.
 */

const SERVER_REGION_CHANGED = 'conference.server_region_changed';
/**
 * New text message was received.
 */

const MESSAGE_RECEIVED = 'conference.messageReceived';
/**
 * Event indicates that the current selected input device has no signal
 */

const NO_AUDIO_INPUT = 'conference.no_audio_input';
/**
 * Event indicates that the current microphone used by the conference is noisy.
 */

const NOISY_MIC = 'conference.noisy_mic';
/**
 * New private text message was received.
 */

const PRIVATE_MESSAGE_RECEIVED = 'conference.privateMessageReceived';
/**
 * Event fired when JVB sends notification about interrupted/restored user's
 * ICE connection status or we detect local problem with the video track.
 * First argument is the ID of the participant and
 * the seconds is a string indicating if the connection is currently
 * - active - the connection is active
 * - inactive - the connection is inactive, was intentionally interrupted by
 * the bridge
 * - interrupted - a network problem occurred
 * - restoring - the connection was inactive and is restoring now
 *
 * The current status value can be obtained by calling
 * JitsiParticipant.getConnectionStatus().
 */

const PARTICIPANT_CONN_STATUS_CHANGED = 'conference.participant_conn_status_changed';
/**
 * Indicates that the features of the participant has been changed.
 */

const PARTCIPANT_FEATURES_CHANGED = 'conference.partcipant_features_changed';
/**
 * Indicates that a the value of a specific property of a specific participant
 * has changed.
 */

const PARTICIPANT_PROPERTY_CHANGED = 'conference.participant_property_changed';
/**
 * Indicates that the conference has switched between JVB and P2P connections.
 * The first argument of this event is a <tt>boolean</tt> which when set to
 * <tt>true</tt> means that the conference is running on the P2P connection.
 */

const P2P_STATUS = 'conference.p2pStatus';
/**
 * Indicates that phone number changed.
 */

const PHONE_NUMBER_CHANGED = 'conference.phoneNumberChanged';
/**
 * The conference properties changed.
 * @type {string}
 */

const PROPERTIES_CHANGED = 'conference.propertiesChanged';
/**
 * Indicates that recording state changed.
 */

const RECORDER_STATE_CHANGED = 'conference.recorderStateChanged';
/**
 * Indicates that video SIP GW state changed.
 * @param {VideoSIPGWConstants} status.
 */

const VIDEO_SIP_GW_AVAILABILITY_CHANGED = 'conference.videoSIPGWAvailabilityChanged';
/**
 * Indicates that video SIP GW Session state changed.
 * @param {options} event - {
 *     {string} address,
 *     {VideoSIPGWConstants} oldState,
 *     {VideoSIPGWConstants} newState,
 *     {string} displayName}
 * }.
 */

const VIDEO_SIP_GW_SESSION_STATE_CHANGED = 'conference.videoSIPGWSessionStateChanged';
/**
 * Indicates that start muted settings changed.
 */

const START_MUTED_POLICY_CHANGED = 'conference.start_muted_policy_changed';
/**
 * Indicates that the local user has started muted.
 */

const STARTED_MUTED = 'conference.started_muted';
/**
 * Indicates that subject of the conference has changed.
 */

const SUBJECT_CHANGED = 'conference.subjectChanged';
/**
 * Indicates that DTMF support changed.
 */

const SUSPEND_DETECTED = 'conference.suspendDetected';
/**
 * Event indicates that local user is talking while he muted himself
 */

const TALK_WHILE_MUTED = 'conference.talk_while_muted';
/**
 * A new media track was added to the conference. The event provides the
 * following parameters to its listeners:
 *
 * @param {JitsiTrack} track the added JitsiTrack
 */

const TRACK_ADDED = 'conference.trackAdded';
/**
 * Audio levels of a media track ( attached to the conference) was changed.
 */

const TRACK_AUDIO_LEVEL_CHANGED = 'conference.audioLevelsChanged';
/**
 * A media track ( attached to the conference) mute status was changed.
 * @param {JitsiParticipant|null} the participant that initiated the mute
 * if it is a remote mute.
 */

const TRACK_MUTE_CHANGED = 'conference.trackMuteChanged';
/**
 * The media track was removed from the conference. The event provides the
 * following parameters to its listeners:
 *
 * @param {JitsiTrack} track the removed JitsiTrack
 */

const TRACK_REMOVED = 'conference.trackRemoved';
/**
 * Notifies for transcription status changes. The event provides the
 * following parameters to its listeners:
 *
 * @param {String} status - The new status.
 */

const TRANSCRIPTION_STATUS_CHANGED = 'conference.transcriptionStatusChanged';
/**
 * A new user joined the conference.
 */

const USER_JOINED = 'conference.userJoined';
/**
 * A user has left the conference.
 */

const USER_LEFT = 'conference.userLeft';
/**
 * User role changed.
 */

const USER_ROLE_CHANGED = 'conference.roleChanged';
/**
 * User status changed.
 */

const USER_STATUS_CHANGED = 'conference.statusChanged';
/**
 * Event indicates that the bot participant type changed.
 */

const BOT_TYPE_CHANGED = 'conference.bot_type_changed';

/***/ }),

/***/ "./JitsiConnection.js":
/*!****************************!*\
  !*** ./JitsiConnection.js ***!
  \****************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JitsiConnection; });
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _JitsiConference__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./JitsiConference */ "./JitsiConference.js");
/* harmony import */ var _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./JitsiConnectionEvents */ "./JitsiConnectionEvents.js");
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./modules/xmpp/xmpp */ "./modules/xmpp/xmpp.js");





/**
 * Creates a new connection object for the Jitsi Meet server side video
 * conferencing service. Provides access to the JitsiConference interface.
 * @param appID identification for the provider of Jitsi Meet video conferencing
 * services.
 * @param token the JWT token used to authenticate with the server(optional)
 * @param options Object with properties / settings related to connection with
 * the server.
 * @constructor
 */

function JitsiConnection(appID, token, options) {
  this.appID = appID;
  this.token = token;
  this.options = options;
  this.xmpp = new _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_4__["default"](options, token);
  /* eslint-disable max-params */

  this.addEventListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_2__["CONNECTION_FAILED"], (errType, msg, credentials, details) => {
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_3__["default"].sendAnalyticsAndLog(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["createConnectionFailedEvent"])(errType, msg, details));
  });
  /* eslint-enable max-params */

  this.addEventListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_2__["CONNECTION_DISCONNECTED"], msg => {
    // we can see disconnects from normal tab closing of the browser
    // and then there are no msgs, but we want to log only disconnects
    // when there is real error
    // XXX Do we need the difference in handling between the log and
    // analytics event here?
    if (msg) {
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_3__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["CONNECTION_DISCONNECTED"], {
        message: msg
      });
    }

    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_3__["default"].sendLog(JSON.stringify({
      id: _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["CONNECTION_DISCONNECTED"],
      msg
    }));
  });
}
/**
 * Connect the client with the server.
 * @param options {object} connecting options
 * (for example authentications parameters).
 */

JitsiConnection.prototype.connect = function (options = {}) {
  this.xmpp.connect(options.id, options.password);
};
/**
 * Attach to existing connection. Can be used for optimizations. For example:
 * if the connection is created on the server we can attach to it and start
 * using it.
 *
 * @param options {object} connecting options - rid, sid and jid.
 */


JitsiConnection.prototype.attach = function (options) {
  this.xmpp.attach(options);
};
/**
 * Disconnect the client from the server.
 * @returns {Promise} - Resolves when the disconnect process is finished or rejects with an error.
 */


JitsiConnection.prototype.disconnect = function (...args) {
  // XXX Forward any arguments passed to JitsiConnection.disconnect to
  // XMPP.disconnect. For example, the caller of JitsiConnection.disconnect
  // may optionally pass the event which triggered the disconnect in order to
  // provide the implementation with finer-grained context.
  return this.xmpp.disconnect(...args);
};
/**
 * Returns the jid of the participant associated with the XMPP connection.
 *
 * @returns {string} The jid of the participant.
 */


JitsiConnection.prototype.getJid = function () {
  return this.xmpp.getJid();
};
/**
 * This method allows renewal of the tokens if they are expiring.
 * @param token the new token.
 */


JitsiConnection.prototype.setToken = function (token) {
  this.token = token;
};
/**
 * Creates and joins new conference.
 * @param name the name of the conference; if null - a generated name will be
 * provided from the api
 * @param options Object with properties / settings related to the conference
 * that will be created.
 * @returns {JitsiConference} returns the new conference object.
 */


JitsiConnection.prototype.initJitsiConference = function (name, options) {
  return new _JitsiConference__WEBPACK_IMPORTED_MODULE_1__["default"]({
    name,
    config: options,
    connection: this
  });
};
/**
 * Subscribes the passed listener to the event.
 * @param event {JitsiConnectionEvents} the connection event.
 * @param listener {Function} the function that will receive the event
 */


JitsiConnection.prototype.addEventListener = function (event, listener) {
  this.xmpp.addListener(event, listener);
};
/**
 * Unsubscribes the passed handler.
 * @param event {JitsiConnectionEvents} the connection event.
 * @param listener {Function} the function that will receive the event
 */


JitsiConnection.prototype.removeEventListener = function (event, listener) {
  this.xmpp.removeListener(event, listener);
};
/**
 * Returns measured connectionTimes.
 */


JitsiConnection.prototype.getConnectionTimes = function () {
  return this.xmpp.connectionTimes;
};
/**
 * Adds new feature to the list of supported features for the local
 * participant.
 * @param {String} feature the name of the feature.
 * @param {boolean} submit if true - the new list of features will be
 * immediately submitted to the others.
 */


JitsiConnection.prototype.addFeature = function (feature, submit = false) {
  return this.xmpp.caps.addFeature(feature, submit);
};
/**
 * Removes a feature from the list of supported features for the local
 * participant
 * @param {String} feature the name of the feature.
 * @param {boolean} submit if true - the new list of features will be
 * immediately submitted to the others.
 */


JitsiConnection.prototype.removeFeature = function (feature, submit = false) {
  return this.xmpp.caps.removeFeature(feature, submit);
};

/***/ }),

/***/ "./JitsiConnectionErrors.js":
/*!**********************************!*\
  !*** ./JitsiConnectionErrors.js ***!
  \**********************************/
/*! exports provided: CONNECTION_DROPPED_ERROR, OTHER_ERROR, PASSWORD_REQUIRED, SERVER_ERROR */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_DROPPED_ERROR", function() { return CONNECTION_DROPPED_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OTHER_ERROR", function() { return OTHER_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PASSWORD_REQUIRED", function() { return PASSWORD_REQUIRED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SERVER_ERROR", function() { return SERVER_ERROR; });
/**
 * The errors for the connection.
 */

/**
 * Indicates that the connection was dropped with an error which was most likely
 * caused by some networking issues. The dropped term in this context means that
 * the connection was closed unexpectedly (not on user's request).
 *
 * One example is 'item-not-found' error thrown by Prosody when the BOSH session
 * times out after 60 seconds of inactivity. On the other hand 'item-not-found'
 * could also happen when BOSH request is sent to the server with the session-id
 * that is not know to the server. But this should not happen in lib-jitsi-meet
 * case as long as the service is configured correctly (there is no bug).
 */
const CONNECTION_DROPPED_ERROR = 'connection.droppedError';
/**
 * Not specified errors.
 */

const OTHER_ERROR = 'connection.otherError';
/**
 * Indicates that a password is required in order to join the conference.
 */

const PASSWORD_REQUIRED = 'connection.passwordRequired';
/**
 * Indicates that the connection was dropped, because of too many 5xx HTTP
 * errors on BOSH requests.
 */

const SERVER_ERROR = 'connection.serverError';

/***/ }),

/***/ "./JitsiConnectionEvents.js":
/*!**********************************!*\
  !*** ./JitsiConnectionEvents.js ***!
  \**********************************/
/*! exports provided: CONNECTION_DISCONNECTED, CONNECTION_ESTABLISHED, CONNECTION_FAILED, WRONG_STATE */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_DISCONNECTED", function() { return CONNECTION_DISCONNECTED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_ESTABLISHED", function() { return CONNECTION_ESTABLISHED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_FAILED", function() { return CONNECTION_FAILED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "WRONG_STATE", function() { return WRONG_STATE; });
/**
 * The events for the connection.
 */

/**
 * Indicates that the connection has been disconnected. The event provides
 * the following parameters to its listeners:
 *
 * @param msg {string} a message associated with the disconnect such as the
 * last (known) error message
 */
const CONNECTION_DISCONNECTED = 'connection.connectionDisconnected';
/**
 * Indicates that the connection has been established. The event provides
 * the following parameters to its listeners:
 *
 * @param id {string} the ID of the local endpoint/participant/peer (within
 * the context of the established connection)
 */

const CONNECTION_ESTABLISHED = 'connection.connectionEstablished';
/**
 * Indicates that the connection has been failed for some reason. The event
 * provides the following parameters to its listeners:
 *
 * @param errType {JitsiConnectionErrors} the type of error associated with
 * the failure
 * @param errReason {string} the error (message) associated with the failure
 * @param credentials {object} the credentials used to connect (if any)
 * @param errReasonDetails {object} an optional object with details about
 * the error, like shard moving, suspending. Used for analytics purposes.
 */

const CONNECTION_FAILED = 'connection.connectionFailed';
/**
 * Indicates that the performed action cannot be executed because the
 * connection is not in the correct state(connected, disconnected, etc.)
 */

const WRONG_STATE = 'connection.wrongState';

/***/ }),

/***/ "./JitsiMediaDevices.js":
/*!******************************!*\
  !*** ./JitsiMediaDevices.js ***!
  \******************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _modules_browser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./modules/browser */ "./modules/browser/index.js");
/* harmony import */ var _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./modules/RTC/RTC */ "./modules/RTC/RTC.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4__);
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./JitsiMediaDevicesEvents */ "./JitsiMediaDevicesEvents.js");
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }








const AUDIO_PERMISSION_NAME = 'microphone';
const PERMISSION_GRANTED_STATUS = 'granted';
const VIDEO_PERMISSION_NAME = 'camera';
/**
 * Media devices utilities for Jitsi.
 */

class JitsiMediaDevices {
  /**
   * Initializes a {@code JitsiMediaDevices} object. There will be a single
   * instance of this class.
   */
  constructor() {
    this._eventEmitter = new events__WEBPACK_IMPORTED_MODULE_0___default.a();
    this._grantedPermissions = {};
    _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4___default.a.DEVICE_LIST_CHANGED, devices => this._eventEmitter.emit(_JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_6__["DEVICE_LIST_CHANGED"], devices));
    _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4___default.a.DEVICE_LIST_AVAILABLE, devices => this._logOutputDevice(this.getAudioOutputDevice(), devices));
    _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4___default.a.GRANTED_PERMISSIONS, grantedPermissions => this._handleGrantedPermissions(grantedPermissions)); // Test if the W3C Permissions API is implemented and the 'camera' and
    // 'microphone' permissions are implemented. (Testing for at least one
    // of them seems sufficient).

    this._permissionsApiSupported = new Promise(resolve => {
      if (!navigator.permissions) {
        resolve(false);
        return;
      }

      navigator.permissions.query({
        name: VIDEO_PERMISSION_NAME
      }).then(() => resolve(true), () => resolve(false));
    });
  }
  /**
   * Updated the local granted permissions cache. A permissions might be
   * granted, denied, or undefined. This is represented by having its media
   * type key set to {@code true} or {@code false} respectively.
   *
   * @param {Object} grantedPermissions - Array with the permissions
   * which were granted.
   */


  _handleGrantedPermissions(grantedPermissions) {
    this._grantedPermissions = _objectSpread({}, this._grantedPermissions, grantedPermissions);
  }
  /**
   * Gathers data and sends it to statistics.
   * @param deviceID the device id to log
   * @param devices list of devices
   */


  _logOutputDevice(deviceID, devices) {
    const device = devices.find(d => d.kind === 'audiooutput' && d.deviceId === deviceID);

    if (device) {
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_5__["default"].sendActiveDeviceListEvent(_modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].getEventDataForActiveDevice(device));
    }
  }
  /**
   * Executes callback with list of media devices connected.
   * @param {function} callback
   */


  enumerateDevices(callback) {
    _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].enumerateDevices(callback);
  }
  /**
   * Checks if its possible to enumerate available cameras/micropones.
   * @returns {Promise<boolean>} a Promise which will be resolved only once
   * the WebRTC stack is ready, either with true if the device listing is
   * available available or with false otherwise.
   */


  isDeviceListAvailable() {
    return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].isDeviceListAvailable();
  }
  /**
   * Returns true if changing the input (camera / microphone) or output
   * (audio) device is supported and false if not.
   * @param {string} [deviceType] - type of device to change. Default is
   *      undefined or 'input', 'output' - for audio output device change.
   * @returns {boolean} true if available, false otherwise.
   */


  isDeviceChangeAvailable(deviceType) {
    return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].isDeviceChangeAvailable(deviceType);
  }
  /**
   * Checks if the permission for the given device was granted.
   *
   * @param {'audio'|'video'} [type] - type of devices to check,
   *      undefined stands for both 'audio' and 'video' together
   * @returns {Promise<boolean>}
   */


  isDevicePermissionGranted(type) {
    return new Promise(resolve => {
      // Shortcut: first check if we already know the permission was
      // granted.
      if (type in this._grantedPermissions) {
        resolve(this._grantedPermissions[type]);
        return;
      } // Check using the Permissions API.


      this._permissionsApiSupported.then(supported => {
        if (!supported) {
          resolve(false);
          return;
        }

        const promises = [];

        switch (type) {
          case _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__["VIDEO"]:
            promises.push(navigator.permissions.query({
              name: VIDEO_PERMISSION_NAME
            }));
            break;

          case _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__["AUDIO"]:
            promises.push(navigator.permissions.query({
              name: AUDIO_PERMISSION_NAME
            }));
            break;

          default:
            promises.push(navigator.permissions.query({
              name: VIDEO_PERMISSION_NAME
            }));
            promises.push(navigator.permissions.query({
              name: AUDIO_PERMISSION_NAME
            }));
        }

        Promise.all(promises).then(results => resolve(results.every(permissionStatus => {
          // The status attribute is deprecated, and state
          // should be used instead, but check both for now
          // for backwards compatibility.
          const grantStatus = permissionStatus.state || permissionStatus.status;
          return grantStatus === PERMISSION_GRANTED_STATUS;
        })), () => resolve(false));
      });
    });
  }
  /**
   * Returns true if it is possible to be simultaneously capturing audio
   * from more than one device.
   *
   * @returns {boolean}
   */


  isMultipleAudioInputSupported() {
    return !_modules_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isFirefox();
  }
  /**
   * Returns currently used audio output device id, 'default' stands
   * for default device
   * @returns {string}
   */


  getAudioOutputDevice() {
    return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].getAudioOutputDevice();
  }
  /**
   * Sets current audio output device.
   * @param {string} deviceId - id of 'audiooutput' device from
   *      navigator.mediaDevices.enumerateDevices(), 'default' is for
   *      default device
   * @returns {Promise} - resolves when audio output is changed, is rejected
   *      otherwise
   */


  setAudioOutputDevice(deviceId) {
    const availableDevices = _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].getCurrentlyAvailableMediaDevices();

    if (availableDevices && availableDevices.length > 0) {
      // if we have devices info report device to stats
      // normally this will not happen on startup as this method is called
      // too early. This will happen only on user selection of new device
      this._logOutputDevice(deviceId, _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].getCurrentlyAvailableMediaDevices());
    }

    return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"].setAudioOutputDevice(deviceId);
  }
  /**
   * Adds an event handler.
   * @param {string} event - event name
   * @param {function} handler - event handler
   */


  addEventListener(event, handler) {
    this._eventEmitter.addListener(event, handler);
  }
  /**
   * Removes event handler.
   * @param {string} event - event name
   * @param {function} handler - event handler
   */


  removeEventListener(event, handler) {
    this._eventEmitter.removeListener(event, handler);
  }
  /**
   * Emits an event.
   * @param {string} event - event name
   */


  emitEvent(event, ...args) {
    this._eventEmitter.emit(event, ...args);
  }
  /**
   * Returns whether or not the current browser can support capturing video,
   * be it camera or desktop, and displaying received video.
   *
   * @returns {boolean}
   */


  supportsVideo() {
    // Defer to the browser capabilities to allow exposure of the api to the
    // consumer but prevent other files from having to import
    // JitsiMediaDevices.
    return _modules_browser__WEBPACK_IMPORTED_MODULE_2__["default"].supportsVideo();
  }

}

/* harmony default export */ __webpack_exports__["default"] = (new JitsiMediaDevices());

/***/ }),

/***/ "./JitsiMediaDevicesEvents.js":
/*!************************************!*\
  !*** ./JitsiMediaDevicesEvents.js ***!
  \************************************/
/*! exports provided: DEVICE_LIST_CHANGED, PERMISSION_PROMPT_IS_SHOWN */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DEVICE_LIST_CHANGED", function() { return DEVICE_LIST_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PERMISSION_PROMPT_IS_SHOWN", function() { return PERMISSION_PROMPT_IS_SHOWN; });
/**
 * The events for the media devices.
 */

/**
 * Indicates that the list of available media devices has been changed. The
 * event provides the following parameters to its listeners:
 *
 * @param {MediaDeviceInfo[]} devices - array of MediaDeviceInfo or
 *  MediaDeviceInfo-like objects that are currently connected.
 *  @see https://developer.mozilla.org/en-US/docs/Web/API/MediaDeviceInfo
 */
const DEVICE_LIST_CHANGED = 'mediaDevices.devicechange';
/**
 * Indicates that the environment is currently showing permission prompt to
 * access camera and/or microphone. The event provides the following
 * parameters to its listeners:
 *
 * @param {'chrome'|'opera'|'firefox'|'safari'|'nwjs'
 *  |'react-native'|'android'} environmentType - type of browser or
 *  other execution environment.
 */

const PERMISSION_PROMPT_IS_SHOWN = 'mediaDevices.permissionPromptIsShown';

/***/ }),

/***/ "./JitsiMeetJS.js":
/*!************************!*\
  !*** ./JitsiMeetJS.js ***!
  \************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony import */ var _modules_detection_ActiveDeviceDetector__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./modules/detection/ActiveDeviceDetector */ "./modules/detection/ActiveDeviceDetector.js");
/* harmony import */ var _modules_webaudio_AudioMixer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./modules/webaudio/AudioMixer */ "./modules/webaudio/AudioMixer.js");
/* harmony import */ var _modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./modules/detection/DetectionEvents */ "./modules/detection/DetectionEvents.js");
/* harmony import */ var _modules_detection_TrackVADEmitter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./modules/detection/TrackVADEmitter */ "./modules/detection/TrackVADEmitter.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _modules_util_AuthUtil__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./modules/util/AuthUtil */ "./modules/util/AuthUtil.js");
/* harmony import */ var _modules_util_AuthUtil__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(_modules_util_AuthUtil__WEBPACK_IMPORTED_MODULE_5__);
/* harmony import */ var _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./service/connectivity/ConnectionQualityEvents */ "./service/connectivity/ConnectionQualityEvents.js");
/* harmony import */ var _service_e2eping_E2ePingEvents__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./service/e2eping/E2ePingEvents */ "./service/e2eping/E2ePingEvents.js");
/* harmony import */ var _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./modules/util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8___default = /*#__PURE__*/__webpack_require__.n(_modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8__);
/* harmony import */ var _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./JitsiConferenceErrors */ "./JitsiConferenceErrors.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _JitsiConnection__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./JitsiConnection */ "./JitsiConnection.js");
/* harmony import */ var _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./JitsiConnectionErrors */ "./JitsiConnectionErrors.js");
/* harmony import */ var _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./JitsiConnectionEvents */ "./JitsiConnectionEvents.js");
/* harmony import */ var _JitsiMediaDevices__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./JitsiMediaDevices */ "./JitsiMediaDevices.js");
/* harmony import */ var _JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./JitsiMediaDevicesEvents */ "./JitsiMediaDevicesEvents.js");
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./JitsiTrackError */ "./JitsiTrackError.js");
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./JitsiTrackErrors */ "./JitsiTrackErrors.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./JitsiTrackEvents */ "./JitsiTrackEvents.js");
/* harmony import */ var _JitsiTranscriptionStatus__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./JitsiTranscriptionStatus */ "./JitsiTranscriptionStatus.js");
/* harmony import */ var _modules_statistics_LocalStatsCollector__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./modules/statistics/LocalStatsCollector */ "./modules/statistics/LocalStatsCollector.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./service/RTC/Resolutions */ "./service/RTC/Resolutions.js");
/* harmony import */ var _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_23___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_23__);
/* harmony import */ var _modules_connectivity_ParticipantConnectionStatus__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./modules/connectivity/ParticipantConnectionStatus */ "./modules/connectivity/ParticipantConnectionStatus.js");
/* harmony import */ var _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./modules/RTC/RTC */ "./modules/RTC/RTC.js");
/* harmony import */ var _modules_browser__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./modules/browser */ "./modules/browser/index.js");
/* harmony import */ var _modules_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./modules/util/ScriptUtil */ "./modules/util/ScriptUtil.js");
/* harmony import */ var _modules_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_27___default = /*#__PURE__*/__webpack_require__.n(_modules_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_27__);
/* harmony import */ var _modules_recording_recordingConstants__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./modules/recording/recordingConstants */ "./modules/recording/recordingConstants.js");
/* harmony import */ var _modules_proxyconnection_ProxyConnectionService__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./modules/proxyconnection/ProxyConnectionService */ "./modules/proxyconnection/ProxyConnectionService.js");
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _modules_videosipgw_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./modules/videosipgw/VideoSIPGWConstants */ "./modules/videosipgw/VideoSIPGWConstants.js");
/* global __filename */
































const logger = jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21___default.a.getLogger(__filename);
/**
 * The amount of time to wait until firing
 * {@link JitsiMediaDevicesEvents.PERMISSION_PROMPT_IS_SHOWN} event.
 */

const USER_MEDIA_PERMISSION_PROMPT_TIMEOUT = 1000;
/**
 * Gets the next lowest desirable resolution to try for a camera. If the given
 * resolution is already the lowest acceptable resolution, returns {@code null}.
 *
 * @param resolution the current resolution
 * @return the next lowest resolution from the given one, or {@code null} if it
 * is already the lowest acceptable resolution.
 */

function getLowerResolution(resolution) {
  if (!_service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_23___default.a[resolution]) {
    return null;
  }

  const order = _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_23___default.a[resolution].order;
  let res = null;
  let resName = null;
  Object.keys(_service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_23___default.a).forEach(r => {
    const value = _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_23___default.a[r];

    if (!res || res.order < value.order && value.order < order) {
      resName = r;
      res = value;
    }
  });

  if (resName === resolution) {
    resName = null;
  }

  return resName;
}
/**
 * Extracts from an 'options' objects with a specific format (TODO what IS the
 * format?) the attributes which are to be logged in analytics events.
 *
 * @param options gum options (???)
 * @returns {*} the attributes to attach to analytics events.
 */


function getAnalyticsAttributesFromOptions(options) {
  const attributes = {
    'audio_requested': options.devices.includes('audio'),
    'video_requested': options.devices.includes('video'),
    'screen_sharing_requested': options.devices.includes('desktop')
  };

  if (attributes.video_requested) {
    attributes.resolution = options.resolution;
  }

  return attributes;
}
/**
 * Tries to deal with the following problem: {@code JitsiMeetJS} is not only
 * this module, it's also a global (i.e. attached to {@code window}) namespace
 * for all globals of the projects in the Jitsi Meet family. If lib-jitsi-meet
 * is loaded through an HTML {@code script} tag, {@code JitsiMeetJS} will
 * automatically be attached to {@code window} by webpack. Unfortunately,
 * webpack's source code does not check whether the global variable has already
 * been assigned and overwrites it. Which is OK for the module
 * {@code JitsiMeetJS} but is not OK for the namespace {@code JitsiMeetJS}
 * because it may already contain the values of other projects in the Jitsi Meet
 * family. The solution offered here works around webpack by merging all
 * existing values of the namespace {@code JitsiMeetJS} into the module
 * {@code JitsiMeetJS}.
 *
 * @param {Object} module - The module {@code JitsiMeetJS} (which will be
 * exported and may be attached to {@code window} by webpack later on).
 * @private
 * @returns {Object} - A {@code JitsiMeetJS} module which contains all existing
 * value of the namespace {@code JitsiMeetJS} (if any).
 */


function _mergeNamespaceAndModule(module) {
  return typeof window.JitsiMeetJS === 'object' ? Object.assign({}, window.JitsiMeetJS, module) : module;
}
/**
 * The public API of the Jitsi Meet library (a.k.a. {@code JitsiMeetJS}).
 */


/* harmony default export */ __webpack_exports__["default"] = (_mergeNamespaceAndModule({
  version: '{#COMMIT_HASH#}',
  JitsiConnection: _JitsiConnection__WEBPACK_IMPORTED_MODULE_11__["default"],

  /**
   * {@code ProxyConnectionService} is used to connect a remote peer to a
   * local Jitsi participant without going through a Jitsi conference. It is
   * currently used for room integration development, specifically wireless
   * screensharing. Its API is experimental and will likely change; usage of
   * it is advised against.
   */
  ProxyConnectionService: _modules_proxyconnection_ProxyConnectionService__WEBPACK_IMPORTED_MODULE_29__["default"],
  constants: {
    participantConnectionStatus: _modules_connectivity_ParticipantConnectionStatus__WEBPACK_IMPORTED_MODULE_24__["ParticipantConnectionStatus"],
    recording: _modules_recording_recordingConstants__WEBPACK_IMPORTED_MODULE_28__["default"],
    sipVideoGW: _modules_videosipgw_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_31__,
    transcriptionStatus: _JitsiTranscriptionStatus__WEBPACK_IMPORTED_MODULE_19__
  },
  events: {
    conference: _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_10__,
    connection: _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_13__,
    detection: _modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__,
    track: _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_18__,
    mediaDevices: _JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_15__,
    connectionQuality: _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_6__,
    e2eping: _service_e2eping_E2ePingEvents__WEBPACK_IMPORTED_MODULE_7__
  },
  errors: {
    conference: _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_9__,
    connection: _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_12__,
    track: _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_17__
  },
  errorTypes: {
    JitsiTrackError: _JitsiTrackError__WEBPACK_IMPORTED_MODULE_16__["default"]
  },
  logLevels: jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21___default.a.levels,
  mediaDevices: _JitsiMediaDevices__WEBPACK_IMPORTED_MODULE_14__["default"],
  analytics: _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].analytics,

  init(options = {}) {
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].init(options); // Initialize global window.connectionTimes
    // FIXME do not use 'window'

    if (!window.connectionTimes) {
      window.connectionTimes = {};
    }

    if (options.enableAnalyticsLogging !== true) {
      logger.warn('Analytics disabled, disposing.');
      this.analytics.dispose();
    }

    if (options.enableWindowOnErrorHandler) {
      _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8___default.a.addHandler(this.getGlobalOnErrorHandler.bind(this));
    } // Log deployment-specific information, if available. Defined outside
    // the application by individual deployments


    const aprops = options.deploymentInfo;

    if (aprops && Object.keys(aprops).length > 0) {
      const logObject = {};

      for (const attr in aprops) {
        if (aprops.hasOwnProperty(attr)) {
          logObject[attr] = aprops[attr];
        }
      }

      logObject.id = 'deployment_info';
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendLog(JSON.stringify(logObject));
    }

    if (this.version) {
      const logObject = {
        id: 'component_version',
        component: 'lib-jitsi-meet',
        version: this.version
      };
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendLog(JSON.stringify(logObject));
    }

    return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_25__["default"].init(options);
  },

  /**
   * Returns whether the desktop sharing is enabled or not.
   *
   * @returns {boolean}
   */
  isDesktopSharingEnabled() {
    return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_25__["default"].isDesktopSharingEnabled();
  },

  /**
   * Returns whether the current execution environment supports WebRTC (for
   * use within this library).
   *
   * @returns {boolean} {@code true} if WebRTC is supported in the current
   * execution environment (for use within this library); {@code false},
   * otherwise.
   */
  isWebRtcSupported() {
    return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_25__["default"].isWebRtcSupported();
  },

  setLogLevel(level) {
    jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21___default.a.setLogLevel(level);
  },

  /**
   * Sets the log level to the <tt>Logger</tt> instance with given id.
   *
   * @param {Logger.levels} level the logging level to be set
   * @param {string} id the logger id to which new logging level will be set.
   * Usually it's the name of the JavaScript source file including the path
   * ex. "modules/xmpp/ChatRoom.js"
   */
  setLogLevelById(level, id) {
    jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21___default.a.setLogLevelById(level, id);
  },

  /**
   * Registers new global logger transport to the library logging framework.
   *
   * @param globalTransport
   * @see Logger.addGlobalTransport
   */
  addGlobalLogTransport(globalTransport) {
    jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21___default.a.addGlobalTransport(globalTransport);
  },

  /**
   * Removes global logging transport from the library logging framework.
   *
   * @param globalTransport
   * @see Logger.removeGlobalTransport
   */
  removeGlobalLogTransport(globalTransport) {
    jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21___default.a.removeGlobalTransport(globalTransport);
  },

  /**
  * Sets global options which will be used by all loggers. Changing these
  * works even after other loggers are created.
  *
  * @param options
  * @see Logger.setGlobalOptions
  */
  setGlobalLogOptions(options) {
    jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_21___default.a.setGlobalOptions(options);
  },

  /**
   * Creates the media tracks and returns them trough the callback.
   *
   * @param options Object with properties / settings specifying the tracks
   * which should be created. should be created or some additional
   * configurations about resolution for example.
   * @param {Array} options.effects optional effects array for the track
   * @param {Array} options.devices the devices that will be requested
   * @param {string} options.resolution resolution constraints
   * @param {string} options.cameraDeviceId
   * @param {string} options.micDeviceId
   * @param {object} options.desktopSharingExtensionExternalInstallation -
   * enables external installation process for desktop sharing extension if
   * the inline installation is not posible. The following properties should
   * be provided:
   * @param {intiger} interval - the interval (in ms) for
   * checking whether the desktop sharing extension is installed or not
   * @param {Function} checkAgain - returns boolean. While checkAgain()==true
   * createLocalTracks will wait and check on every "interval" ms for the
   * extension. If the desktop extension is not install and checkAgain()==true
   * createLocalTracks will finish with rejected Promise.
   * @param {Function} listener - The listener will be called to notify the
   * user of lib-jitsi-meet that createLocalTracks is starting external
   * extension installation process.
   * NOTE: If the inline installation process is not possible and external
   * installation is enabled the listener property will be called to notify
   * the start of external installation process. After that createLocalTracks
   * will start to check for the extension on every interval ms until the
   * plugin is installed or until checkAgain return false. If the extension
   * is found createLocalTracks will try to get the desktop sharing track and
   * will finish the execution. If checkAgain returns false, createLocalTracks
   * will finish the execution with rejected Promise.
   *
   * @param {boolean} (firePermissionPromptIsShownEvent) - if event
   * JitsiMediaDevicesEvents.PERMISSION_PROMPT_IS_SHOWN should be fired
   * @param originalOptions - internal use only, to be able to store the
   * originally requested options.
   * @returns {Promise.<{Array.<JitsiTrack>}, JitsiConferenceError>} A promise
   * that returns an array of created JitsiTracks if resolved, or a
   * JitsiConferenceError if rejected.
   */
  createLocalTracks(options = {}, firePermissionPromptIsShownEvent, originalOptions) {
    let promiseFulfilled = false;

    if (firePermissionPromptIsShownEvent === true) {
      window.setTimeout(() => {
        if (!promiseFulfilled) {
          _JitsiMediaDevices__WEBPACK_IMPORTED_MODULE_14__["default"].emitEvent(_JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_15__["PERMISSION_PROMPT_IS_SHOWN"], _modules_browser__WEBPACK_IMPORTED_MODULE_26__["default"].getName());
        }
      }, USER_MEDIA_PERMISSION_PROMPT_TIMEOUT);
    }

    if (!window.connectionTimes) {
      window.connectionTimes = {};
    }

    window.connectionTimes['obtainPermissions.start'] = window.performance.now();
    return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_25__["default"].obtainAudioAndVideoPermissions(options).then(tracks => {
      promiseFulfilled = true;
      window.connectionTimes['obtainPermissions.end'] = window.performance.now();
      _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__["createGetUserMediaEvent"])('success', getAnalyticsAttributesFromOptions(options)));

      if (!_modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_25__["default"].options.disableAudioLevels) {
        for (let i = 0; i < tracks.length; i++) {
          const track = tracks[i];
          const mStream = track.getOriginalStream();

          if (track.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_22__["AUDIO"]) {
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].startLocalStats(mStream, track.setAudioLevel.bind(track));
            track.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_18__["LOCAL_TRACK_STOPPED"], () => {
              _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].stopLocalStats(mStream);
            });
          }
        }
      } // set real device ids


      const currentlyAvailableMediaDevices = _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_25__["default"].getCurrentlyAvailableMediaDevices();

      if (currentlyAvailableMediaDevices) {
        for (let i = 0; i < tracks.length; i++) {
          const track = tracks[i];

          track._setRealDeviceIdFromDeviceList(currentlyAvailableMediaDevices);
        }
      } // set the contentHint to "detail" for desktop tracks
      // eslint-disable-next-line prefer-const


      for (const track of tracks) {
        if (track.type === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_22__["VIDEO"] && track.videoType === 'desktop') {
          this.setVideoTrackContentHints(track.track, 'detail');
        }
      }

      return tracks;
    }).catch(error => {
      promiseFulfilled = true;

      if (error.name === _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_17__["UNSUPPORTED_RESOLUTION"] && !_modules_browser__WEBPACK_IMPORTED_MODULE_26__["default"].usesNewGumFlow()) {
        const oldResolution = options.resolution || '720';
        const newResolution = getLowerResolution(oldResolution);

        if (newResolution !== null) {
          options.resolution = newResolution;
          logger.debug('Retry createLocalTracks with resolution', newResolution);
          _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__["createGetUserMediaEvent"])('warning', {
            'old_resolution': oldResolution,
            'new_resolution': newResolution,
            reason: 'unsupported resolution'
          }));
          return this.createLocalTracks(options, undefined, originalOptions || Object.assign({}, options));
        } // We tried everything. If there is a mandatory device id,
        // remove it and let gum find a device to use.


        if (originalOptions && error.gum.constraints && error.gum.constraints.video && error.gum.constraints.video.mandatory && error.gum.constraints.video.mandatory.sourceId) {
          originalOptions.cameraDeviceId = undefined;
          return this.createLocalTracks(originalOptions);
        }
      }

      if (error.name === _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_17__["CHROME_EXTENSION_USER_CANCELED"]) {
        // User cancelled action is not really an error, so only
        // log it as an event to avoid having conference classified
        // as partially failed
        const logObject = {
          id: 'chrome_extension_user_canceled',
          message: error.message
        };
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendLog(JSON.stringify(logObject));
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__["createGetUserMediaEvent"])('warning', {
          reason: 'extension install user canceled'
        }));
      } else if (error.name === _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_17__["NOT_FOUND"]) {
        // logs not found devices with just application log to cs
        const logObject = {
          id: 'usermedia_missing_device',
          status: error.gum.devices
        };
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendLog(JSON.stringify(logObject));
        const attributes = getAnalyticsAttributesFromOptions(options);
        attributes.reason = 'device not found';
        attributes.devices = error.gum.devices.join('.');
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__["createGetUserMediaEvent"])('error', attributes));
      } else {
        // Report gUM failed to the stats
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendGetUserMediaFailed(error);
        const attributes = getAnalyticsAttributesFromOptions(options);
        attributes.reason = error.name;
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__["createGetUserMediaEvent"])('error', attributes));
      }

      window.connectionTimes['obtainPermissions.end'] = window.performance.now();
      return Promise.reject(error);
    });
  },

  /**
   * Create a TrackVADEmitter service that connects an audio track to an VAD (voice activity detection) processor in
   * order to obtain VAD scores for individual PCM audio samples.
   * @param {string} localAudioDeviceId - The target local audio device.
   * @param {number} sampleRate - Sample rate at which the emitter will operate. Possible values  256, 512, 1024,
   * 4096, 8192, 16384. Passing other values will default to closes neighbor.
   * I.e. Providing a value of 4096 means that the emitter will process 4096 PCM samples at a time, higher values mean
   * longer calls, lowers values mean more calls but shorter.
   * @param {Object} vadProcessor - VAD Processors that does the actual compute on a PCM sample.The processor needs
   * to implement the following functions:
   * - <tt>getSampleLength()</tt> - Returns the sample size accepted by calculateAudioFrameVAD.
   * - <tt>getRequiredPCMFrequency()</tt> - Returns the PCM frequency at which the processor operates.
   * i.e. (16KHz, 44.1 KHz etc.)
   * - <tt>calculateAudioFrameVAD(pcmSample)</tt> - Process a 32 float pcm sample of getSampleLength size.
   * @returns {Promise<TrackVADEmitter>}
   */
  createTrackVADEmitter(localAudioDeviceId, sampleRate, vadProcessor) {
    return _modules_detection_TrackVADEmitter__WEBPACK_IMPORTED_MODULE_3__["default"].create(localAudioDeviceId, sampleRate, vadProcessor);
  },

  /**
   * Create AudioMixer, which is essentially a wrapper over web audio ChannelMergerNode. It essentially allows the
   * user to mix multiple MediaStreams into a single one.
   *
   * @returns {AudioMixer}
   */
  createAudioMixer() {
    return new _modules_webaudio_AudioMixer__WEBPACK_IMPORTED_MODULE_1__["default"]();
  },

  /**
   * Go through all audio devices on the system and return one that is active, i.e. has audio signal.
   *
   * @returns Promise<Object> - Object containing information about the found device.
   */
  getActiveAudioDevice() {
    return Object(_modules_detection_ActiveDeviceDetector__WEBPACK_IMPORTED_MODULE_0__["default"])();
  },

  /**
   * Checks if its possible to enumerate available cameras/microphones.
   *
   * @returns {Promise<boolean>} a Promise which will be resolved only once
   * the WebRTC stack is ready, either with true if the device listing is
   * available available or with false otherwise.
   * @deprecated use JitsiMeetJS.mediaDevices.isDeviceListAvailable instead
   */
  isDeviceListAvailable() {
    logger.warn('This method is deprecated, use ' + 'JitsiMeetJS.mediaDevices.isDeviceListAvailable instead');
    return this.mediaDevices.isDeviceListAvailable();
  },

  /**
   * Returns true if changing the input (camera / microphone) or output
   * (audio) device is supported and false if not.
   *
   * @param {string} [deviceType] - type of device to change. Default is
   * {@code undefined} or 'input', 'output' - for audio output device change.
   * @returns {boolean} {@code true} if available; {@code false}, otherwise.
   * @deprecated use JitsiMeetJS.mediaDevices.isDeviceChangeAvailable instead
   */
  isDeviceChangeAvailable(deviceType) {
    logger.warn('This method is deprecated, use ' + 'JitsiMeetJS.mediaDevices.isDeviceChangeAvailable instead');
    return this.mediaDevices.isDeviceChangeAvailable(deviceType);
  },

  /**
   * Checks if the current environment supports having multiple audio
   * input devices in use simultaneously.
   *
   * @returns {boolean} True if multiple audio input devices can be used.
   */
  isMultipleAudioInputSupported() {
    return this.mediaDevices.isMultipleAudioInputSupported();
  },

  /**
   * Checks if local tracks can collect stats and collection is enabled.
   *
   * @param {boolean} True if stats are being collected for local tracks.
   */
  isCollectingLocalStats() {
    return _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].audioLevelsEnabled && _modules_statistics_LocalStatsCollector__WEBPACK_IMPORTED_MODULE_20__["default"].isLocalStatsSupported();
  },

  /**
   * Executes callback with list of media devices connected.
   *
   * @param {function} callback
   * @deprecated use JitsiMeetJS.mediaDevices.enumerateDevices instead
   */
  enumerateDevices(callback) {
    logger.warn('This method is deprecated, use ' + 'JitsiMeetJS.mediaDevices.enumerateDevices instead');
    this.mediaDevices.enumerateDevices(callback);
  },

  /* eslint-disable max-params */

  /**
   * @returns function that can be used to be attached to window.onerror and
   * if options.enableWindowOnErrorHandler is enabled returns
   * the function used by the lib.
   * (function(message, source, lineno, colno, error)).
   */
  getGlobalOnErrorHandler(message, source, lineno, colno, error) {
    logger.error(`UnhandledError: ${message}`, `Script: ${source}`, `Line: ${lineno}`, `Column: ${colno}`, 'StackTrace: ', error);
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_30__["default"].reportGlobalError(error);
  },

  /**
   * Set the contentHint on the transmitted stream track to indicate
   * charaterstics in the video stream, which informs PeerConnection
   * on how to encode the track (to prefer motion or individual frame detail)
   * @param {MediaStreamTrack} track - the track that is transmitted
   * @param {String} hint - contentHint value that needs to be set on the track
   */
  setVideoTrackContentHints(track, hint) {
    if ('contentHint' in track) {
      track.contentHint = hint;

      if (track.contentHint !== hint) {
        logger.debug('Invalid video track contentHint');
      }
    } else {
      logger.debug('MediaStreamTrack contentHint attribute not supported');
    }
  },

  /* eslint-enable max-params */

  /**
   * Represents a hub/namespace for utility functionality which may be of
   * interest to lib-jitsi-meet clients.
   */
  util: {
    AuthUtil: (_modules_util_AuthUtil__WEBPACK_IMPORTED_MODULE_5___default()),
    ScriptUtil: (_modules_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_27___default()),
    browser: _modules_browser__WEBPACK_IMPORTED_MODULE_26__["default"]
  }
}));
/* WEBPACK VAR INJECTION */}.call(this, "JitsiMeetJS.js"))

/***/ }),

/***/ "./JitsiParticipant.js":
/*!*****************************!*\
  !*** ./JitsiParticipant.js ***!
  \*****************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JitsiParticipant; });
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _modules_connectivity_ParticipantConnectionStatus__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./modules/connectivity/ParticipantConnectionStatus */ "./modules/connectivity/ParticipantConnectionStatus.js");
/* harmony import */ var _modules_xmpp_Caps__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./modules/xmpp/Caps */ "./modules/xmpp/Caps.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./service/RTC/MediaType.js");






const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__["getLogger"])(__filename);
/**
 * Represents a participant in (i.e. a member of) a conference.
 */

class JitsiParticipant {
  /* eslint-disable max-params */

  /**
   * Initializes a new JitsiParticipant instance.
   *
   * @constructor
   * @param jid the conference XMPP jid
   * @param conference
   * @param displayName
   * @param {Boolean} hidden - True if the new JitsiParticipant instance is to
   * represent a hidden participant; otherwise, false.
   * @param {string} statsID - optional participant statsID
   * @param {string} status - the initial status if any.
   * @param {object} identity - the xmpp identity
   */
  constructor(jid, conference, displayName, hidden, statsID, status, identity) {
    this._jid = jid;
    this._id = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);
    this._conference = conference;
    this._displayName = displayName;
    this._supportsDTMF = false;
    this._tracks = [];
    this._role = 'none';
    this._status = status;
    this._hidden = hidden;
    this._statsID = statsID;
    this._connectionStatus = _modules_connectivity_ParticipantConnectionStatus__WEBPACK_IMPORTED_MODULE_3__["ParticipantConnectionStatus"].ACTIVE;
    this._properties = {};
    this._identity = identity;
  }
  /* eslint-enable max-params */

  /**
   * @returns {JitsiConference} The conference that this participant belongs
   * to.
   */


  getConference() {
    return this._conference;
  }
  /**
   * Gets the value of a property of this participant.
   */


  getProperty(name) {
    return this._properties[name];
  }
  /**
   * Checks whether this <tt>JitsiParticipant</tt> has any video tracks which
   * are muted according to their underlying WebRTC <tt>MediaStreamTrack</tt>
   * muted status.
   * @return {boolean} <tt>true</tt> if this <tt>participant</tt> contains any
   * video <tt>JitsiTrack</tt>s which are muted as defined in
   * {@link JitsiTrack.isWebRTCTrackMuted}.
   */


  hasAnyVideoTrackWebRTCMuted() {
    return this.getTracks().some(jitsiTrack => jitsiTrack.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"] && jitsiTrack.isWebRTCTrackMuted());
  }
  /**
   * Updates participant's connection status.
   * @param {string} state the current participant connection state.
   * {@link ParticipantConnectionStatus}.
   * @private
   */


  _setConnectionStatus(status) {
    this._connectionStatus = status;
  }
  /**
   * Return participant's connectivity status.
   *
   * @returns {string} the connection status
   * <tt>ParticipantConnectionStatus</tt> of the user.
   * {@link ParticipantConnectionStatus}.
   */


  getConnectionStatus() {
    return this._connectionStatus;
  }
  /**
   * Sets the value of a property of this participant, and fires an event if
   * the value has changed.
   * @name the name of the property.
   * @value the value to set.
   */


  setProperty(name, value) {
    const oldValue = this._properties[name];

    if (value !== oldValue) {
      this._properties[name] = value;

      this._conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__["PARTICIPANT_PROPERTY_CHANGED"], this, name, oldValue, value);
    }
  }
  /**
   * @returns {Array.<JitsiTrack>} The list of media tracks for this
   * participant.
   */


  getTracks() {
    return this._tracks.slice();
  }
  /**
   * @param {MediaType} mediaType
   * @returns {Array.<JitsiTrack>} an array of media tracks for this
   * participant, for given media type.
   */


  getTracksByMediaType(mediaType) {
    return this.getTracks().filter(track => track.getType() === mediaType);
  }
  /**
   * @returns {String} The ID of this participant.
   */


  getId() {
    return this._id;
  }
  /**
   * @returns {String} The JID of this participant.
   */


  getJid() {
    return this._jid;
  }
  /**
   * @returns {String} The human-readable display name of this participant.
   */


  getDisplayName() {
    return this._displayName;
  }
  /**
   * @returns {String} The stats ID of this participant.
   */


  getStatsID() {
    return this._statsID;
  }
  /**
   * @returns {String} The status of the participant.
   */


  getStatus() {
    return this._status;
  }
  /**
   * @returns {Boolean} Whether this participant is a moderator or not.
   */


  isModerator() {
    return this._role === 'moderator';
  }
  /**
   * @returns {Boolean} Whether this participant is a hidden participant. Some
   * special system participants may want to join hidden (like for example the
   * recorder).
   */


  isHidden() {
    return this._hidden;
  }
  /**
   * @returns {Boolean} Whether this participant has muted their audio.
   */


  isAudioMuted() {
    return this._isMediaTypeMuted(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["AUDIO"]);
  }
  /**
   * Determines whether all JitsiTracks which are of a specific MediaType and
   * which belong to this JitsiParticipant are muted.
   *
   * @param {MediaType} mediaType - The MediaType of the JitsiTracks to be
   * checked.
   * @private
   * @returns {Boolean} True if all JitsiTracks which are of the specified
   * mediaType and which belong to this JitsiParticipant are muted; otherwise,
   * false.
   */


  _isMediaTypeMuted(mediaType) {
    return this.getTracks().reduce((muted, track) => muted && (track.getType() !== mediaType || track.isMuted()), true);
  }
  /**
   * @returns {Boolean} Whether this participant has muted their video.
   */


  isVideoMuted() {
    return this._isMediaTypeMuted(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]);
  }
  /**
   * @returns {String} The role of this participant.
   */


  getRole() {
    return this._role;
  }
  /**
   *
   */


  supportsDTMF() {
    return this._supportsDTMF;
  }
  /**
   * Returns a set with the features for the participant.
   * @param {int} timeout the timeout in ms for reply from the participant.
   * @returns {Promise<Set<String>, Error>}
   */


  getFeatures(timeout = 5000) {
    if (this._getFeaturesPromise) {
      return this._getFeaturesPromise;
    }

    this._getFeaturesPromise = this._conference.xmpp.caps.getFeatures(this._jid, timeout).catch(error => {
      // Retry on feature version mismatch
      if (error === _modules_xmpp_Caps__WEBPACK_IMPORTED_MODULE_4__["ERROR_FEATURE_VERSION_MISMATCH"]) {
        return this._conference.xmpp.caps.getFeatures(this._jid, timeout);
      }

      logger.warn(`Failed to discover features of ${this._jid}`, error);
      return Promise.reject(error);
    });
    return this._getFeaturesPromise.then(result => {
      this._getFeaturesPromise = undefined;
      return result;
    }, error => {
      this._getFeaturesPromise = undefined;
      throw error;
    });
  }
  /**
   * Returns the bot type for the participant.
   *
   * @returns {string|undefined} - The bot type of the participant.
   */


  getBotType() {
    return this._botType;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "JitsiParticipant.js"))

/***/ }),

/***/ "./JitsiTrackError.js":
/*!****************************!*\
  !*** ./JitsiTrackError.js ***!
  \****************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./JitsiTrackErrors */ "./JitsiTrackErrors.js");

const TRACK_ERROR_TO_MESSAGE_MAP = {};
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["UNSUPPORTED_RESOLUTION"]] = 'Video resolution is not supported: ';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["CHROME_EXTENSION_INSTALLATION_ERROR"]] = 'Failed to install Chrome extension';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["CHROME_EXTENSION_USER_GESTURE_REQUIRED"]] = 'Failed to install Chrome extension - installations can only be initiated' + ' by a user gesture.';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["CHROME_EXTENSION_USER_CANCELED"]] = 'User canceled Chrome\'s screen sharing prompt';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["CHROME_EXTENSION_GENERIC_ERROR"]] = 'Unknown error from Chrome extension';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["ELECTRON_DESKTOP_PICKER_ERROR"]] = 'Unkown error from desktop picker';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["ELECTRON_DESKTOP_PICKER_NOT_FOUND"]] = 'Failed to detect desktop picker';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["GENERAL"]] = 'Generic getUserMedia error';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["PERMISSION_DENIED"]] = 'User denied permission to use device(s): ';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["NOT_FOUND"]] = 'Requested device(s) was/were not found: ';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["CONSTRAINT_FAILED"]] = 'Constraint could not be satisfied: ';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["TRACK_IS_DISPOSED"]] = 'Track has been already disposed';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["TRACK_NO_STREAM_FOUND"]] = 'Track does not have an associated Media Stream'; // FIXME: Using prototype inheritance because otherwise instanceof is not
// working properly (see https://github.com/babel/babel/issues/3083)

/**
 *
 * Represents an error that occurred to a JitsiTrack. Can represent various
 * types of errors. For error descriptions (@see JitsiTrackErrors).
 *
 * @extends Error
 *
 *
 * @constructor
 * @param {Object|string} error - error object or error name
 * @param {Object|string} (options) - getUserMedia constraints object or
 * error message
 * @param {('audio'|'video'|'desktop'|'screen'|'audiooutput')[]} (devices) -
 * list of getUserMedia requested devices
 */

function JitsiTrackError(error, options, devices) {
  if (typeof error === 'object' && typeof error.name !== 'undefined') {
    /**
     * Additional information about original getUserMedia error
     * and constraints.
     * @type {{
     *     error: Object,
     *     constraints: Object,
     *     devices: Array.<'audio'|'video'|'desktop'|'screen'>
     * }}
     */
    this.gum = {
      error,
      constraints: options,
      devices: devices && Array.isArray(devices) ? devices.slice(0) : undefined
    };

    switch (error.name) {
      case 'NotAllowedError':
      case 'PermissionDeniedError':
      case 'SecurityError':
        this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["PERMISSION_DENIED"];
        this.message = TRACK_ERROR_TO_MESSAGE_MAP[this.name] + (this.gum.devices || []).join(', ');
        break;

      case 'DevicesNotFoundError':
      case 'NotFoundError':
        this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["NOT_FOUND"];
        this.message = TRACK_ERROR_TO_MESSAGE_MAP[this.name] + (this.gum.devices || []).join(', ');
        break;

      case 'ConstraintNotSatisfiedError':
      case 'OverconstrainedError':
        {
          const constraintName = error.constraintName || error.constraint; // we treat deviceId as unsupported resolution, as we want to
          // retry and finally if everything fails to remove deviceId from
          // mandatory constraints

          if (options && options.video && (!devices || devices.indexOf('video') > -1) && (constraintName === 'minWidth' || constraintName === 'maxWidth' || constraintName === 'minHeight' || constraintName === 'maxHeight' || constraintName === 'width' || constraintName === 'height' || constraintName === 'deviceId')) {
            this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["UNSUPPORTED_RESOLUTION"];
            this.message = TRACK_ERROR_TO_MESSAGE_MAP[this.name] + getResolutionFromFailedConstraint(constraintName, options);
          } else {
            this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["CONSTRAINT_FAILED"];
            this.message = TRACK_ERROR_TO_MESSAGE_MAP[this.name] + error.constraintName;
          }

          break;
        }

      default:
        this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__["GENERAL"];
        this.message = error.message || TRACK_ERROR_TO_MESSAGE_MAP[this.name];
        break;
    }
  } else if (typeof error === 'string') {
    if (TRACK_ERROR_TO_MESSAGE_MAP[error]) {
      this.name = error;
      this.message = options || TRACK_ERROR_TO_MESSAGE_MAP[error];
    } else {
      // this is some generic error that do not fit any of our
      // pre-defined errors, so don't give it any specific name, just
      // store message
      this.message = error;
    }
  } else {
    throw new Error('Invalid arguments');
  }

  this.stack = error.stack || new Error().stack;
}

JitsiTrackError.prototype = Object.create(Error.prototype);
JitsiTrackError.prototype.constructor = JitsiTrackError;
/**
 * Gets failed resolution constraint from corresponding object.
 * @param {string} failedConstraintName
 * @param {Object} constraints
 * @returns {string|number}
 */

function getResolutionFromFailedConstraint(failedConstraintName, constraints) {
  if (constraints && constraints.video && constraints.video.mandatory) {
    switch (failedConstraintName) {
      case 'width':
        return constraints.video.mandatory.minWidth;

      case 'height':
        return constraints.video.mandatory.minHeight;

      default:
        return constraints.video.mandatory[failedConstraintName] || '';
    }
  }

  return '';
}

/* harmony default export */ __webpack_exports__["default"] = (JitsiTrackError);

/***/ }),

/***/ "./JitsiTrackErrors.js":
/*!*****************************!*\
  !*** ./JitsiTrackErrors.js ***!
  \*****************************/
/*! exports provided: CHROME_EXTENSION_GENERIC_ERROR, CHROME_EXTENSION_INSTALLATION_ERROR, CHROME_EXTENSION_USER_GESTURE_REQUIRED, CHROME_EXTENSION_USER_CANCELED, CONSTRAINT_FAILED, ELECTRON_DESKTOP_PICKER_ERROR, ELECTRON_DESKTOP_PICKER_NOT_FOUND, FIREFOX_EXTENSION_NEEDED, GENERAL, NOT_FOUND, PERMISSION_DENIED, TRACK_IS_DISPOSED, TRACK_NO_STREAM_FOUND, UNSUPPORTED_RESOLUTION */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CHROME_EXTENSION_GENERIC_ERROR", function() { return CHROME_EXTENSION_GENERIC_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CHROME_EXTENSION_INSTALLATION_ERROR", function() { return CHROME_EXTENSION_INSTALLATION_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CHROME_EXTENSION_USER_GESTURE_REQUIRED", function() { return CHROME_EXTENSION_USER_GESTURE_REQUIRED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CHROME_EXTENSION_USER_CANCELED", function() { return CHROME_EXTENSION_USER_CANCELED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONSTRAINT_FAILED", function() { return CONSTRAINT_FAILED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ELECTRON_DESKTOP_PICKER_ERROR", function() { return ELECTRON_DESKTOP_PICKER_ERROR; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ELECTRON_DESKTOP_PICKER_NOT_FOUND", function() { return ELECTRON_DESKTOP_PICKER_NOT_FOUND; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "FIREFOX_EXTENSION_NEEDED", function() { return FIREFOX_EXTENSION_NEEDED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "GENERAL", function() { return GENERAL; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NOT_FOUND", function() { return NOT_FOUND; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PERMISSION_DENIED", function() { return PERMISSION_DENIED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_IS_DISPOSED", function() { return TRACK_IS_DISPOSED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_NO_STREAM_FOUND", function() { return TRACK_NO_STREAM_FOUND; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "UNSUPPORTED_RESOLUTION", function() { return UNSUPPORTED_RESOLUTION; });
/**
 * The errors for the JitsiTrack objects.
 */

/**
 * Generic error for jidesha extension for Chrome.
 */
const CHROME_EXTENSION_GENERIC_ERROR = 'gum.chrome_extension_generic_error';
/**
 * An error which indicates that the jidesha extension for Chrome is
 * failed to install.
 */

const CHROME_EXTENSION_INSTALLATION_ERROR = 'gum.chrome_extension_installation_error';
/**
 * This error indicates that the attempt to start screensharing was initiated by
 * a script which did not originate in user gesture handler. It means that
 * you should to trigger the action again in response to a button click for
 * example.
 * @type {string}
 */

const CHROME_EXTENSION_USER_GESTURE_REQUIRED = 'gum.chrome_extension_user_gesture_required';
/**
 * An error which indicates that user canceled screen sharing window
 * selection dialog in jidesha extension for Chrome.
 */

const CHROME_EXTENSION_USER_CANCELED = 'gum.chrome_extension_user_canceled';
/**
 * An error which indicates that some of requested constraints in
 * getUserMedia call were not satisfied.
 */

const CONSTRAINT_FAILED = 'gum.constraint_failed';
/**
 * A generic error which indicates an error occurred while selecting
 * a DesktopCapturerSource from the electron app.
 */

const ELECTRON_DESKTOP_PICKER_ERROR = 'gum.electron_desktop_picker_error';
/**
 * An error which indicates a custom desktop picker could not be detected
 * for the electron app.
 */

const ELECTRON_DESKTOP_PICKER_NOT_FOUND = 'gum.electron_desktop_picker_not_found';
/**
 * An error which indicates that the jidesha extension for Firefox is
 * needed to proceed with screen sharing, and that it is not installed.
 */

const FIREFOX_EXTENSION_NEEDED = 'gum.firefox_extension_needed';
/**
 * Generic getUserMedia error.
 */

const GENERAL = 'gum.general';
/**
 * An error which indicates that requested device was not found.
 */

const NOT_FOUND = 'gum.not_found';
/**
 * An error which indicates that user denied permission to share requested
 * device.
 */

const PERMISSION_DENIED = 'gum.permission_denied';
/**
 * An error which indicates that track has been already disposed and cannot
 * be longer used.
 */

const TRACK_IS_DISPOSED = 'track.track_is_disposed';
/**
 * An error which indicates that track has no MediaStream associated.
 */

const TRACK_NO_STREAM_FOUND = 'track.no_stream_found';
/**
 * An error which indicates that requested video resolution is not supported
 * by a webcam.
 */

const UNSUPPORTED_RESOLUTION = 'gum.unsupported_resolution';

/***/ }),

/***/ "./JitsiTrackEvents.js":
/*!*****************************!*\
  !*** ./JitsiTrackEvents.js ***!
  \*****************************/
/*! exports provided: LOCAL_TRACK_STOPPED, TRACK_AUDIO_LEVEL_CHANGED, TRACK_AUDIO_OUTPUT_CHANGED, TRACK_MUTE_CHANGED, TRACK_VIDEOTYPE_CHANGED, NO_DATA_FROM_SOURCE */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LOCAL_TRACK_STOPPED", function() { return LOCAL_TRACK_STOPPED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_AUDIO_LEVEL_CHANGED", function() { return TRACK_AUDIO_LEVEL_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_AUDIO_OUTPUT_CHANGED", function() { return TRACK_AUDIO_OUTPUT_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_MUTE_CHANGED", function() { return TRACK_MUTE_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_VIDEOTYPE_CHANGED", function() { return TRACK_VIDEOTYPE_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NO_DATA_FROM_SOURCE", function() { return NO_DATA_FROM_SOURCE; });
/**
 * The media track was removed to the conference.
 */
const LOCAL_TRACK_STOPPED = 'track.stopped';
/**
 * Audio levels of a this track was changed.
 * The first argument is a number with audio level value in range [0, 1].
 * The second argument is a <tt>TraceablePeerConnection</tt> which is the peer
 * connection which measured the audio level (one audio track can be added
 * to multiple peer connection at the same time). This argument is optional for
 * local tracks for which we can measure audio level without the peer
 * connection (the value will be <tt>undefined</tt>).
 *
 * NOTE The second argument should be treated as library internal and can be
 * removed at any time.
 */

const TRACK_AUDIO_LEVEL_CHANGED = 'track.audioLevelsChanged';
/**
 * The audio output of the track was changed.
 */

const TRACK_AUDIO_OUTPUT_CHANGED = 'track.audioOutputChanged';
/**
 * A media track mute status was changed.
 */

const TRACK_MUTE_CHANGED = 'track.trackMuteChanged';
/**
 * The video type("camera" or "desktop") of the track was changed.
 */

const TRACK_VIDEOTYPE_CHANGED = 'track.videoTypeChanged';
/**
 * Indicates that the track is not receiving any data even though we expect it
 * to receive data (i.e. the stream is not stopped).
 */

const NO_DATA_FROM_SOURCE = 'track.no_data_from_source';

/***/ }),

/***/ "./JitsiTranscriptionStatus.js":
/*!*************************************!*\
  !*** ./JitsiTranscriptionStatus.js ***!
  \*************************************/
/*! exports provided: ON, OFF */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ON", function() { return ON; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OFF", function() { return OFF; });
/**
 * The transciption is on.
 *
 * @type {String}
 */
const ON = 'on';
/**
 * The transciption is off.
 *
 * @type {String}
 */

const OFF = 'off';

/***/ }),

/***/ "./authenticateAndUpgradeRole.js":
/*!***************************************!*\
  !*** ./authenticateAndUpgradeRole.js ***!
  \***************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return authenticateAndUpgradeRole; });
/* harmony import */ var _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./JitsiConnectionEvents */ "./JitsiConnectionEvents.js");
/* harmony import */ var _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./modules/xmpp/xmpp */ "./modules/xmpp/xmpp.js");


/**
 * @typedef {Object} UpgradeRoleError
 *
 * @property {JitsiConnectionErrors} [connectionError] - One of
 * {@link JitsiConnectionErrors} which occurred when trying to connect to the
 * XMPP server.
 * @property {String} [authenticationError] - One of XMPP error conditions
 * returned by Jicofo on authentication attempt. See
 * {@link https://xmpp.org/rfcs/rfc3920.html#streams-error}.
 * @property {String} [message] - More details about the error.
 * @property {Object} [credentials] - The credentials that failed the
 * authentication.
 * @property {String} [credentials.jid] - The XMPP ID part of the credentials
 * that failed the authentication.
 * @property {string} [credentials.password] - The password part of the
 * credentials that failed the authentication.
 *
 * NOTE If neither one of the errors is present, then the operation has been
 * canceled.
 */

/* eslint-disable no-invalid-this */

/**
 * Connects to the XMPP server using the specified credentials and contacts
 * Jicofo in order to obtain a session ID (which is then stored in the local
 * storage). The user's role of the parent conference will be upgraded to
 * moderator (by Jicofo). It's also used to join the conference when starting
 * from anonymous domain and only authenticated users are allowed to create new
 * rooms.
 *
 * @param {Object} options
 * @param {string} options.id - XMPP user's ID to log in. For example,
 * user@xmpp-server.com.
 * @param {string} options.password - XMPP user's password to log in with.
 * @param {string} [options.roomPassword] - The password to join the MUC with.
 * @param {Function} [options.onLoginSuccessful] - Callback called when logging
 * into the XMPP server was successful. The next step will be to obtain a new
 * session ID from Jicofo and join the MUC using it which will effectively
 * upgrade the user's role to moderator.
 * @returns {Object} A <tt>thenable</tt> which (1) settles when the process of
 * authenticating and upgrading the role of the specified XMPP user finishes and
 * (2) has a <tt>cancel</tt> method that allows the caller to interrupt the
 * process. If the process finishes successfully, the session ID has been stored
 * in the settings and the <tt>thenable</tt> is resolved. If the process
 * finishes with failure, the <tt>thenable</tt> is rejected with reason of type
 * {@link UpgradeRoleError} which will have either <tt>connectionError</tt> or
 * <tt>authenticationError</tt> property set depending on which of the steps has
 * failed. If <tt>cancel</tt> is called before the process finishes, then the
 * thenable will be rejected with an empty object (i.e. no error property will
 * be set on the rejection reason).
 */

function authenticateAndUpgradeRole({
  // 1. Log the specified XMPP user in.
  id,
  password,
  onCreateResource,
  // 2. Let the API client/consumer know as soon as the XMPP user has been
  //    successfully logged in.
  onLoginSuccessful,
  // 3. Join the MUC.
  roomPassword
}) {
  let canceled = false;
  let rejectPromise;
  let xmpp = new _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_1__["default"](this.connection.options);
  const process = new Promise((resolve, reject) => {
    // The process is represented by a Thenable with a cancel method. The
    // Thenable is implemented using Promise and the cancel using the
    // Promise's reject function.
    rejectPromise = reject;
    xmpp.addListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_0__["CONNECTION_DISCONNECTED"], () => {
      xmpp = undefined;
    });
    xmpp.addListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_0__["CONNECTION_ESTABLISHED"], () => {
      if (canceled) {
        return;
      } // Let the caller know that the XMPP login was successful.


      onLoginSuccessful && onLoginSuccessful(); // Now authenticate with Jicofo and get a new session ID.

      const room = xmpp.createRoom(this.options.name, this.options.config, onCreateResource);
      room.moderator.authenticate().then(() => {
        xmpp && xmpp.disconnect();

        if (canceled) {
          return;
        } // At this point we should have the new session ID
        // stored in the settings. Jicofo will allow to join the
        // room.


        this.join(roomPassword);
        resolve();
      }).catch(({
        error,
        message
      }) => {
        xmpp.disconnect();
        reject({
          authenticationError: error,
          message
        });
      });
    });
    xmpp.addListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_0__["CONNECTION_FAILED"], (connectionError, message, credentials) => {
      reject({
        connectionError,
        credentials,
        message
      });
      xmpp = undefined;
    });
    canceled || xmpp.connect(id, password);
  });
  /**
   * Cancels the process, if it's in progress, of authenticating and upgrading
   * the role of the local participant/user.
   *
   * @public
   * @returns {void}
   */

  process.cancel = () => {
    canceled = true;
    rejectPromise({});
    xmpp && xmpp.disconnect();
  };

  return process;
}
/* eslint-enable no-invalid-this */

/***/ }),

/***/ "./index.js":
/*!******************!*\
  !*** ./index.js ***!
  \******************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// For legacy purposes, preserve the UMD of the public API of the Jitsi Meet
// library (a.k.a. JitsiMeetJS).
module.exports = __webpack_require__(/*! ./JitsiMeetJS */ "./JitsiMeetJS.js").default;

/***/ }),

/***/ "./modules/RTC/BridgeChannel.js":
/*!**************************************!*\
  !*** ./modules/RTC/BridgeChannel.js ***!
  \**************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return BridgeChannel; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4__);





const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Handles a WebRTC RTCPeerConnection or a WebSocket instance to communicate
 * with the videobridge.
 */

class BridgeChannel {
  /**
   * Binds "ondatachannel" event listener on the given RTCPeerConnection
   * instance, or creates a WebSocket connection with the videobridge.
   * At least one of both, peerconnection or wsUrl parameters, must be
   * given.
   * @param {RTCPeerConnection} [peerconnection] WebRTC peer connection
   * instance.
   * @param {string} [wsUrl] WebSocket URL.
   * @param {EventEmitter} eventEmitter EventEmitter instance.
   */
  constructor(peerconnection, wsUrl, emitter) {
    if (!peerconnection && !wsUrl) {
      throw new TypeError('At least peerconnection or wsUrl must be given');
    } else if (peerconnection && wsUrl) {
      throw new TypeError('Just one of peerconnection or wsUrl must be given');
    }

    if (peerconnection) {
      logger.debug('constructor() with peerconnection');
    } else {
      logger.debug(`constructor() with wsUrl:"${wsUrl}"`);
    } // The underlying WebRTC RTCDataChannel or WebSocket instance.
    // @type {RTCDataChannel|WebSocket}


    this._channel = null; // @type {EventEmitter}

    this._eventEmitter = emitter; // Whether a RTCDataChannel or WebSocket is internally used.
    // @type {string} "datachannel" / "websocket"

    this._mode = null; // Indicates whether the connection retries are enabled or not.

    this._areRetriesEnabled = false; // Indicates whether the connection was closed from the client or not.

    this._closedFromClient = false; // If a RTCPeerConnection is given, listen for new RTCDataChannel
    // event.

    if (peerconnection) {
      const datachannel = peerconnection.createDataChannel('JVB data channel', {
        protocol: 'http://jitsi.org/protocols/colibri'
      }); // Handle the RTCDataChannel.

      this._handleChannel(datachannel);

      this._mode = 'datachannel'; // Otherwise create a WebSocket connection.
    } else if (wsUrl) {
      this._areRetriesEnabled = true;
      this._wsUrl = wsUrl;

      this._initWebSocket();
    }
  }
  /**
   * Initializes the web socket channel.
   *
   * @returns {void}
   */


  _initWebSocket() {
    // Create a WebSocket instance.
    const ws = new WebSocket(this._wsUrl); // Handle the WebSocket.

    this._handleChannel(ws);

    this._mode = 'websocket';
  }
  /**
   * Starts the websocket connection retries.
   *
   * @returns {void}
   */


  _startConnectionRetries() {
    let timeoutS = 1;

    const reload = () => {
      if (this.isOpen()) {
        return;
      }

      this._initWebSocket(this._wsUrl);

      timeoutS = Math.min(timeoutS * 2, 60);
      this._retryTimeout = setTimeout(reload, timeoutS * 1000);
    };

    this._retryTimeout = setTimeout(reload, timeoutS * 1000);
  }
  /**
   * Stops the websocket connection retries.
   *
   * @returns {void}
   */


  _stopConnectionRetries() {
    if (this._retryTimeout) {
      clearTimeout(this._retryTimeout);
      this._retryTimeout = undefined;
    }
  }
  /**
   * Retries to establish the websocket connection after the connection was closed by the server.
   *
   * @param {CloseEvent} closeEvent - The close event that triggered the retries.
   * @returns {void}
   */


  _retryWebSocketConnection(closeEvent) {
    if (!this._areRetriesEnabled) {
      return;
    }

    const {
      code,
      reason
    } = closeEvent;
    _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_2__["createBridgeChannelClosedEvent"])(code, reason));
    this._areRetriesEnabled = false;

    this._eventEmitter.once(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default.a.DATA_CHANNEL_OPEN, () => {
      this._stopConnectionRetries();

      this._areRetriesEnabled = true;
    });

    this._startConnectionRetries();
  }
  /**
   * The channel mode.
   * @return {string} "datachannel" or "websocket" (or null if not yet set).
   */


  get mode() {
    return this._mode;
  }
  /**
   * Closes the currently opened channel.
   */


  close() {
    this._closedFromClient = true;

    this._stopConnectionRetries();

    this._areRetriesEnabled = false;

    if (this._channel) {
      try {
        this._channel.close();
      } catch (error) {} // eslint-disable-line no-empty


      this._channel = null;
    }
  }
  /**
   * Whether there is an underlying RTCDataChannel or WebSocket and it's
   * open.
   * @return {boolean}
   */


  isOpen() {
    return this._channel && (this._channel.readyState === 'open' || this._channel.readyState === WebSocket.OPEN);
  }
  /**
   * Sends message via the channel.
   * @param {string} to The id of the endpoint that should receive the
   * message. If "" the message will be sent to all participants.
   * @param  {object} payload The payload of the message.
   * @throws NetworkError or InvalidStateError from RTCDataChannel#send (@see
   * {@link https://developer.mozilla.org/docs/Web/API/RTCDataChannel/send})
   * or from WebSocket#send or Error with "No opened channel" message.
   */


  sendMessage(to, payload) {
    this._send({
      colibriClass: 'EndpointMessage',
      msgPayload: payload,
      to
    });
  }
  /**
   * Sends a "lastN value changed" message via the channel.
   * @param {number} value The new value for lastN. -1 means unlimited.
   */


  sendSetLastNMessage(value) {
    const jsonObject = {
      colibriClass: 'LastNChangedEvent',
      lastN: value
    };

    this._send(jsonObject);

    logger.log(`Channel lastN set to: ${value}`);
  }
  /**
   * Sends a "pinned endpoint changed" message via the channel.
   * @param {string} endpointId The id of the pinned endpoint.
   * @throws NetworkError or InvalidStateError from RTCDataChannel#send (@see
   * {@link https://developer.mozilla.org/docs/Web/API/RTCDataChannel/send})
   * or from WebSocket#send or Error with "No opened channel" message.
   */


  sendPinnedEndpointMessage(endpointId) {
    logger.log('sending pinned changed notification to the bridge for endpoint ', endpointId);

    this._send({
      colibriClass: 'PinnedEndpointChangedEvent',
      pinnedEndpoint: endpointId || null
    });
  }
  /**
   * Sends a "selected endpoints changed" message via the channel.
   *
   * @param {Array<string>} endpointIds - The ids of the selected endpoints.
   * @throws NetworkError or InvalidStateError from RTCDataChannel#send (@see
   * {@link https://developer.mozilla.org/docs/Web/API/RTCDataChannel/send})
   * or from WebSocket#send or Error with "No opened channel" message.
   */


  sendSelectedEndpointsMessage(endpointIds) {
    logger.log('sending selected changed notification to the bridge for endpoints', endpointIds);

    this._send({
      colibriClass: 'SelectedEndpointsChangedEvent',
      selectedEndpoints: endpointIds
    });
  }
  /**
   * Sends a "receiver video constraint" message via the channel.
   * @param {Number} maxFrameHeightPixels the maximum frame height,
   * in pixels, this receiver is willing to receive
   */


  sendReceiverVideoConstraintMessage(maxFrameHeightPixels) {
    logger.log('sending a ReceiverVideoConstraint message with ' + `a maxFrameHeight of ${maxFrameHeightPixels} pixels`);

    this._send({
      colibriClass: 'ReceiverVideoConstraint',
      maxFrameHeight: maxFrameHeightPixels
    });
  }
  /**
   * Set events on the given RTCDataChannel or WebSocket instance.
   */


  _handleChannel(channel) {
    const emitter = this._eventEmitter;

    channel.onopen = () => {
      logger.info(`${this._mode} channel opened`); // Code sample for sending string and/or binary data.
      // Sends string message to the bridge:
      //     channel.send("Hello bridge!");
      // Sends 12 bytes binary message to the bridge:
      //     channel.send(new ArrayBuffer(12));

      emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default.a.DATA_CHANNEL_OPEN);
    };

    channel.onerror = event => {
      // WS error events contain no information about the failure (this is available in the onclose event) and
      // the event references the WS object itself, which causes hangs on mobile.
      if (this._mode !== 'websocket') {
        logger.error(`Channel error: ${event.message}`);
      }
    };

    channel.onmessage = ({
      data
    }) => {
      // JSON object.
      let obj;

      try {
        obj = JSON.parse(data);
      } catch (error) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4___default.a.callErrorHandler(error);
        logger.error('Failed to parse channel message as JSON: ', data, error);
        return;
      }

      const colibriClass = obj.colibriClass;

      switch (colibriClass) {
        case 'DominantSpeakerEndpointChangeEvent':
          {
            // Endpoint ID from the Videobridge.
            const dominantSpeakerEndpoint = obj.dominantSpeakerEndpoint;
            logger.info('Channel new dominant speaker event: ', dominantSpeakerEndpoint);
            emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default.a.DOMINANT_SPEAKER_CHANGED, dominantSpeakerEndpoint);
            break;
          }

        case 'EndpointConnectivityStatusChangeEvent':
          {
            const endpoint = obj.endpoint;
            const isActive = obj.active === 'true';
            logger.info(`Endpoint connection status changed: ${endpoint} active ? ${isActive}`);
            emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default.a.ENDPOINT_CONN_STATUS_CHANGED, endpoint, isActive);
            break;
          }

        case 'EndpointMessage':
          {
            emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default.a.ENDPOINT_MESSAGE_RECEIVED, obj.from, obj.msgPayload);
            break;
          }

        case 'LastNEndpointsChangeEvent':
          {
            // The new/latest list of last-n endpoint IDs.
            const lastNEndpoints = obj.lastNEndpoints;
            logger.info('Channel new last-n event: ', lastNEndpoints, obj);
            emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default.a.LASTN_ENDPOINT_CHANGED, lastNEndpoints, obj);
            break;
          }

        case 'SelectedUpdateEvent':
          {
            const isSelected = obj.isSelected;
            logger.info(`SelectedUpdateEvent isSelected? ${isSelected}`);
            emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default.a.IS_SELECTED_CHANGED, isSelected);
            break;
          }

        default:
          {
            logger.debug('Channel JSON-formatted message: ', obj); // The received message appears to be appropriately formatted
            // (i.e. is a JSON object which assigns a value to the
            // mandatory property colibriClass) so don't just swallow it,
            // expose it to public consumption.

            emitter.emit(`rtc.datachannel.${colibriClass}`, obj);
          }
      }
    };

    channel.onclose = event => {
      logger.info(`Channel closed by ${this._closedFromClient ? 'client' : 'server'}`);

      if (this._mode === 'websocket') {
        if (!this._closedFromClient) {
          logger.error(`Channel closed: ${event.code} ${event.reason}`);

          this._retryWebSocketConnection(event);
        }
      } // Remove the channel.


      this._channel = null;
    }; // Store the channel.


    this._channel = channel;
  }
  /**
   * Sends passed object via the channel.
   * @param {object} jsonObject The object that will be sent.
   * @throws NetworkError or InvalidStateError from RTCDataChannel#send (@see
   * {@link https://developer.mozilla.org/docs/Web/API/RTCDataChannel/send})
   * or from WebSocket#send or Error with "No opened channel" message.
   */


  _send(jsonObject) {
    const channel = this._channel;

    if (!this.isOpen()) {
      logger.error('Bridge Channel send: no opened channel.');
      throw new Error('No opened channel');
    }

    channel.send(JSON.stringify(jsonObject));
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\BridgeChannel.js"))

/***/ }),

/***/ "./modules/RTC/JitsiLocalTrack.js":
/*!****************************************!*\
  !*** ./modules/RTC/JitsiLocalTrack.js ***!
  \****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JitsiLocalTrack; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiTrack__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./JitsiTrack */ "./modules/RTC/JitsiTrack.js");
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackError */ "./JitsiTrackError.js");
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../JitsiTrackErrors */ "./JitsiTrackErrors.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./JitsiTrackEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _RTCUtils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./RTCUtils */ "./modules/RTC/RTCUtils.js");
/* harmony import */ var _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../service/RTC/CameraFacingMode */ "./service/RTC/CameraFacingMode.js");
/* harmony import */ var _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_7___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_7__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__);
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./service/RTC/VideoType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10__);
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");
/* global __filename, Promise */













const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Represents a single media track(either audio or video).
 * One <tt>JitsiLocalTrack</tt> corresponds to one WebRTC MediaStreamTrack.
 */

class JitsiLocalTrack extends _JitsiTrack__WEBPACK_IMPORTED_MODULE_1__["default"] {
  /**
   * Constructs new JitsiLocalTrack instance.
   *
   * @constructor
   * @param {Object} trackInfo
   * @param {number} trackInfo.rtcId the ID assigned by the RTC module
   * @param trackInfo.stream WebRTC MediaStream, parent of the track
   * @param trackInfo.track underlying WebRTC MediaStreamTrack for new
   * JitsiRemoteTrack
   * @param trackInfo.mediaType the MediaType of the JitsiRemoteTrack
   * @param trackInfo.videoType the VideoType of the JitsiRemoteTrack
   * @param trackInfo.effects the effects array contains the effect instance to use
   * @param trackInfo.resolution the video resolution if it's a video track
   * @param trackInfo.deviceId the ID of the local device for this track
   * @param trackInfo.facingMode the camera facing mode used in getUserMedia
   * call
   * @param {sourceId} trackInfo.sourceId - The id of the desktop sharing
   * source. NOTE: defined for desktop sharing tracks only.
   */
  constructor({
    deviceId,
    facingMode,
    mediaType,
    resolution,
    rtcId,
    sourceId,
    sourceType,
    stream,
    track,
    videoType,
    effects = []
  }) {
    super(
    /* conference */
    null, stream, track,
    /* streamInactiveHandler */
    () => this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_4__["LOCAL_TRACK_STOPPED"]), mediaType, videoType);
    this._setEffectInProgress = false;
    const effect = effects.find(e => e.isEnabled(this));

    if (effect) {
      this._startStreamEffect(effect);
    }
    /**
     * The ID assigned by the RTC module on instance creation.
     *
     * @type {number}
     */


    this.rtcId = rtcId;
    this.sourceId = sourceId;
    this.sourceType = sourceType;

    if (_browser__WEBPACK_IMPORTED_MODULE_5__["default"].usesNewGumFlow()) {
      // Get the resolution from the track itself because it cannot be
      // certain which resolution webrtc has fallen back to using.
      this.resolution = track.getSettings().height; // Cache the constraints of the track in case of any this track
      // model needs to call getUserMedia again, such as when unmuting.

      this._constraints = track.getConstraints(); // Safari returns an empty constraints object, construct the constraints using getSettings.

      if (!Object.keys(this._constraints).length && videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10___default.a.CAMERA) {
        this._constraints = {
          height: track.getSettings().height,
          width: track.getSettings().width
        };
      }
    } else {
      // FIXME Currently, Firefox is ignoring our constraints about
      // resolutions so we do not store it, to avoid wrong reporting of
      // local track resolution.
      this.resolution = _browser__WEBPACK_IMPORTED_MODULE_5__["default"].isFirefox() ? null : resolution;
    }

    this.deviceId = deviceId;
    /**
     * The <tt>Promise</tt> which represents the progress of a previously
     * queued/scheduled {@link _setMuted} (from the point of view of
     * {@link _queueSetMuted}).
     *
     * @private
     * @type {Promise}
     */

    this._prevSetMuted = Promise.resolve();
    /**
     * The facing mode of the camera from which this JitsiLocalTrack
     * instance was obtained.
     *
     * @private
     * @type {CameraFacingMode|undefined}
     */

    this._facingMode = facingMode; // Currently there is no way to know the MediaStreamTrack ended due to
    // to device disconnect in Firefox through e.g. "readyState" property.
    // Instead we will compare current track's label with device labels from
    // enumerateDevices() list.

    this._trackEnded = false;
    /**
     * Indicates whether data has been sent or not.
     */

    this._hasSentData = false;
    /**
     * Used only for detection of audio problems. We want to check only once
     * whether the track is sending data ot not. This flag is set to false
     * after the check.
     */

    this._testDataSent = true; // Currently there is no way to determine with what device track was
    // created (until getConstraints() support), however we can associate
    // tracks with real devices obtained from enumerateDevices() call as
    // soon as it's called.
    // NOTE: this.deviceId corresponds to the device id specified in GUM constraints and this._realDeviceId seems to
    // correspond to the id of a matching device from the available device list.

    this._realDeviceId = this.deviceId === '' ? undefined : this.deviceId;
    this._trackMutedTS = 0;

    this._onDeviceListWillChange = devices => {
      const oldRealDeviceId = this._realDeviceId;

      this._setRealDeviceIdFromDeviceList(devices);

      if ( // Mark track as ended for those browsers that do not support
      // "readyState" property. We do not touch tracks created with
      // default device ID "".
      typeof this.getTrack().readyState === 'undefined' && typeof this._realDeviceId !== 'undefined' && !devices.find(d => d.deviceId === this._realDeviceId) || // If there was an associated realDeviceID and after the device change the realDeviceId is undefined
      // then the associated device has been disconnected and the _trackEnded flag needs to be set. In
      // addition on some Chrome versions the readyState property is set after the device change event is
      // triggered which causes issues in jitsi-meet with the selection of a new device because we don't
      // detect that the old one was removed.
      typeof oldRealDeviceId !== 'undefined' && typeof this._realDeviceId === 'undefined') {
        this._trackEnded = true;
      }
    }; // Subscribe each created local audio track to
    // RTCEvents.AUDIO_OUTPUT_DEVICE_CHANGED event. This is different from
    // handling this event for remote tracks (which are handled in RTC.js),
    // because there might be local tracks not attached to a conference.


    if (this.isAudioTrack() && _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].isDeviceChangeAvailable('output')) {
      this._onAudioOutputDeviceChanged = this.setAudioOutput.bind(this);
      _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.AUDIO_OUTPUT_DEVICE_CHANGED, this._onAudioOutputDeviceChanged);
    }

    _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.DEVICE_LIST_WILL_CHANGE, this._onDeviceListWillChange);

    this._initNoDataFromSourceHandlers();
  }
  /**
   * Returns if associated MediaStreamTrack is in the 'ended' state
   *
   * @returns {boolean}
   */


  isEnded() {
    if (this.isVideoTrack() && this.isMuted()) {
      // If a video track is muted the readyState will be ended, that's why we need to rely only on the
      // _trackEnded flag.
      return this._trackEnded;
    }

    return this.getTrack().readyState === 'ended' || this._trackEnded;
  }
  /**
   * Sets handlers to the MediaStreamTrack object that will detect camera
   * issues.
   */


  _initNoDataFromSourceHandlers() {
    if (!this._isNoDataFromSourceEventsEnabled()) {
      return;
    }

    this._setHandler('track_mute', () => {
      this._trackMutedTS = window.performance.now();

      this._fireNoDataFromSourceEvent();
    });

    this._setHandler('track_unmute', () => {
      this._fireNoDataFromSourceEvent();

      _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].sendAnalyticsAndLog(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_11__["TRACK_UNMUTED"], {
        'media_type': this.getType(),
        'track_type': 'local',
        value: window.performance.now() - this._trackMutedTS
      });
    });

    if (this.isVideoTrack() && this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10___default.a.CAMERA) {
      this._setHandler('track_ended', () => {
        if (!this.isReceivingData()) {
          this._fireNoDataFromSourceEvent();
        }
      });
    }
  }
  /**
   * Returns true if no data from source events are enabled for this JitsiLocalTrack and false otherwise.
   *
   * @returns {boolean} - True if no data from source events are enabled for this JitsiLocalTrack and false otherwise.
   */


  _isNoDataFromSourceEventsEnabled() {
    // Disable the events for screen sharing.
    return !this.isVideoTrack() || this.videoType !== _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10___default.a.DESKTOP;
  }
  /**
   * Fires NO_DATA_FROM_SOURCE event and logs it to analytics and callstats.
   */


  _fireNoDataFromSourceEvent() {
    const value = !this.isReceivingData();
    this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_4__["NO_DATA_FROM_SOURCE"], value); // FIXME: Should we report all of those events

    _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_11__["createNoDataFromSourceEvent"])(this.getType(), value));
    _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].sendLog(JSON.stringify({
      name: _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_4__["NO_DATA_FROM_SOURCE"],
      log: value
    }));
  }
  /**
   * Sets real device ID by comparing track information with device
   * information. This is temporary solution until getConstraints() method
   * will be implemented in browsers.
   *
   * @param {MediaDeviceInfo[]} devices - list of devices obtained from
   * enumerateDevices() call
   */


  _setRealDeviceIdFromDeviceList(devices) {
    const track = this.getTrack();
    const kind = `${track.kind}input`;
    let device = devices.find(d => d.kind === kind && d.label === track.label);

    if (!device && this._realDeviceId === 'default') {
      // the default device has been changed.
      // If the default device was 'A' and the default device is changed to 'B' the label for the track will
      // remain 'Default - A' but the label for the device in the device list will be updated to 'A'. That's
      // why in order to match it we need to remove the 'Default - ' part.
      const label = (track.label || '').replace('Default - ', '');
      device = devices.find(d => d.kind === kind && d.label === label);
    }

    if (device) {
      this._realDeviceId = device.deviceId;
    } else {
      this._realDeviceId = undefined;
    }
  }
  /**
   * Sets the stream property of JitsiLocalTrack object and sets all stored
   * handlers to it.
   *
   * @param {MediaStream} stream the new stream.
   * @protected
   */


  _setStream(stream) {
    super._setStream(stream);

    if (stream) {
      // Store the MSID for video mute/unmute purposes.
      this.storedMSID = this.getMSID();
      logger.debug(`Setting new MSID: ${this.storedMSID} on ${this}`);
    } else {
      logger.debug(`Setting 'null' stream on ${this}`);
    }
  }
  /**
   * Starts the effect process and returns the modified stream.
   *
   * @private
   * @param {*} effect - Represents effect instance
   * @returns {void}
   */


  _startStreamEffect(effect) {
    this._streamEffect = effect;
    this._originalStream = this.stream;

    this._setStream(this._streamEffect.startEffect(this._originalStream));
  }
  /**
   * Stops the effect process and returns the original stream.
   *
   * @private
   * @returns {void}
   */


  _stopStreamEffect() {
    if (this._streamEffect) {
      this._streamEffect.stopEffect();

      this._setStream(this._originalStream);
    }
  }
  /**
   * Stops the currently used effect (if there is one) and starts the passed effect (if there is one).
   *
   * @param {Object|undefined} effect - The new effect to be set.
   */


  _switchStreamEffect(effect) {
    if (this._streamEffect) {
      this._stopStreamEffect();

      this._streamEffect = undefined;
    }

    if (effect) {
      this._startStreamEffect(effect);
    }
  }
  /**
   * Sets the effect and switches between the modified stream and original one.
   *
   * @param {Object} effect - Represents the effect instance to be used.
   * @returns {Promise}
   */


  setEffect(effect) {
    if (typeof this._streamEffect === 'undefined' && typeof effect === 'undefined') {
      return Promise.resolve();
    }

    if (typeof effect !== 'undefined' && !effect.isEnabled(this)) {
      return Promise.reject(new Error('Incompatible effect instance!'));
    }

    if (this._setEffectInProgress === true) {
      return Promise.reject(new Error('setEffect already in progress!'));
    } // In case we have an audio track that is being enhanced with an effect, we still want it to be applied,
    // even if the track is muted. Where as for video the actual track doesn't exists if it's muted.


    if (this.isMuted() && !this.isAudioTrack()) {
      this._streamEffect = effect;
      return Promise.resolve();
    }

    const conference = this.conference;

    if (!conference) {
      this._switchStreamEffect(effect);

      return Promise.resolve();
    }

    this._setEffectInProgress = true;

    if (_browser__WEBPACK_IMPORTED_MODULE_5__["default"].usesUnifiedPlan()) {
      this._switchStreamEffect(effect);

      if (this.isVideoTrack()) {
        this.containers.forEach(cont => _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].attachMediaStream(cont, this.stream));
      }

      return conference.replaceTrack(this, this).then(() => {
        this._setEffectInProgress = false;
      }).catch(error => {
        this._setEffectInProgress = false;

        this._switchStreamEffect();

        logger.error('Failed to switch to the new stream!', error);
        throw error;
      });
    } // TODO: Create new JingleSessionPC method for replacing a stream in JitsiLocalTrack without offer answer.


    return conference.removeTrack(this).then(() => {
      this._switchStreamEffect(effect);

      if (this.isVideoTrack()) {
        this.containers.forEach(cont => _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].attachMediaStream(cont, this.stream));
      }

      return conference.addTrack(this);
    }).then(() => {
      this._setEffectInProgress = false;
    }).catch(error => {
      // Any error will be not recovarable and will trigger CONFERENCE_FAILED event. But let's try to cleanup
      // everyhting related to the effect functionality.
      this._setEffectInProgress = false;

      this._switchStreamEffect();

      logger.error('Failed to switch to the new stream!', error);
      throw error;
    });
  }
  /**
   * Asynchronously mutes this track.
   *
   * @returns {Promise}
   */


  mute() {
    return this._queueSetMuted(true);
  }
  /**
   * Asynchronously unmutes this track.
   *
   * @returns {Promise}
   */


  unmute() {
    return this._queueSetMuted(false);
  }
  /**
   * Initializes a new Promise to execute {@link #_setMuted}. May be called
   * multiple times in a row and the invocations of {@link #_setMuted} and,
   * consequently, {@link #mute} and/or {@link #unmute} will be resolved in a
   * serialized fashion.
   *
   * @param {boolean} muted - The value to invoke <tt>_setMuted</tt> with.
   * @returns {Promise}
   */


  _queueSetMuted(muted) {
    const setMuted = this._setMuted.bind(this, muted);

    this._prevSetMuted = this._prevSetMuted.then(setMuted, setMuted);
    return this._prevSetMuted;
  }
  /**
   * Mutes / unmutes this track.
   *
   * @param {boolean} muted - If <tt>true</tt>, this track will be muted;
   * otherwise, this track will be unmuted.
   * @private
   * @returns {Promise}
   */


  _setMuted(muted) {
    if (this.isMuted() === muted) {
      return Promise.resolve();
    }

    if (this.disposed) {
      return Promise.reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_2__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_3__["TRACK_IS_DISPOSED"]));
    }

    let promise = Promise.resolve(); // A function that will print info about muted status transition

    const logMuteInfo = () => logger.info(`Mute ${this}: ${muted}`);

    if (this.isAudioTrack() || this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10___default.a.DESKTOP || !_browser__WEBPACK_IMPORTED_MODULE_5__["default"].doesVideoMuteByStreamRemove()) {
      logMuteInfo();

      if (this.track) {
        this.track.enabled = !muted;
      }
    } else if (muted) {
      promise = new Promise((resolve, reject) => {
        logMuteInfo();

        this._removeStreamFromConferenceAsMute(() => {
          if (this._streamEffect) {
            this._stopStreamEffect();
          } // FIXME: Maybe here we should set the SRC for the
          // containers to something
          // We don't want any events to be fired on this stream


          this._unregisterHandlers();

          this.stopStream();

          this._setStream(null);

          resolve();
        }, reject);
      });
    } else {
      logMuteInfo(); // This path is only for camera.

      const streamOptions = {
        cameraDeviceId: this.getDeviceId(),
        devices: [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__["VIDEO"]],
        effects: this._streamEffect ? [this._streamEffect] : [],
        facingMode: this.getCameraFacingMode()
      };

      if (_browser__WEBPACK_IMPORTED_MODULE_5__["default"].usesNewGumFlow()) {
        promise = _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].newObtainAudioAndVideoPermissions(Object.assign({}, streamOptions, {
          constraints: {
            video: this._constraints
          }
        }));
      } else {
        if (this.resolution) {
          streamOptions.resolution = this.resolution;
        }

        promise = _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].obtainAudioAndVideoPermissions(streamOptions);
      }

      promise.then(streamsInfo => {
        // The track kind for presenter track is video as well.
        const mediaType = this.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__["PRESENTER"] ? _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__["VIDEO"] : this.getType();
        const streamInfo = _browser__WEBPACK_IMPORTED_MODULE_5__["default"].usesNewGumFlow() ? streamsInfo.find(info => info.track.kind === mediaType) : streamsInfo.find(info => info.mediaType === mediaType);

        if (streamInfo) {
          this._setStream(streamInfo.stream);

          this.track = streamInfo.track; // This is not good when video type changes after
          // unmute, but let's not crash here

          if (this.videoType !== streamInfo.videoType) {
            logger.warn(`${this}: video type has changed after unmute!`, this.videoType, streamInfo.videoType);
            this.videoType = streamInfo.videoType;
          }
        } else {
          throw new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_2__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_3__["TRACK_NO_STREAM_FOUND"]);
        }

        if (this._streamEffect) {
          this._startStreamEffect(this._streamEffect);
        }

        this.containers.map(cont => _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].attachMediaStream(cont, this.stream));
        return this._addStreamToConferenceAsUnmute();
      });
    }

    return promise.then(() => this._sendMuteStatus(muted)).then(() => this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_4__["TRACK_MUTE_CHANGED"], this));
  }
  /**
   * Adds stream to conference and marks it as "unmute" operation.
   *
   * @private
   * @returns {Promise}
   */


  _addStreamToConferenceAsUnmute() {
    if (!this.conference) {
      return Promise.resolve();
    } // FIXME it would be good to not included conference as part of this
    // process. Only TraceablePeerConnections to which the track is attached
    // should care about this action. The TPCs to which the track is not
    // attached can sync up when track is re-attached.
    // A problem with that is that the "modify sources" queue is part of
    // the JingleSessionPC and it would be excluded from the process. One
    // solution would be to extract class between TPC and JingleSessionPC
    // which would contain the queue and would notify the signaling layer
    // when local SSRCs are changed. This would help to separate XMPP from
    // the RTC module.


    return new Promise((resolve, reject) => {
      this.conference._addLocalTrackAsUnmute(this).then(resolve, error => reject(new Error(error)));
    });
  }
  /**
   * Removes stream from conference and marks it as "mute" operation.
   *
   * @param {Function} successCallback will be called on success
   * @param {Function} errorCallback will be called on error
   * @private
   */


  _removeStreamFromConferenceAsMute(successCallback, errorCallback) {
    if (!this.conference) {
      successCallback();
      return;
    }

    this.conference._removeLocalTrackAsMute(this).then(successCallback, error => errorCallback(new Error(error)));
  }
  /**
   * Sends mute status for a track to conference if any.
   *
   * @param {boolean} mute - If track is muted.
   * @private
   * @returns {Promise}
   */


  _sendMuteStatus(mute) {
    if (!this.conference || !this.conference.room) {
      return Promise.resolve();
    }

    return new Promise(resolve => {
      this.conference.room[this.isAudioTrack() ? 'setAudioMute' : 'setVideoMute'](mute, resolve);
    });
  }
  /**
   * @inheritdoc
   *
   * Stops sending the media track. And removes it from the HTML.
   * NOTE: Works for local tracks only.
   *
   * @extends JitsiTrack#dispose
   * @returns {Promise}
   */


  dispose() {
    this._switchStreamEffect();

    let promise = Promise.resolve();

    if (this.conference) {
      promise = this.conference.removeTrack(this);
    }

    if (this.stream) {
      this.stopStream();
      this.detach();
    }

    _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.DEVICE_LIST_WILL_CHANGE, this._onDeviceListWillChange);

    if (this._onAudioOutputDeviceChanged) {
      _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.AUDIO_OUTPUT_DEVICE_CHANGED, this._onAudioOutputDeviceChanged);
    }

    return promise.then(() => super.dispose());
  }
  /**
   * Returns <tt>true</tt> - if the stream is muted and <tt>false</tt>
   * otherwise.
   *
   * @returns {boolean} <tt>true</tt> - if the stream is muted and
   * <tt>false</tt> otherwise.
   */


  isMuted() {
    // this.stream will be null when we mute local video on Chrome
    if (!this.stream) {
      return true;
    }

    if (this.isVideoTrack() && !this.isActive()) {
      return true;
    }

    return !this.track || !this.track.enabled;
  }
  /**
   * Sets the JitsiConference object associated with the track. This is temp
   * solution.
   *
   * @param conference the JitsiConference object
   */


  _setConference(conference) {
    this.conference = conference; // We want to keep up with postponed events which should have been fired
    // on "attach" call, but for local track we not always have the
    // conference before attaching. However this may result in duplicated
    // events if they have been triggered on "attach" already.

    for (let i = 0; i < this.containers.length; i++) {
      this._maybeFireTrackAttached(this.containers[i]);
    }
  }
  /**
   * Returns <tt>true</tt>.
   *
   * @returns {boolean} <tt>true</tt>
   */


  isLocal() {
    return true;
  }
  /**
   * Returns device id associated with track.
   *
   * @returns {string}
   */


  getDeviceId() {
    return this._realDeviceId || this.deviceId;
  }
  /**
   * Returns the participant id which owns the track.
   *
   * @returns {string} the id of the participants. It corresponds to the
   * Colibri endpoint id/MUC nickname in case of Jitsi-meet.
   */


  getParticipantId() {
    return this.conference && this.conference.myUserId();
  }
  /**
   * Handles bytes sent statistics.
   *
   * @param {TraceablePeerConnection} tpc the source of the "bytes sent" stat
   * @param {number} bytesSent the new value
   * NOTE: used only for audio tracks to detect audio issues.
   */


  _onByteSentStatsReceived(tpc, bytesSent) {
    if (bytesSent > 0) {
      this._hasSentData = true;
    }

    const iceConnectionState = tpc.getConnectionState();

    if (this._testDataSent && iceConnectionState === 'connected') {
      setTimeout(() => {
        if (!this._hasSentData) {
          logger.warn(`${this} 'bytes sent' <= 0: \
                        ${bytesSent}`);
          _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].analytics.sendEvent(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_11__["NO_BYTES_SENT"], {
            'media_type': this.getType()
          });
        }
      }, 3000);
      this._testDataSent = false;
    }
  }
  /**
   * Returns facing mode for video track from camera. For other cases (e.g.
   * audio track or 'desktop' video track) returns undefined.
   *
   * @returns {CameraFacingMode|undefined}
   */


  getCameraFacingMode() {
    if (this.isVideoTrack() && this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10___default.a.CAMERA) {
      // MediaStreamTrack#getSettings() is not implemented in many
      // browsers, so we need feature checking here. Progress on the
      // respective browser's implementation can be tracked at
      // https://bugs.chromium.org/p/webrtc/issues/detail?id=2481 for
      // Chromium and https://bugzilla.mozilla.org/show_bug.cgi?id=1213517
      // for Firefox. Even if a browser implements getSettings() already,
      // it might still not return anything for 'facingMode'.
      let trackSettings;

      try {
        trackSettings = this.track.getSettings();
      } catch (e) {// XXX React-native-webrtc, for example, defines
        // MediaStreamTrack#getSettings() but the implementation throws
        // a "Not implemented" Error.
      }

      if (trackSettings && 'facingMode' in trackSettings) {
        return trackSettings.facingMode;
      }

      if (typeof this._facingMode !== 'undefined') {
        return this._facingMode;
      } // In most cases we are showing a webcam. So if we've gotten here,
      // it should be relatively safe to assume that we are probably
      // showing the user-facing camera.


      return _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_7___default.a.USER;
    }

    return undefined;
  }
  /**
   * Stops the associated MediaStream.
   */


  stopStream() {
    /**
     * Indicates that we are executing {@link #stopStream} i.e.
     * {@link RTCUtils#stopMediaStream} for the <tt>MediaStream</tt>
     * associated with this <tt>JitsiTrack</tt> instance.
     *
     * @private
     * @type {boolean}
     */
    this._stopStreamInProgress = true;

    try {
      _RTCUtils__WEBPACK_IMPORTED_MODULE_6__["default"].stopMediaStream(this.stream);
    } finally {
      this._stopStreamInProgress = false;
    }
  }
  /**
   * Switches the camera facing mode if the WebRTC implementation supports the
   * custom MediaStreamTrack._switchCamera method. Currently, the method in
   * question is implemented in react-native-webrtc only. When such a WebRTC
   * implementation is executing, the method is the preferred way to switch
   * between the front/user-facing and the back/environment-facing cameras
   * because it will likely be (as is the case of react-native-webrtc)
   * noticeably faster that creating a new MediaStreamTrack via a new
   * getUserMedia call with the switched facingMode constraint value.
   * Moreover, the approach with a new getUserMedia call may not even work:
   * WebRTC on Android and iOS is either very slow to open the camera a second
   * time or plainly freezes attempting to do that.
   */


  _switchCamera() {
    if (this.isVideoTrack() && this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10___default.a.CAMERA && typeof this.track._switchCamera === 'function') {
      this.track._switchCamera();

      this._facingMode = this._facingMode === _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_7___default.a.ENVIRONMENT ? _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_7___default.a.USER : _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_7___default.a.ENVIRONMENT;
    }
  }
  /**
   * Checks whether the attached MediaStream is receiving data from source or
   * not. If the stream property is null(because of mute or another reason)
   * this method will return false.
   * NOTE: This method doesn't indicate problem with the streams directly.
   * For example in case of video mute the method will return false or if the
   * user has disposed the track.
   *
   * @returns {boolean} true if the stream is receiving data and false
   * this otherwise.
   */


  isReceivingData() {
    if (this.isVideoTrack() && (this.isMuted() || this._stopStreamInProgress || this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10___default.a.DESKTOP)) {
      return true;
    }

    if (!this.stream) {
      return false;
    } // In older version of the spec there is no muted property and
    // readyState can have value muted. In the latest versions
    // readyState can have values "live" and "ended" and there is
    // muted boolean property. If the stream is muted that means that
    // we aren't receiving any data from the source. We want to notify
    // the users for error if the stream is muted or ended on it's
    // creation.
    // For video blur enabled use the original video stream


    const stream = this._effectEnabled ? this._originalStream : this.stream;
    return stream.getTracks().some(track => (!('readyState' in track) || track.readyState === 'live') && (!('muted' in track) || track.muted !== true));
  }
  /**
   * Creates a text representation of this local track instance.
   *
   * @return {string}
   */


  toString() {
    return `LocalTrack[${this.rtcId},${this.getType()}]`;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\JitsiLocalTrack.js"))

/***/ }),

/***/ "./modules/RTC/JitsiRemoteTrack.js":
/*!*****************************************!*\
  !*** ./modules/RTC/JitsiRemoteTrack.js ***!
  \*****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JitsiRemoteTrack; });
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _JitsiTrack__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./JitsiTrack */ "./modules/RTC/JitsiTrack.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./JitsiTrackEvents.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");





const logger = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js").getLogger(__filename);

const RTCEvents = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");

let ttfmTrackerAudioAttached = false;
let ttfmTrackerVideoAttached = false;
/**
 * List of container events that we are going to process. _onContainerEventHandler will be added as listener to the
 * container for every event in the list.
 */

const containerEvents = ['abort', 'canplay', 'canplaythrough', 'emptied', 'ended', 'error', 'loadeddata', 'loadedmetadata', 'loadstart', 'pause', 'play', 'playing', 'ratechange', 'stalled', 'suspend', 'waiting'];
/* eslint-disable max-params */

/**
 * Represents a single media track (either audio or video).
 */

class JitsiRemoteTrack extends _JitsiTrack__WEBPACK_IMPORTED_MODULE_1__["default"] {
  /**
   * Creates new JitsiRemoteTrack instance.
   * @param {RTC} rtc the RTC service instance.
   * @param {JitsiConference} conference the conference to which this track
   *        belongs to
   * @param {string} ownerEndpointId the endpoint ID of the track owner
   * @param {MediaStream} stream WebRTC MediaStream, parent of the track
   * @param {MediaStreamTrack} track underlying WebRTC MediaStreamTrack for
   *        the new JitsiRemoteTrack
   * @param {MediaType} mediaType the type of the media
   * @param {VideoType} videoType the type of the video if applicable
   * @param {number} ssrc the SSRC number of the Media Stream
   * @param {boolean} muted the initial muted state
   * @param {boolean} isP2P indicates whether or not this track belongs to a
   * P2P session
   * @throws {TypeError} if <tt>ssrc</tt> is not a number.
   * @constructor
   */
  constructor(rtc, conference, ownerEndpointId, stream, track, mediaType, videoType, ssrc, muted, isP2P) {
    super(conference, stream, track, () => {// Nothing to do if the track is inactive.
    }, mediaType, videoType);
    this.rtc = rtc; // Prevent from mixing up type of SSRC which should be a number

    if (typeof ssrc !== 'number') {
      throw new TypeError(`SSRC ${ssrc} is not a number`);
    }

    this.ssrc = ssrc;
    this.ownerEndpointId = ownerEndpointId;
    this.muted = muted;
    this.isP2P = isP2P;
    logger.debug(`New remote track added: ${this}`); // we want to mark whether the track has been ever muted
    // to detect ttfm events for startmuted conferences, as it can
    // significantly increase ttfm values

    this.hasBeenMuted = muted; // Bind 'onmute' and 'onunmute' event handlers

    if (this.rtc && this.track) {
      this._bindTrackHandlers();
    }

    this._containerHandlers = {};
    containerEvents.forEach(event => {
      this._containerHandlers[event] = this._containerEventHandler.bind(this, event);
    });
  }
  /* eslint-enable max-params */

  /**
   * Attaches the track handlers.
   *
   * @returns {void}
   */


  _bindTrackHandlers() {
    this.track.addEventListener('mute', () => this._onTrackMute());
    this.track.addEventListener('unmute', () => this._onTrackUnmute());
    this.track.addEventListener('ended', () => {
      logger.debug(`"onended" event(${Date.now()}): ${this}`);
    });
  }
  /**
   * Callback invoked when the track is muted. Emits an event notifying
   * listeners of the mute event.
   *
   * @private
   * @returns {void}
   */


  _onTrackMute() {
    logger.debug(`"onmute" event(${Date.now()}): ${this}`);
    this.rtc.eventEmitter.emit(RTCEvents.REMOTE_TRACK_MUTE, this);
  }
  /**
   * Callback invoked when the track is unmuted. Emits an event notifying
   * listeners of the mute event.
   *
   * @private
   * @returns {void}
   */


  _onTrackUnmute() {
    logger.debug(`"onunmute" event(${Date.now()}): ${this}`);
    this.rtc.eventEmitter.emit(RTCEvents.REMOTE_TRACK_UNMUTE, this);
  }
  /**
   * Sets current muted status and fires an events for the change.
   * @param value the muted status.
   */


  setMute(value) {
    if (this.muted === value) {
      return;
    }

    if (value) {
      this.hasBeenMuted = true;
    } // we can have a fake video stream


    if (this.stream) {
      this.stream.muted = value;
    }

    this.muted = value;
    this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_MUTE_CHANGED"], this);
  }
  /**
   * Returns the current muted status of the track.
   * @returns {boolean|*|JitsiRemoteTrack.muted} <tt>true</tt> if the track is
   * muted and <tt>false</tt> otherwise.
   */


  isMuted() {
    return this.muted;
  }
  /**
   * Returns the participant id which owns the track.
   *
   * @returns {string} the id of the participants. It corresponds to the
   * Colibri endpoint id/MUC nickname in case of Jitsi-meet.
   */


  getParticipantId() {
    return this.ownerEndpointId;
  }
  /**
   * Return false;
   */


  isLocal() {
    return false;
  }
  /**
   * Returns the synchronization source identifier (SSRC) of this remote
   * track.
   *
   * @returns {number} the SSRC of this remote track.
   */


  getSSRC() {
    return this.ssrc;
  }
  /**
   * Changes the video type of the track.
   *
   * @param {string} type - The new video type("camera", "desktop").
   */


  _setVideoType(type) {
    if (this.videoType === type) {
      return;
    }

    this.videoType = type;
    this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_VIDEOTYPE_CHANGED"], type);
  }
  /**
   * Handles track play events.
   */


  _playCallback() {
    const type = this.isVideoTrack() ? 'video' : 'audio';
    const now = window.performance.now();
    console.log(`(TIME) Render ${type}:\t`, now);
    this.conference.getConnectionTimes()[`${type}.render`] = now; // The conference can be started without calling GUM
    // FIXME if there would be a module for connection times this kind
    // of logic (gumDuration or ttfm) should end up there

    const gumStart = window.connectionTimes['obtainPermissions.start'];
    const gumEnd = window.connectionTimes['obtainPermissions.end'];
    const gumDuration = !isNaN(gumEnd) && !isNaN(gumStart) ? gumEnd - gumStart : 0; // Subtract the muc.joined-to-session-initiate duration because jicofo
    // waits until there are 2 participants to start Jingle sessions.

    const ttfm = now - (this.conference.getConnectionTimes()['session.initiate'] - this.conference.getConnectionTimes()['muc.joined']) - gumDuration;
    this.conference.getConnectionTimes()[`${type}.ttfm`] = ttfm;
    console.log(`(TIME) TTFM ${type}:\t`, ttfm);
    _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["createTtfmEvent"])({
      'media_type': type,
      muted: this.hasBeenMuted,
      value: ttfm
    }));
  }
  /**
   * Attach time to first media tracker only if there is conference and only
   * for the first element.
   * @param container the HTML container which can be 'video' or 'audio'
   * element.
   * @private
   */


  _attachTTFMTracker(container) {
    if (ttfmTrackerAudioAttached && this.isAudioTrack() || ttfmTrackerVideoAttached && this.isVideoTrack()) {
      return;
    }

    if (this.isAudioTrack()) {
      ttfmTrackerAudioAttached = true;
    }

    if (this.isVideoTrack()) {
      ttfmTrackerVideoAttached = true;
    }

    container.addEventListener('canplay', this._playCallback.bind(this));
  }
  /**
   * Called when the track has been attached to a new container.
   *
   * @param {HTMLElement} container the HTML container which can be 'video' or
   * 'audio' element.
   * @private
   */


  _onTrackAttach(container) {
    logger.debug(`Track has been attached to a container: ${this}`);
    containerEvents.forEach(event => {
      container.addEventListener(event, this._containerHandlers[event]);
    });
  }
  /**
   * Called when the track has been detached from a container.
   *
   * @param {HTMLElement} container the HTML container which can be 'video' or
   * 'audio' element.
   * @private
   */


  _onTrackDetach(container) {
    logger.debug(`Track has been detached from a container: ${this}`);
    containerEvents.forEach(event => {
      container.removeEventListener(event, this._containerHandlers[event]);
    });
  }
  /**
   * An event handler for events triggered by the attached container.
   *
   * @param {string} type - The type of the event.
   */


  _containerEventHandler(type) {
    logger.debug(`${type} handler was called for a container with attached ${this}`);
  }
  /**
   * Returns a string with a description of the current status of the track.
   *
   * @returns {string}
   */


  _getStatus() {
    const {
      enabled,
      muted,
      readyState
    } = this.track;
    return `readyState: ${readyState}, muted: ${muted}, enabled: ${enabled}`;
  }
  /**
   * Creates a text representation of this remote track instance.
   * @return {string}
   */


  toString() {
    return `RemoteTrack[userID: ${this.getParticipantId()}, type: ${this.getType()}, ssrc: ${this.getSSRC()}, p2p: ${this.isP2P}, status: ${this._getStatus()}]`;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\JitsiRemoteTrack.js"))

/***/ }),

/***/ "./modules/RTC/JitsiTrack.js":
/*!***********************************!*\
  !*** ./modules/RTC/JitsiTrack.js ***!
  \***********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JitsiTrack; });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./JitsiTrackEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _RTCUtils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./RTCUtils */ "./modules/RTC/RTCUtils.js");
/* global __filename, module */





const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__["getLogger"])(__filename);
/**
 * Maps our handler types to MediaStreamTrack properties.
 */

const trackHandler2Prop = {
  'track_mute': 'onmute',
  // Not supported on FF
  'track_unmute': 'onunmute',
  'track_ended': 'onended'
};
/**
 * Adds onended/oninactive handler to a MediaStream.
 * @param mediaStream a MediaStream to attach onended/oninactive handler
 * @param handler the handler
 */

function addMediaStreamInactiveHandler(mediaStream, handler) {
  mediaStream.oninactive = handler;
}
/**
 * Represents a single media track (either audio or video).
 */


class JitsiTrack extends events__WEBPACK_IMPORTED_MODULE_0___default.a {
  /* eslint-disable max-params */

  /**
   * Represents a single media track (either audio or video).
   * @constructor
   * @param conference the rtc instance
   * @param stream the WebRTC MediaStream instance
   * @param track the WebRTC MediaStreamTrack instance, must be part of
   * the given <tt>stream</tt>.
   * @param streamInactiveHandler the function that will handle
   *        onended/oninactive events of the stream.
   * @param trackMediaType the media type of the JitsiTrack
   * @param videoType the VideoType for this track if any
   */
  constructor(conference, stream, track, streamInactiveHandler, trackMediaType, videoType) {
    super(); // aliases for addListener/removeListener

    this.addEventListener = this.addListener;
    this.removeEventListener = this.off = this.removeListener;
    /**
     * Array with the HTML elements that are displaying the streams.
     * @type {Array}
     */

    this.containers = [];
    this.conference = conference;
    this.audioLevel = -1;
    this.type = trackMediaType;
    this.track = track;
    this.videoType = videoType;
    this.handlers = new Map();
    /**
     * Indicates whether this JitsiTrack has been disposed. If true, this
     * JitsiTrack is to be considered unusable and operations involving it
     * are to fail (e.g. {@link JitsiConference#addTrack(JitsiTrack)},
     * {@link JitsiConference#removeTrack(JitsiTrack)}).
     * @type {boolean}
     */

    this.disposed = false;
    /**
     * The inactive handler which will be triggered when the underlying
     * <tt>MediaStream</tt> ends.
     *
     * @private
     * @type {Function}
     */

    this._streamInactiveHandler = streamInactiveHandler;

    this._setStream(stream);
  }
  /* eslint-enable max-params */

  /**
   * Sets handler to the WebRTC MediaStream or MediaStreamTrack object
   * depending on the passed type.
   * @param {string} type the type of the handler that is going to be set
   * @param {Function} handler the handler.
   */


  _setHandler(type, handler) {
    if (!trackHandler2Prop.hasOwnProperty(type)) {
      logger.error(`Invalid handler type ${type}`);
      return;
    }

    if (handler) {
      this.handlers.set(type, handler);
    } else {
      this.handlers.delete(type);
    }

    if (this.stream) {
      for (const track of this.stream.getTracks()) {
        track[trackHandler2Prop[type]] = handler;
      }
    }
  }
  /**
   * Unregisters all event handlers bound to the underlying media stream/track
   * @private
   */


  _unregisterHandlers() {
    if (!this.stream) {
      logger.warn(`${this}: unable to unregister handlers - no stream object`);
      return;
    }

    for (const type of this.handlers.keys()) {
      // FIXME Why only video tracks?
      for (const videoTrack of this.stream.getVideoTracks()) {
        videoTrack[trackHandler2Prop[type]] = undefined;
      }
    }

    if (this._streamInactiveHandler) {
      addMediaStreamInactiveHandler(this.stream, undefined);
    }
  }
  /**
   * Sets the stream property of JitsiTrack object and sets all stored
   * handlers to it.
   *
   * @param {MediaStream} stream the new stream.
   * @protected
   */


  _setStream(stream) {
    if (this.stream === stream) {
      return;
    }

    this.stream = stream; // TODO Practically, that's like the opposite of _unregisterHandlers
    // i.e. may be abstracted into a function/method called
    // _registerHandlers for clarity and easing the maintenance of the two
    // pieces of source code.

    if (this.stream) {
      for (const type of this.handlers.keys()) {
        this._setHandler(type, this.handlers.get(type));
      }

      if (this._streamInactiveHandler) {
        addMediaStreamInactiveHandler(this.stream, this._streamInactiveHandler);
      }
    }
  }
  /**
   * Returns the type (audio or video) of this track.
   */


  getType() {
    return this.type;
  }
  /**
   * Check if this is an audio track.
   */


  isAudioTrack() {
    return this.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__["AUDIO"];
  }
  /**
   * Checks whether the underlying WebRTC <tt>MediaStreamTrack</tt> is muted
   * according to it's 'muted' field status.
   * @return {boolean} <tt>true</tt> if the underlying
   * <tt>MediaStreamTrack</tt> is muted or <tt>false</tt> otherwise.
   */


  isWebRTCTrackMuted() {
    return this.track && this.track.muted;
  }
  /**
   * Check if this is a video track.
   */


  isVideoTrack() {
    return this.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__["VIDEO"];
  }
  /**
   * Checks whether this is a local track.
   * @abstract
   * @return {boolean} 'true' if it's a local track or 'false' otherwise.
   */


  isLocal() {
    throw new Error('Not implemented by subclass');
  }
  /**
   * Check whether this is a local audio track.
   *
   * @return {boolean} -  true if track represents a local audio track, false otherwise.
   */


  isLocalAudioTrack() {
    return this.isAudioTrack() && this.isLocal();
  }
  /**
   * Returns the WebRTC MediaStream instance.
   */


  getOriginalStream() {
    return this.stream;
  }
  /**
   * Returns the ID of the underlying WebRTC Media Stream(if any)
   * @returns {String|null}
   */


  getStreamId() {
    return this.stream ? this.stream.id : null;
  }
  /**
   * Return the underlying WebRTC MediaStreamTrack
   * @returns {MediaStreamTrack}
   */


  getTrack() {
    return this.track;
  }
  /**
   * Return the underlying WebRTC MediaStreamTrack label
   * @returns {string}
   */


  getTrackLabel() {
    return this.track.label;
  }
  /**
   * Returns the ID of the underlying WebRTC MediaStreamTrack(if any)
   * @returns {String|null}
   */


  getTrackId() {
    return this.track ? this.track.id : null;
  }
  /**
   * Return meaningful usage label for this track depending on it's media and
   * eventual video type.
   * @returns {string}
   */


  getUsageLabel() {
    if (this.isAudioTrack()) {
      return 'mic';
    }

    return this.videoType ? this.videoType : 'default';
  }
  /**
   * Eventually will trigger RTCEvents.TRACK_ATTACHED event.
   * @param container the video/audio container to which this stream is
   *        attached and for which event will be fired.
   * @private
   */


  _maybeFireTrackAttached(container) {
    if (this.conference && container) {
      this.conference._onTrackAttach(this, container);
    }
  }
  /**
   * Attaches the MediaStream of this track to an HTML container.
   * Adds the container to the list of containers that are displaying the
   * track.
   *
   * @param container the HTML container which can be 'video' or 'audio'
   * element.
   *
   * @returns {void}
   */


  attach(container) {
    if (this.stream) {
      this._onTrackAttach(container);

      _RTCUtils__WEBPACK_IMPORTED_MODULE_4__["default"].attachMediaStream(container, this.stream);
    }

    this.containers.push(container);

    this._maybeFireTrackAttached(container);

    this._attachTTFMTracker(container);
  }
  /**
   * Removes this JitsiTrack from the passed HTML container.
   *
   * @param container the HTML container to detach from this JitsiTrack. If
   * <tt>null</tt> or <tt>undefined</tt>, all containers are removed. A
   * container can be a 'video', 'audio' or 'object' HTML element instance to
   * which this JitsiTrack is currently attached.
   */


  detach(container) {
    for (let cs = this.containers, i = cs.length - 1; i >= 0; --i) {
      const c = cs[i];

      if (!container) {
        this._onTrackDetach(c);

        _RTCUtils__WEBPACK_IMPORTED_MODULE_4__["default"].attachMediaStream(c, null);
      }

      if (!container || c === container) {
        cs.splice(i, 1);
      }
    }

    if (container) {
      this._onTrackDetach(container);

      _RTCUtils__WEBPACK_IMPORTED_MODULE_4__["default"].attachMediaStream(container, null);
    }
  }
  /**
   * Called when the track has been attached to a new container.
   *
   * @param {HTMLElement} container the HTML container which can be 'video' or
   * 'audio' element.
   * @private
   */


  _onTrackAttach(container) {} // eslint-disable-line no-unused-vars
  // Should be defined by the classes that are extending JitsiTrack

  /**
   * Called when the track has been detached from a container.
   *
   * @param {HTMLElement} container the HTML container which can be 'video' or
   * 'audio' element.
   * @private
   */


  _onTrackDetach(container) {} // eslint-disable-line no-unused-vars
  // Should be defined by the classes that are extending JitsiTrack

  /**
   * Attach time to first media tracker only if there is conference and only
   * for the first element.
   *
   * @param {HTMLElement} container the HTML container which can be 'video' or
   * 'audio' element.
   * @private
   */


  _attachTTFMTracker(container) {} // eslint-disable-line no-unused-vars
  // Should be defined by the classes that are extending JitsiTrack

  /**
   * Removes attached event listeners.
   *
   * @returns {Promise}
   */


  dispose() {
    this.removeAllListeners();
    this.disposed = true;
    return Promise.resolve();
  }
  /**
   * Returns true if this is a video track and the source of the video is a
   * screen capture as opposed to a camera.
   */


  isScreenSharing() {} // FIXME: Should be fixed or removed.

  /**
   * Returns id of the track.
   * @returns {string|null} id of the track or null if this is fake track.
   */


  getId() {
    if (this.stream) {
      return _RTCUtils__WEBPACK_IMPORTED_MODULE_4__["default"].getStreamID(this.stream);
    }

    return null;
  }
  /**
   * Checks whether the MediaStream is active/not ended.
   * When there is no check for active we don't have information and so
   * will return that stream is active (in case of FF).
   * @returns {boolean} whether MediaStream is active.
   */


  isActive() {
    if (typeof this.stream.active !== 'undefined') {
      return this.stream.active;
    }

    return true;
  }
  /**
   * Sets the audio level for the stream
   * @param {number} audioLevel value between 0 and 1
   * @param {TraceablePeerConnection} [tpc] the peerconnection instance which
   * is source for the audio level. It can be <tt>undefined</tt> for
   * a local track if the audio level was measured outside of the
   * peerconnection (see /modules/statistics/LocalStatsCollector.js).
   */


  setAudioLevel(audioLevel, tpc) {
    if (this.audioLevel !== audioLevel) {
      this.audioLevel = audioLevel;
      this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_AUDIO_LEVEL_CHANGED"], audioLevel, tpc);
    }
  }
  /**
   * Returns the msid of the stream attached to the JitsiTrack object or null
   * if no stream is attached.
   */


  getMSID() {
    const streamId = this.getStreamId();
    const trackId = this.getTrackId();
    return streamId && trackId ? `${streamId} ${trackId}` : null;
  }
  /**
   * Sets new audio output device for track's DOM elements. Video tracks are
   * ignored.
   * @param {string} audioOutputDeviceId - id of 'audiooutput' device from
   *      navigator.mediaDevices.enumerateDevices(), '' for default device
   * @emits JitsiTrackEvents.TRACK_AUDIO_OUTPUT_CHANGED
   * @returns {Promise}
   */


  setAudioOutput(audioOutputDeviceId) {
    if (!_RTCUtils__WEBPACK_IMPORTED_MODULE_4__["default"].isDeviceChangeAvailable('output')) {
      return Promise.reject(new Error('Audio output device change is not supported'));
    } // All audio communication is done through audio tracks, so ignore
    // changing audio output for video tracks at all.


    if (this.isVideoTrack()) {
      return Promise.resolve();
    }

    return Promise.all(this.containers.map(element => element.setSinkId(audioOutputDeviceId).catch(error => {
      logger.warn('Failed to change audio output device on' + ' element. Default or previously set' + ' audio output device will be used.', element, error);
      throw error;
    }))).then(() => {
      this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_AUDIO_OUTPUT_CHANGED"], audioOutputDeviceId);
    });
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\JitsiTrack.js"))

/***/ }),

/***/ "./modules/RTC/LocalSdpMunger.js":
/*!***************************************!*\
  !*** ./modules/RTC/LocalSdpMunger.js ***!
  \***************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return LocalSdpMunger; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _xmpp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../xmpp/SdpTransformUtil */ "./modules/xmpp/SdpTransformUtil.js");
/* global __filename */



const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Fakes local SDP exposed to {@link JingleSessionPC} through the local
 * description getter. Modifies the SDP, so that it will contain muted local
 * video tracks description, even though their underlying {MediaStreamTrack}s
 * are no longer in the WebRTC peerconnection. That prevents from SSRC updates
 * being sent to Jicofo/remote peer and prevents sRD/sLD cycle on the remote
 * side.
 */

class LocalSdpMunger {
  /**
   * Creates new <tt>LocalSdpMunger</tt> instance.
   *
   * @param {TraceablePeerConnection} tpc
   */
  constructor(tpc) {
    this.tpc = tpc;
  }
  /**
   * Makes sure that muted local video tracks associated with the parent
   * {@link TraceablePeerConnection} are described in the local SDP. It's done
   * in order to prevent from sending 'source-remove'/'source-add' Jingle
   * notifications when local video track is muted (<tt>MediaStream</tt> is
   * removed from the peerconnection).
   *
   * NOTE 1 video track is assumed
   *
   * @param {SdpTransformWrap} transformer the transformer instance which will
   * be used to process the SDP.
   * @return {boolean} <tt>true</tt> if there were any modifications to
   * the SDP wrapped by <tt>transformer</tt>.
   * @private
   */


  _addMutedLocalVideoTracksToSDP(transformer) {
    // Go over each video tracks and check if the SDP has to be changed
    const localVideos = this.tpc.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__["VIDEO"]);

    if (!localVideos.length) {
      return false;
    } else if (localVideos.length !== 1) {
      logger.error(`${this.tpc} there is more than 1 video track ! ` + 'Strange things may happen !', localVideos);
    }

    const videoMLine = transformer.selectMedia('video');

    if (!videoMLine) {
      logger.debug(`${this.tpc} unable to hack local video track SDP` + '- no "video" media');
      return false;
    }

    let modified = false;

    for (const videoTrack of localVideos) {
      const muted = videoTrack.isMuted();
      const mediaStream = videoTrack.getOriginalStream(); // During the mute/unmute operation there are periods of time when
      // the track's underlying MediaStream is not added yet to
      // the PeerConnection. The SDP needs to be munged in such case.

      const isInPeerConnection = mediaStream && this.tpc.isMediaStreamInPc(mediaStream);
      const shouldFakeSdp = muted || !isInPeerConnection;
      logger.debug(`${this.tpc} ${videoTrack} muted: ${muted}, is in PeerConnection: ${isInPeerConnection} => should fake sdp ? : ${shouldFakeSdp}`);

      if (!shouldFakeSdp) {
        continue; // eslint-disable-line no-continue
      } // Inject removed SSRCs


      const requiredSSRCs = this.tpc.isSimulcastOn() ? this.tpc.simulcast.ssrcCache : [this.tpc.sdpConsistency.cachedPrimarySsrc];

      if (!requiredSSRCs.length) {
        logger.error(`No SSRCs stored for: ${videoTrack} in ${this.tpc}`);
        continue; // eslint-disable-line no-continue
      }

      modified = true; // We need to fake sendrecv.
      // NOTE the SDP produced here goes only to Jicofo and is never set
      // as localDescription. That's why
      // TraceablePeerConnection.mediaTransferActive is ignored here.

      videoMLine.direction = 'sendrecv'; // Check if the recvonly has MSID

      const primarySSRC = requiredSSRCs[0]; // FIXME The cname could come from the stream, but may turn out to
      // be too complex. It is fine to come up with any value, as long as
      // we only care about the actual SSRC values when deciding whether
      // or not an update should be sent.

      const primaryCname = `injected-${primarySSRC}`;

      for (const ssrcNum of requiredSSRCs) {
        // Remove old attributes
        videoMLine.removeSSRC(ssrcNum); // Inject

        logger.debug(`${this.tpc} injecting video SSRC: ${ssrcNum} for ${videoTrack}`);
        videoMLine.addSSRCAttribute({
          id: ssrcNum,
          attribute: 'cname',
          value: primaryCname
        });
        videoMLine.addSSRCAttribute({
          id: ssrcNum,
          attribute: 'msid',
          value: videoTrack.storedMSID
        });
      }

      if (requiredSSRCs.length > 1) {
        const group = {
          ssrcs: requiredSSRCs.join(' '),
          semantics: 'SIM'
        };

        if (!videoMLine.findGroup(group.semantics, group.ssrcs)) {
          // Inject the group
          logger.debug(`${this.tpc} injecting SIM group for ${videoTrack}`, group);
          videoMLine.addSSRCGroup(group);
        }
      } // Insert RTX
      // FIXME in P2P RTX is used by Chrome regardless of config option
      // status. Because of that 'source-remove'/'source-add'
      // notifications are still sent to remove/add RTX SSRC and FID group


      if (!this.tpc.options.disableRtx) {
        this.tpc.rtxModifier.modifyRtxSsrcs2(videoMLine);
      }
    }

    return modified;
  }
  /**
   * Modifies 'cname', 'msid', 'label' and 'mslabel' by appending
   * the id of {@link LocalSdpMunger#tpc} at the end, preceding by a dash
   * sign.
   *
   * @param {MLineWrap} mediaSection - The media part (audio or video) of the
   * session description which will be modified in place.
   * @returns {void}
   * @private
   */


  _transformMediaIdentifiers(mediaSection) {
    const pcId = this.tpc.id;

    for (const ssrcLine of mediaSection.ssrcs) {
      switch (ssrcLine.attribute) {
        case 'cname':
        case 'label':
        case 'mslabel':
          ssrcLine.value = ssrcLine.value && `${ssrcLine.value}-${pcId}`;
          break;

        case 'msid':
          {
            if (ssrcLine.value) {
              const streamAndTrackIDs = ssrcLine.value.split(' ');

              if (streamAndTrackIDs.length === 2) {
                const streamId = streamAndTrackIDs[0];
                const trackId = streamAndTrackIDs[1];
                ssrcLine.value = `${streamId}-${pcId} ${trackId}-${pcId}`;
              } else {
                logger.warn('Unable to munge local MSID' + `- weird format detected: ${ssrcLine.value}`);
              }
            }

            break;
          }
      }
    }
  }
  /**
   * Maybe modifies local description to fake local video tracks SDP when
   * those are muted.
   *
   * @param {object} desc the WebRTC SDP object instance for the local
   * description.
   * @returns {RTCSessionDescription}
   */


  maybeAddMutedLocalVideoTracksToSDP(desc) {
    if (!desc) {
      throw new Error('No local description passed in.');
    }

    const transformer = new _xmpp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_2__["SdpTransformWrap"](desc.sdp);

    if (this._addMutedLocalVideoTracksToSDP(transformer)) {
      return new RTCSessionDescription({
        type: desc.type,
        sdp: transformer.toRawSDP()
      });
    }

    return desc;
  }
  /**
   * This transformation will make sure that stream identifiers are unique
   * across all of the local PeerConnections even if the same stream is used
   * by multiple instances at the same time.
   * Each PeerConnection assigns different SSRCs to the same local
   * MediaStream, but the MSID remains the same as it's used to identify
   * the stream by the WebRTC backend. The transformation will append
   * {@link TraceablePeerConnection#id} at the end of each stream's identifier
   * ("cname", "msid", "label" and "mslabel").
   *
   * @param {RTCSessionDescription} sessionDesc - The local session
   * description (this instance remains unchanged).
   * @return {RTCSessionDescription} - Transformed local session description
   * (a modified copy of the one given as the input).
   */


  transformStreamIdentifiers(sessionDesc) {
    // FIXME similar check is probably duplicated in all other transformers
    if (!sessionDesc || !sessionDesc.sdp || !sessionDesc.type) {
      return sessionDesc;
    }

    const transformer = new _xmpp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_2__["SdpTransformWrap"](sessionDesc.sdp);
    const audioMLine = transformer.selectMedia('audio');

    if (audioMLine) {
      this._transformMediaIdentifiers(audioMLine);
    }

    const videoMLine = transformer.selectMedia('video');

    if (videoMLine) {
      this._transformMediaIdentifiers(videoMLine);
    }

    return new RTCSessionDescription({
      type: sessionDesc.type,
      sdp: transformer.toRawSDP()
    });
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\LocalSdpMunger.js"))

/***/ }),

/***/ "./modules/RTC/RTC.js":
/*!****************************!*\
  !*** ./modules/RTC/RTC.js ***!
  \****************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return RTC; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _BridgeChannel__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./BridgeChannel */ "./modules/RTC/BridgeChannel.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _JitsiLocalTrack__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./JitsiLocalTrack */ "./modules/RTC/JitsiLocalTrack.js");
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/Listenable */ "./modules/util/Listenable.js");
/* harmony import */ var _util_MathUtil__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/MathUtil */ "./modules/util/MathUtil.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__);
/* harmony import */ var _RTCUtils__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./RTCUtils */ "./modules/RTC/RTCUtils.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _TraceablePeerConnection__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./TraceablePeerConnection */ "./modules/RTC/TraceablePeerConnection.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./service/RTC/VideoType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_13___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_13__);
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

/* global __filename */














const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * The counter used to generated id numbers assigned to peer connections
 * @type {number}
 */

let peerConnectionIdCounter = 0;
/**
 * The counter used to generate id number for the local
 * <code>MediaStreamTrack</code>s.
 * @type {number}
 */

let rtcTrackIdCounter = 0;
/**
 *
 * @param tracksInfo
 * @param options
 */

function createLocalTracks(tracksInfo, options) {
  const newTracks = [];
  let deviceId = null;
  tracksInfo.forEach(trackInfo => {
    if (trackInfo.mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["AUDIO"]) {
      deviceId = options.micDeviceId;
    } else if (trackInfo.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_13___default.a.CAMERA) {
      deviceId = options.cameraDeviceId;
    }

    rtcTrackIdCounter = Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_6__["safeCounterIncrement"])(rtcTrackIdCounter);
    const localTrack = new _JitsiLocalTrack__WEBPACK_IMPORTED_MODULE_4__["default"](_objectSpread({}, trackInfo, {
      deviceId,
      facingMode: options.facingMode,
      rtcId: rtcTrackIdCounter,
      effects: options.effects
    }));
    newTracks.push(localTrack);
  });
  return newTracks;
}
/**
 * Creates {@code JitsiLocalTrack} instances from the passed in meta information
 * about MedieaTracks.
 *
 * @param {Object[]} mediaStreamMetaData - An array of meta information with
 * MediaTrack instances. Each can look like:
 * {{
 *     stream: MediaStream instance that holds a track with audio or video,
 *     track: MediaTrack within the MediaStream,
 *     videoType: "camera" or "desktop" or falsy,
 *     sourceId: ID of the desktopsharing source,
 *     sourceType: The desktopsharing source type,
 *     effects: Array of effect types
 * }}
 */


function _newCreateLocalTracks(mediaStreamMetaData = []) {
  return mediaStreamMetaData.map(metaData => {
    const {
      sourceId,
      sourceType,
      stream,
      track,
      videoType,
      effects
    } = metaData;
    const {
      deviceId,
      facingMode
    } = track.getSettings(); // FIXME Move rtcTrackIdCounter to a static method in JitsiLocalTrack
    // so RTC does not need to handle ID management. This move would be
    // safer to do once the old createLocalTracks is removed.

    rtcTrackIdCounter = Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_6__["safeCounterIncrement"])(rtcTrackIdCounter);
    return new _JitsiLocalTrack__WEBPACK_IMPORTED_MODULE_4__["default"]({
      deviceId,
      facingMode,
      mediaType: track.kind,
      rtcId: rtcTrackIdCounter,
      sourceId,
      sourceType,
      stream,
      track,
      videoType: videoType || null,
      effects
    });
  });
}
/**
 *
 */


class RTC extends _util_Listenable__WEBPACK_IMPORTED_MODULE_5__["default"] {
  /**
   *
   * @param conference
   * @param options
   */
  constructor(conference, options = {}) {
    super();
    this.conference = conference;
    /**
     * A map of active <tt>TraceablePeerConnection</tt>.
     * @type {Map.<number, TraceablePeerConnection>}
     */

    this.peerConnections = new Map();
    this.localTracks = [];
    this.options = options; // BridgeChannel instance.
    // @private
    // @type {BridgeChannel}

    this._channel = null; // A flag whether we had received that the channel had opened we can
    // get this flag out of sync if for some reason channel got closed
    // from server, a desired behaviour so we can see errors when this
    // happen.
    // @private
    // @type {boolean}

    this._channelOpen = false;
    /**
     * The value specified to the last invocation of setLastN before the
     * channel completed opening. If non-null, the value will be sent
     * through a channel (once) as soon as it opens and will then be
     * discarded.
     * @private
     * @type {number}
     */

    this._lastN = -1;
    /**
     * Defines the last N endpoints list. It can be null or an array once
     * initialised with a channel last N event.
     * @type {Array<string>|null}
     * @private
     */

    this._lastNEndpoints = null;
    /**
     * The number representing the maximum video height the local client
     * should receive from the bridge.
     *
     * @type {number|undefined}
     * @private
     */

    this._maxFrameHeight = undefined;
    /**
     * The endpoint ID of currently pinned participant or <tt>null</tt> if
     * no user is pinned.
     * @type {string|null}
     * @private
     */

    this._pinnedEndpoint = null;
    /**
     * The endpoint IDs of currently selected participants.
     *
     * @type {Array}
     * @private
     */

    this._selectedEndpoints = []; // The last N change listener.

    this._lastNChangeListener = this._onLastNChanged.bind(this);
    this._onDeviceListChanged = this._onDeviceListChanged.bind(this);
    this._updateAudioOutputForAudioTracks = this._updateAudioOutputForAudioTracks.bind(this); // Switch audio output device on all remote audio tracks. Local audio
    // tracks handle this event by themselves.

    if (_RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].isDeviceChangeAvailable('output')) {
      _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.AUDIO_OUTPUT_DEVICE_CHANGED, this._updateAudioOutputForAudioTracks);
      _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.DEVICE_LIST_CHANGED, this._onDeviceListChanged);
    }
  }
  /**
   * Removes any listeners and stored state from this {@code RTC} instance.
   *
   * @returns {void}
   */


  destroy() {
    _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.AUDIO_OUTPUT_DEVICE_CHANGED, this._updateAudioOutputForAudioTracks);
    _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.DEVICE_LIST_CHANGED, this._onDeviceListChanged);
    this.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.LASTN_ENDPOINT_CHANGED, this._lastNChangeListener);

    if (this._channelOpenListener) {
      this.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.DATA_CHANNEL_OPEN, this._channelOpenListener);
    }
  }
  /**
   * Exposes the private helper for converting a WebRTC MediaStream to a
   * JitsiLocalTrack.
   *
   * @param {Array<Object>} tracksInfo
   * @returns {Array<JitsiLocalTrack>}
   */


  static newCreateLocalTracks(tracksInfo) {
    return _newCreateLocalTracks(tracksInfo);
  }
  /**
   * Creates the local MediaStreams.
   * @param {object} [options] Optional parameters.
   * @param {array} options.devices The devices that will be requested.
   * @param {string} options.resolution Resolution constraints.
   * @param {string} options.cameraDeviceId
   * @param {string} options.micDeviceId
   * @returns {*} Promise object that will receive the new JitsiTracks
   */


  static obtainAudioAndVideoPermissions(options) {
    const usesNewGumFlow = _browser__WEBPACK_IMPORTED_MODULE_8__["default"].usesNewGumFlow();
    const obtainMediaPromise = usesNewGumFlow ? _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].newObtainAudioAndVideoPermissions(options) : _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].obtainAudioAndVideoPermissions(options);
    return obtainMediaPromise.then(tracksInfo => {
      if (usesNewGumFlow) {
        return _newCreateLocalTracks(tracksInfo);
      }

      return createLocalTracks(tracksInfo, options);
    });
  }
  /**
   * Initializes the bridge channel of this instance.
   * At least one of both, peerconnection or wsUrl parameters, must be
   * given.
   * @param {RTCPeerConnection} [peerconnection] WebRTC peer connection
   * instance.
   * @param {string} [wsUrl] WebSocket URL.
   */


  initializeBridgeChannel(peerconnection, wsUrl) {
    this._channel = new _BridgeChannel__WEBPACK_IMPORTED_MODULE_1__["default"](peerconnection, wsUrl, this.eventEmitter);

    this._channelOpenListener = () => {
      // Mark that channel as opened.
      this._channelOpen = true; // When the channel becomes available, tell the bridge about
      // video selections so that it can do adaptive simulcast,
      // we want the notification to trigger even if userJid
      // is undefined, or null.

      try {
        this._channel.sendPinnedEndpointMessage(this._pinnedEndpoint);

        this._channel.sendSelectedEndpointsMessage(this._selectedEndpoints);

        if (typeof this._maxFrameHeight !== 'undefined') {
          this._channel.sendReceiverVideoConstraintMessage(this._maxFrameHeight);
        }
      } catch (error) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default.a.callErrorHandler(error);
        logger.error(`Cannot send selected(${this._selectedEndpoint})` + `pinned(${this._pinnedEndpoint})` + `frameHeight(${this._maxFrameHeight}) endpoint message`, error);
      }

      this.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.DATA_CHANNEL_OPEN, this._channelOpenListener);
      this._channelOpenListener = null; // If setLastN was invoked before the bridge channel completed
      // opening, apply the specified value now that the channel
      // is open. NOTE that -1 is the default value assumed by both
      // RTC module and the JVB.

      if (this._lastN !== -1) {
        this._channel.sendSetLastNMessage(this._lastN);
      }
    };

    this.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.DATA_CHANNEL_OPEN, this._channelOpenListener); // Add Last N change listener.

    this.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.LASTN_ENDPOINT_CHANGED, this._lastNChangeListener);
  }
  /**
   * Callback invoked when the list of known audio and video devices has
   * been updated. Attempts to update the known available audio output
   * devices.
   *
   * @private
   * @returns {void}
   */


  _onDeviceListChanged() {
    this._updateAudioOutputForAudioTracks(_RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getAudioOutputDevice());
  }
  /**
   * Receives events when Last N had changed.
   * @param {array} lastNEndpoints The new Last N endpoints.
   * @private
   */


  _onLastNChanged(lastNEndpoints = []) {
    const oldLastNEndpoints = this._lastNEndpoints || [];
    let leavingLastNEndpoints = [];
    let enteringLastNEndpoints = [];
    this._lastNEndpoints = lastNEndpoints;
    leavingLastNEndpoints = oldLastNEndpoints.filter(id => !this.isInLastN(id));
    enteringLastNEndpoints = lastNEndpoints.filter(id => oldLastNEndpoints.indexOf(id) === -1);
    this.conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__["LAST_N_ENDPOINTS_CHANGED"], leavingLastNEndpoints, enteringLastNEndpoints);
  }
  /**
   * Should be called when current media session ends and after the
   * PeerConnection has been closed using PeerConnection.close() method.
   */


  onCallEnded() {
    if (this._channel) {
      // The BridgeChannel is not explicitly closed as the PeerConnection
      // is closed on call ended which triggers datachannel onclose
      // events. If using a WebSocket, the channel must be closed since
      // it is not managed by the PeerConnection.
      // The reference is cleared to disable any logic related to the
      // channel.
      if (this._channel && this._channel.mode === 'websocket') {
        this._channel.close();
      }

      this._channel = null;
      this._channelOpen = false;
    }
  }
  /**
   * Sets the maximum video size the local participant should receive from
   * remote participants. Will cache the value and send it through the channel
   * once it is created.
   *
   * @param {number} maxFrameHeightPixels the maximum frame height, in pixels,
   * this receiver is willing to receive.
   * @returns {void}
   */


  setReceiverVideoConstraint(maxFrameHeight) {
    this._maxFrameHeight = maxFrameHeight;

    if (this._channel && this._channelOpen) {
      this._channel.sendReceiverVideoConstraintMessage(maxFrameHeight);
    }
  }
  /**
   * Elects the participants with the given ids to be the selected
   * participants in order to always receive video for this participant (even
   * when last n is enabled). If there is no channel we store it and send it
   * through the channel once it is created.
   *
   * @param {Array<string>} ids - The user ids.
   * @throws NetworkError or InvalidStateError or Error if the operation
   * fails.
   * @returns {void}
   */


  selectEndpoints(ids) {
    this._selectedEndpoints = ids;

    if (this._channel && this._channelOpen) {
      this._channel.sendSelectedEndpointsMessage(ids);
    }
  }
  /**
   * Elects the participant with the given id to be the pinned participant in
   * order to always receive video for this participant (even when last n is
   * enabled).
   * @param {stirng} id The user id.
   * @throws NetworkError or InvalidStateError or Error if the operation
   * fails.
   */


  pinEndpoint(id) {
    // Cache the value if channel is missing, till we open it.
    this._pinnedEndpoint = id;

    if (this._channel && this._channelOpen) {
      this._channel.sendPinnedEndpointMessage(id);
    }
  }
  /**
   *
   * @param eventType
   * @param listener
   */


  static addListener(eventType, listener) {
    _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].addListener(eventType, listener);
  }
  /**
   *
   * @param eventType
   * @param listener
   */


  static removeListener(eventType, listener) {
    _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].removeListener(eventType, listener);
  }
  /**
   *
   * @param options
   */


  static init(options = {}) {
    this.options = options;
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].init(this.options);
  }
  /* eslint-disable max-params */

  /**
   * Creates new <tt>TraceablePeerConnection</tt>
   * @param {SignalingLayer} signaling The signaling layer that will
   *      provide information about the media or participants which is not
   *      carried over SDP.
   * @param {object} iceConfig An object describing the ICE config like
   *      defined in the WebRTC specification.
   * @param {boolean} isP2P Indicates whether or not the new TPC will be used
   *      in a peer to peer type of session.
   * @param {object} options The config options.
   * @param {boolean} options.disableSimulcast If set to 'true' will disable
   *      the simulcast.
   * @param {boolean} options.disableRtx If set to 'true' will disable the
   *      RTX.
   * @param {boolean} options.disableH264 If set to 'true' H264 will be
   *      disabled by removing it from the SDP.
   * @param {boolean} options.preferH264 If set to 'true' H264 will be
   *      preferred over other video codecs.
   * @param {boolean} options.startSilent If set to 'true' no audio will be sent or received.
   * @return {TraceablePeerConnection}
   */


  createPeerConnection(signaling, iceConfig, isP2P, options) {
    const pcConstraints = RTC.getPCConstraints(isP2P);

    if (typeof options.abtestSuspendVideo !== 'undefined') {
      _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].setSuspendVideo(pcConstraints, options.abtestSuspendVideo);
      _statistics_statistics__WEBPACK_IMPORTED_MODULE_11__["default"].analytics.addPermanentProperties({
        abtestSuspendVideo: options.abtestSuspendVideo
      });
    } // FIXME: We should rename iceConfig to pcConfig.


    if (_browser__WEBPACK_IMPORTED_MODULE_8__["default"].supportsInsertableStreams()) {
      logger.debug('E2EE - setting insertable streams constraints');
      iceConfig.forceEncodedAudioInsertableStreams = true;
      iceConfig.forceEncodedVideoInsertableStreams = true;
    }

    if (_browser__WEBPACK_IMPORTED_MODULE_8__["default"].supportsSdpSemantics()) {
      iceConfig.sdpSemantics = 'plan-b';
    } // Set the RTCBundlePolicy to max-bundle so that only one set of ice candidates is generated.
    // The default policy generates separate ice candidates for audio and video connections.
    // This change is necessary for Unified plan to work properly on Chrome and Safari.


    iceConfig.bundlePolicy = 'max-bundle';
    peerConnectionIdCounter = Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_6__["safeCounterIncrement"])(peerConnectionIdCounter);
    const newConnection = new _TraceablePeerConnection__WEBPACK_IMPORTED_MODULE_12__["default"](this, peerConnectionIdCounter, signaling, iceConfig, pcConstraints, isP2P, options);
    this.peerConnections.set(newConnection.id, newConnection);
    return newConnection;
  }
  /* eslint-enable max-params */

  /**
   * Removed given peer connection from this RTC module instance.
   * @param {TraceablePeerConnection} traceablePeerConnection
   * @return {boolean} <tt>true</tt> if the given peer connection was removed
   * successfully or <tt>false</tt> if there was no peer connection mapped in
   * this RTC instance.
   */


  _removePeerConnection(traceablePeerConnection) {
    const id = traceablePeerConnection.id;

    if (this.peerConnections.has(id)) {
      // NOTE Remote tracks are not removed here.
      this.peerConnections.delete(id);
      return true;
    }

    return false;
  }
  /**
   *
   * @param track
   */


  addLocalTrack(track) {
    if (!track) {
      throw new Error('track must not be null nor undefined');
    }

    this.localTracks.push(track);
    track.conference = this.conference;
  }
  /**
   * Returns the current value for "lastN" - the amount of videos are going
   * to be delivered. When set to -1 for unlimited or all available videos.
   * @return {number}
   */


  getLastN() {
    return this._lastN;
  }
  /**
   * Get local video track.
   * @returns {JitsiLocalTrack|undefined}
   */


  getLocalVideoTrack() {
    const localVideo = this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["VIDEO"]);
    return localVideo.length ? localVideo[0] : undefined;
  }
  /**
   * Get local audio track.
   * @returns {JitsiLocalTrack|undefined}
   */


  getLocalAudioTrack() {
    const localAudio = this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["AUDIO"]);
    return localAudio.length ? localAudio[0] : undefined;
  }
  /**
   * Returns the local tracks of the given media type, or all local tracks if
   * no specific type is given.
   * @param {MediaType} [mediaType] Optional media type filter.
   * (audio or video).
   */


  getLocalTracks(mediaType) {
    let tracks = this.localTracks.slice();

    if (mediaType !== undefined) {
      tracks = tracks.filter(track => track.getType() === mediaType);
    }

    return tracks;
  }
  /**
   * Obtains all remote tracks currently known to this RTC module instance.
   * @param {MediaType} [mediaType] The remote tracks will be filtered
   *      by their media type if this argument is specified.
   * @return {Array<JitsiRemoteTrack>}
   */


  getRemoteTracks(mediaType) {
    let remoteTracks = [];

    for (const tpc of this.peerConnections.values()) {
      const pcRemoteTracks = tpc.getRemoteTracks(undefined, mediaType);

      if (pcRemoteTracks) {
        remoteTracks = remoteTracks.concat(pcRemoteTracks);
      }
    }

    return remoteTracks;
  }
  /**
   * Set mute for all local audio streams attached to the conference.
   * @param value The mute value.
   * @returns {Promise}
   */


  setAudioMute(value) {
    const mutePromises = [];
    this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["AUDIO"]).forEach(audioTrack => {
      // this is a Promise
      mutePromises.push(value ? audioTrack.mute() : audioTrack.unmute());
    }); // We return a Promise from all Promises so we can wait for their
    // execution.

    return Promise.all(mutePromises);
  }
  /**
   *
   * @param track
   */


  removeLocalTrack(track) {
    const pos = this.localTracks.indexOf(track);

    if (pos === -1) {
      return;
    }

    this.localTracks.splice(pos, 1);
  }
  /**
   * Removes all JitsiRemoteTracks associated with given MUC nickname
   * (resource part of the JID). Returns array of removed tracks.
   *
   * @param {string} Owner The resource part of the MUC JID.
   * @returns {JitsiRemoteTrack[]}
   */


  removeRemoteTracks(owner) {
    let removedTracks = [];

    for (const tpc of this.peerConnections.values()) {
      const pcRemovedTracks = tpc.removeRemoteTracks(owner);
      removedTracks = removedTracks.concat(pcRemovedTracks);
    }

    logger.debug(`Removed remote tracks for ${owner}` + ` count: ${removedTracks.length}`);
    return removedTracks;
  }
  /**
   *
   */


  static getPCConstraints(isP2P) {
    const pcConstraints = isP2P ? _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].p2pPcConstraints : _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].pcConstraints;

    if (!pcConstraints) {
      return {};
    }

    return JSON.parse(JSON.stringify(pcConstraints));
  }
  /**
   *
   * @param elSelector
   * @param stream
   */


  static attachMediaStream(elSelector, stream) {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].attachMediaStream(elSelector, stream);
  }
  /**
   * Returns the id of the given stream.
   * @param {MediaStream} stream
   */


  static getStreamID(stream) {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getStreamID(stream);
  }
  /**
   * Returns the id of the given track.
   * @param {MediaStreamTrack} track
   */


  static getTrackID(track) {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getTrackID(track);
  }
  /**
   * Returns true if retrieving the the list of input devices is supported
   * and false if not.
   */


  static isDeviceListAvailable() {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].isDeviceListAvailable();
  }
  /**
   * Returns true if changing the input (camera / microphone) or output
   * (audio) device is supported and false if not.
   * @param {string} [deviceType] Type of device to change. Default is
   *      undefined or 'input', 'output' - for audio output device change.
   * @returns {boolean} true if available, false otherwise.
   */


  static isDeviceChangeAvailable(deviceType) {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].isDeviceChangeAvailable(deviceType);
  }
  /**
   * Returns whether the current execution environment supports WebRTC (for
   * use within this library).
   *
   * @returns {boolean} {@code true} if WebRTC is supported in the current
   * execution environment (for use within this library); {@code false},
   * otherwise.
   */


  static isWebRtcSupported() {
    return _browser__WEBPACK_IMPORTED_MODULE_8__["default"].isSupported();
  }
  /**
   * Returns currently used audio output device id, '' stands for default
   * device
   * @returns {string}
   */


  static getAudioOutputDevice() {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getAudioOutputDevice();
  }
  /**
   * Returns list of available media devices if its obtained, otherwise an
   * empty array is returned/
   * @returns {array} list of available media devices.
   */


  static getCurrentlyAvailableMediaDevices() {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getCurrentlyAvailableMediaDevices();
  }
  /**
   * Returns event data for device to be reported to stats.
   * @returns {MediaDeviceInfo} device.
   */


  static getEventDataForActiveDevice(device) {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getEventDataForActiveDevice(device);
  }
  /**
   * Sets current audio output device.
   * @param {string} deviceId Id of 'audiooutput' device from
   *      navigator.mediaDevices.enumerateDevices().
   * @returns {Promise} resolves when audio output is changed, is rejected
   *      otherwise
   */


  static setAudioOutputDevice(deviceId) {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].setAudioOutputDevice(deviceId);
  }
  /**
   * Returns <tt>true<tt/> if given WebRTC MediaStream is considered a valid
   * "user" stream which means that it's not a "receive only" stream nor a
   * "mixed" JVB stream.
   *
   * Clients that implement Unified Plan, such as Firefox use recvonly
   * "streams/channels/tracks" for receiving remote stream/tracks, as opposed
   * to Plan B where there are only 3 channels: audio, video and data.
   *
   * @param {MediaStream} stream The WebRTC MediaStream instance.
   * @returns {boolean}
   */


  static isUserStream(stream) {
    return RTC.isUserStreamById(_RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getStreamID(stream));
  }
  /**
   * Returns <tt>true<tt/> if a WebRTC MediaStream identified by given stream
   * ID is considered a valid "user" stream which means that it's not a
   * "receive only" stream nor a "mixed" JVB stream.
   *
   * Clients that implement Unified Plan, such as Firefox use recvonly
   * "streams/channels/tracks" for receiving remote stream/tracks, as opposed
   * to Plan B where there are only 3 channels: audio, video and data.
   *
   * @param {string} streamId The id of WebRTC MediaStream.
   * @returns {boolean}
   */


  static isUserStreamById(streamId) {
    return streamId && streamId !== 'mixedmslabel' && streamId !== 'default';
  }
  /**
   * Allows to receive list of available cameras/microphones.
   * @param {function} callback Would receive array of devices as an
   *      argument.
   */


  static enumerateDevices(callback) {
    _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].enumerateDevices(callback);
  }
  /**
   * A method to handle stopping of the stream.
   * One point to handle the differences in various implementations.
   * @param {MediaStream} mediaStream MediaStream object to stop.
   */


  static stopMediaStream(mediaStream) {
    _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].stopMediaStream(mediaStream);
  }
  /**
   * Returns whether the desktop sharing is enabled or not.
   * @returns {boolean}
   */


  static isDesktopSharingEnabled() {
    return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].isDesktopSharingEnabled();
  }
  /**
   * Closes the currently opened bridge channel.
   */


  closeBridgeChannel() {
    if (this._channel) {
      this._channel.close();

      this._channelOpen = false;
      this.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.LASTN_ENDPOINT_CHANGED, this._lastNChangeListener);
    }
  }
  /* eslint-disable max-params */

  /**
   *
   * @param {TraceablePeerConnection} tpc
   * @param {number} ssrc
   * @param {number} audioLevel
   * @param {boolean} isLocal
   */


  setAudioLevel(tpc, ssrc, audioLevel, isLocal) {
    const track = tpc.getTrackBySSRC(ssrc);

    if (!track) {
      return;
    } else if (!track.isAudioTrack()) {
      logger.warn(`Received audio level for non-audio track: ${ssrc}`);
      return;
    } else if (track.isLocal() !== isLocal) {
      logger.error(`${track} was expected to ${isLocal ? 'be' : 'not be'} local`);
    }

    track.setAudioLevel(audioLevel, tpc);
  }
  /* eslint-enable max-params */

  /**
   * Sends message via the bridge channel.
   * @param {string} to The id of the endpoint that should receive the
   *      message. If "" the message will be sent to all participants.
   * @param {object} payload The payload of the message.
   * @throws NetworkError or InvalidStateError or Error if the operation
   * fails or there is no data channel created.
   */


  sendChannelMessage(to, payload) {
    if (this._channel) {
      this._channel.sendMessage(to, payload);
    } else {
      throw new Error('Channel support is disabled!');
    }
  }
  /**
   * Selects a new value for "lastN". The requested amount of videos are going
   * to be delivered after the value is in effect. Set to -1 for unlimited or
   * all available videos.
   * @param {number} value the new value for lastN.
   */


  setLastN(value) {
    if (this._lastN !== value) {
      this._lastN = value;

      if (this._channel && this._channelOpen) {
        this._channel.sendSetLastNMessage(value);
      }

      this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9___default.a.LASTN_VALUE_CHANGED, value);
    }
  }
  /**
   * Indicates if the endpoint id is currently included in the last N.
   * @param {string} id The endpoint id that we check for last N.
   * @returns {boolean} true if the endpoint id is in the last N or if we
   * don't have bridge channel support, otherwise we return false.
   */


  isInLastN(id) {
    return !this._lastNEndpoints // lastNEndpoints not initialised yet.
    || this._lastNEndpoints.indexOf(id) > -1;
  }
  /**
   * Updates the target audio output device for all remote audio tracks.
   *
   * @param {string} deviceId - The device id of the audio ouput device to
   * use for all remote tracks.
   * @private
   * @returns {void}
   */


  _updateAudioOutputForAudioTracks(deviceId) {
    const remoteAudioTracks = this.getRemoteTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["AUDIO"]);

    for (const track of remoteAudioTracks) {
      track.setAudioOutput(deviceId);
    }
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\RTC.js"))

/***/ }),

/***/ "./modules/RTC/RTCUtils.js":
/*!*********************************!*\
  !*** ./modules/RTC/RTCUtils.js ***!
  \*********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/CameraFacingMode */ "./service/RTC/CameraFacingMode.js");
/* harmony import */ var _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4__);
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../JitsiTrackError */ "./JitsiTrackError.js");
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/Listenable */ "./modules/util/Listenable.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../service/RTC/Resolutions */ "./service/RTC/Resolutions.js");
/* harmony import */ var _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8__);
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10__);
/* harmony import */ var _ScreenObtainer__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./ScreenObtainer */ "./modules/RTC/ScreenObtainer.js");
/* harmony import */ var _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../xmpp/SDPUtil */ "./modules/xmpp/SDPUtil.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./service/RTC/VideoType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_14___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_14__);
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

/* global
          __filename,
          MediaStreamTrack,
          RTCIceCandidate: true,
          RTCPeerConnection,
          RTCSessionDescription: true
*/















const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_3__["getLogger"])(__filename); // Require adapter only for certain browsers. This is being done for
// react-native, which has its own shims, and while browsers are being migrated
// over to use adapter's shims.

if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesAdapter()) {
  __webpack_require__(/*! webrtc-adapter */ "./node_modules/webrtc-adapter/src/js/adapter_core.js");
}

const eventEmitter = new events__WEBPACK_IMPORTED_MODULE_2___default.a();
const AVAILABLE_DEVICES_POLL_INTERVAL_TIME = 3000; // ms

/**
 * Default resolution to obtain for video tracks if no resolution is specified.
 * This default is used for old gum flow only, as new gum flow uses
 * {@link DEFAULT_CONSTRAINTS}.
 */

const OLD_GUM_DEFAULT_RESOLUTION = 720;
/**
 * Default devices to obtain when no specific devices are specified. This
 * default is used for old gum flow only.
 */

const OLD_GUM_DEFAULT_DEVICES = ['audio', 'video'];
/**
 * Default MediaStreamConstraints to use for calls to getUserMedia.
 *
 * @private
 */

const DEFAULT_CONSTRAINTS = {
  video: {
    height: {
      ideal: 720,
      max: 720,
      min: 240
    }
  }
};
/**
 * The default frame rate for Screen Sharing.
 */

const SS_DEFAULT_FRAME_RATE = 5; // Currently audio output device change is supported only in Chrome and
// default output always has 'default' device ID

let audioOutputDeviceId = 'default'; // default device
// whether user has explicitly set a device to use

let audioOutputChanged = false; // Disables all audio processing

let disableAP = false; // Disables Acoustic Echo Cancellation

let disableAEC = false; // Disables Noise Suppression

let disableNS = false; // Disables Automatic Gain Control

let disableAGC = false; // Disables Highpass Filter

let disableHPF = false;
const featureDetectionAudioEl = document.createElement('audio');
const isAudioOutputDeviceChangeAvailable = typeof featureDetectionAudioEl.setSinkId !== 'undefined';
let availableDevices;
let availableDevicesPollTimer;
/**
 * Initialize wrapper function for enumerating devices.
 * TODO: remove this, it should no longer be needed.
 *
 * @returns {?Function}
 */

function initEnumerateDevicesWithCallback() {
  if (navigator.mediaDevices && navigator.mediaDevices.enumerateDevices) {
    return callback => {
      navigator.mediaDevices.enumerateDevices().then(callback, () => callback([]));
    };
  }
}
/**
 *
 * @param constraints
 * @param isNewStyleConstraintsSupported
 * @param resolution
 */


function setResolutionConstraints(constraints, isNewStyleConstraintsSupported, resolution) {
  if (_service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8___default.a[resolution]) {
    if (isNewStyleConstraintsSupported) {
      constraints.video.width = {
        ideal: _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8___default.a[resolution].width
      };
      constraints.video.height = {
        ideal: _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8___default.a[resolution].height
      };
    }

    constraints.video.mandatory.minWidth = _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8___default.a[resolution].width;
    constraints.video.mandatory.minHeight = _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8___default.a[resolution].height;
  }

  if (constraints.video.mandatory.minWidth) {
    constraints.video.mandatory.maxWidth = constraints.video.mandatory.minWidth;
  }

  if (constraints.video.mandatory.minHeight) {
    constraints.video.mandatory.maxHeight = constraints.video.mandatory.minHeight;
  }
}
/**
 * @param {string[]} um required user media types
 *
 * @param {Object} [options={}] optional parameters
 * @param {string} options.resolution
 * @param {number} options.bandwidth
 * @param {number} options.fps
 * @param {string} options.desktopStream
 * @param {string} options.cameraDeviceId
 * @param {string} options.micDeviceId
 * @param {CameraFacingMode} options.facingMode
 * @param {bool} firefox_fake_device
 * @param {Object} options.frameRate - used only for dekstop sharing.
 * @param {Object} options.frameRate.min - Minimum fps
 * @param {Object} options.frameRate.max - Maximum fps
 * @param {bool}   options.screenShareAudio - Used by electron clients to
 * enable system audio screen sharing.
 */


function getConstraints(um, options = {}) {
  const constraints = {
    audio: false,
    video: false
  }; // Don't mix new and old style settings for Chromium as this leads
  // to TypeError in new Chromium versions. @see
  // https://bugs.chromium.org/p/chromium/issues/detail?id=614716
  // This is a temporary solution, in future we will fully split old and
  // new style constraints when new versions of Chromium and Firefox will
  // have stable support of new constraints format. For more information
  // @see https://github.com/jitsi/lib-jitsi-meet/pull/136

  const isNewStyleConstraintsSupported = _browser__WEBPACK_IMPORTED_MODULE_9__["default"].isFirefox() || _browser__WEBPACK_IMPORTED_MODULE_9__["default"].isSafari() || _browser__WEBPACK_IMPORTED_MODULE_9__["default"].isReactNative();

  if (um.indexOf('video') >= 0) {
    // same behaviour as true
    constraints.video = {
      mandatory: {},
      optional: []
    };

    if (options.cameraDeviceId) {
      if (isNewStyleConstraintsSupported) {
        // New style of setting device id.
        constraints.video.deviceId = options.cameraDeviceId;
      } // Old style.


      constraints.video.mandatory.sourceId = options.cameraDeviceId;
    } else {
      // Prefer the front i.e. user-facing camera (to the back i.e.
      // environment-facing camera, for example).
      // TODO: Maybe use "exact" syntax if options.facingMode is defined,
      // but this probably needs to be decided when updating other
      // constraints, as we currently don't use "exact" syntax anywhere.
      const facingMode = options.facingMode || _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_1___default.a.USER;

      if (isNewStyleConstraintsSupported) {
        constraints.video.facingMode = facingMode;
      }

      constraints.video.optional.push({
        facingMode
      });
    }

    if (options.minFps || options.maxFps || options.fps) {
      // for some cameras it might be necessary to request 30fps
      // so they choose 30fps mjpg over 10fps yuy2
      if (options.minFps || options.fps) {
        // Fall back to options.fps for backwards compatibility
        options.minFps = options.minFps || options.fps;
        constraints.video.mandatory.minFrameRate = options.minFps;
      }

      if (options.maxFps) {
        constraints.video.mandatory.maxFrameRate = options.maxFps;
      }
    }

    setResolutionConstraints(constraints, isNewStyleConstraintsSupported, options.resolution);
  }

  if (um.indexOf('audio') >= 0) {
    if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isReactNative()) {
      // The react-native-webrtc project that we're currently using
      // expects the audio constraint to be a boolean.
      constraints.audio = true;
    } else if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isFirefox()) {
      if (options.micDeviceId) {
        constraints.audio = {
          mandatory: {},
          deviceId: options.micDeviceId,
          // new style
          optional: [{
            sourceId: options.micDeviceId // old style

          }]
        };
      } else {
        constraints.audio = true;
      }
    } else {
      // same behaviour as true
      constraints.audio = {
        mandatory: {},
        optional: []
      };

      if (options.micDeviceId) {
        if (isNewStyleConstraintsSupported) {
          // New style of setting device id.
          constraints.audio.deviceId = options.micDeviceId;
        } // Old style.


        constraints.audio.optional.push({
          sourceId: options.micDeviceId
        });
      } // if it is good enough for hangouts...


      constraints.audio.optional.push({
        echoCancellation: !disableAEC && !disableAP
      }, {
        googEchoCancellation: !disableAEC && !disableAP
      }, {
        googAutoGainControl: !disableAGC && !disableAP
      }, {
        googNoiseSuppression: !disableNS && !disableAP
      }, {
        googHighpassFilter: !disableHPF && !disableAP
      }, {
        googNoiseSuppression2: !disableNS && !disableAP
      }, {
        googEchoCancellation2: !disableAEC && !disableAP
      }, {
        googAutoGainControl2: !disableAGC && !disableAP
      });
    }
  }

  if (um.indexOf('screen') >= 0) {
    if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isChrome()) {
      constraints.video = {
        mandatory: getSSConstraints(_objectSpread({}, options, {
          source: 'screen'
        })),
        optional: []
      };
    } else if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isFirefox()) {
      constraints.video = {
        mozMediaSource: 'window',
        mediaSource: 'window',
        frameRate: options.frameRate || {
          min: SS_DEFAULT_FRAME_RATE,
          max: SS_DEFAULT_FRAME_RATE
        }
      };
    } else {
      const errmsg = '\'screen\' WebRTC media source is supported only in Chrome' + ' and Firefox';
      _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4___default.a.callErrorHandler(new Error(errmsg));
      logger.error(errmsg);
    }
  }

  if (um.indexOf('desktop') >= 0) {
    constraints.video = {
      mandatory: getSSConstraints(_objectSpread({}, options, {
        source: 'desktop'
      })),
      optional: []
    }; // Audio screen sharing for electron only works for screen type devices.
    // i.e. when the user shares the whole desktop.

    if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isElectron() && options.screenShareAudio && options.desktopStream.indexOf('screen') >= 0) {
      // Provide constraints as described by the electron desktop capturer
      // documentation here:
      // https://www.electronjs.org/docs/api/desktop-capturer
      constraints.audio = {
        mandatory: {
          chromeMediaSource: constraints.video.mandatory.chromeMediaSource
        }
      };
      delete constraints.video.mandatory.chromeMediaSourceId;
    }
  }

  if (options.bandwidth) {
    if (!constraints.video) {
      // same behaviour as true
      constraints.video = {
        mandatory: {},
        optional: []
      };
    }

    constraints.video.optional.push({
      bandwidth: options.bandwidth
    });
  } // we turn audio for both audio and video tracks, the fake audio & video
  // seems to work only when enabled in one getUserMedia call, we cannot get
  // fake audio separate by fake video this later can be a problem with some
  // of the tests


  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isFirefox() && options.firefox_fake_device) {
    // seems to be fixed now, removing this experimental fix, as having
    // multiple audio tracks brake the tests
    // constraints.audio = true;
    constraints.fake = true;
  }

  return constraints;
}
/**
 * Creates a constraints object to be passed into a call to getUserMedia.
 *
 * @param {Array} um - An array of user media types to get. The accepted
 * types are "video", "audio", and "desktop."
 * @param {Object} options - Various values to be added to the constraints.
 * @param {string} options.cameraDeviceId - The device id for the video
 * capture device to get video from.
 * @param {Object} options.constraints - Default constraints object to use
 * as a base for the returned constraints.
 * @param {Object} options.desktopStream - The desktop source id from which
 * to capture a desktop sharing video.
 * @param {string} options.facingMode - Which direction the camera is
 * pointing to.
 * @param {string} options.micDeviceId - The device id for the audio capture
 * device to get audio from.
 * @param {Object} options.frameRate - used only for dekstop sharing.
 * @param {Object} options.frameRate.min - Minimum fps
 * @param {Object} options.frameRate.max - Maximum fps
 * @private
 * @returns {Object}
 */


function newGetConstraints(um = [], options = {}) {
  // Create a deep copy of the constraints to avoid any modification of
  // the passed in constraints object.
  const constraints = JSON.parse(JSON.stringify(options.constraints || DEFAULT_CONSTRAINTS));

  if (um.indexOf('video') >= 0) {
    if (!constraints.video) {
      constraints.video = {};
    }

    if (options.cameraDeviceId) {
      constraints.video.deviceId = options.cameraDeviceId;
    } else {
      const facingMode = options.facingMode || _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_1___default.a.USER;
      constraints.video.facingMode = facingMode;
    }
  } else {
    constraints.video = false;
  }

  if (um.indexOf('audio') >= 0) {
    if (!constraints.audio || typeof constraints.audio === 'boolean') {
      constraints.audio = {};
    } // NOTE(brian): the new-style ('advanced' instead of 'optional')
    // doesn't seem to carry through the googXXX constraints
    // Changing back to 'optional' here (even with video using
    // the 'advanced' style) allows them to be passed through
    // but also requires the device id to capture to be set in optional
    // as sourceId otherwise the constraints are considered malformed.


    if (!constraints.audio.optional) {
      constraints.audio.optional = [];
    }

    constraints.audio.optional.push({
      sourceId: options.micDeviceId
    }, {
      echoCancellation: !disableAEC && !disableAP
    }, {
      googEchoCancellation: !disableAEC && !disableAP
    }, {
      googAutoGainControl: !disableAGC && !disableAP
    }, {
      googNoiseSuppression: !disableNS && !disableAP
    }, {
      googHighpassFilter: !disableHPF && !disableAP
    }, {
      googNoiseSuppression2: !disableNS && !disableAP
    }, {
      googEchoCancellation2: !disableAEC && !disableAP
    }, {
      googAutoGainControl2: !disableAGC && !disableAP
    });
  } else {
    constraints.audio = false;
  }

  if (um.indexOf('desktop') >= 0) {
    if (!constraints.video || typeof constraints.video === 'boolean') {
      constraints.video = {};
    }

    constraints.video = {
      mandatory: getSSConstraints(_objectSpread({}, options, {
        source: 'desktop'
      }))
    };
  }

  return constraints;
}
/**
 * Generates GUM constraints for screen sharing.
 *
 * @param {Object} options - The options passed to
 * <tt>obtainAudioAndVideoPermissions</tt>.
 * @returns {Object} - GUM constraints.
 *
 * TODO: Currently only the new GUM flow and Chrome is using the method. We
 * should make it work for all use cases.
 */


function getSSConstraints(options = {}) {
  const {
    desktopStream,
    frameRate = {
      min: SS_DEFAULT_FRAME_RATE,
      max: SS_DEFAULT_FRAME_RATE
    }
  } = options;
  const {
    max,
    min
  } = frameRate;
  const constraints = {
    chromeMediaSource: options.source,
    maxWidth: window.screen.width,
    maxHeight: window.screen.height
  };

  if (typeof min === 'number') {
    constraints.minFrameRate = min;
  }

  if (typeof max === 'number') {
    constraints.maxFrameRate = max;
  }

  if (typeof desktopStream !== 'undefined') {
    constraints.chromeMediaSourceId = desktopStream;
  }

  return constraints;
}
/**
 * Generates constraints for screen sharing when using getDisplayMedia.
 * The constraints(MediaTrackConstraints) are applied to the resulting track.
 *
 * @returns {Object} - MediaTrackConstraints constraints.
 */


function getTrackSSConstraints(options = {}) {
  // we used to set height and width in the constraints, but this can lead
  // to inconsistencies if the browser is on a lower resolution screen
  // and we share a screen with bigger resolution, so they are now not set
  const constraints = {
    frameRate: SS_DEFAULT_FRAME_RATE
  };
  const {
    desktopSharingFrameRate
  } = options;

  if (desktopSharingFrameRate && desktopSharingFrameRate.max) {
    constraints.frameRate = desktopSharingFrameRate.max;
  }

  return constraints;
}
/**
 * Updates the granted permissions based on the options we requested and the
 * streams we received.
 * @param um the options we requested to getUserMedia.
 * @param stream the stream we received from calling getUserMedia.
 */


function updateGrantedPermissions(um, stream) {
  const audioTracksReceived = Boolean(stream) && stream.getAudioTracks().length > 0;
  const videoTracksReceived = Boolean(stream) && stream.getVideoTracks().length > 0;
  const grantedPermissions = {};

  if (um.indexOf('video') !== -1) {
    grantedPermissions.video = videoTracksReceived;
  }

  if (um.indexOf('audio') !== -1) {
    grantedPermissions.audio = audioTracksReceived;
  }

  eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.GRANTED_PERMISSIONS, grantedPermissions);
}
/**
 * Checks if new list of available media devices differs from previous one.
 * @param {MediaDeviceInfo[]} newDevices - list of new devices.
 * @returns {boolean} - true if list is different, false otherwise.
 */


function compareAvailableMediaDevices(newDevices) {
  if (newDevices.length !== availableDevices.length) {
    return true;
  }
  /* eslint-disable newline-per-chained-call */


  return newDevices.map(mediaDeviceInfoToJSON).sort().join('') !== availableDevices.map(mediaDeviceInfoToJSON).sort().join('');
  /* eslint-enable newline-per-chained-call */

  /**
   *
   * @param info
   */

  function mediaDeviceInfoToJSON(info) {
    return JSON.stringify({
      kind: info.kind,
      deviceId: info.deviceId,
      groupId: info.groupId,
      label: info.label,
      facing: info.facing
    });
  }
}
/**
 * Sends analytics event with the passed device list.
 *
 * @param {Array<MediaDeviceInfo>} deviceList - List with info about the
 * available devices.
 * @returns {void}
 */


function sendDeviceListToAnalytics(deviceList) {
  const audioInputDeviceCount = deviceList.filter(d => d.kind === 'audioinput').length;
  const audioOutputDeviceCount = deviceList.filter(d => d.kind === 'audiooutput').length;
  const videoInputDeviceCount = deviceList.filter(d => d.kind === 'videoinput').length;
  const videoOutputDeviceCount = deviceList.filter(d => d.kind === 'videooutput').length;
  deviceList.forEach(device => {
    const attributes = {
      'audio_input_device_count': audioInputDeviceCount,
      'audio_output_device_count': audioOutputDeviceCount,
      'video_input_device_count': videoInputDeviceCount,
      'video_output_device_count': videoOutputDeviceCount,
      'device_id': device.deviceId,
      'device_group_id': device.groupId,
      'device_kind': device.kind,
      'device_label': device.label
    };
    _statistics_statistics__WEBPACK_IMPORTED_MODULE_13__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["AVAILABLE_DEVICE"], attributes);
  });
}
/**
 * Event handler for the 'devicechange' event.
 *
 * @param {MediaDeviceInfo[]} devices - list of media devices.
 * @emits RTCEvents.DEVICE_LIST_CHANGED
 */


function onMediaDevicesListChanged(devicesReceived) {
  availableDevices = devicesReceived.slice(0);
  logger.info('list of media devices has changed:', availableDevices);
  sendDeviceListToAnalytics(availableDevices); // Used by tracks to update the real device id before the consumer of lib-jitsi-meet receives the new device list.

  eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.DEVICE_LIST_WILL_CHANGE, devicesReceived);
  eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.DEVICE_LIST_CHANGED, devicesReceived);
}
/**
 * Handles the newly created Media Streams.
 * @param streams the new Media Streams
 * @param resolution the resolution of the video streams
 * @returns {*[]} object that describes the new streams
 */


function handleLocalStream(streams, resolution) {
  let audioStream, desktopStream, videoStream;
  const res = []; // XXX The function obtainAudioAndVideoPermissions has examined the type of
  // the browser, its capabilities, etc. and has taken the decision whether to
  // invoke getUserMedia per device (e.g. Firefox) or once for both audio and
  // video (e.g. Chrome). In order to not duplicate the logic here, examine
  // the specified streams and figure out what we've received based on
  // obtainAudioAndVideoPermissions' decision.

  if (streams) {
    // As mentioned above, certian types of browser (e.g. Chrome) support
    // (with a result which meets our requirements expressed bellow) calling
    // getUserMedia once for both audio and video.
    const audioVideo = streams.audioVideo;

    if (audioVideo) {
      const audioTracks = audioVideo.getAudioTracks();

      if (audioTracks.length) {
        audioStream = new MediaStream();

        for (let i = 0; i < audioTracks.length; i++) {
          audioStream.addTrack(audioTracks[i]);
        }
      }

      const videoTracks = audioVideo.getVideoTracks();

      if (videoTracks.length) {
        videoStream = new MediaStream();

        for (let j = 0; j < videoTracks.length; j++) {
          videoStream.addTrack(videoTracks[j]);
        }
      }
    } else {
      // On other types of browser (e.g. Firefox) we choose (namely,
      // obtainAudioAndVideoPermissions) to call getUserMedia per device
      // (type).
      audioStream = streams.audio;
      videoStream = streams.video;
    }

    desktopStream = streams.desktop;
  }

  if (desktopStream) {
    const {
      stream,
      sourceId,
      sourceType
    } = desktopStream;
    res.push({
      stream,
      sourceId,
      sourceType,
      track: stream.getVideoTracks()[0],
      mediaType: _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["VIDEO"],
      videoType: _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_14___default.a.DESKTOP
    });
  }

  if (audioStream) {
    res.push({
      stream: audioStream,
      track: audioStream.getAudioTracks()[0],
      mediaType: _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["AUDIO"],
      videoType: null
    });
  }

  if (videoStream) {
    res.push({
      stream: videoStream,
      track: videoStream.getVideoTracks()[0],
      mediaType: _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_7__["VIDEO"],
      videoType: _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_14___default.a.CAMERA,
      resolution
    });
  }

  return res;
}
/**
 * Represents a default implementation of setting a <tt>MediaStream</tt> as the
 * source of a video element that tries to be browser-agnostic through feature
 * checking. Note though that it was not completely clear from the predating
 * browser-specific implementations what &quot;videoSrc&quot; was because one
 * implementation of {@link RTCUtils#getVideoSrc} would return
 * <tt>MediaStream</tt> (e.g. Firefox), another a <tt>string</tt> representation
 * of the <tt>URL</tt> of the <tt>MediaStream</tt> (e.g. Chrome) and the return
 * value was only used by {@link RTCUIHelper#getVideoId} which itself did not
 * appear to be used anywhere. Generally, the implementation will try to follow
 * the related standards i.e. work with the <tt>srcObject</tt> and <tt>src</tt>
 * properties of the specified <tt>element</tt> taking into account vender
 * prefixes.
 *
 * @param element the element whose video source/src is to be set to the
 * specified <tt>stream</tt>
 * @param {MediaStream} stream the <tt>MediaStream</tt> to set as the video
 * source/src of <tt>element</tt>
 */


function defaultSetVideoSrc(element, stream) {
  // srcObject
  let srcObjectPropertyName = 'srcObject';

  if (!(srcObjectPropertyName in element)) {
    srcObjectPropertyName = 'mozSrcObject';

    if (!(srcObjectPropertyName in element)) {
      srcObjectPropertyName = null;
    }
  }

  if (srcObjectPropertyName) {
    element[srcObjectPropertyName] = stream;
    return;
  } // src


  let src;

  if (stream) {
    src = stream.jitsiObjectURL; // Save the created URL for stream so we can reuse it and not keep
    // creating URLs.

    if (!src) {
      stream.jitsiObjectURL = src = URL.createObjectURL(stream);
    }
  }

  element.src = src || '';
}
/**
 *
 */


class RTCUtils extends _util_Listenable__WEBPACK_IMPORTED_MODULE_6__["default"] {
  /**
   *
   */
  constructor() {
    super(eventEmitter);
  }
  /**
   * Depending on the browser, sets difference instance methods for
   * interacting with user media and adds methods to native WebRTC-related
   * objects. Also creates an instance variable for peer connection
   * constraints.
   *
   * @param {Object} options
   * @returns {void}
   */


  init(options = {}) {
    if (typeof options.disableAEC === 'boolean') {
      disableAEC = options.disableAEC;
      logger.info(`Disable AEC: ${disableAEC}`);
    }

    if (typeof options.disableNS === 'boolean') {
      disableNS = options.disableNS;
      logger.info(`Disable NS: ${disableNS}`);
    }

    if (typeof options.disableAP === 'boolean') {
      disableAP = options.disableAP;
      logger.info(`Disable AP: ${disableAP}`);
    }

    if (typeof options.disableAGC === 'boolean') {
      disableAGC = options.disableAGC;
      logger.info(`Disable AGC: ${disableAGC}`);
    }

    if (typeof options.disableHPF === 'boolean') {
      disableHPF = options.disableHPF;
      logger.info(`Disable HPF: ${disableHPF}`);
    }

    availableDevices = undefined;
    window.clearInterval(availableDevicesPollTimer);
    availableDevicesPollTimer = undefined;
    this.enumerateDevices = initEnumerateDevicesWithCallback();

    if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesNewGumFlow()) {
      this.RTCPeerConnectionType = RTCPeerConnection;
      this.attachMediaStream = wrapAttachMediaStream((element, stream) => {
        if (element) {
          element.srcObject = stream;
        }
      });

      this.getStreamID = ({
        id
      }) => id;

      this.getTrackID = ({
        id
      }) => id;
    } else if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isChromiumBased() // this is chrome < 61
    || _browser__WEBPACK_IMPORTED_MODULE_9__["default"].isReactNative()) {
      this.RTCPeerConnectionType = RTCPeerConnection;
      this.attachMediaStream = wrapAttachMediaStream((element, stream) => {
        defaultSetVideoSrc(element, stream);
        return element;
      });

      this.getStreamID = function ({
        id
      }) {
        // A. MediaStreams from FF endpoints have the characters '{' and
        // '}' that make jQuery choke.
        // B. The react-native-webrtc implementation that we use at the
        // time of this writing returns a number for the id of
        // MediaStream. Let's just say that a number contains no special
        // characters.
        return typeof id === 'number' ? id : _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_12__["default"].filterSpecialChars(id);
      };

      this.getTrackID = ({
        id
      }) => id;

      if (!MediaStream.prototype.getVideoTracks) {
        MediaStream.prototype.getVideoTracks = function () {
          return this.videoTracks;
        };
      }

      if (!MediaStream.prototype.getAudioTracks) {
        MediaStream.prototype.getAudioTracks = function () {
          return this.audioTracks;
        };
      }
    } else {
      const message = 'Endpoint does not appear to be WebRTC-capable';
      logger.error(message);
      throw new Error(message);
    }

    this._initPCConstraints(options);

    _ScreenObtainer__WEBPACK_IMPORTED_MODULE_11__["default"].init(options, this.getUserMediaWithConstraints.bind(this));

    if (this.isDeviceListAvailable()) {
      this.enumerateDevices(ds => {
        availableDevices = ds.splice(0);
        logger.debug('Available devices: ', availableDevices);
        sendDeviceListToAnalytics(availableDevices);
        eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.DEVICE_LIST_AVAILABLE, availableDevices); // Use a shared callback to handle both the devicechange event
        // and the polling implementations. This prevents duplication
        // and works around a chrome bug (verified to occur on 68) where
        // devicechange fires twice in a row, which can cause async post
        // devicechange processing to collide.

        const updateKnownDevices = () => this.enumerateDevices(pds => {
          if (compareAvailableMediaDevices(pds)) {
            onMediaDevicesListChanged(pds);
          }
        });

        if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].supportsDeviceChangeEvent()) {
          navigator.mediaDevices.addEventListener('devicechange', updateKnownDevices);
        } else {
          // Periodically poll enumerateDevices() method to check if
          // list of media devices has changed.
          availableDevicesPollTimer = window.setInterval(updateKnownDevices, AVAILABLE_DEVICES_POLL_INTERVAL_TIME);
        }
      });
    }
  }
  /**
   * Creates instance objects for peer connection constraints both for p2p
   * and outside of p2p.
   *
   * @params {Object} options - Configuration for setting RTCUtil's instance
   * objects for peer connection constraints.
   * @params {boolean} options.useIPv6 - Set to true if IPv6 should be used.
   * @params {Object} options.testing - Additional configuration for work in
   * development.
   * @params {Object} options.testing.forceP2PSuspendVideoRatio - True if
   * video should become suspended if bandwidth estimation becomes low while
   * in peer to peer connection mode.
   */


  _initPCConstraints(options) {
    if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isFirefox()) {
      this.pcConstraints = {};
    } else if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isChromiumBased() || _browser__WEBPACK_IMPORTED_MODULE_9__["default"].isReactNative()) {
      this.pcConstraints = {
        optional: [{
          googHighStartBitrate: 0
        }, {
          googPayloadPadding: true
        }, {
          googScreencastMinBitrate: 100
        }, {
          googCpuOveruseDetection: true
        }, {
          googCpuOveruseEncodeUsage: true
        }, {
          googCpuUnderuseThreshold: 55
        }, {
          googCpuOveruseThreshold: 85
        }]
      };

      if (options.useIPv6) {
        // https://code.google.com/p/webrtc/issues/detail?id=2828
        this.pcConstraints.optional.push({
          googIPv6: true
        });
      }

      this.p2pPcConstraints = JSON.parse(JSON.stringify(this.pcConstraints));
    }

    this.p2pPcConstraints = this.p2pPcConstraints || this.pcConstraints;
  }
  /* eslint-disable max-params */

  /**
  * @param {string[]} um required user media types
  * @param {Object} [options] optional parameters
  * @param {string} options.resolution
  * @param {number} options.bandwidth
  * @param {number} options.fps
  * @param {string} options.desktopStream
  * @param {string} options.cameraDeviceId
  * @param {string} options.micDeviceId
  * @param {Object} options.frameRate - used only for dekstop sharing.
  * @param {Object} options.frameRate.min - Minimum fps
  * @param {Object} options.frameRate.max - Maximum fps
  * @param {bool}   options.screenShareAudio - Used by electron clients to
  * enable system audio screen sharing.
  * @returns {Promise} Returns a media stream on success or a JitsiTrackError
  * on failure.
  **/


  getUserMediaWithConstraints(um, options = {}) {
    const constraints = getConstraints(um, options);
    logger.info('Get media constraints', constraints);
    return new Promise((resolve, reject) => {
      navigator.mediaDevices.getUserMedia(constraints).then(stream => {
        logger.log('onUserMediaSuccess');
        updateGrantedPermissions(um, stream);
        resolve(stream);
      }).catch(error => {
        logger.warn('Failed to get access to local media. ' + ` ${error} ${constraints} `);
        updateGrantedPermissions(um, undefined);
        reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_5__["default"](error, constraints, um));
      });
    });
  }
  /**
   * Acquires a media stream via getUserMedia that
   * matches the given constraints
   *
   * @param {array} umDevices which devices to acquire (e.g. audio, video)
   * @param {Object} constraints - Stream specifications to use.
   * @returns {Promise}
   */


  _newGetUserMediaWithConstraints(umDevices, constraints = {}) {
    return new Promise((resolve, reject) => {
      navigator.mediaDevices.getUserMedia(constraints).then(stream => {
        logger.log('onUserMediaSuccess');
        updateGrantedPermissions(umDevices, stream);
        resolve(stream);
      }).catch(error => {
        logger.warn('Failed to get access to local media. ' + ` ${error} ${constraints} `);
        updateGrantedPermissions(umDevices, undefined);
        reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_5__["default"](error, constraints, umDevices));
      });
    });
  }
  /**
   * Acquire a display stream via the screenObtainer. This requires extra
   * logic compared to use screenObtainer versus normal device capture logic
   * in RTCUtils#_newGetUserMediaWithConstraints.
   *
   * @param {Object} options
   * @param {Object} options.desktopSharingExtensionExternalInstallation
   * @param {string[]} options.desktopSharingSources
   * @param {Object} options.desktopSharingFrameRate
   * @param {Object} options.desktopSharingFrameRate.min - Minimum fps
   * @param {Object} options.desktopSharingFrameRate.max - Maximum fps
   * @returns {Promise} A promise which will be resolved with an object which
   * contains the acquired display stream. If desktop sharing is not supported
   * then a rejected promise will be returned.
   */


  _newGetDesktopMedia(options) {
    if (!_ScreenObtainer__WEBPACK_IMPORTED_MODULE_11__["default"].isSupported() || !_browser__WEBPACK_IMPORTED_MODULE_9__["default"].supportsVideo()) {
      return Promise.reject(new Error('Desktop sharing is not supported!'));
    }

    return new Promise((resolve, reject) => {
      _ScreenObtainer__WEBPACK_IMPORTED_MODULE_11__["default"].obtainStream(this._parseDesktopSharingOptions(options), stream => {
        resolve(stream);
      }, error => {
        reject(error);
      });
    });
  }
  /* eslint-enable max-params */

  /**
   * Creates the local MediaStreams.
   * @param {Object} [options] optional parameters
   * @param {Array} options.devices the devices that will be requested
   * @param {string} options.resolution resolution constraints
   * @param {string} options.cameraDeviceId
   * @param {string} options.micDeviceId
   * @param {Object} options.desktopSharingFrameRate
   * @param {Object} options.desktopSharingFrameRate.min - Minimum fps
   * @param {Object} options.desktopSharingFrameRate.max - Maximum fps
   * @returns {*} Promise object that will receive the new JitsiTracks
   */


  obtainAudioAndVideoPermissions(options = {}) {
    options.devices = options.devices || [...OLD_GUM_DEFAULT_DEVICES];
    options.resolution = options.resolution || OLD_GUM_DEFAULT_RESOLUTION;
    const requestingDesktop = options.devices.includes('desktop');

    if (requestingDesktop && !_ScreenObtainer__WEBPACK_IMPORTED_MODULE_11__["default"].isSupported()) {
      return Promise.reject(new Error('Desktop sharing is not supported!'));
    }

    return this._getAudioAndVideoStreams(options).then(streams => handleLocalStream(streams, options.resolution));
  }
  /**
   * Performs one call to getUserMedia for audio and/or video and another call
   * for desktop.
   *
   * @param {Object} options - An object describing how the gUM request should
   * be executed. See {@link obtainAudioAndVideoPermissions} for full options.
   * @returns {*} Promise object that will receive the new JitsiTracks on
   * success or a JitsiTrackError on failure.
   */


  _getAudioAndVideoStreams(options) {
    const requestingDesktop = options.devices.includes('desktop');
    options.devices = options.devices.filter(device => device !== 'desktop');
    const gumPromise = options.devices.length ? this.getUserMediaWithConstraints(options.devices, options) : Promise.resolve(null);
    return gumPromise.then(avStream => {
      // If any requested devices are missing, call gum again in
      // an attempt to obtain the actual error. For example, the
      // requested video device is missing or permission was
      // denied.
      const missingTracks = this._getMissingTracks(options.devices, avStream);

      if (missingTracks.length) {
        this.stopMediaStream(avStream);
        return this.getUserMediaWithConstraints(missingTracks, options) // GUM has already failed earlier and this success
        // handling should not be reached.
        .then(() => Promise.reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_5__["default"]({
          name: 'UnknownError'
        }, getConstraints(options.devices, options), missingTracks)));
      }

      return avStream;
    }).then(audioVideo => {
      if (!requestingDesktop) {
        return {
          audioVideo
        };
      }

      if (options.desktopSharingSourceDevice) {
        this.stopMediaStream(audioVideo);
        throw new Error('Using a camera as screenshare source is' + 'not supported on this browser.');
      }

      return new Promise((resolve, reject) => {
        _ScreenObtainer__WEBPACK_IMPORTED_MODULE_11__["default"].obtainStream(this._parseDesktopSharingOptions(options), desktop => resolve({
          audioVideo,
          desktop
        }), error => {
          if (audioVideo) {
            this.stopMediaStream(audioVideo);
          }

          reject(error);
        });
      });
    });
  }
  /**
   * Private utility for determining if the passed in MediaStream contains
   * tracks of the type(s) specified in the requested devices.
   *
   * @param {string[]} requestedDevices - The track types that are expected to
   * be includes in the stream.
   * @param {MediaStream} stream - The MediaStream to check if it has the
   * expected track types.
   * @returns {string[]} An array of string with the missing track types. The
   * array will be empty if all requestedDevices are found in the stream.
   */


  _getMissingTracks(requestedDevices = [], stream) {
    const missingDevices = [];
    const audioDeviceRequested = requestedDevices.includes('audio');
    const audioTracksReceived = stream && stream.getAudioTracks().length > 0;

    if (audioDeviceRequested && !audioTracksReceived) {
      missingDevices.push('audio');
    }

    const videoDeviceRequested = requestedDevices.includes('video');
    const videoTracksReceived = stream && stream.getVideoTracks().length > 0;

    if (videoDeviceRequested && !videoTracksReceived) {
      missingDevices.push('video');
    }

    return missingDevices;
  }
  /**
   * Returns an object formatted for specifying desktop sharing parameters.
   *
   * @param {Object} options - Takes in the same options object as
   * {@link obtainAudioAndVideoPermissions}.
   * @returns {Object}
   */


  _parseDesktopSharingOptions(options) {
    return _objectSpread({}, options.desktopSharingExtensionExternalInstallation, {
      desktopSharingSources: options.desktopSharingSources,
      gumOptions: {
        frameRate: options.desktopSharingFrameRate
      },
      trackOptions: getTrackSSConstraints(options)
    });
  }
  /**
   * Gets streams from specified device types. This function intentionally
   * ignores errors for upstream to catch and handle instead.
   *
   * @param {Object} options - A hash describing what devices to get and
   * relevant constraints.
   * @param {string[]} options.devices - The types of media to capture. Valid
   * values are "desktop", "audio", and "video".
   * @param {Object} options.desktopSharingFrameRate
   * @param {Object} options.desktopSharingFrameRate.min - Minimum fps
   * @param {Object} options.desktopSharingFrameRate.max - Maximum fps
   * @param {String} options.desktopSharingSourceDevice - The device id or
   * label for a video input source that should be used for screensharing.
   * @returns {Promise} The promise, when successful, will return an array of
   * meta data for the requested device type, which includes the stream and
   * track. If an error occurs, it will be deferred to the caller for
   * handling.
   */


  newObtainAudioAndVideoPermissions(options) {
    logger.info('Using the new gUM flow');
    const mediaStreamsMetaData = []; // Declare private functions to be used in the promise chain below.
    // These functions are declared in the scope of this function because
    // they are not being used anywhere else, so only this function needs to
    // know about them.

    /**
     * Executes a request for desktop media if specified in options.
     *
     * @returns {Promise}
     */

    const maybeRequestDesktopDevice = function () {
      const umDevices = options.devices || [];
      const isDesktopDeviceRequested = umDevices.indexOf('desktop') !== -1;

      if (!isDesktopDeviceRequested) {
        return Promise.resolve();
      }

      const {
        desktopSharingExtensionExternalInstallation,
        desktopSharingSourceDevice,
        desktopSharingSources,
        desktopSharingFrameRate
      } = options; // Attempt to use a video input device as a screenshare source if
      // the option is defined.

      if (desktopSharingSourceDevice) {
        const matchingDevice = availableDevices && availableDevices.find(device => device.kind === 'videoinput' && (device.deviceId === desktopSharingSourceDevice || device.label === desktopSharingSourceDevice));

        if (!matchingDevice) {
          return Promise.reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_5__["default"]({
            name: 'ConstraintNotSatisfiedError'
          }, {}, [desktopSharingSourceDevice]));
        }

        const requestedDevices = ['video']; // Leverage the helper used by {@link _newGetDesktopMedia} to
        // get constraints for the desktop stream.

        const {
          gumOptions,
          trackOptions
        } = this._parseDesktopSharingOptions(options);

        const constraints = {
          video: _objectSpread({}, gumOptions, {
            deviceId: matchingDevice.deviceId
          })
        };
        return this._newGetUserMediaWithConstraints(requestedDevices, constraints).then(stream => {
          const track = stream && stream.getTracks()[0];
          const applyConstrainsPromise = track && track.applyConstraints ? track.applyConstraints(trackOptions) : Promise.resolve();
          return applyConstrainsPromise.then(() => {
            return {
              sourceType: 'device',
              stream
            };
          });
        });
      }

      return this._newGetDesktopMedia({
        desktopSharingExtensionExternalInstallation,
        desktopSharingSources,
        desktopSharingFrameRate
      });
    }.bind(this);
    /**
     * Creates a meta data object about the passed in desktopStream and
     * pushes the meta data to the internal array mediaStreamsMetaData to be
     * returned later.
     *
     * @param {MediaStreamTrack} desktopStream - A track for a desktop
     * capture.
     * @returns {void}
     */


    const maybeCreateAndAddDesktopTrack = function (desktopStream) {
      if (!desktopStream) {
        return;
      }

      const {
        stream,
        sourceId,
        sourceType
      } = desktopStream;
      const desktopAudioTracks = stream.getAudioTracks();

      if (desktopAudioTracks.length) {
        const desktopAudioStream = new MediaStream(desktopAudioTracks);
        mediaStreamsMetaData.push({
          stream: desktopAudioStream,
          sourceId,
          sourceType,
          track: desktopAudioStream.getAudioTracks()[0]
        });
      }

      const desktopVideoTracks = stream.getVideoTracks();

      if (desktopVideoTracks.length) {
        const desktopVideoStream = new MediaStream(desktopVideoTracks);
        mediaStreamsMetaData.push({
          stream: desktopVideoStream,
          sourceId,
          sourceType,
          track: desktopVideoStream.getVideoTracks()[0],
          videoType: _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_14___default.a.DESKTOP
        });
      }
    };
    /**
     * Executes a request for audio and/or video, as specified in options.
     * By default both audio and video will be captured if options.devices
     * is not defined.
     *
     * @returns {Promise}
     */


    const maybeRequestCaptureDevices = function () {
      const umDevices = options.devices || ['audio', 'video'];
      const requestedCaptureDevices = umDevices.filter(device => device === 'audio' || device === 'video' && _browser__WEBPACK_IMPORTED_MODULE_9__["default"].supportsVideo());

      if (!requestedCaptureDevices.length) {
        return Promise.resolve();
      }

      const constraints = newGetConstraints(requestedCaptureDevices, options);
      logger.info('Got media constraints: ', constraints);
      return this._newGetUserMediaWithConstraints(requestedCaptureDevices, constraints);
    }.bind(this);
    /**
     * Splits the passed in media stream into separate audio and video
     * streams and creates meta data objects for each and pushes them to the
     * internal array mediaStreamsMetaData to be returned later.
     *
     * @param {MediaStreamTrack} avStream - A track for with audio and/or
     * video track.
     * @returns {void}
     */


    const maybeCreateAndAddAVTracks = function (avStream) {
      if (!avStream) {
        return;
      }

      const audioTracks = avStream.getAudioTracks();

      if (audioTracks.length) {
        const audioStream = new MediaStream(audioTracks);
        mediaStreamsMetaData.push({
          stream: audioStream,
          track: audioStream.getAudioTracks()[0],
          effects: options.effects
        });
      }

      const videoTracks = avStream.getVideoTracks();

      if (videoTracks.length) {
        const videoStream = new MediaStream(videoTracks);
        mediaStreamsMetaData.push({
          stream: videoStream,
          track: videoStream.getVideoTracks()[0],
          videoType: _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_14___default.a.CAMERA,
          effects: options.effects
        });
      }
    };

    return maybeRequestDesktopDevice().then(maybeCreateAndAddDesktopTrack).then(maybeRequestCaptureDevices).then(maybeCreateAndAddAVTracks).then(() => mediaStreamsMetaData).catch(error => {
      mediaStreamsMetaData.forEach(({
        stream
      }) => {
        this.stopMediaStream(stream);
      });
      return Promise.reject(error);
    });
  }
  /**
   * Checks whether it is possible to enumerate available cameras/microphones.
   *
   * @returns {boolean} {@code true} if the device listing is available;
   * {@code false}, otherwise.
   */


  isDeviceListAvailable() {
    return Boolean(navigator.mediaDevices && navigator.mediaDevices.enumerateDevices);
  }
  /**
   * Returns true if changing the input (camera / microphone) or output
   * (audio) device is supported and false if not.
   * @params {string} [deviceType] - type of device to change. Default is
   *      undefined or 'input', 'output' - for audio output device change.
   * @returns {boolean} true if available, false otherwise.
   */


  isDeviceChangeAvailable(deviceType) {
    return deviceType === 'output' || deviceType === 'audiooutput' ? isAudioOutputDeviceChangeAvailable : true;
  }
  /**
   * A method to handle stopping of the stream.
   * One point to handle the differences in various implementations.
   * @param mediaStream MediaStream object to stop.
   */


  stopMediaStream(mediaStream) {
    if (!mediaStream) {
      return;
    }

    mediaStream.getTracks().forEach(track => {
      if (track.stop) {
        track.stop();
      }
    }); // leave stop for implementation still using it

    if (mediaStream.stop) {
      mediaStream.stop();
    } // The MediaStream implementation of the react-native-webrtc project has
    // an explicit release method that is to be invoked in order to release
    // used resources such as memory.


    if (mediaStream.release) {
      mediaStream.release();
    } // if we have done createObjectURL, lets clean it


    const url = mediaStream.jitsiObjectURL;

    if (url) {
      delete mediaStream.jitsiObjectURL;
      URL.revokeObjectURL(url);
    }
  }
  /**
   * Returns whether the desktop sharing is enabled or not.
   * @returns {boolean}
   */


  isDesktopSharingEnabled() {
    return _ScreenObtainer__WEBPACK_IMPORTED_MODULE_11__["default"].isSupported();
  }
  /**
   * Sets current audio output device.
   * @param {string} deviceId - id of 'audiooutput' device from
   *      navigator.mediaDevices.enumerateDevices(), 'default' for default
   *      device
   * @returns {Promise} - resolves when audio output is changed, is rejected
   *      otherwise
   */


  setAudioOutputDevice(deviceId) {
    if (!this.isDeviceChangeAvailable('output')) {
      return Promise.reject(new Error('Audio output device change is not supported'));
    }

    return featureDetectionAudioEl.setSinkId(deviceId).then(() => {
      audioOutputDeviceId = deviceId;
      audioOutputChanged = true;
      logger.log(`Audio output device set to ${deviceId}`);
      eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.AUDIO_OUTPUT_DEVICE_CHANGED, deviceId);
    });
  }
  /**
   * Returns currently used audio output device id, '' stands for default
   * device
   * @returns {string}
   */


  getAudioOutputDevice() {
    return audioOutputDeviceId;
  }
  /**
   * Returns list of available media devices if its obtained, otherwise an
   * empty array is returned/
   * @returns {Array} list of available media devices.
   */


  getCurrentlyAvailableMediaDevices() {
    return availableDevices;
  }
  /**
   * Returns event data for device to be reported to stats.
   * @returns {MediaDeviceInfo} device.
   */


  getEventDataForActiveDevice(device) {
    const deviceList = [];
    const deviceData = {
      'deviceId': device.deviceId,
      'kind': device.kind,
      'label': device.label,
      'groupId': device.groupId
    };
    deviceList.push(deviceData);
    return {
      deviceList
    };
  }
  /**
   * Configures the given PeerConnection constraints to either enable or
   * disable (according to the value of the 'enable' parameter) the
   * 'googSuspendBelowMinBitrate' option.
   * @param constraints the constraints on which to operate.
   * @param enable {boolean} whether to enable or disable the suspend video
   * option.
   */


  setSuspendVideo(constraints, enable) {
    if (!constraints.optional) {
      constraints.optional = [];
    } // Get rid of all "googSuspendBelowMinBitrate" constraints (we assume
    // that the elements of constraints.optional contain a single property).


    constraints.optional = constraints.optional.filter(c => !c.hasOwnProperty('googSuspendBelowMinBitrate'));

    if (enable) {
      constraints.optional.push({
        googSuspendBelowMinBitrate: 'true'
      });
    }
  }

}

const rtcUtils = new RTCUtils();
/**
 * Wraps original attachMediaStream function to set current audio output device
 * if this is supported.
 * @param {Function} origAttachMediaStream
 * @returns {Function}
 */

function wrapAttachMediaStream(origAttachMediaStream) {
  return function (element, stream) {
    // eslint-disable-next-line prefer-rest-params
    const res = origAttachMediaStream.apply(rtcUtils, arguments);

    if (stream && rtcUtils.isDeviceChangeAvailable('output') && stream.getAudioTracks && stream.getAudioTracks().length // we skip setting audio output if there was no explicit change
    && audioOutputChanged) {
      element.setSinkId(rtcUtils.getAudioOutputDevice()).catch(function (ex) {
        const err = new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_5__["default"](ex, null, ['audiooutput']);
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4___default.a.callUnhandledRejectionHandler({
          promise: this,
          // eslint-disable-line no-invalid-this
          reason: err
        });
        logger.warn('Failed to set audio output device for the element.' + ' Default audio output device will be used' + ' instead', element, err);
      });
    }

    return res;
  };
}

/* harmony default export */ __webpack_exports__["default"] = (rtcUtils);
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\RTCUtils.js"))

/***/ }),

/***/ "./modules/RTC/ScreenObtainer.js":
/*!***************************************!*\
  !*** ./modules/RTC/ScreenObtainer.js ***!
  \***************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../JitsiTrackError */ "./JitsiTrackError.js");
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiTrackErrors */ "./JitsiTrackErrors.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

/* global chrome, $, alert */




const logger = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js").getLogger(__filename);

const GlobalOnErrorHandler = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/**
 * Indicates whether the Chrome desktop sharing extension is installed.
 * @type {boolean}
 */


let chromeExtInstalled = false;
/**
 * Indicates whether an update of the Chrome desktop sharing extension is
 * required.
 * @type {boolean}
 */

let chromeExtUpdateRequired = false;
let gumFunction = null;
/**
 * The error message returned by chrome when the extension is installed.
 */

const CHROME_NO_EXTENSION_ERROR_MSG // eslint-disable-line no-unused-vars
= 'Could not establish connection. Receiving end does not exist.';
/**
 * Handles obtaining a stream from a screen capture on different browsers.
 */

const ScreenObtainer = {
  /**
   * If not <tt>null</tt> it means that the initialization process is still in
   * progress. It is used to make desktop stream request wait and continue
   * after it's done.
   * {@type Promise|null}
   */
  intChromeExtPromise: null,
  obtainStream: null,

  /**
   * Initializes the function used to obtain a screen capture
   * (this.obtainStream).
   *
   * @param {object} options
   * @param {boolean} [options.desktopSharingChromeDisabled]
   * @param {boolean} [options.desktopSharingChromeExtId]
   * @param {boolean} [options.desktopSharingFirefoxDisabled]
   * @param {Function} gum GUM method
   */
  init(options = {
    desktopSharingChromeDisabled: false,
    desktopSharingChromeExtId: null,
    desktopSharingFirefoxDisabled: false
  }, gum) {
    this.options = options;
    gumFunction = gum;
    this.obtainStream = this._createObtainStreamMethod(options);

    if (!this.obtainStream) {
      logger.info('Desktop sharing disabled');
    }
  },

  /**
   * Returns a method which will be used to obtain the screen sharing stream
   * (based on the browser type).
   *
   * @param {object} options passed from {@link init} - check description
   * there
   * @returns {Function}
   * @private
   */
  _createObtainStreamMethod(options) {
    if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isNWJS()) {
      return (_, onSuccess, onFailure) => {
        window.JitsiMeetNW.obtainDesktopStream(onSuccess, (error, constraints) => {
          let jitsiError; // FIXME:
          // This is very very dirty fix for recognising that the
          // user have clicked the cancel button from the Desktop
          // sharing pick window. The proper solution would be to
          // detect this in the NWJS application by checking the
          // streamId === "". Even better solution would be to
          // stop calling GUM from the NWJS app and just pass the
          // streamId to lib-jitsi-meet. This way the desktop
          // sharing implementation for NWJS and chrome extension
          // will be the same and lib-jitsi-meet will be able to
          // control the constraints, check the streamId, etc.
          //
          // I cannot find documentation about "InvalidStateError"
          // but this is what we are receiving from GUM when the
          // streamId for the desktop sharing is "".

          if (error && error.name === 'InvalidStateError') {
            jitsiError = new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__["CHROME_EXTENSION_USER_CANCELED"]);
          } else {
            jitsiError = new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](error, constraints, ['desktop']);
          }

          typeof onFailure === 'function' && onFailure(jitsiError);
        });
      };
    } else if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isElectron()) {
      return this.obtainScreenOnElectron;
    } else if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isChrome() || _browser__WEBPACK_IMPORTED_MODULE_2__["default"].isOpera()) {
      if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].supportsGetDisplayMedia() && !options.desktopSharingChromeDisabled) {
        return this.obtainScreenFromGetDisplayMedia;
      } else if (options.desktopSharingChromeDisabled || !options.desktopSharingChromeExtId) {
        return null;
      }

      logger.info('Using Chrome extension for desktop sharing');
      this.intChromeExtPromise = initChromeExtension(options).then(() => {
        this.intChromeExtPromise = null;
      });
      return this.obtainScreenFromExtension;
    } else if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isFirefox()) {
      if (options.desktopSharingFirefoxDisabled) {
        return null;
      } else if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].supportsGetDisplayMedia()) {
        // Firefox 66 support getDisplayMedia
        return this.obtainScreenFromGetDisplayMedia;
      } // Legacy Firefox


      return this.obtainScreenOnFirefox;
    } else if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isSafari() && _browser__WEBPACK_IMPORTED_MODULE_2__["default"].supportsGetDisplayMedia()) {
      return this.obtainScreenFromGetDisplayMedia;
    }

    logger.log('Screen sharing not supported by the current browser: ', _browser__WEBPACK_IMPORTED_MODULE_2__["default"].getName());
    return null;
  },

  /**
   * Checks whether obtaining a screen capture is supported in the current
   * environment.
   * @returns {boolean}
   */
  isSupported() {
    return this.obtainStream !== null;
  },

  /**
   * Obtains a screen capture stream on Firefox.
   * @param callback
   * @param errorCallback
   */
  obtainScreenOnFirefox(options, callback, errorCallback) {
    obtainWebRTCScreen(options.gumOptions, callback, errorCallback);
  },

  /**
   * Obtains a screen capture stream on Electron.
   *
   * @param {Object} [options] - Screen sharing options.
   * @param {Array<string>} [options.desktopSharingSources] - Array with the
   * sources that have to be displayed in the desktop picker window ('screen',
   * 'window', etc.).
   * @param onSuccess - Success callback.
   * @param onFailure - Failure callback.
   */
  obtainScreenOnElectron(options = {}, onSuccess, onFailure) {
    if (window.JitsiMeetScreenObtainer && window.JitsiMeetScreenObtainer.openDesktopPicker) {
      const {
        desktopSharingSources,
        gumOptions
      } = options;
      window.JitsiMeetScreenObtainer.openDesktopPicker({
        desktopSharingSources: desktopSharingSources || this.options.desktopSharingChromeSources
      }, (streamId, streamType, screenShareAudio = false) => onGetStreamResponse({
        response: {
          streamId,
          streamType,
          screenShareAudio
        },
        gumOptions
      }, onSuccess, onFailure), err => onFailure(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__["ELECTRON_DESKTOP_PICKER_ERROR"], err)));
    } else {
      onFailure(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__["ELECTRON_DESKTOP_PICKER_NOT_FOUND"]));
    }
  },

  /**
   * Asks Chrome extension to call chooseDesktopMedia and gets chrome
   * 'desktop' stream for returned stream token.
   */
  obtainScreenFromExtension(options, streamCallback, failCallback) {
    if (this.intChromeExtPromise !== null) {
      this.intChromeExtPromise.then(() => {
        this.obtainScreenFromExtension(options, streamCallback, failCallback);
      });
      return;
    }

    const {
      desktopSharingChromeExtId,
      desktopSharingChromeSources
    } = this.options;
    const {
      gumOptions
    } = options;
    const doGetStreamFromExtensionOptions = {
      desktopSharingChromeExtId,
      desktopSharingChromeSources: options.desktopSharingSources || desktopSharingChromeSources,
      gumOptions
    };

    if (chromeExtInstalled) {
      doGetStreamFromExtension(doGetStreamFromExtensionOptions, streamCallback, failCallback);
    } else {
      if (chromeExtUpdateRequired) {
        /* eslint-disable no-alert */
        alert('Jitsi Desktop Streamer requires update. ' + 'Changes will take effect after next Chrome restart.');
        /* eslint-enable no-alert */
      }

      this.handleExternalInstall(options, streamCallback, failCallback);
    }
  },

  /* eslint-disable max-params */
  handleExternalInstall(options, streamCallback, failCallback, e) {
    const webStoreInstallUrl = getWebStoreInstallUrl(this.options);
    options.listener('waitingForExtension', webStoreInstallUrl);
    this.checkForChromeExtensionOnInterval(options, streamCallback, failCallback, e);
  },

  /* eslint-enable max-params */
  checkForChromeExtensionOnInterval(options, streamCallback, failCallback) {
    if (options.checkAgain() === false) {
      failCallback(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__["CHROME_EXTENSION_INSTALLATION_ERROR"]));
      return;
    }

    waitForExtensionAfterInstall(this.options, options.interval, 1).then(() => {
      chromeExtInstalled = true;
      options.listener('extensionFound');
      this.obtainScreenFromExtension(options, streamCallback, failCallback);
    }).catch(() => {
      this.checkForChromeExtensionOnInterval(options, streamCallback, failCallback);
    });
  },

  /**
   * Obtains a screen capture stream using getDisplayMedia.
   *
   * @param callback - The success callback.
   * @param errorCallback - The error callback.
   */
  obtainScreenFromGetDisplayMedia(options, callback, errorCallback) {
    logger.info('Using getDisplayMedia for screen sharing');
    let getDisplayMedia;

    if (navigator.getDisplayMedia) {
      getDisplayMedia = navigator.getDisplayMedia.bind(navigator);
    } else {
      // eslint-disable-next-line max-len
      getDisplayMedia = navigator.mediaDevices.getDisplayMedia.bind(navigator.mediaDevices);
    }

    getDisplayMedia({
      video: true,
      audio: true
    }).then(stream => {
      let applyConstraintsPromise;

      if (stream && stream.getTracks() && stream.getTracks().length > 0) {
        const videoTrack = stream.getVideoTracks()[0]; // Apply video track constraint.

        if (videoTrack) {
          applyConstraintsPromise = videoTrack.applyConstraints(options.trackOptions);
        }
      } else {
        applyConstraintsPromise = Promise.resolve();
      }

      applyConstraintsPromise.then(() => callback({
        stream,
        sourceId: stream.id
      }));
    }).catch(() => errorCallback(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__["CHROME_EXTENSION_USER_CANCELED"])));
  }

};
/**
 * Obtains a desktop stream using getUserMedia.
 * For this to work on Chrome, the
 * 'chrome://flags/#enable-usermedia-screen-capture' flag must be enabled.
 *
 * On firefox, the document's domain must be white-listed in the
 * 'media.getusermedia.screensharing.allowed_domains' preference in
 * 'about:config'.
 */

function obtainWebRTCScreen(options, streamCallback, failCallback) {
  gumFunction(['screen'], options).then(stream => streamCallback({
    stream
  }), failCallback);
}
/**
 * Constructs inline install URL for Chrome desktop streaming extension.
 * The 'chromeExtensionId' must be defined in options parameter.
 * @param options supports "desktopSharingChromeExtId"
 * @returns {string}
 */


function getWebStoreInstallUrl(options) {
  return `https://chrome.google.com/webstore/detail/${options.desktopSharingChromeExtId}`;
}
/**
 * Checks whether an update of the Chrome extension is required.
 * @param minVersion minimal required version
 * @param extVersion current extension version
 * @returns {boolean}
 */


function isUpdateRequired(minVersion, extVersion) {
  try {
    const s1 = minVersion.split('.');
    const s2 = extVersion.split('.');
    const len = Math.max(s1.length, s2.length);

    for (let i = 0; i < len; i++) {
      let n1 = 0,
          n2 = 0;

      if (i < s1.length) {
        n1 = parseInt(s1[i], 10);
      }

      if (i < s2.length) {
        n2 = parseInt(s2[i], 10);
      }

      if (isNaN(n1) || isNaN(n2)) {
        return true;
      } else if (n1 !== n2) {
        return n1 > n2;
      }
    } // will happen if both versions have identical numbers in
    // their components (even if one of them is longer, has more components)


    return false;
  } catch (e) {
    GlobalOnErrorHandler.callErrorHandler(e);
    logger.error('Failed to parse extension version', e);
    return true;
  }
}
/**
 *
 * @param callback
 * @param options
 */


function checkChromeExtInstalled(callback, options) {
  if (typeof chrome === 'undefined' || !chrome || !chrome.runtime) {
    // No API, so no extension for sure
    callback(false, false);
    return;
  }

  chrome.runtime.sendMessage(options.desktopSharingChromeExtId, {
    getVersion: true
  }, response => {
    if (!response || !response.version) {
      // Communication failure - assume that no endpoint exists
      logger.warn('Extension not installed?: ', chrome.runtime.lastError);
      callback(false, false);
      return;
    } // Check installed extension version


    const extVersion = response.version;
    logger.log(`Extension version is: ${extVersion}`);
    const updateRequired = isUpdateRequired(options.desktopSharingChromeMinExtVersion, extVersion);
    callback(!updateRequired, updateRequired);
  });
}
/**
 *
 * @param options
 * @param streamCallback
 * @param failCallback
 */


function doGetStreamFromExtension(options, streamCallback, failCallback) {
  const {
    desktopSharingChromeSources,
    desktopSharingChromeExtId,
    gumOptions
  } = options; // Sends 'getStream' msg to the extension.
  // Extension id must be defined in the config.

  chrome.runtime.sendMessage(desktopSharingChromeExtId, {
    getStream: true,
    sources: desktopSharingChromeSources
  }, response => {
    if (!response) {
      // possibly re-wraping error message to make code consistent
      const lastError = chrome.runtime.lastError;
      failCallback(lastError instanceof Error ? lastError : new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__["CHROME_EXTENSION_GENERIC_ERROR"], lastError));
      return;
    }

    logger.log('Response from extension: ', response);
    onGetStreamResponse({
      response,
      gumOptions
    }, streamCallback, failCallback);
  });
}
/**
 * Initializes <link rel=chrome-webstore-item /> with extension id set in
 * config.js to support inline installs. Host site must be selected as main
 * website of published extension.
 * @param options supports "desktopSharingChromeExtId"
 */


function initInlineInstalls(options) {
  if ($('link[rel=chrome-webstore-item]').length === 0) {
    $('head').append('<link rel="chrome-webstore-item">');
  }

  $('link[rel=chrome-webstore-item]').attr('href', getWebStoreInstallUrl(options));
}
/**
 *
 * @param options
 *
 * @return {Promise} - a Promise resolved once the initialization process is
 * finished.
 */


function initChromeExtension(options) {
  // Initialize Chrome extension inline installs
  initInlineInstalls(options);
  return new Promise(resolve => {
    // Check if extension is installed
    checkChromeExtInstalled((installed, updateRequired) => {
      chromeExtInstalled = installed;
      chromeExtUpdateRequired = updateRequired;
      logger.info(`Chrome extension installed: ${chromeExtInstalled} updateRequired: ${chromeExtUpdateRequired}`);
      resolve();
    }, options);
  });
}
/**
 * Checks "retries" times on every "waitInterval"ms whether the ext is alive.
 * @param {Object} options the options passed to ScreanObtainer.obtainStream
 * @param {int} waitInterval the number of ms between retries
 * @param {int} retries the number of retries
 * @returns {Promise} returns promise that will be resolved when the extension
 * is alive and rejected if the extension is not alive even after "retries"
 * checks
 */


function waitForExtensionAfterInstall(options, waitInterval, retries) {
  if (retries === 0) {
    return Promise.reject();
  }

  return new Promise((resolve, reject) => {
    let currentRetries = retries;
    const interval = window.setInterval(() => {
      checkChromeExtInstalled(installed => {
        if (installed) {
          window.clearInterval(interval);
          resolve();
        } else {
          currentRetries--;

          if (currentRetries === 0) {
            reject();
            window.clearInterval(interval);
          }
        }
      }, options);
    }, waitInterval);
  });
}
/**
 * Handles response from external application / extension and calls GUM to
 * receive the desktop streams or reports error.
 * @param {object} options
 * @param {object} options.response
 * @param {string} options.response.streamId - the streamId for the desktop
 * stream.
 * @param {bool}   options.response.screenShareAudio - Used by electron clients to
 * enable system audio screen sharing.
 * @param {string} options.response.error - error to be reported.
 * @param {object} options.gumOptions - options passed to GUM.
 * @param {Function} onSuccess - callback for success.
 * @param {Function} onFailure - callback for failure.
 * @param {object} gumOptions - options passed to GUM.
 */


function onGetStreamResponse(options = {
  response: {},
  gumOptions: {}
}, onSuccess, onFailure) {
  const {
    streamId,
    streamType,
    screenShareAudio,
    error
  } = options.response || {};

  if (streamId) {
    const gumOptions = _objectSpread({
      desktopStream: streamId,
      screenShareAudio
    }, options.gumOptions);

    gumFunction(['desktop'], gumOptions).then(stream => onSuccess({
      stream,
      sourceId: streamId,
      sourceType: streamType
    }), onFailure);
  } else {
    // As noted in Chrome Desktop Capture API:
    // If user didn't select any source (i.e. canceled the prompt)
    // then the callback is called with an empty streamId.
    if (streamId === '') {
      onFailure(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__["CHROME_EXTENSION_USER_CANCELED"]));
      return;
    }

    onFailure(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__["CHROME_EXTENSION_GENERIC_ERROR"], error));
  }
}

/* harmony default export */ __webpack_exports__["default"] = (ScreenObtainer);
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\ScreenObtainer.js"))

/***/ }),

/***/ "./modules/RTC/TPCUtils.js":
/*!*********************************!*\
  !*** ./modules/RTC/TPCUtils.js ***!
  \*********************************/
/*! exports provided: SIM_LAYER_RIDS, TPCUtils */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SIM_LAYER_RIDS", function() { return SIM_LAYER_RIDS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TPCUtils", function() { return TPCUtils; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(sdp_transform__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./JitsiTrackEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4__);





const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
const SIM_LAYER_1_RID = '1';
const SIM_LAYER_2_RID = '2';
const SIM_LAYER_3_RID = '3';
const SIM_LAYER_RIDS = [SIM_LAYER_1_RID, SIM_LAYER_2_RID, SIM_LAYER_3_RID];
/**
 * Handles track related operations on TraceablePeerConnection when browser is
 * running in unified plan mode.
 */

class TPCUtils {
  /**
   * @constructor
   */
  constructor(peerconnection) {
    this.pc = peerconnection;
    /**
     * The simulcast encodings that will be configured on the RTCRtpSender
     * for the video tracks in the unified plan mode.
     */

    this.simulcastEncodings = [{
      active: true,
      maxBitrate: _browser__WEBPACK_IMPORTED_MODULE_3__["default"].isFirefox() ? 2500000 : 200000,
      rid: SIM_LAYER_1_RID,
      scaleResolutionDownBy: _browser__WEBPACK_IMPORTED_MODULE_3__["default"].isFirefox() ? 1.0 : 4.0
    }, {
      active: true,
      maxBitrate: 700000,
      rid: SIM_LAYER_2_RID,
      scaleResolutionDownBy: 2.0
    }, {
      active: true,
      maxBitrate: _browser__WEBPACK_IMPORTED_MODULE_3__["default"].isFirefox() ? 200000 : 2500000,
      rid: SIM_LAYER_3_RID,
      scaleResolutionDownBy: _browser__WEBPACK_IMPORTED_MODULE_3__["default"].isFirefox() ? 4.0 : 1.0
    }];
  }
  /**
   * Ensures that the ssrcs associated with a FID ssrc-group appear in the correct order, i.e.,
   * the primary ssrc first and the secondary rtx ssrc later. This is important for unified
   * plan since we have only one FID group per media description.
   * @param {Object} description the webRTC session description instance for the remote
   * description.
   * @private
   */


  _ensureCorrectOrderOfSsrcs(description) {
    const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_1___default.a.parse(description.sdp);
    parsedSdp.media.forEach(mLine => {
      if (mLine.type === 'audio') {
        return;
      }

      if (!mLine.ssrcGroups || !mLine.ssrcGroups.length) {
        return;
      }

      let reorderedSsrcs = [];
      mLine.ssrcGroups[0].ssrcs.split(' ').forEach(ssrc => {
        const sources = mLine.ssrcs.filter(source => source.id.toString() === ssrc);
        reorderedSsrcs = reorderedSsrcs.concat(sources);
      });
      mLine.ssrcs = reorderedSsrcs;
    });
    return new RTCSessionDescription({
      type: description.type,
      sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_1___default.a.write(parsedSdp)
    });
  }
  /**
   * Obtains stream encodings that need to be configured on the given track.
   * @param {JitsiLocalTrack} localTrack
   */


  _getStreamEncodings(localTrack) {
    if (this.pc.isSimulcastOn() && localTrack.isVideoTrack()) {
      return this.simulcastEncodings;
    }

    return [{
      active: true
    }];
  }
  /**
   * Takes in a *unified plan* offer and inserts the appropriate
   * parameters for adding simulcast receive support.
   * @param {Object} desc - A session description object
   * @param {String} desc.type - the type (offer/answer)
   * @param {String} desc.sdp - the sdp content
   *
   * @return {Object} A session description (same format as above) object
   * with its sdp field modified to advertise simulcast receive support
   */


  _insertUnifiedPlanSimulcastReceive(desc) {
    // a=simulcast line is not needed on browsers where
    // we munge SDP for turning on simulcast. Remove this check
    // when we move to RID/MID based simulcast on all browsers.
    if (_browser__WEBPACK_IMPORTED_MODULE_3__["default"].usesSdpMungingForSimulcast()) {
      return desc;
    }

    const sdp = sdp_transform__WEBPACK_IMPORTED_MODULE_1___default.a.parse(desc.sdp);
    const idx = sdp.media.findIndex(mline => mline.type === 'video');

    if (sdp.media[idx].rids && (sdp.media[idx].simulcast_03 || sdp.media[idx].simulcast)) {
      // Make sure we don't have the simulcast recv line on video descriptions other than the
      // the first video description.
      sdp.media.forEach((mline, i) => {
        if (mline.type === 'video' && i !== idx) {
          sdp.media[i].rids = undefined;
          sdp.media[i].simulcast = undefined; // eslint-disable-next-line camelcase

          sdp.media[i].simulcast_03 = undefined;
        }
      });
      return new RTCSessionDescription({
        type: desc.type,
        sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_1___default.a.write(sdp)
      });
    } // In order of highest to lowest spatial quality


    sdp.media[idx].rids = [{
      id: SIM_LAYER_1_RID,
      direction: 'recv'
    }, {
      id: SIM_LAYER_2_RID,
      direction: 'recv'
    }, {
      id: SIM_LAYER_3_RID,
      direction: 'recv'
    }]; // Firefox 72 has stopped parsing the legacy rid= parameters in simulcast attributes.
    // eslint-disable-next-line max-len
    // https://www.fxsitecompat.dev/en-CA/docs/2019/pt-and-rid-in-webrtc-simulcast-attributes-are-no-longer-supported/

    const simulcastLine = _browser__WEBPACK_IMPORTED_MODULE_3__["default"].isFirefox() && _browser__WEBPACK_IMPORTED_MODULE_3__["default"].isVersionGreaterThan(71) ? `recv ${SIM_LAYER_RIDS.join(';')}` : `recv rid=${SIM_LAYER_RIDS.join(';')}`; // eslint-disable-next-line camelcase

    sdp.media[idx].simulcast_03 = {
      value: simulcastLine
    };
    return new RTCSessionDescription({
      type: desc.type,
      sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_1___default.a.write(sdp)
    });
  }
  /**
  * Adds {@link JitsiLocalTrack} to the WebRTC peerconnection for the first time.
  * @param {JitsiLocalTrack} track - track to be added to the peerconnection.
  * @returns {boolean} Returns true if the operation is successful,
  * false otherwise.
  */


  addTrack(localTrack, isInitiator = true) {
    const track = localTrack.getTrack();

    if (isInitiator) {
      // Use pc.addTransceiver() for the initiator case when local tracks are getting added
      // to the peerconnection before a session-initiate is sent over to the peer.
      const transceiverInit = {
        direction: 'sendrecv',
        streams: [localTrack.getOriginalStream()],
        sendEncodings: []
      };

      if (!_browser__WEBPACK_IMPORTED_MODULE_3__["default"].isFirefox()) {
        transceiverInit.sendEncodings = this._getStreamEncodings(localTrack);
      }

      this.pc.peerconnection.addTransceiver(track, transceiverInit);
    } else {
      // Use pc.addTrack() for responder case so that we can re-use the m-lines that were created
      // when setRemoteDescription was called. pc.addTrack() automatically  attaches to any existing
      // unused "recv-only" transceiver.
      this.pc.peerconnection.addTrack(track);
    }
  }
  /**
   * Adds a track on the RTCRtpSender as part of the unmute operation.
   * @param {JitsiLocalTrack} localTrack - track to be unmuted.
   * @returns {Promise<boolean>} - Promise that resolves to false if unmute
   * operation is successful, a reject otherwise.
   */


  addTrackUnmute(localTrack) {
    const mediaType = localTrack.getType();
    const track = localTrack.getTrack(); // The assumption here is that the first transceiver of the specified
    // media type is that of the local track.

    const transceiver = this.pc.peerconnection.getTransceivers().find(t => t.receiver && t.receiver.track && t.receiver.track.kind === mediaType);

    if (!transceiver) {
      return Promise.reject(new Error(`RTCRtpTransceiver for ${mediaType} not found`));
    }

    logger.debug(`Adding ${localTrack} on ${this.pc}`); // If the client starts with audio/video muted setting, the transceiver direction
    // will be set to 'recvonly'. Use addStream here so that a MSID is generated for the stream.

    if (transceiver.direction === 'recvonly') {
      this.pc.peerconnection.addStream(localTrack.getOriginalStream());
      this.setEncodings(localTrack);
      this.pc.localTracks.set(localTrack.rtcId, localTrack);
      transceiver.direction = 'sendrecv';
      return Promise.resolve(false);
    }

    return transceiver.sender.replaceTrack(track).then(() => {
      this.pc.localTracks.set(localTrack.rtcId, localTrack);
      return Promise.resolve(false);
    });
  }
  /**
   * Removes the track from the RTCRtpSender as part of the mute operation.
   * @param {JitsiLocalTrack} localTrack - track to be removed.
   * @returns {Promise<boolean>} - Promise that resolves to false if unmute
   * operation is successful, a reject otherwise.
   */


  removeTrackMute(localTrack) {
    const mediaType = localTrack.getType();
    const transceiver = this.pc.peerconnection.getTransceivers().find(t => t.sender && t.sender.track && t.sender.track.id === localTrack.getTrackId());

    if (!transceiver) {
      return Promise.reject(new Error(`RTCRtpTransceiver for ${mediaType} not found`));
    }

    logger.debug(`Removing ${localTrack} on ${this.pc}`);
    return transceiver.sender.replaceTrack(null).then(() => {
      this.pc.localTracks.delete(localTrack.rtcId);
      return Promise.resolve(false);
    });
  }
  /**
   * Replaces the existing track on a RTCRtpSender with the given track.
   * @param {JitsiLocalTrack} oldTrack - existing track on the sender that needs to be removed.
   * @param {JitsiLocalTrack} newTrack - new track that needs to be added to the sender.
   * @returns {Promise<false>} Promise that resolves with false as we don't want
   * renegotiation to be triggered automatically after this operation. Renegotiation is
   * done when the browser fires the negotiationeeded event.
   */


  replaceTrack(oldTrack, newTrack) {
    if (oldTrack && newTrack) {
      const mediaType = newTrack.getType();
      const stream = newTrack.getOriginalStream();
      const track = stream.getVideoTracks()[0];
      const transceiver = this.pc.peerconnection.getTransceivers().find(t => t.receiver.track.kind === mediaType && !t.stopped);

      if (!transceiver) {
        return Promise.reject(new Error('replace track failed'));
      }

      logger.debug(`Replacing ${oldTrack} with ${newTrack} on ${this.pc}`);
      return transceiver.sender.replaceTrack(track).then(() => {
        const ssrc = this.pc.localSSRCs.get(oldTrack.rtcId);
        this.pc.localTracks.delete(oldTrack.rtcId);
        this.pc.localSSRCs.delete(oldTrack.rtcId);
        this.pc._addedStreams = this.pc._addedStreams.filter(s => s !== stream);
        this.pc.localTracks.set(newTrack.rtcId, newTrack);

        this.pc._addedStreams.push(stream);

        this.pc.localSSRCs.set(newTrack.rtcId, ssrc);
        this.pc.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_4___default.a.LOCAL_TRACK_SSRC_UPDATED, newTrack, this.pc._extractPrimarySSRC(ssrc));
      });
    } else if (oldTrack && !newTrack) {
      if (!this.removeTrackMute(oldTrack)) {
        return Promise.reject(new Error('replace track failed'));
      }

      this.pc.localTracks.delete(oldTrack.rtcId);
      this.pc.localSSRCs.delete(oldTrack.rtcId);
    } else if (newTrack && !oldTrack) {
      const ssrc = this.pc.localSSRCs.get(newTrack.rtcId);

      if (!this.addTrackUnmute(newTrack)) {
        return Promise.reject(new Error('replace track failed'));
      }

      newTrack.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_MUTE_CHANGED"], newTrack);
      this.pc.localTracks.set(newTrack.rtcId, newTrack);
      this.pc.localSSRCs.set(newTrack.rtcId, ssrc);
    }

    return Promise.resolve(false);
  }
  /**
  * Enables/disables audio transmission on the peer connection. When
  * disabled the audio transceiver direction will be set to 'inactive'
  * which means that no data will be sent nor accepted, but
  * the connection should be kept alive.
  * @param {boolean} active - true to enable audio media transmission or
  * false to disable.
  * @returns {false} - returns false always so that renegotiation is not automatically
  * triggered after this operation.
  */


  setAudioTransferActive(active) {
    return this.setMediaTransferActive('audio', active);
  }
  /**
   * Set the simulcast stream encoding properties on the RTCRtpSender.
   * @param {JitsiLocalTrack} track - the current track in use for which
   * the encodings are to be set.
   */


  setEncodings(track) {
    const transceiver = this.pc.peerconnection.getTransceivers().find(t => t.sender && t.sender.track && t.sender.track.kind === track.getType());
    const parameters = transceiver.sender.getParameters();
    parameters.encodings = this._getStreamEncodings(track);
    transceiver.sender.setParameters(parameters);
  }
  /**
   * Enables/disables media transmission on the peerconnection by changing the direction
   * on the transceiver for the specified media type.
   * @param {String} mediaType - 'audio' or 'video'
   * @param {boolean} active - true to enable media transmission or false
   * to disable.
   * @returns {false} - returns false always so that renegotiation is not automatically
   * triggered after this operation
   */


  setMediaTransferActive(mediaType, active) {
    const transceivers = this.pc.peerconnection.getTransceivers().filter(t => t.receiver && t.receiver.track && t.receiver.track.kind === mediaType);
    const localTracks = Array.from(this.pc.localTracks.values()).filter(track => track.getType() === mediaType);

    if (active) {
      transceivers.forEach(transceiver => {
        if (localTracks.length) {
          transceiver.direction = 'sendrecv';
          const parameters = transceiver.sender.getParameters();

          if (parameters && parameters.encodings && parameters.encodings.length) {
            parameters.encodings.forEach(encoding => {
              encoding.active = true;
            });
            transceiver.sender.setParameters(parameters);
          }
        } else {
          transceiver.direction = 'recvonly';
        }
      });
    } else {
      transceivers.forEach(transceiver => {
        transceiver.direction = 'inactive';
      });
    }

    return false;
  }
  /**
  * Enables/disables video media transmission on the peer connection. When
  * disabled the SDP video media direction in the local SDP will be adjusted to
  * 'inactive' which means that no data will be sent nor accepted, but
  * the connection should be kept alive.
  * @param {boolean} active - true to enable video media transmission or
  * false to disable.
  * @returns {false} - returns false always so that renegotiation is not automatically
  * triggered after this operation.
  */


  setVideoTransferActive(active) {
    return this.setMediaTransferActive('video', active);
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\TPCUtils.js"))

/***/ }),

/***/ "./modules/RTC/TraceablePeerConnection.js":
/*!************************************************!*\
  !*** ./modules/RTC/TraceablePeerConnection.js ***!
  \************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return TraceablePeerConnection; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _jitsi_sdp_interop__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @jitsi/sdp-interop */ "./node_modules/@jitsi/sdp-interop/lib/index.js");
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(sdp_transform__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _JitsiRemoteTrack__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./JitsiRemoteTrack */ "./modules/RTC/JitsiRemoteTrack.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _LocalSdpMunger__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./LocalSdpMunger */ "./modules/RTC/LocalSdpMunger.js");
/* harmony import */ var _RTC__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./RTC */ "./modules/RTC/RTC.js");
/* harmony import */ var _RTCUtils__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./RTCUtils */ "./modules/RTC/RTCUtils.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10__);
/* harmony import */ var _xmpp_RtxModifier__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../xmpp/RtxModifier */ "./modules/xmpp/RtxModifier.js");
/* harmony import */ var _TPCUtils__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./TPCUtils */ "./modules/RTC/TPCUtils.js");
/* harmony import */ var _xmpp_SDP__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../xmpp/SDP */ "./modules/xmpp/SDP.js");
/* harmony import */ var _xmpp_SdpConsistency__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../xmpp/SdpConsistency */ "./modules/xmpp/SdpConsistency.js");
/* harmony import */ var _xmpp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../xmpp/SdpTransformUtil */ "./modules/xmpp/SdpTransformUtil.js");
/* harmony import */ var _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../xmpp/SDPUtil */ "./modules/xmpp/SDPUtil.js");
/* harmony import */ var _service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../../service/RTC/SignalingEvents */ "./service/RTC/SignalingEvents.js");
/* global __filename, RTCSessionDescription */












 // FIXME SDP tools should end up in some kind of util module






const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
const MAX_BITRATE = 2500000;
const DESKSTOP_SHARE_RATE = 500000;
/* eslint-disable max-params */

/**
 * Creates new instance of 'TraceablePeerConnection'.
 *
 * @param {RTC} rtc the instance of <tt>RTC</tt> service
 * @param {number} id the peer connection id assigned by the parent RTC module.
 * @param {SignalingLayer} signalingLayer the signaling layer instance
 * @param {object} iceConfig WebRTC 'PeerConnection' ICE config
 * @param {object} constraints WebRTC 'PeerConnection' constraints
 * @param {boolean} isP2P indicates whether or not the new instance will be used
 * in a peer to peer connection
 * @param {object} options <tt>TracablePeerConnection</tt> config options.
 * @param {boolean} options.disableSimulcast if set to 'true' will disable
 * the simulcast.
 * @param {boolean} options.disableRtx if set to 'true' will disable the RTX
 * @param {boolean} options.capScreenshareBitrate if set to 'true' simulcast will
 * be disabled for screenshare and a max bitrate of 500Kbps will applied on the
 * stream.
 * @param {boolean} options.disableH264 If set to 'true' H264 will be
 *      disabled by removing it from the SDP.
 * @param {boolean} options.preferH264 if set to 'true' H264 will be preferred
 * over other video codecs.
 * @param {boolean} options.enableLayerSuspension if set to 'true', we will
 * cap the video send bitrate when we are told we have not been selected by
 * any endpoints (and therefore the non-thumbnail streams are not in use).
 * @param {boolean} options.startSilent If set to 'true' no audio will be sent or received.
 *
 * FIXME: initially the purpose of TraceablePeerConnection was to be able to
 * debug the peer connection. Since many other responsibilities have been added
 * it would make sense to extract a separate class from it and come up with
 * a more suitable name.
 *
 * @constructor
 */

function TraceablePeerConnection(rtc, id, signalingLayer, iceConfig, constraints, isP2P, options) {
  /**
   * Indicates whether or not this peer connection instance is actively
   * sending/receiving audio media. When set to <tt>false</tt> the SDP audio
   * media direction will be adjusted to 'inactive' in order to suspend
   * the transmission.
   * @type {boolean}
   * @private
   */
  this.audioTransferActive = !(options.startSilent === true);
  /**
   * The DTMF sender instance used to send DTMF tones.
   *
   * @type {RTCDTMFSender|undefined}
   * @private
   */

  this._dtmfSender = undefined;
  /**
   * @typedef {Object} TouchToneRequest
   * @property {string} tones - The DTMF tones string as defined by
   * {@code RTCDTMFSender.insertDTMF}, 'tones' argument.
   * @property {number} duration - The amount of time in milliseconds that
   * each DTMF should last.
   * @property {string} interToneGap - The length of time in miliseconds to
   * wait between tones.
   */

  /**
   * TouchToneRequests which are waiting to be played. This queue is filled
   * if there are touch tones currently being played.
   *
   * @type {Array<TouchToneRequest>}
   * @private
   */

  this._dtmfTonesQueue = [];
  /**
   * Indicates whether or not this peer connection instance is actively
   * sending/receiving video media. When set to <tt>false</tt> the SDP video
   * media direction will be adjusted to 'inactive' in order to suspend
   * the transmission.
   * @type {boolean}
   * @private
   */

  this.videoTransferActive = true;
  /**
   * The parent instance of RTC service which created this
   * <tt>TracablePeerConnection</tt>.
   * @type {RTC}
   */

  this.rtc = rtc;
  /**
   * The peer connection identifier assigned by the RTC module.
   * @type {number}
   */

  this.id = id;
  /**
   * Indicates whether or not this instance is used in a peer to peer
   * connection.
   * @type {boolean}
   */

  this.isP2P = isP2P; // FIXME: We should support multiple streams per jid.

  /**
   * The map holds remote tracks associated with this peer connection.
   * It maps user's JID to media type and remote track
   * (one track per media type per user's JID).
   * @type {Map<string, Map<MediaType, JitsiRemoteTrack>>}
   */

  this.remoteTracks = new Map();
  /**
   * A map which stores local tracks mapped by {@link JitsiLocalTrack.rtcId}
   * @type {Map<number, JitsiLocalTrack>}
   */

  this.localTracks = new Map();
  /**
   * Keeps tracks of the WebRTC <tt>MediaStream</tt>s that have been added to
   * the underlying WebRTC PeerConnection.
   * @type {Array}
   * @private
   */

  this._addedStreams = [];
  /**
   * @typedef {Object} TPCGroupInfo
   * @property {string} semantics the SSRC groups semantics
   * @property {Array<number>} ssrcs group's SSRCs in order where the first
   * one is group's primary SSRC, the second one is secondary (RTX) and so
   * on...
   */

  /**
   * @typedef {Object} TPCSSRCInfo
   * @property {Array<number>} ssrcs an array which holds all track's SSRCs
   * @property {Array<TPCGroupInfo>} groups an array stores all track's SSRC
   * groups
   */

  /**
   * Holds the info about local track's SSRCs mapped per their
   * {@link JitsiLocalTrack.rtcId}
   * @type {Map<number, TPCSSRCInfo>}
   */

  this.localSSRCs = new Map();
  /**
   * The local ICE username fragment for this session.
   */

  this.localUfrag = null;
  /**
   * The remote ICE username fragment for this session.
   */

  this.remoteUfrag = null;
  /**
   * The signaling layer which operates this peer connection.
   * @type {SignalingLayer}
   */

  this.signalingLayer = signalingLayer; // SignalingLayer listeners

  this._peerVideoTypeChanged = this._peerVideoTypeChanged.bind(this);
  this.signalingLayer.on(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_17__["PEER_VIDEO_TYPE_CHANGED"], this._peerVideoTypeChanged);
  this._peerMutedChanged = this._peerMutedChanged.bind(this);
  this.signalingLayer.on(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_17__["PEER_MUTED_CHANGED"], this._peerMutedChanged);
  this.options = options;
  this.peerconnection = new _RTCUtils__WEBPACK_IMPORTED_MODULE_8__["default"].RTCPeerConnectionType(iceConfig, constraints);
  this.tpcUtils = new _TPCUtils__WEBPACK_IMPORTED_MODULE_12__["TPCUtils"](this);
  this.updateLog = [];
  this.stats = {};
  this.statsinterval = null;
  /**
   * @type {number} The max number of stats to keep in this.stats. Limit to
   * 300 values, i.e. 5 minutes; set to 0 to disable
   */

  this.maxstats = options.maxstats;
  this.interop = new _jitsi_sdp_interop__WEBPACK_IMPORTED_MODULE_1__["Interop"]();

  const Simulcast = __webpack_require__(/*! @jitsi/sdp-simulcast */ "./node_modules/@jitsi/sdp-simulcast/lib/index.js");

  this.simulcast = new Simulcast({
    numOfLayers: _TPCUtils__WEBPACK_IMPORTED_MODULE_12__["SIM_LAYER_RIDS"].length,
    explodeRemoteSimulcast: false,
    usesUnifiedPlan: _browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()
  });
  this.sdpConsistency = new _xmpp_SdpConsistency__WEBPACK_IMPORTED_MODULE_14__["default"](this.toString());
  /**
   * Munges local SDP provided to the Jingle Session in order to prevent from
   * sending SSRC updates on attach/detach and mute/unmute (for video).
   * @type {LocalSdpMunger}
   */

  this.localSdpMunger = new _LocalSdpMunger__WEBPACK_IMPORTED_MODULE_6__["default"](this);
  /**
   * TracablePeerConnection uses RTC's eventEmitter
   * @type {EventEmitter}
   */

  this.eventEmitter = rtc.eventEmitter;
  this.rtxModifier = new _xmpp_RtxModifier__WEBPACK_IMPORTED_MODULE_11__["default"](); // override as desired

  this.trace = (what, info) => {
    logger.debug(what, info);
    this.updateLog.push({
      time: new Date(),
      type: what,
      value: info || ''
    });
  };

  this.onicecandidate = null;

  this.peerconnection.onicecandidate = event => {
    this.trace('onicecandidate', JSON.stringify(event.candidate, null, ' '));

    if (this.onicecandidate !== null) {
      this.onicecandidate(event);
    }
  }; // Use stream events in plan-b and track events in unified plan.


  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesPlanB()) {
    this.peerconnection.onaddstream = event => this._remoteStreamAdded(event.stream);

    this.peerconnection.onremovestream = event => this._remoteStreamRemoved(event.stream);
  } else {
    this.peerconnection.ontrack = event => {
      const stream = event.streams[0];

      this._remoteTrackAdded(stream, event.track, event.transceiver);

      stream.onremovetrack = evt => {
        this._remoteTrackRemoved(stream, evt.track);
      };
    };
  }

  this.onsignalingstatechange = null;

  this.peerconnection.onsignalingstatechange = event => {
    this.trace('onsignalingstatechange', this.signalingState);

    if (this.onsignalingstatechange !== null) {
      this.onsignalingstatechange(event);
    }
  };

  this.oniceconnectionstatechange = null;

  this.peerconnection.oniceconnectionstatechange = event => {
    this.trace('oniceconnectionstatechange', this.iceConnectionState);

    if (this.oniceconnectionstatechange !== null) {
      this.oniceconnectionstatechange(event);
    }
  };

  this.onnegotiationneeded = null;

  this.peerconnection.onnegotiationneeded = event => {
    this.trace('onnegotiationneeded');

    if (this.onnegotiationneeded !== null) {
      this.onnegotiationneeded(event);
    }
  };

  this.ondatachannel = null;

  this.peerconnection.ondatachannel = event => {
    this.trace('ondatachannel');

    if (this.ondatachannel !== null) {
      this.ondatachannel(event);
    }
  };

  if (this.maxstats) {
    this.statsinterval = window.setInterval(() => {
      this.getStats(stats => {
        if (stats.result && typeof stats.result === 'function') {
          const results = stats.result();

          for (let i = 0; i < results.length; ++i) {
            const res = results[i];
            res.names().forEach(name => {
              this._processStat(res, name, res.stat(name));
            });
          }
        } else {
          stats.forEach(r => this._processStat(r, '', r));
        }
      }, () => {// empty error callback
      });
    }, 1000);
  }

  logger.info(`Create new ${this}`);
}
/* eslint-enable max-params */

/**
 * Process stat and adds it to the array of stats we store.
 * @param report the current stats report.
 * @param name the name of the report, if available
 * @param statValue the value to add.
 * @private
 */

TraceablePeerConnection.prototype._processStat = function (report, name, statValue) {
  const id = `${report.id}-${name}`;
  let s = this.stats[id];
  const now = new Date();

  if (!s) {
    this.stats[id] = s = {
      startTime: now,
      endTime: now,
      values: [],
      times: []
    };
  }

  s.values.push(statValue);
  s.times.push(now.getTime());

  if (s.values.length > this.maxstats) {
    s.values.shift();
    s.times.shift();
  }

  s.endTime = now;
};
/**
 * Returns a string representation of a SessionDescription object.
 */


const dumpSDP = function (description) {
  if (typeof description === 'undefined' || description === null) {
    return '';
  }

  return `type: ${description.type}\r\n${description.sdp}`;
};
/**
 * Forwards the {@link peerconnection.iceConnectionState} state except that it
 * will convert "completed" into "connected" where both mean that the ICE has
 * succeeded and is up and running. We never see "completed" state for
 * the JVB connection, but it started appearing for the P2P one. This method
 * allows to adapt old logic to this new situation.
 * @return {string}
 */


TraceablePeerConnection.prototype.getConnectionState = function () {
  const state = this.peerconnection.iceConnectionState;

  if (state === 'completed') {
    return 'connected';
  }

  return state;
};
/**
 * Obtains the media direction for given {@link MediaType}. The method takes
 * into account whether or not there are any local tracks for media and
 * the {@link audioTransferActive} and {@link videoTransferActive} flags.
 * @param {MediaType} mediaType
 * @return {string} one of the SDP direction constants ('sendrecv, 'recvonly'
 * etc.) which should be used when setting local description on the peer
 * connection.
 * @private
 */


TraceablePeerConnection.prototype._getDesiredMediaDirection = function (mediaType) {
  let mediaTransferActive = true;

  if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["AUDIO"]) {
    mediaTransferActive = this.audioTransferActive;
  } else if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]) {
    mediaTransferActive = this.videoTransferActive;
  }

  if (mediaTransferActive) {
    return this.hasAnyTracksOfType(mediaType) ? 'sendrecv' : 'recvonly';
  }

  return 'inactive';
};
/**
 * Tells whether or not this TPC instance is using Simulcast.
 * @return {boolean} <tt>true</tt> if simulcast is enabled and active or
 * <tt>false</tt> if it's turned off.
 */


TraceablePeerConnection.prototype.isSimulcastOn = function () {
  return !this.options.disableSimulcast;
};
/**
 * Handles {@link SignalingEvents.PEER_VIDEO_TYPE_CHANGED}
 * @param {string} endpointId the video owner's ID (MUC nickname)
 * @param {VideoType} videoType the new value
 * @private
 */


TraceablePeerConnection.prototype._peerVideoTypeChanged = function (endpointId, videoType) {
  // Check if endpointId has a value to avoid action on random track
  if (!endpointId) {
    logger.error(`No endpointID on peerVideoTypeChanged ${this}`);
    return;
  }

  const videoTrack = this.getRemoteTracks(endpointId, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]);

  if (videoTrack.length) {
    // NOTE 1 track per media type is assumed
    videoTrack[0]._setVideoType(videoType);
  }
};
/**
 * Handles remote track mute / unmute events.
 * @param {string} endpointId the track owner's identifier (MUC nickname)
 * @param {MediaType} mediaType "audio" or "video"
 * @param {boolean} isMuted the new mute state
 * @private
 */


TraceablePeerConnection.prototype._peerMutedChanged = function (endpointId, mediaType, isMuted) {
  // Check if endpointId is a value to avoid doing action on all remote tracks
  if (!endpointId) {
    logger.error('On peerMuteChanged - no endpoint ID');
    return;
  }

  const track = this.getRemoteTracks(endpointId, mediaType);

  if (track.length) {
    // NOTE 1 track per media type is assumed
    track[0].setMute(isMuted);
  }
};
/**
 * Obtains local tracks for given {@link MediaType}. If the <tt>mediaType</tt>
 * argument is omitted the list of all local tracks will be returned.
 * @param {MediaType} [mediaType]
 * @return {Array<JitsiLocalTrack>}
 */


TraceablePeerConnection.prototype.getLocalTracks = function (mediaType) {
  let tracks = Array.from(this.localTracks.values());

  if (mediaType !== undefined) {
    tracks = tracks.filter(track => track.getType() === mediaType);
  }

  return tracks;
};
/**
 * Checks whether or not this {@link TraceablePeerConnection} instance contains
 * any local tracks for given <tt>mediaType</tt>.
 * @param {MediaType} mediaType
 * @return {boolean}
 */


TraceablePeerConnection.prototype.hasAnyTracksOfType = function (mediaType) {
  if (!mediaType) {
    throw new Error('"mediaType" is required');
  }

  return this.getLocalTracks(mediaType).length > 0;
};
/**
 * Obtains all remote tracks currently known to this PeerConnection instance.
 * @param {string} [endpointId] the track owner's identifier (MUC nickname)
 * @param {MediaType} [mediaType] the remote tracks will be filtered
 * by their media type if this argument is specified.
 * @return {Array<JitsiRemoteTrack>}
 */


TraceablePeerConnection.prototype.getRemoteTracks = function (endpointId, mediaType) {
  const remoteTracks = [];
  const endpoints = endpointId ? [endpointId] : this.remoteTracks.keys();

  for (const endpoint of endpoints) {
    const endpointTrackMap = this.remoteTracks.get(endpoint);

    if (!endpointTrackMap) {
      // Otherwise an empty Map() would have to be allocated above
      // eslint-disable-next-line no-continue
      continue;
    }

    for (const trackMediaType of endpointTrackMap.keys()) {
      // per media type filtering
      if (!mediaType || mediaType === trackMediaType) {
        const mediaTrack = endpointTrackMap.get(trackMediaType);

        if (mediaTrack) {
          remoteTracks.push(mediaTrack);
        }
      }
    }
  }

  return remoteTracks;
};
/**
 * Tries to find {@link JitsiTrack} for given SSRC number. It will search both
 * local and remote tracks bound to this instance.
 * @param {number} ssrc
 * @return {JitsiTrack|null}
 */


TraceablePeerConnection.prototype.getTrackBySSRC = function (ssrc) {
  if (typeof ssrc !== 'number') {
    throw new Error(`SSRC ${ssrc} is not a number`);
  }

  for (const localTrack of this.localTracks.values()) {
    if (this.getLocalSSRC(localTrack) === ssrc) {
      return localTrack;
    }
  }

  for (const remoteTrack of this.getRemoteTracks()) {
    if (remoteTrack.getSSRC() === ssrc) {
      return remoteTrack;
    }
  }

  return null;
};
/**
 * Tries to find SSRC number for given {@link JitsiTrack} id. It will search
 * both local and remote tracks bound to this instance.
 * @param {string} id
 * @return {number|null}
 */


TraceablePeerConnection.prototype.getSsrcByTrackId = function (id) {
  const findTrackById = track => track.getTrack().id === id;

  const localTrack = this.getLocalTracks().find(findTrackById);

  if (localTrack) {
    return this.getLocalSSRC(localTrack);
  }

  const remoteTrack = this.getRemoteTracks().find(findTrackById);

  if (remoteTrack) {
    return remoteTrack.getSSRC();
  }

  return null;
};
/**
 * Called when new remote MediaStream is added to the PeerConnection.
 * @param {MediaStream} stream the WebRTC MediaStream for remote participant
 */


TraceablePeerConnection.prototype._remoteStreamAdded = function (stream) {
  const streamId = _RTC__WEBPACK_IMPORTED_MODULE_7__["default"].getStreamID(stream);

  if (!_RTC__WEBPACK_IMPORTED_MODULE_7__["default"].isUserStreamById(streamId)) {
    logger.info(`${this} ignored remote 'stream added' event for non-user stream` + `id: ${streamId}`);
    return;
  } // Bind 'addtrack'/'removetrack' event handlers


  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isChromiumBased()) {
    stream.onaddtrack = event => {
      this._remoteTrackAdded(stream, event.track);
    };

    stream.onremovetrack = event => {
      this._remoteTrackRemoved(stream, event.track);
    };
  } // Call remoteTrackAdded for each track in the stream


  const streamAudioTracks = stream.getAudioTracks();

  for (const audioTrack of streamAudioTracks) {
    this._remoteTrackAdded(stream, audioTrack);
  }

  const streamVideoTracks = stream.getVideoTracks();

  for (const videoTrack of streamVideoTracks) {
    this._remoteTrackAdded(stream, videoTrack);
  }
};
/**
 * Called on "track added" and "stream added" PeerConnection events (because we
 * handle streams on per track basis). Finds the owner and the SSRC for
 * the track and passes that to ChatRoom for further processing.
 * @param {MediaStream} stream the WebRTC MediaStream instance which is
 * the parent of the track
 * @param {MediaStreamTrack} track the WebRTC MediaStreamTrack added for remote
 * participant.
 * @param {RTCRtpTransceiver} transceiver the WebRTC transceiver that is created
 * for the remote participant in unified plan.
 */


TraceablePeerConnection.prototype._remoteTrackAdded = function (stream, track, transceiver = null) {
  const streamId = _RTC__WEBPACK_IMPORTED_MODULE_7__["default"].getStreamID(stream);
  const mediaType = track.kind;

  if (!this.isP2P && !_RTC__WEBPACK_IMPORTED_MODULE_7__["default"].isUserStreamById(streamId)) {
    logger.info(`${this} ignored remote 'stream added' event for non-user stream` + `id: ${streamId}`);
    return;
  }

  logger.info(`${this} remote track added:`, streamId, mediaType); // look up an associated JID for a stream id

  if (!mediaType) {
    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__["callErrorHandler"](new Error(`MediaType undefined for remote track, stream id: ${streamId}`)); // Abort

    return;
  }

  const remoteSDP = _browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesPlanB() ? new _xmpp_SDP__WEBPACK_IMPORTED_MODULE_13__["default"](this.remoteDescription.sdp) : new _xmpp_SDP__WEBPACK_IMPORTED_MODULE_13__["default"](this.peerconnection.remoteDescription.sdp);
  let mediaLines;

  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()) {
    if (transceiver && transceiver.mid) {
      const mid = transceiver.mid;
      mediaLines = remoteSDP.media.filter(mls => _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLine(mls, `a=mid:${mid}`));
    } else {
      mediaLines = remoteSDP.media.filter(mls => {
        const msid = _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLine(mls, 'a=msid');
        return typeof msid !== 'undefined' && streamId === msid.substring(7).split(' ')[0];
      });
    }
  } else {
    mediaLines = remoteSDP.media.filter(mls => mls.startsWith(`m=${mediaType}`));
  }

  if (!mediaLines.length) {
    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__["callErrorHandler"](new Error(`No media lines for type ${mediaType} found in remote SDP for remote track: ${streamId}`)); // Abort

    return;
  }

  let ssrcLines = _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLines(mediaLines[0], 'a=ssrc:');
  ssrcLines = ssrcLines.filter(line => line.indexOf(`msid:${streamId}`) !== -1);

  if (!ssrcLines.length) {
    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__["callErrorHandler"](new Error(`No SSRC lines for streamId ${streamId} for remote track, media type: ${mediaType}`)); // Abort

    return;
  } // FIXME the length of ssrcLines[0] not verified, but it will fail
  // with global error handler anyway


  const ssrcStr = ssrcLines[0].substring(7).split(' ')[0];
  const trackSsrc = Number(ssrcStr);
  const ownerEndpointId = this.signalingLayer.getSSRCOwner(trackSsrc);

  if (isNaN(trackSsrc) || trackSsrc < 0) {
    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__["callErrorHandler"](new Error(`Invalid SSRC: ${ssrcStr} for remote track, msid: ${streamId} media type: ${mediaType}`)); // Abort

    return;
  } else if (!ownerEndpointId) {
    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__["callErrorHandler"](new Error(`No SSRC owner known for: ${trackSsrc} for remote track, msid: ${streamId} media type: ${mediaType}`)); // Abort

    return;
  }

  logger.log(`${this} associated ssrc`, ownerEndpointId, trackSsrc);
  const peerMediaInfo = this.signalingLayer.getPeerMediaInfo(ownerEndpointId, mediaType);

  if (!peerMediaInfo) {
    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__["callErrorHandler"](new Error(`${this}: no peer media info available for ${ownerEndpointId}`));
    return;
  }

  const muted = peerMediaInfo.muted;
  const videoType = peerMediaInfo.videoType; // can be undefined

  this._createRemoteTrack(ownerEndpointId, stream, track, mediaType, videoType, trackSsrc, muted);
}; // FIXME cleanup params

/* eslint-disable max-params */

/**
 * Initializes a new JitsiRemoteTrack instance with the data provided by
 * the signaling layer and SDP.
 *
 * @param {string} ownerEndpointId the owner's endpoint ID (MUC nickname)
 * @param {MediaStream} stream the WebRTC stream instance
 * @param {MediaStreamTrack} track the WebRTC track instance
 * @param {MediaType} mediaType the track's type of the media
 * @param {VideoType} [videoType] the track's type of the video (if applicable)
 * @param {number} ssrc the track's main SSRC number
 * @param {boolean} muted the initial muted status
 */


TraceablePeerConnection.prototype._createRemoteTrack = function (ownerEndpointId, stream, track, mediaType, videoType, ssrc, muted) {
  let remoteTracksMap = this.remoteTracks.get(ownerEndpointId);

  if (!remoteTracksMap) {
    remoteTracksMap = new Map();
    this.remoteTracks.set(ownerEndpointId, remoteTracksMap);
  }

  const existingTrack = remoteTracksMap.get(mediaType);

  if (existingTrack && existingTrack.getTrack() === track) {
    // Ignore duplicated event which can originate either from
    // 'onStreamAdded' or 'onTrackAdded'.
    logger.info(`${this} ignored duplicated remote track added event for: ` + `${ownerEndpointId}, ${mediaType}`);
    return;
  } else if (existingTrack) {
    logger.error(`${this} overwriting remote track for` + `${ownerEndpointId} ${mediaType}`);
  }

  const remoteTrack = new _JitsiRemoteTrack__WEBPACK_IMPORTED_MODULE_4__["default"](this.rtc, this.rtc.conference, ownerEndpointId, stream, track, mediaType, videoType, ssrc, muted, this.isP2P);
  remoteTracksMap.set(mediaType, remoteTrack);
  this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.REMOTE_TRACK_ADDED, remoteTrack);
};
/* eslint-enable max-params */

/**
 * Handles remote stream removal.
 * @param stream the WebRTC MediaStream object which is being removed from the
 * PeerConnection
 */


TraceablePeerConnection.prototype._remoteStreamRemoved = function (stream) {
  if (!_RTC__WEBPACK_IMPORTED_MODULE_7__["default"].isUserStream(stream)) {
    const id = _RTC__WEBPACK_IMPORTED_MODULE_7__["default"].getStreamID(stream);
    logger.info(`Ignored remote 'stream removed' event for non-user stream ${id}`);
    return;
  } // Call remoteTrackRemoved for each track in the stream


  const streamVideoTracks = stream.getVideoTracks();

  for (const videoTrack of streamVideoTracks) {
    this._remoteTrackRemoved(stream, videoTrack);
  }

  const streamAudioTracks = stream.getAudioTracks();

  for (const audioTrack of streamAudioTracks) {
    this._remoteTrackRemoved(stream, audioTrack);
  }
};
/**
 * Handles remote media track removal.
 * @param {MediaStream} stream WebRTC MediaStream instance which is the parent
 * of the track.
 * @param {MediaStreamTrack} track the WebRTC MediaStreamTrack which has been
 * removed from the PeerConnection.
 */


TraceablePeerConnection.prototype._remoteTrackRemoved = function (stream, track) {
  const streamId = _RTC__WEBPACK_IMPORTED_MODULE_7__["default"].getStreamID(stream);
  const trackId = track && _RTC__WEBPACK_IMPORTED_MODULE_7__["default"].getTrackID(track);
  logger.info(`${this} - remote track removed: ${streamId}, ${trackId}`);

  if (!streamId) {
    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__["callErrorHandler"](new Error(`${this} remote track removal failed - no stream ID`));
    return;
  }

  if (!trackId) {
    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_3__["callErrorHandler"](new Error(`${this} remote track removal failed - no track ID`));
    return;
  }

  if (!this._removeRemoteTrackById(streamId, trackId)) {
    // NOTE this warning is always printed when user leaves the room,
    // because we remove remote tracks manually on MUC member left event,
    // before the SSRCs are removed by Jicofo. In most cases it is fine to
    // ignore this warning, but still it's better to keep it printed for
    // debugging purposes.
    //
    // We could change the behaviour to emit track removed only from here,
    // but the order of the events will change and consuming apps could
    // behave unexpectedly (the "user left" event would come before "track
    // removed" events).
    logger.warn(`${this} Removed track not found for msid: ${streamId},
             track id: ${trackId}`);
  }
};
/**
 * Finds remote track by it's stream and track ids.
 * @param {string} streamId the media stream id as defined by the WebRTC
 * @param {string} trackId the media track id as defined by the WebRTC
 * @return {JitsiRemoteTrack|undefined} the track's instance or
 * <tt>undefined</tt> if not found.
 * @private
 */


TraceablePeerConnection.prototype._getRemoteTrackById = function (streamId, trackId) {
  // .find will break the loop once the first match is found
  for (const endpointTrackMap of this.remoteTracks.values()) {
    for (const mediaTrack of endpointTrackMap.values()) {
      // FIXME verify and try to use ===

      /* eslint-disable eqeqeq */
      if (mediaTrack.getStreamId() == streamId && mediaTrack.getTrackId() == trackId) {
        return mediaTrack;
      }
      /* eslint-enable eqeqeq */

    }
  }

  return undefined;
};
/**
 * Removes all JitsiRemoteTracks associated with given MUC nickname
 * (resource part of the JID). Returns array of removed tracks.
 *
 * @param {string} owner - The resource part of the MUC JID.
 * @returns {JitsiRemoteTrack[]}
 */


TraceablePeerConnection.prototype.removeRemoteTracks = function (owner) {
  const removedTracks = [];
  const remoteTracksMap = this.remoteTracks.get(owner);

  if (remoteTracksMap) {
    const removedAudioTrack = remoteTracksMap.get(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["AUDIO"]);
    const removedVideoTrack = remoteTracksMap.get(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]);
    removedAudioTrack && removedTracks.push(removedAudioTrack);
    removedVideoTrack && removedTracks.push(removedVideoTrack);
    this.remoteTracks.delete(owner);
  }

  logger.debug(`${this} removed remote tracks for ${owner} count: ${removedTracks.length}`);
  return removedTracks;
};
/**
 * Removes and disposes given <tt>JitsiRemoteTrack</tt> instance. Emits
 * {@link RTCEvents.REMOTE_TRACK_REMOVED}.
 * @param {JitsiRemoteTrack} toBeRemoved
 */


TraceablePeerConnection.prototype._removeRemoteTrack = function (toBeRemoved) {
  toBeRemoved.dispose();
  const participantId = toBeRemoved.getParticipantId();
  const remoteTracksMap = this.remoteTracks.get(participantId);

  if (!remoteTracksMap) {
    logger.error(`removeRemoteTrack: no remote tracks map for ${participantId}`);
  } else if (!remoteTracksMap.delete(toBeRemoved.getType())) {
    logger.error(`Failed to remove ${toBeRemoved} - type mapping messed up ?`);
  }

  this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.REMOTE_TRACK_REMOVED, toBeRemoved);
};
/**
 * Removes and disposes <tt>JitsiRemoteTrack</tt> identified by given stream and
 * track ids.
 *
 * @param {string} streamId the media stream id as defined by the WebRTC
 * @param {string} trackId the media track id as defined by the WebRTC
 * @returns {JitsiRemoteTrack|undefined} the track which has been removed or
 * <tt>undefined</tt> if no track matching given stream and track ids was
 * found.
 */


TraceablePeerConnection.prototype._removeRemoteTrackById = function (streamId, trackId) {
  const toBeRemoved = this._getRemoteTrackById(streamId, trackId);

  if (toBeRemoved) {
    this._removeRemoteTrack(toBeRemoved);
  }

  return toBeRemoved;
};
/**
 * @typedef {Object} SSRCGroupInfo
 * @property {Array<number>} ssrcs group's SSRCs
 * @property {string} semantics
 */

/**
 * @typedef {Object} TrackSSRCInfo
 * @property {Array<number>} ssrcs track's SSRCs
 * @property {Array<SSRCGroupInfo>} groups track's SSRC groups
 */

/**
 * Returns map with keys msid and <tt>TrackSSRCInfo</tt> values.
 * @param {Object} desc the WebRTC SDP instance.
 * @return {Map<string,TrackSSRCInfo>}
 */


function extractSSRCMap(desc) {
  /**
   * Track SSRC infos mapped by stream ID (msid)
   * @type {Map<string,TrackSSRCInfo>}
   */
  const ssrcMap = new Map();
  /**
   * Groups mapped by primary SSRC number
   * @type {Map<number,Array<SSRCGroupInfo>>}
   */

  const groupsMap = new Map();

  if (typeof desc !== 'object' || desc === null || typeof desc.sdp !== 'string') {
    logger.warn('An empty description was passed as an argument.');
    return ssrcMap;
  }

  const session = sdp_transform__WEBPACK_IMPORTED_MODULE_2___default.a.parse(desc.sdp);

  if (!Array.isArray(session.media)) {
    return ssrcMap;
  }

  for (const mLine of session.media) {
    if (!Array.isArray(mLine.ssrcs)) {
      continue; // eslint-disable-line no-continue
    }

    if (Array.isArray(mLine.ssrcGroups)) {
      for (const group of mLine.ssrcGroups) {
        if (typeof group.semantics !== 'undefined' && typeof group.ssrcs !== 'undefined') {
          // Parse SSRCs and store as numbers
          const groupSSRCs = group.ssrcs.split(' ').map(ssrcStr => parseInt(ssrcStr, 10));
          const primarySSRC = groupSSRCs[0]; // Note that group.semantics is already present

          group.ssrcs = groupSSRCs; // eslint-disable-next-line max-depth

          if (!groupsMap.has(primarySSRC)) {
            groupsMap.set(primarySSRC, []);
          }

          groupsMap.get(primarySSRC).push(group);
        }
      }
    }

    for (const ssrc of mLine.ssrcs) {
      if (ssrc.attribute !== 'msid') {
        continue; // eslint-disable-line no-continue
      }

      const msid = ssrc.value;
      let ssrcInfo = ssrcMap.get(msid);

      if (!ssrcInfo) {
        ssrcInfo = {
          ssrcs: [],
          groups: [],
          msid
        };
        ssrcMap.set(msid, ssrcInfo);
      }

      const ssrcNumber = ssrc.id;
      ssrcInfo.ssrcs.push(ssrcNumber);

      if (groupsMap.has(ssrcNumber)) {
        const ssrcGroups = groupsMap.get(ssrcNumber);

        for (const group of ssrcGroups) {
          ssrcInfo.groups.push(group);
        }
      }
    }
  }

  return ssrcMap;
}
/**
 * Takes a SessionDescription object and returns a "normalized" version.
 * Currently it takes care of ordering the a=ssrc lines and denoting receive
 * only SSRCs.
 */


const normalizePlanB = function (desc) {
  if (typeof desc !== 'object' || desc === null || typeof desc.sdp !== 'string') {
    logger.warn('An empty description was passed as an argument.');
    return desc;
  } // eslint-disable-next-line no-shadow


  const transform = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");

  const session = transform.parse(desc.sdp);

  if (typeof session !== 'undefined' && typeof session.media !== 'undefined' && Array.isArray(session.media)) {
    session.media.forEach(mLine => {
      // Chrome appears to be picky about the order in which a=ssrc lines
      // are listed in an m-line when rtx is enabled (and thus there are
      // a=ssrc-group lines with FID semantics). Specifically if we have
      // "a=ssrc-group:FID S1 S2" and the "a=ssrc:S2" lines appear before
      // the "a=ssrc:S1" lines, SRD fails.
      // So, put SSRC which appear as the first SSRC in an FID ssrc-group
      // first.
      const firstSsrcs = [];
      const newSsrcLines = [];

      if (typeof mLine.ssrcGroups !== 'undefined' && Array.isArray(mLine.ssrcGroups)) {
        mLine.ssrcGroups.forEach(group => {
          if (typeof group.semantics !== 'undefined' && group.semantics === 'FID') {
            if (typeof group.ssrcs !== 'undefined') {
              firstSsrcs.push(Number(group.ssrcs.split(' ')[0]));
            }
          }
        });
      }

      if (Array.isArray(mLine.ssrcs)) {
        let i;

        for (i = 0; i < mLine.ssrcs.length; i++) {
          if (typeof mLine.ssrcs[i] === 'object' && typeof mLine.ssrcs[i].id !== 'undefined' && firstSsrcs.indexOf(mLine.ssrcs[i].id) >= 0) {
            newSsrcLines.push(mLine.ssrcs[i]);
            delete mLine.ssrcs[i];
          }
        }

        for (i = 0; i < mLine.ssrcs.length; i++) {
          if (typeof mLine.ssrcs[i] !== 'undefined') {
            newSsrcLines.push(mLine.ssrcs[i]);
          }
        }

        mLine.ssrcs = replaceDefaultUnifiedPlanMsid(newSsrcLines);
      }
    });
  }

  const resStr = transform.write(session);
  return new RTCSessionDescription({
    type: desc.type,
    sdp: resStr
  });
};
/**
 * Unified plan differentiates a remote track not associated with a stream using
 * the msid "-", which can incorrectly trigger an onaddstream event in plan-b.
 * For jitsi, these tracks are actually receive-only ssrcs. To prevent
 * onaddstream from firing, remove the ssrcs with msid "-" except the cname
 * line. Normally the ssrcs are not used by the client, as the bridge controls
 * media flow, but keep one reference to the ssrc for the p2p case.
 *
 * @param {Array<Object>} ssrcLines - The ssrc lines from a remote description.
 * @private
 * @returns {Array<Object>} ssrcLines with removed lines referencing msid "-".
 */


function replaceDefaultUnifiedPlanMsid(ssrcLines = []) {
  if (!_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isChrome() || !_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isVersionGreaterThan(70)) {
    return ssrcLines;
  }

  let filteredLines = [...ssrcLines];
  const problematicSsrcIds = ssrcLines.filter(ssrcLine => ssrcLine.attribute === 'mslabel' && ssrcLine.value === '-').map(ssrcLine => ssrcLine.id);
  problematicSsrcIds.forEach(ssrcId => {
    // Find the cname which is to be modified and left in.
    const cnameLine = filteredLines.find(line => line.id === ssrcId && line.attribute === 'cname');
    cnameLine.value = `recvonly-${ssrcId}`; // Remove all of lines for the ssrc.

    filteredLines = filteredLines.filter(line => line.id !== ssrcId); // But re-add the cname line so there is a reference kept to the ssrc
    // in the SDP.

    filteredLines.push(cnameLine);
  });
  return filteredLines;
}
/**
 * Makes sure that both audio and video directions are configured as 'sendrecv'.
 * @param {Object} localDescription the SDP object as defined by WebRTC.
 * @param {object} options <tt>TracablePeerConnection</tt> config options.
 */


const enforceSendRecv = function (localDescription, options) {
  if (!localDescription) {
    throw new Error('No local description passed in.');
  }

  const transformer = new _xmpp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_15__["SdpTransformWrap"](localDescription.sdp);
  const audioMedia = transformer.selectMedia('audio');
  let changed = false;

  if (audioMedia && audioMedia.direction !== 'sendrecv') {
    if (options.startSilent) {
      audioMedia.direction = 'inactive';
    } else {
      audioMedia.direction = 'sendrecv';
    }

    changed = true;
  }

  const videoMedia = transformer.selectMedia('video');

  if (videoMedia && videoMedia.direction !== 'sendrecv') {
    videoMedia.direction = 'sendrecv';
    changed = true;
  }

  if (changed) {
    return new RTCSessionDescription({
      type: localDescription.type,
      sdp: transformer.toRawSDP()
    });
  }

  return localDescription;
};
/**
 *
 * @param {JitsiLocalTrack} localTrack
 */


TraceablePeerConnection.prototype.getLocalSSRC = function (localTrack) {
  const ssrcInfo = this._getSSRC(localTrack.rtcId);

  return ssrcInfo && ssrcInfo.ssrcs[0];
};
/**
 * When doing unified plan simulcast, we'll have a set of ssrcs with the
 * same msid but no ssrc-group, since unified plan signals the simulcast
 * group via the a=simulcast line.  Unfortunately, Jicofo will complain
 * if it sees ssrcs with matching msids but no ssrc-group, so we'll inject
 * an ssrc-group line to make Jicofo happy.
 * NOTE: unlike plan B simulcast, the ssrcs in this inject ssrc-group will
 * NOT necessarily be in order of quality (low to high) because:
 * a) when translating between unified plan and plan b the order of the ssrcs
 * is not preserved and
 * b) it isn't guaranteed that firefox will give them to us in order to begin
 * with
 * @param desc A session description object (with 'type' and 'sdp' fields)
 * @return A session description object with its sdp field modified to
 * contain an inject ssrc-group for simulcast
 */


TraceablePeerConnection.prototype._injectSsrcGroupForUnifiedSimulcast = function (desc) {
  const sdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2___default.a.parse(desc.sdp);
  const video = sdp.media.find(mline => mline.type === 'video');

  if (video.simulcast || video.simulcast_03) {
    const ssrcs = [];
    video.ssrcs.forEach(ssrc => {
      if (ssrc.attribute === 'msid') {
        ssrcs.push(ssrc.id);
      }
    });
    video.ssrcGroups = video.ssrcGroups || [];

    if (video.ssrcGroups.find(group => group.semantics === 'SIM')) {
      // Group already exists, no need to do anything
      return desc;
    }

    video.ssrcGroups.push({
      semantics: 'SIM',
      ssrcs: ssrcs.join(' ')
    });
  }

  return new RTCSessionDescription({
    type: desc.type,
    sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_2___default.a.write(sdp)
  });
};
/* eslint-disable-next-line vars-on-top */


const getters = {
  signalingState() {
    return this.peerconnection.signalingState;
  },

  iceConnectionState() {
    return this.peerconnection.iceConnectionState;
  },

  localDescription() {
    let desc = this.peerconnection.localDescription;

    if (!desc) {
      logger.debug('getLocalDescription no localDescription found');
      return {};
    }

    this.trace('getLocalDescription::preTransform', dumpSDP(desc)); // if we're running on FF, transform to Plan B first.

    if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()) {
      desc = this.interop.toPlanB(desc);
      this.trace('getLocalDescription::postTransform (Plan B)', dumpSDP(desc));
      desc = this._injectSsrcGroupForUnifiedSimulcast(desc);
      this.trace('getLocalDescription::postTransform (inject ssrc group)', dumpSDP(desc));
    } else {
      if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].doesVideoMuteByStreamRemove()) {
        desc = this.localSdpMunger.maybeAddMutedLocalVideoTracksToSDP(desc);
        logger.debug('getLocalDescription::postTransform (munge local SDP)', desc);
      } // What comes out of this getter will be signalled over Jingle to
      // the other peer, so we need to make sure the media direction is
      // 'sendrecv' because we won't change the direction later and don't want
      // the other peer to think we can't send or receive.
      //
      // Note that the description we set in chrome does have the accurate
      // direction (e.g. 'recvonly'), since that is technically what is
      // happening (check setLocalDescription impl).


      desc = enforceSendRecv(desc, this.options);
    } // See the method's doc for more info about this transformation.


    desc = this.localSdpMunger.transformStreamIdentifiers(desc);
    return desc;
  },

  remoteDescription() {
    let desc = this.peerconnection.remoteDescription;

    if (!desc) {
      logger.debug('getRemoteDescription no remoteDescription found');
      return {};
    }

    this.trace('getRemoteDescription::preTransform', dumpSDP(desc)); // if we're running on FF, transform to Plan B first.

    if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()) {
      desc = this.interop.toPlanB(desc);
      this.trace('getRemoteDescription::postTransform (Plan B)', dumpSDP(desc));
    }

    return desc;
  }

};
Object.keys(getters).forEach(prop => {
  Object.defineProperty(TraceablePeerConnection.prototype, prop, {
    get: getters[prop]
  });
});

TraceablePeerConnection.prototype._getSSRC = function (rtcId) {
  return this.localSSRCs.get(rtcId);
};
/**
 * Add {@link JitsiLocalTrack} to this TPC.
 * @param {JitsiLocalTrack} track
 */


TraceablePeerConnection.prototype.addTrack = function (track, isInitiator = false) {
  const rtcId = track.rtcId;
  logger.info(`add ${track} to: ${this}`);

  if (this.localTracks.has(rtcId)) {
    logger.error(`${track} is already in ${this}`);
    return;
  }

  this.localTracks.set(rtcId, track);

  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan() && isInitiator) {
    return this.tpcUtils.addTrack(track, isInitiator);
  }

  const webrtcStream = track.getOriginalStream();

  if (webrtcStream) {
    this._addStream(webrtcStream); // It's not ok for a track to not have a WebRTC stream if:

  } else if (!_browser__WEBPACK_IMPORTED_MODULE_9__["default"].doesVideoMuteByStreamRemove() || track.isAudioTrack() || track.isVideoTrack() && !track.isMuted()) {
    logger.error(`${this} no WebRTC stream for: ${track}`);
  } // Muted video tracks do not have WebRTC stream


  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesPlanB() && _browser__WEBPACK_IMPORTED_MODULE_9__["default"].doesVideoMuteByStreamRemove() && track.isVideoTrack() && track.isMuted()) {
    const ssrcInfo = this.generateNewStreamSSRCInfo(track);
    this.sdpConsistency.setPrimarySsrc(ssrcInfo.ssrcs[0]);
    const simGroup = ssrcInfo.groups.find(groupInfo => groupInfo.semantics === 'SIM');

    if (simGroup) {
      this.simulcast.setSsrcCache(simGroup.ssrcs);
    }

    const fidGroups = ssrcInfo.groups.filter(groupInfo => groupInfo.semantics === 'FID');

    if (fidGroups) {
      const rtxSsrcMapping = new Map();
      fidGroups.forEach(fidGroup => {
        const primarySsrc = fidGroup.ssrcs[0];
        const rtxSsrc = fidGroup.ssrcs[1];
        rtxSsrcMapping.set(primarySsrc, rtxSsrc);
      });
      this.rtxModifier.setSsrcCache(rtxSsrcMapping);
    }
  }

  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan() && !_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesSdpMungingForSimulcast()) {
    this.tpcUtils.setEncodings(track);
  }
};
/**
 * Adds local track as part of the unmute operation.
 * @param {JitsiLocalTrack} track the track to be added as part of the unmute
 * operation
 * @return {Promise<boolean>} Promise that resolves to true if the underlying PeerConnection's
 * state has changed and renegotiation is required, false if no renegotiation is needed or
 * Promise is rejected when something goes wrong.
 */


TraceablePeerConnection.prototype.addTrackUnmute = function (track) {
  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()) {
    return this.tpcUtils.addTrackUnmute(track);
  }

  if (!this._assertTrackBelongs('addTrackUnmute', track)) {
    // Abort
    return Promise.reject('Track not found on the peerconnection');
  }

  logger.info(`Adding ${track} as unmute to ${this}`);
  const webRtcStream = track.getOriginalStream();

  if (!webRtcStream) {
    logger.error(`Unable to add ${track} as unmute to ${this} - no WebRTC stream`);
    return Promise.reject('Stream not found');
  }

  this._addStream(webRtcStream);

  return Promise.resolve(true);
};
/**
 * Adds WebRTC media stream to the underlying PeerConnection
 * @param {MediaStream} mediaStream
 * @private
 */


TraceablePeerConnection.prototype._addStream = function (mediaStream) {
  this.peerconnection.addStream(mediaStream);

  this._addedStreams.push(mediaStream);
};
/**
 * Removes WebRTC media stream from the underlying PeerConection
 * @param {MediaStream} mediaStream
 */


TraceablePeerConnection.prototype._removeStream = function (mediaStream) {
  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].supportsRtpSender()) {
    this._handleSenderRemoveStream(mediaStream);
  } else {
    this.peerconnection.removeStream(mediaStream);
  }

  this._addedStreams = this._addedStreams.filter(stream => stream !== mediaStream);
};
/**
 * This method when called will check if given <tt>localTrack</tt> belongs to
 * this TPC (that it has been previously added using {@link addTrack}). If the
 * track does not belong an error message will be logged.
 * @param {string} methodName the method name that will be logged in an error
 * message
 * @param {JitsiLocalTrack} localTrack
 * @return {boolean} <tt>true</tt> if given local track belongs to this TPC or
 * <tt>false</tt> otherwise.
 * @private
 */


TraceablePeerConnection.prototype._assertTrackBelongs = function (methodName, localTrack) {
  const doesBelong = this.localTracks.has(localTrack.rtcId);

  if (!doesBelong) {
    logger.error(`${methodName}: ${localTrack} does not belong to ${this}`);
  }

  return doesBelong;
};
/**
 * Tells if the given WebRTC <tt>MediaStream</tt> has been added to
 * the underlying WebRTC PeerConnection.
 * @param {MediaStream} mediaStream
 * @returns {boolean}
 */


TraceablePeerConnection.prototype.isMediaStreamInPc = function (mediaStream) {
  return this._addedStreams.indexOf(mediaStream) > -1;
};
/**
 * Remove local track from this TPC.
 * @param {JitsiLocalTrack} localTrack the track to be removed from this TPC.
 *
 * FIXME It should probably remove a boolean just like {@link removeTrackMute}
 *       The same applies to addTrack.
 */


TraceablePeerConnection.prototype.removeTrack = function (localTrack) {
  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()) {
    return this.tpcUtils.removeTrack(localTrack);
  }

  const webRtcStream = localTrack.getOriginalStream();
  this.trace('removeStream', localTrack.rtcId, webRtcStream ? webRtcStream.id : undefined);

  if (!this._assertTrackBelongs('removeStream', localTrack)) {
    // Abort - nothing to be done here
    return;
  }

  this.localTracks.delete(localTrack.rtcId);
  this.localSSRCs.delete(localTrack.rtcId);

  if (webRtcStream) {
    if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].supportsRtpSender()) {
      this._handleSenderRemoveStream(webRtcStream);
    } else {
      this.peerconnection.removeStream(webRtcStream);
    }
  }
};
/**
 * Returns the sender corresponding to the given media type.
 * @param {MEDIA_TYPE} mediaType - The media type 'audio' or 'video' to be used for the search.
 * @returns {RTPSender|undefined} - The found sender or undefined if no sender
 * was found.
 */


TraceablePeerConnection.prototype.findSenderByKind = function (mediaType) {
  return this.peerconnection.getSenders().find(s => s.track && s.track.kind === mediaType);
};
/**
 * Returns the sender corresponding to the given MediaStream.
 *
 * @param {MediaStream} stream - The media stream used for the search.
 * @returns {RTPSender|undefined} - The found sender or undefined if no sender
 * was found.
 */


TraceablePeerConnection.prototype.findSenderByStream = function (stream) {
  const track = stream.getTracks()[0];

  if (!track) {
    logger.error('Cannot find sender: no tracks.');
    return;
  } // Find the right sender (for audio or video)


  return this.peerconnection.getSenders().find(s => s.track === track);
};
/**
 * Returns the receiver corresponding to the given MediaStreamTrack.
 *
 * @param {MediaSreamTrack} track - The media stream track used for the search.
 * @returns {RTCRtpReceiver|undefined} - The found receiver or undefined if no receiver
 * was found.
 */


TraceablePeerConnection.prototype.findReceiverForTrack = function (track) {
  return this.peerconnection.getReceivers().find(r => r.track === track);
};
/**
 * Returns the sender corresponding to the given MediaStreamTrack.
 *
 * @param {MediaSreamTrack} track - The media stream track used for the search.
 * @returns {RTCRtpSender|undefined} - The found sender or undefined if no sender
 * was found.
 */


TraceablePeerConnection.prototype.findSenderForTrack = function (track) {
  return this.peerconnection.getSenders().find(s => s.track === track);
};
/**
 * Replaces <tt>oldTrack</tt> with <tt>newTrack</tt> from the peer connection.
 * Either <tt>oldTrack</tt> or <tt>newTrack</tt> can be null; replacing a valid
 * <tt>oldTrack</tt> with a null <tt>newTrack</tt> effectively just removes
 * <tt>oldTrack</tt>
 *
 * @param {JitsiLocalTrack|null} oldTrack - The current track in use to be
 * replaced
 * @param {JitsiLocalTrack|null} newTrack - The new track to use
 * @returns {Promise<boolean>} - If the promise resolves with true,
 * renegotiation will be needed. Otherwise no renegotiation is needed.
 */


TraceablePeerConnection.prototype.replaceTrack = function (oldTrack, newTrack) {
  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()) {
    return this.tpcUtils.replaceTrack(oldTrack, newTrack);
  }

  if (oldTrack) {
    this.removeTrack(oldTrack);
  }

  if (newTrack) {
    this.addTrack(newTrack);
  }

  return Promise.resolve(true);
};
/**
 * Removes local track as part of the mute operation.
 * @param {JitsiLocalTrack} localTrack the local track to be remove as part of
 * the mute operation.
 * @return {Promise<boolean>} Promise that resolves to true if the underlying PeerConnection's
 * state has changed and renegotiation is required, false if no renegotiation is needed or
 * Promise is rejected when something goes wrong.
 */


TraceablePeerConnection.prototype.removeTrackMute = function (localTrack) {
  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()) {
    return this.tpcUtils.removeTrackMute(localTrack);
  }

  const webRtcStream = localTrack.getOriginalStream();
  this.trace('removeStreamMute', localTrack.rtcId, webRtcStream ? webRtcStream.id : null);

  if (!this._assertTrackBelongs('removeStreamMute', localTrack)) {
    // Abort - nothing to be done here
    return Promise.reject('Track not found in the peerconnection');
  }

  if (webRtcStream) {
    logger.info(`Removing ${localTrack} as mute from ${this}`);

    this._removeStream(webRtcStream);

    return Promise.resolve(true);
  }

  logger.error(`removeStreamMute - no WebRTC stream for ${localTrack}`);
  return Promise.reject('Stream not found');
};
/**
 * Remove stream handling for browsers supporting RTPSender
 * @param stream: webrtc media stream
 */


TraceablePeerConnection.prototype._handleSenderRemoveStream = function (stream) {
  if (!stream) {
    // There is nothing to be changed
    return;
  }

  const sender = this.findSenderByStream(stream);

  if (sender) {
    this.peerconnection.removeTrack(sender);
  } else {
    logger.log('Cannot remove tracks: no RTPSender.');
  }
};

TraceablePeerConnection.prototype.createDataChannel = function (label, opts) {
  this.trace('createDataChannel', label, opts);
  return this.peerconnection.createDataChannel(label, opts);
};
/**
 * Ensures that the simulcast ssrc-group appears after any other ssrc-groups
 * in the SDP so that simulcast is properly activated.
 *
 * @param {Object} localSdp the WebRTC session description instance for
 * the local description.
 * @private
 */


TraceablePeerConnection.prototype._ensureSimulcastGroupIsLast = function (localSdp) {
  let sdpStr = localSdp.sdp;
  const videoStartIndex = sdpStr.indexOf('m=video');
  const simStartIndex = sdpStr.indexOf('a=ssrc-group:SIM', videoStartIndex);
  let otherStartIndex = sdpStr.lastIndexOf('a=ssrc-group');

  if (simStartIndex === -1 || otherStartIndex === -1 || otherStartIndex === simStartIndex) {
    return localSdp;
  }

  const simEndIndex = sdpStr.indexOf('\r\n', simStartIndex);
  const simStr = sdpStr.substring(simStartIndex, simEndIndex + 2);
  sdpStr = sdpStr.replace(simStr, '');
  otherStartIndex = sdpStr.lastIndexOf('a=ssrc-group');
  const otherEndIndex = sdpStr.indexOf('\r\n', otherStartIndex);
  const sdpHead = sdpStr.slice(0, otherEndIndex);
  const simStrTrimmed = simStr.trim();
  const sdpTail = sdpStr.slice(otherEndIndex);
  sdpStr = `${sdpHead}\r\n${simStrTrimmed}${sdpTail}`;
  return new RTCSessionDescription({
    type: localSdp.type,
    sdp: sdpStr
  });
};
/**
 * Will adjust audio and video media direction in the given SDP object to
 * reflect the current status of the {@link audioTransferActive} and
 * {@link videoTransferActive} flags.
 * @param {Object} localDescription the WebRTC session description instance for
 * the local description.
 * @private
 */


TraceablePeerConnection.prototype._adjustLocalMediaDirection = function (localDescription) {
  const transformer = new _xmpp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_15__["SdpTransformWrap"](localDescription.sdp);
  let modifiedDirection = false;
  const audioMedia = transformer.selectMedia('audio');

  if (audioMedia) {
    const desiredAudioDirection = this._getDesiredMediaDirection(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["AUDIO"]);

    if (audioMedia.direction !== desiredAudioDirection) {
      audioMedia.direction = desiredAudioDirection;
      logger.info(`Adjusted local audio direction to ${desiredAudioDirection}`);
      modifiedDirection = true;
    }
  } else {
    logger.warn('No "audio" media found int the local description');
  }

  const videoMedia = transformer.selectMedia('video');

  if (videoMedia) {
    const desiredVideoDirection = this._getDesiredMediaDirection(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]);

    if (videoMedia.direction !== desiredVideoDirection) {
      videoMedia.direction = desiredVideoDirection;
      logger.info(`Adjusted local video direction to ${desiredVideoDirection}`);
      modifiedDirection = true;
    }
  } else {
    logger.warn('No "video" media found in the local description');
  }

  if (modifiedDirection) {
    return new RTCSessionDescription({
      type: localDescription.type,
      sdp: transformer.toRawSDP()
    });
  }

  return localDescription;
};

TraceablePeerConnection.prototype.setLocalDescription = function (description) {
  let localSdp = description;
  this.trace('setLocalDescription::preTransform', dumpSDP(localSdp));

  if (this.options.disableH264 || this.options.preferH264) {
    const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2___default.a.parse(localSdp.sdp);
    const videoMLine = parsedSdp.media.find(m => m.type === 'video');

    if (this.options.disableH264) {
      _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].stripVideoCodec(videoMLine, 'h264');
    } else {
      _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].preferVideoCodec(videoMLine, 'h264');
    }

    localSdp = new RTCSessionDescription({
      type: localSdp.type,
      sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_2___default.a.write(parsedSdp)
    });
    this.trace('setLocalDescription::postTransform (H264)', dumpSDP(localSdp));
  }

  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesPlanB()) {
    localSdp = this._adjustLocalMediaDirection(localSdp);
    localSdp = this._ensureSimulcastGroupIsLast(localSdp);
  } else {
    // if we're using unified plan, transform to it first.
    localSdp = this.interop.toUnifiedPlan(localSdp);
    this.trace('setLocalDescription::postTransform (Unified Plan)', dumpSDP(localSdp));
  }

  return new Promise((resolve, reject) => {
    this.peerconnection.setLocalDescription(localSdp).then(() => {
      this.trace('setLocalDescriptionOnSuccess');
      const localUfrag = _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].getUfrag(localSdp.sdp);

      if (localUfrag !== this.localUfrag) {
        this.localUfrag = localUfrag;
        this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.LOCAL_UFRAG_CHANGED, this, localUfrag);
      }

      resolve();
    }, err => {
      this.trace('setLocalDescriptionOnFailure', err);
      this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.SET_LOCAL_DESCRIPTION_FAILED, err, this);
      reject(err);
    });
  });
};
/**
 * Enables/disables audio media transmission on this peer connection. When
 * disabled the SDP audio media direction in the local SDP will be adjusted to
 * 'inactive' which means that no data will be sent nor accepted, but
 * the connection should be kept alive.
 * @param {boolean} active <tt>true</tt> to enable audio media transmission or
 * <tt>false</tt> to disable. If the value is not a boolean the call will have
 * no effect.
 * @return {boolean} <tt>true</tt> if the value has changed and sRD/sLD cycle
 * needs to be executed in order for the changes to take effect or
 * <tt>false</tt> if the given value was the same as the previous one.
 * @public
 */


TraceablePeerConnection.prototype.setAudioTransferActive = function (active) {
  logger.debug(`${this} audio transfer active: ${active}`);

  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()) {
    return this.tpcUtils.setAudioTransferActive(active);
  }

  const changed = this.audioTransferActive !== active;
  this.audioTransferActive = active;
  return changed;
};
/**
 * Sets the max bitrate on the RTCRtpSender so that the
 * bitrate of the enocder doesn't exceed the configured value.
 * This is needed for the desktop share until spec-complaint
 * simulcast is implemented.
 * @param {JitsiLocalTrack} localTrack - the local track whose
 * max bitrate is to be configured.
 */


TraceablePeerConnection.prototype.setMaxBitRate = function (localTrack) {
  const mediaType = localTrack.type; // No need to set max bitrates on the streams in the following cases.
  // 1. When an audio track has been replaced.
  // 2. When a 'camera' track is replaced in plan-b mode, since its a new sender.
  // 3. When the config.js option for capping the SS bitrate is not enabled.

  if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["AUDIO"] || _browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesPlanB() && !this.options.capScreenshareBitrate || _browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesPlanB() && localTrack.videoType === 'camera') {
    return;
  }

  if (!this.peerconnection.getSenders) {
    logger.debug('Browser doesn\'t support RTCRtpSender');
    return;
  }

  const videoType = localTrack.videoType;
  const trackId = localTrack.track.id;
  this.peerconnection.getSenders().filter(s => s.track && s.track.id === trackId).forEach(sender => {
    try {
      const parameters = sender.getParameters();

      if (!parameters.encodings || !parameters.encodings.length) {
        return;
      }

      logger.debug('Setting max bitrate on video stream');

      for (const encoding in parameters.encodings) {
        if (parameters.encodings.hasOwnProperty(encoding)) {
          parameters.encodings[encoding].maxBitrate = videoType === 'desktop' && _browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesPlanB() ? DESKSTOP_SHARE_RATE // In unified plan, simulcast for SS is on by default.
          // When simulcast is disabled through a config.js option,
          // we cap the bitrate on desktop and camera tracks to 2500 Kbps.
          : this.isSimulcastOn() ? this.tpcUtils.simulcastEncodings[encoding].maxBitrate : MAX_BITRATE;
        }
      }

      sender.setParameters(parameters);
    } catch (err) {
      logger.error('Browser does not support getParameters/setParamters ' + 'or setting max bitrate on the encodings: ', err);
    }
  });
};

TraceablePeerConnection.prototype.setRemoteDescription = function (description) {
  this.trace('setRemoteDescription::preTransform', dumpSDP(description));

  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesPlanB()) {
    // TODO the focus should squeze or explode the remote simulcast
    // eslint-disable-next-line no-param-reassign
    description = this.simulcast.mungeRemoteDescription(description);
    this.trace('setRemoteDescription::postTransform (simulcast)', dumpSDP(description));

    if (this.options.preferH264) {
      const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2___default.a.parse(description.sdp);
      const videoMLine = parsedSdp.media.find(m => m.type === 'video');
      _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].preferVideoCodec(videoMLine, 'h264'); // eslint-disable-next-line no-param-reassign

      description = new RTCSessionDescription({
        type: description.type,
        sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_2___default.a.write(parsedSdp)
      });
    } // eslint-disable-next-line no-param-reassign


    description = normalizePlanB(description);
  } else {
    const currentDescription = this.peerconnection.remoteDescription; // eslint-disable-next-line no-param-reassign

    description = this.interop.toUnifiedPlan(description, currentDescription);
    this.trace('setRemoteDescription::postTransform (Unified)', dumpSDP(description));

    if (this.isSimulcastOn()) {
      // eslint-disable-next-line no-param-reassign
      description = this.simulcast.mungeRemoteDescription(description); // eslint-disable-next-line no-param-reassign

      description = this.tpcUtils._insertUnifiedPlanSimulcastReceive(description);
      this.trace('setRemoteDescription::postTransform (sim receive)', dumpSDP(description)); // eslint-disable-next-line no-param-reassign

      description = this.tpcUtils._ensureCorrectOrderOfSsrcs(description);
    }
  }

  return new Promise((resolve, reject) => {
    this.peerconnection.setRemoteDescription(description).then(() => {
      this.trace('setRemoteDescriptionOnSuccess');
      const remoteUfrag = _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].getUfrag(description.sdp);

      if (remoteUfrag !== this.remoteUfrag) {
        this.remoteUfrag = remoteUfrag;
        this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.REMOTE_UFRAG_CHANGED, this, remoteUfrag);
      }

      resolve();
    }, err => {
      this.trace('setRemoteDescriptionOnFailure', err);
      this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.SET_REMOTE_DESCRIPTION_FAILED, err, this);
      reject(err);
    });
  });
};
/**
 * Enables/disables video media transmission on this peer connection. When
 * disabled the SDP video media direction in the local SDP will be adjusted to
 * 'inactive' which means that no data will be sent nor accepted, but
 * the connection should be kept alive.
 * @param {boolean} active <tt>true</tt> to enable video media transmission or
 * <tt>false</tt> to disable. If the value is not a boolean the call will have
 * no effect.
 * @return {boolean} <tt>true</tt> if the value has changed and sRD/sLD cycle
 * needs to be executed in order for the changes to take effect or
 * <tt>false</tt> if the given value was the same as the previous one.
 * @public
 */


TraceablePeerConnection.prototype.setVideoTransferActive = function (active) {
  logger.debug(`${this} video transfer active: ${active}`);

  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesUnifiedPlan()) {
    return this.tpcUtils.setVideoTransferActive(active);
  }

  const changed = this.videoTransferActive !== active;
  this.videoTransferActive = active;
  return changed;
};
/**
 * Sends DTMF tones if possible.
 *
 * @param {string} tones - The DTMF tones string as defined by {@code RTCDTMFSender.insertDTMF}, 'tones' argument.
 * @param {number} duration - The amount of time in milliseconds that each DTMF should last. It's 200ms by default.
 * @param {number} interToneGap - The length of time in miliseconds to wait between tones. It's 200ms by default.
 *
 * @returns {void}
 */


TraceablePeerConnection.prototype.sendTones = function (tones, duration = 200, interToneGap = 200) {
  if (!this._dtmfSender) {
    if (this.peerconnection.getSenders) {
      const rtpSender = this.peerconnection.getSenders().find(s => s.dtmf);
      this._dtmfSender = rtpSender && rtpSender.dtmf;
      this._dtmfSender && logger.info(`${this} initialized DTMFSender using getSenders`);
    }

    if (!this._dtmfSender) {
      const localAudioTrack = Array.from(this.localTracks.values()).find(t => t.isAudioTrack());

      if (this.peerconnection.createDTMFSender && localAudioTrack) {
        this._dtmfSender = this.peerconnection.createDTMFSender(localAudioTrack.getTrack());
      }

      this._dtmfSender && logger.info(`${this} initialized DTMFSender using deprecated createDTMFSender`);
    }

    if (this._dtmfSender) {
      this._dtmfSender.ontonechange = this._onToneChange.bind(this);
    }
  }

  if (this._dtmfSender) {
    if (this._dtmfSender.toneBuffer) {
      this._dtmfTonesQueue.push({
        tones,
        duration,
        interToneGap
      });

      return;
    }

    this._dtmfSender.insertDTMF(tones, duration, interToneGap);
  } else {
    logger.warn(`${this} sendTones - failed to select DTMFSender`);
  }
};
/**
 * Callback ivoked by {@code this._dtmfSender} when it has finished playing
 * a single tone.
 *
 * @param {Object} event - The tonechange event which indicates what characters
 * are left to be played for the current tone.
 * @private
 * @returns {void}
 */


TraceablePeerConnection.prototype._onToneChange = function (event) {
  // An empty event.tone indicates the current tones have finished playing.
  // Automatically start playing any queued tones on finish.
  if (this._dtmfSender && event.tone === '' && this._dtmfTonesQueue.length) {
    const {
      tones,
      duration,
      interToneGap
    } = this._dtmfTonesQueue.shift();

    this._dtmfSender.insertDTMF(tones, duration, interToneGap);
  }
};
/**
 * Makes the underlying TraceablePeerConnection generate new SSRC for
 * the recvonly video stream.
 */


TraceablePeerConnection.prototype.generateRecvonlySsrc = function () {
  const newSSRC = _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].generateSsrc();
  logger.info(`${this} generated new recvonly SSRC: ${newSSRC}`);
  this.sdpConsistency.setPrimarySsrc(newSSRC);
};
/**
 * Makes the underlying TraceablePeerConnection forget the current primary video
 * SSRC.
 */


TraceablePeerConnection.prototype.clearRecvonlySsrc = function () {
  logger.info('Clearing primary video SSRC!');
  this.sdpConsistency.clearVideoSsrcCache();
};
/**
 * Closes underlying WebRTC PeerConnection instance and removes all remote
 * tracks by emitting {@link RTCEvents.REMOTE_TRACK_REMOVED} for each one of
 * them.
 */


TraceablePeerConnection.prototype.close = function () {
  this.trace('stop'); // Off SignalingEvents

  this.signalingLayer.off(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_17__["PEER_MUTED_CHANGED"], this._peerMutedChanged);
  this.signalingLayer.off(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_17__["PEER_VIDEO_TYPE_CHANGED"], this._peerVideoTypeChanged);

  for (const peerTracks of this.remoteTracks.values()) {
    for (const remoteTrack of peerTracks.values()) {
      this._removeRemoteTrack(remoteTrack);
    }
  }

  this.remoteTracks.clear();
  this._addedStreams = [];
  this._dtmfSender = null;
  this._dtmfTonesQueue = [];

  if (!this.rtc._removePeerConnection(this)) {
    logger.error('RTC._removePeerConnection returned false');
  }

  if (this.statsinterval !== null) {
    window.clearInterval(this.statsinterval);
    this.statsinterval = null;
  }

  logger.info(`Closing ${this}...`);
  this.peerconnection.close();
};
/**
 * Modifies the values of the setup attributes (defined by
 * {@link http://tools.ietf.org/html/rfc4145#section-4}) of a specific SDP
 * answer in order to overcome a delay of 1 second in the connection
 * establishment between some devices and Videobridge.
 *
 * @param {SDP} offer - the SDP offer to which the specified SDP answer is
 * being prepared to respond
 * @param {SDP} answer - the SDP to modify
 * @private
 */


const _fixAnswerRFC4145Setup = function (offer, answer) {
  if (!(_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isChromiumBased() || _browser__WEBPACK_IMPORTED_MODULE_9__["default"].isReactNative())) {
    // It looks like Firefox doesn't agree with the fix (at least in its
    // current implementation) because it effectively remains active even
    // after we tell it to become passive. Apart from Firefox which I tested
    // after the fix was deployed, I tested Chrome only. In order to prevent
    // issues with other browsers, limit the fix to known devices for the
    // time being.
    return;
  } // XXX Videobridge is the (SDP) offerer and WebRTC (e.g. Chrome) is the
  // answerer (as orchestrated by Jicofo). In accord with
  // http://tools.ietf.org/html/rfc5245#section-5.2 and because both peers
  // are ICE FULL agents, Videobridge will take on the controlling role and
  // WebRTC will take on the controlled role. In accord with
  // https://tools.ietf.org/html/rfc5763#section-5, Videobridge will use the
  // setup attribute value of setup:actpass and WebRTC will be allowed to
  // choose either the setup attribute value of setup:active or
  // setup:passive. Chrome will by default choose setup:active because it is
  // RECOMMENDED by the respective RFC since setup:passive adds additional
  // latency. The case of setup:active allows WebRTC to send a DTLS
  // ClientHello as soon as an ICE connectivity check of its succeeds.
  // Unfortunately, Videobridge will be unable to respond immediately because
  // may not have WebRTC's answer or may have not completed the ICE
  // connectivity establishment. Even more unfortunate is that in the
  // described scenario Chrome's DTLS implementation will insist on
  // retransmitting its ClientHello after a second (the time is in accord
  // with the respective RFC) and will thus cause the whole connection
  // establishment to exceed at least 1 second. To work around Chrome's
  // idiosyncracy, don't allow it to send a ClientHello i.e. change its
  // default choice of setup:active to setup:passive.


  if (offer && answer && offer.media && answer.media && offer.media.length === answer.media.length) {
    answer.media.forEach((a, i) => {
      if (_xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLine(offer.media[i], 'a=setup:actpass', offer.session)) {
        answer.media[i] = a.replace(/a=setup:active/g, 'a=setup:passive');
      }
    });
    answer.raw = answer.session + answer.media.join('');
  }
};

TraceablePeerConnection.prototype.createAnswer = function (constraints) {
  return this._createOfferOrAnswer(false
  /* answer */
  , constraints);
};

TraceablePeerConnection.prototype.createOffer = function (constraints) {
  return this._createOfferOrAnswer(true
  /* offer */
  , constraints);
};
/**
 * Checks if a camera track has been added to the peerconnection
 * @param {TraceablePeerConnection} peerConnection
 * @return {boolean} <tt>true</tt> if the peerconnection has
 * a camera track for its video source <tt>false</tt> otherwise.
 */


function hasCameraTrack(peerConnection) {
  return peerConnection.getLocalTracks().some(t => t.videoType === 'camera');
}

TraceablePeerConnection.prototype._createOfferOrAnswer = function (isOffer, constraints) {
  const logName = isOffer ? 'Offer' : 'Answer';
  this.trace(`create${logName}`, JSON.stringify(constraints, null, ' '));

  const handleSuccess = (resultSdp, resolveFn, rejectFn) => {
    try {
      this.trace(`create${logName}OnSuccess::preTransform`, dumpSDP(resultSdp));

      if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesPlanB()) {
        // If there are no local video tracks, then a "recvonly"
        // SSRC needs to be generated
        if (!this.hasAnyTracksOfType(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]) && !this.sdpConsistency.hasPrimarySsrcCached()) {
          this.generateRecvonlySsrc();
        } // eslint-disable-next-line no-param-reassign


        resultSdp = new RTCSessionDescription({
          type: resultSdp.type,
          sdp: this.sdpConsistency.makeVideoPrimarySsrcsConsistent(resultSdp.sdp)
        });
        this.trace(`create${logName}OnSuccess::postTransform ` + '(make primary audio/video ssrcs consistent)', dumpSDP(resultSdp));
      } // configure simulcast for camera tracks always and for
      // desktop tracks only when the testing flag for maxbitrates
      // in config.js is disabled.


      if (this.isSimulcastOn() && _browser__WEBPACK_IMPORTED_MODULE_9__["default"].usesSdpMungingForSimulcast() && (!this.options.capScreenshareBitrate || this.options.capScreenshareBitrate && hasCameraTrack(this))) {
        // eslint-disable-next-line no-param-reassign
        resultSdp = this.simulcast.mungeLocalDescription(resultSdp);
        this.trace(`create${logName}` + 'OnSuccess::postTransform (simulcast)', dumpSDP(resultSdp));
      }

      if (!this.options.disableRtx && _browser__WEBPACK_IMPORTED_MODULE_9__["default"].supportsRtx()) {
        // eslint-disable-next-line no-param-reassign
        resultSdp = new RTCSessionDescription({
          type: resultSdp.type,
          sdp: this.rtxModifier.modifyRtxSsrcs(resultSdp.sdp)
        });
        this.trace(`create${logName}` + 'OnSuccess::postTransform (rtx modifier)', dumpSDP(resultSdp));
      } // Fix the setup attribute (see _fixAnswerRFC4145Setup for
      //  details)


      if (!isOffer) {
        const remoteDescription = new _xmpp_SDP__WEBPACK_IMPORTED_MODULE_13__["default"](this.remoteDescription.sdp);
        const localDescription = new _xmpp_SDP__WEBPACK_IMPORTED_MODULE_13__["default"](resultSdp.sdp);

        _fixAnswerRFC4145Setup(remoteDescription, localDescription); // eslint-disable-next-line no-param-reassign


        resultSdp = new RTCSessionDescription({
          type: resultSdp.type,
          sdp: localDescription.raw
        });
      }

      const ssrcMap = extractSSRCMap(resultSdp);
      logger.debug('Got local SSRCs MAP: ', ssrcMap);

      this._processLocalSSRCsMap(ssrcMap);

      resolveFn(resultSdp);
    } catch (e) {
      this.trace(`create${logName}OnError`, e);
      this.trace(`create${logName}OnError`, dumpSDP(resultSdp));
      logger.error(`create${logName}OnError`, e, dumpSDP(resultSdp));
      rejectFn(e);
    }
  };

  const handleFailure = (err, rejectFn) => {
    this.trace(`create${logName}OnFailure`, err);
    const eventType = isOffer ? _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.CREATE_OFFER_FAILED : _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.CREATE_ANSWER_FAILED;
    this.eventEmitter.emit(eventType, err, this);
    rejectFn(err);
  };

  return new Promise((resolve, reject) => {
    let oaPromise;

    if (isOffer) {
      oaPromise = this.peerconnection.createOffer(constraints);
    } else {
      oaPromise = this.peerconnection.createAnswer(constraints);
    }

    oaPromise.then(sdp => handleSuccess(sdp, resolve, reject), error => handleFailure(error, reject));
  });
};
/**
 * Extract primary SSRC from given {@link TrackSSRCInfo} object.
 * @param {TrackSSRCInfo} ssrcObj
 * @return {number|null} the primary SSRC or <tt>null</tt>
 */


TraceablePeerConnection.prototype._extractPrimarySSRC = function (ssrcObj) {
  if (ssrcObj && ssrcObj.groups && ssrcObj.groups.length) {
    return ssrcObj.groups[0].ssrcs[0];
  } else if (ssrcObj && ssrcObj.ssrcs && ssrcObj.ssrcs.length) {
    return ssrcObj.ssrcs[0];
  }

  return null;
};
/**
 * Goes over the SSRC map extracted from the latest local description and tries
 * to match them with the local tracks (by MSID). Will update the values
 * currently stored in the {@link TraceablePeerConnection.localSSRCs} map.
 * @param {Map<string,TrackSSRCInfo>} ssrcMap
 * @private
 */


TraceablePeerConnection.prototype._processLocalSSRCsMap = function (ssrcMap) {
  for (const track of this.localTracks.values()) {
    const trackMSID = track.storedMSID;

    if (ssrcMap.has(trackMSID)) {
      const newSSRC = ssrcMap.get(trackMSID);

      if (!newSSRC) {
        logger.error(`No SSRC found for: ${trackMSID} in ${this}`);
        return;
      }

      const oldSSRC = this.localSSRCs.get(track.rtcId);

      const newSSRCNum = this._extractPrimarySSRC(newSSRC);

      const oldSSRCNum = this._extractPrimarySSRC(oldSSRC); // eslint-disable-next-line no-negated-condition


      if (newSSRCNum !== oldSSRCNum) {
        if (oldSSRCNum === null) {
          logger.info(`Storing new local SSRC for ${track} in ${this}`, newSSRC);
        } else {
          logger.error(`Overwriting SSRC for ${track} ${trackMSID} in ${this} with: `, newSSRC);
        }

        this.localSSRCs.set(track.rtcId, newSSRC);
        this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_10___default.a.LOCAL_TRACK_SSRC_UPDATED, track, newSSRCNum);
      } else {
        logger.debug(`The local SSRC(${newSSRCNum}) for ${track} ${trackMSID}` + `is still up to date in ${this}`);
      }
    } else if (!track.isVideoTrack() && !track.isMuted()) {
      // It is normal to find no SSRCs for a muted video track in
      // the local SDP as the recv-only SSRC is no longer munged in.
      // So log the warning only if it's not a muted video track.
      logger.warn(`No SSRCs found in the local SDP for ${track} MSID: ${trackMSID} in ${this}`);
    }
  }
};

TraceablePeerConnection.prototype.addIceCandidate = function (candidate) {
  this.trace('addIceCandidate', JSON.stringify({
    candidate: candidate.candidate,
    sdpMid: candidate.sdpMid,
    sdpMLineIndex: candidate.sdpMLineIndex,
    usernameFragment: candidate.usernameFragment
  }, null, ' '));
  return this.peerconnection.addIceCandidate(candidate);
};
/**
 * Obtains call-related stats from the peer connection.
 *
 * @param {Function} callback - The function to invoke after successfully
 * obtaining stats.
 * @param {Function} errback - The function to invoke after failing to obtain
 * stats.
 * @returns {void}
 */


TraceablePeerConnection.prototype.getStats = function (callback, errback) {
  // TODO (brian): After moving all browsers to adapter, check if adapter is
  // accounting for different getStats apis, making the browser-checking-if
  // unnecessary.
  if (_browser__WEBPACK_IMPORTED_MODULE_9__["default"].isSafari() || _browser__WEBPACK_IMPORTED_MODULE_9__["default"].isFirefox() || _browser__WEBPACK_IMPORTED_MODULE_9__["default"].isReactNative()) {
    // uses the new Promise based getStats
    this.peerconnection.getStats().then(callback).catch(errback || (() => {// Making sure that getStats won't fail if error callback is
      // not passed.
    }));
  } else {
    this.peerconnection.getStats(callback);
  }
};
/**
 * Generates and stores new SSRC info object for given local track.
 * The method should be called only for a video track being added to this TPC
 * in the muted state (given that the current browser uses this strategy).
 * @param {JitsiLocalTrack} track
 * @return {TPCSSRCInfo}
 */


TraceablePeerConnection.prototype.generateNewStreamSSRCInfo = function (track) {
  const rtcId = track.rtcId;

  let ssrcInfo = this._getSSRC(rtcId);

  if (ssrcInfo) {
    logger.error(`Will overwrite local SSRCs for track ID: ${rtcId}`);
  } // configure simulcast for camera tracks always and for
  // desktop tracks only when the testing flag for maxbitrates
  // in config.js is disabled.


  if (this.isSimulcastOn() && (!this.options.capScreenshareBitrate || this.options.capScreenshareBitrate && hasCameraTrack(this))) {
    ssrcInfo = {
      ssrcs: [],
      groups: []
    };

    for (let i = 0; i < _TPCUtils__WEBPACK_IMPORTED_MODULE_12__["SIM_LAYER_RIDS"].length; i++) {
      ssrcInfo.ssrcs.push(_xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].generateSsrc());
    }

    ssrcInfo.groups.push({
      ssrcs: ssrcInfo.ssrcs.slice(),
      semantics: 'SIM'
    });
  } else {
    ssrcInfo = {
      ssrcs: [_xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].generateSsrc()],
      groups: []
    };
  }

  if (!this.options.disableRtx && _browser__WEBPACK_IMPORTED_MODULE_9__["default"].supportsRtx()) {
    // Specifically use a for loop here because we'll
    //  be adding to the list we're iterating over, so we
    //  only want to iterate through the items originally
    //  on the list
    const currNumSsrcs = ssrcInfo.ssrcs.length;

    for (let i = 0; i < currNumSsrcs; ++i) {
      const primarySsrc = ssrcInfo.ssrcs[i];
      const rtxSsrc = _xmpp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].generateSsrc();
      ssrcInfo.ssrcs.push(rtxSsrc);
      ssrcInfo.groups.push({
        ssrcs: [primarySsrc, rtxSsrc],
        semantics: 'FID'
      });
    }
  }

  ssrcInfo.msid = track.storedMSID;
  this.localSSRCs.set(rtcId, ssrcInfo);
  return ssrcInfo;
};

const handleLayerSuspension = function (peerConnection, isSelected) {
  if (!peerConnection.getSenders) {
    logger.debug('Browser doesn\'t support RTPSender');
    return;
  }

  const videoSender = peerConnection.getSenders().find(sender => sender.track.kind === 'video');

  if (!videoSender) {
    logger.warn('handleLayerSuspension unable to find video sender');
    return;
  }

  if (!videoSender.getParameters) {
    logger.debug('Browser doesn\'t support RTPSender parameters');
    return;
  }

  const parameters = videoSender.getParameters();

  if (isSelected) {
    logger.debug('Currently selected, enabling all sim layers'); // Make sure all encodings are enabled

    parameters.encodings.forEach(e => {
      e.active = true;
    });
  } else {
    logger.debug('Not currently selected, disabling upper layers'); // Turn off the upper simulcast layers

    [1, 2].forEach(simIndex => {
      if (parameters.encodings[simIndex]) {
        parameters.encodings[simIndex].active = false;
      }
    });
  }

  videoSender.setParameters(parameters);
};
/**
 * Set whether or not the endpoint is 'selected' by other endpoints, meaning
 * it appears on their main stage
 */


TraceablePeerConnection.prototype.setIsSelected = function (isSelected) {
  if (this.options.enableLayerSuspension) {
    logger.debug('Layer suspension enabled,' + `currently selected? ${isSelected}`);
    handleLayerSuspension(this.peerconnection, isSelected);
  }
};
/**
 * Creates a text representation of this <tt>TraceablePeerConnection</tt>
 * instance.
 * @return {string}
 */


TraceablePeerConnection.prototype.toString = function () {
  return `TPC[${this.id},p2p:${this.isP2P}]`;
};
/* WEBPACK VAR INJECTION */}.call(this, "modules\\RTC\\TraceablePeerConnection.js"))

/***/ }),

/***/ "./modules/browser/BrowserCapabilities.js":
/*!************************************************!*\
  !*** ./modules/browser/BrowserCapabilities.js ***!
  \************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename, process) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return BrowserCapabilities; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var js_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! js-utils */ "./node_modules/js-utils/index.js");


const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename); // TODO: Move this code to js-utils.
// NOTE: Now we are extending BrowserDetection in order to preserve
// RTCBrowserType interface but maybe it worth exporting BrowserCapabilities
// and BrowserDetection as separate objects in future.

/**
 * Implements browser capabilities for lib-jitsi-meet.
 */

class BrowserCapabilities extends js_utils__WEBPACK_IMPORTED_MODULE_1__["BrowserDetection"] {
  /**
   * Creates new BrowserCapabilities instance.
   */
  constructor() {
    super();
    logger.info(`This appears to be ${this.getName()}, ver: ${this.getVersion()}`);
  }
  /**
   * Tells whether or not the <tt>MediaStream/tt> is removed from
   * the <tt>PeerConnection</tt> and disposed on video mute (in order to turn
   * off the camera device).
   * @return {boolean} <tt>true</tt> if the current browser supports this
   * strategy or <tt>false</tt> otherwise.
   */


  doesVideoMuteByStreamRemove() {
    return this.isChromiumBased() || this.isSafari();
  }
  /**
   * Check whether or not the current browser support peer to peer connections
   * @return {boolean} <tt>true</tt> if p2p is supported or <tt>false</tt>
   * otherwise.
   */


  supportsP2P() {
    return !this.usesUnifiedPlan();
  }
  /**
   * Checks if the current browser is Chromium based, that is, it's either
   * Chrome / Chromium or uses it as its engine, but doesn't identify as
   * Chrome.
   *
   * This includes the following browsers:
   * - Chrome and Chromium
   * - Other browsers which use the Chrome engine, but are detected as Chrome,
   *   such as Brave and Vivaldi
   * - Browsers which are NOT Chrome but use it as their engine, and have
   *   custom detection code: Opera, Electron and NW.JS
   */


  isChromiumBased() {
    return this.isChrome() || this.isElectron() || this.isNWJS() || this.isOpera();
  }
  /**
   * Checks if the current browser is supported.
   *
   * @returns {boolean} true if the browser is supported, false otherwise.
   */


  isSupported() {
    return this.isChromiumBased() || this.isFirefox() || this.isReactNative() || this.isSafari() && !this.isVersionLessThan('12.1');
  }
  /**
   * Returns whether or not the current environment needs a user interaction
   * with the page before any unmute can occur.
   *
   * @returns {boolean}
   */


  isUserInteractionRequiredForUnmute() {
    return this.isFirefox() && this.isVersionLessThan('68') || this.isSafari();
  }
  /**
   * Checks if the current browser triggers 'onmute'/'onunmute' events when
   * user's connection is interrupted and the video stops playback.
   * @returns {*|boolean} 'true' if the event is supported or 'false'
   * otherwise.
   */


  supportsVideoMuteOnConnInterrupted() {
    return this.isChromiumBased() || this.isReactNative() || this.isSafari();
  }
  /**
   * Checks if the current browser reports upload and download bandwidth
   * statistics.
   * @return {boolean}
   */


  supportsBandwidthStatistics() {
    // FIXME bandwidth stats are currently not implemented for FF on our
    // side, but not sure if not possible ?
    return !this.isFirefox() && !this.isSafari();
  }
  /**
   * Checks if the current browser support the device change event.
   * @return {boolean}
   */


  supportsDeviceChangeEvent() {
    return navigator.mediaDevices && typeof navigator.mediaDevices.ondevicechange !== 'undefined' && typeof navigator.mediaDevices.addEventListener !== 'undefined';
  }
  /**
   * Checks if the current browser supports RTT statistics for srflx local
   * candidates through the legacy getStats() API.
   */


  supportsLocalCandidateRttStatistics() {
    return this.isChromiumBased() || this.isReactNative() || this.isSafari();
  }
  /**
   * Checks if the current browser reports round trip time statistics for
   * the ICE candidate pair.
   * @return {boolean}
   */


  supportsRTTStatistics() {
    // Firefox does not seem to report RTT for ICE candidate pair:
    // eslint-disable-next-line max-len
    // https://www.w3.org/TR/webrtc-stats/#dom-rtcicecandidatepairstats-currentroundtriptime
    // It does report mozRTT for RTP streams, but at the time of this
    // writing it's value does not make sense most of the time
    // (is reported as 1):
    // https://bugzilla.mozilla.org/show_bug.cgi?id=1241066
    // For Chrome and others we rely on 'googRtt'.
    return !this.isFirefox();
  }
  /**
   * Checks whether the browser supports RTPSender.
   *
   * @returns {boolean}
   */


  supportsRtpSender() {
    return this.isFirefox() || this.isSafari();
  }
  /**
   * Checks whether the browser supports RTX.
   *
   * @returns {boolean}
   */


  supportsRtx() {
    return !this.isFirefox();
  }
  /**
   * Returns whether or not the current browser can support capturing video,
   * be it camera or desktop, and displaying received video.
   *
   * @returns {boolean}
   */


  supportsVideo() {
    return true;
  }
  /**
   * Checks if the browser uses plan B.
   *
   * @returns {boolean}
   */


  usesPlanB() {
    return !this.usesUnifiedPlan();
  }
  /**
   * Checks if the browser uses SDP munging for turning on simulcast.
   *
   * @returns {boolean}
   */


  usesSdpMungingForSimulcast() {
    return this.isChromiumBased() || this.isSafari();
  }
  /**
   * Checks if the browser uses unified plan.
   *
   * @returns {boolean}
   */


  usesUnifiedPlan() {
    if (this.isFirefox()) {
      return true;
    }

    if (this.isSafari() && typeof window.RTCRtpTransceiver !== 'undefined') {
      // eslint-disable-next-line max-len
      // https://trac.webkit.org/changeset/236144/webkit/trunk/LayoutTests/webrtc/video-addLegacyTransceiver.html
      // eslint-disable-next-line no-undef
      return Object.keys(RTCRtpTransceiver.prototype).indexOf('currentDirection') > -1;
    }

    return false;
  }
  /**
   * Returns whether or not the current browser should be using the new
   * getUserMedia flow, which utilizes the adapter shim. This method should
   * be temporary and used while migrating all browsers to use adapter and
   * the new getUserMedia.
   *
   * @returns {boolean}
   */


  usesNewGumFlow() {
    const REQUIRED_CHROME_VERSION = 61;

    if (this.isChrome()) {
      return !this.isVersionLessThan(REQUIRED_CHROME_VERSION);
    }

    if (this.isFirefox() || this.isSafari()) {
      return true;
    }

    if (this.isChromiumBased()) {
      return this._getChromiumBasedVersion() >= REQUIRED_CHROME_VERSION;
    }

    return false;
  }
  /**
   * Checks if the browser uses webrtc-adapter. All browsers using the new
   * getUserMedia flow and Edge.
   *
   * @returns {boolean}
   */


  usesAdapter() {
    return this.usesNewGumFlow();
  }
  /**
   * Checks if the browser uses RIDs/MIDs for siganling the simulcast streams
   * to the bridge instead of the ssrcs.
   */


  usesRidsForSimulcast() {
    return false;
  }
  /**
   * Checks if the browser supports getDisplayMedia.
   * @returns {boolean} {@code true} if the browser supports getDisplayMedia.
   */


  supportsGetDisplayMedia() {
    return typeof navigator.getDisplayMedia !== 'undefined' || typeof navigator.mediaDevices !== 'undefined' && typeof navigator.mediaDevices.getDisplayMedia !== 'undefined';
  }
  /**
   * Checks if the browser supports insertable streams, needed for E2EE.
   * @returns {boolean} {@code true} if the browser supports insertable streams.
   */


  supportsInsertableStreams() {
    return Boolean(typeof window.RTCRtpSender !== 'undefined' && window.RTCRtpSender.prototype.createEncodedVideoStreams);
  }
  /**
   * Checks if the browser supports the "sdpSemantics" configuration option.
   * https://webrtc.org/web-apis/chrome/unified-plan/
   *
   * @returns {boolean}
   */


  supportsSdpSemantics() {
    return this.isChromiumBased() && this._getChromiumBasedVersion() >= 65;
  }
  /**
   * Returns the version of a Chromium based browser.
   *
   * @returns {Number}
   */


  _getChromiumBasedVersion() {
    if (this.isChromiumBased()) {
      // NW.JS doesn't expose the Chrome version in the UA string.
      if (this.isNWJS()) {
        // eslint-disable-next-line no-undef
        return Number.parseInt(process.versions.chromium, 10);
      } // Here we process all browsers which use the Chrome engine but
      // don't necessarily identify as Chrome. We cannot use the version
      // comparing functions because the Electron, Opera and NW.JS
      // versions are inconsequential here, as we need to know the actual
      // Chrome engine version.


      const ua = navigator.userAgent;

      if (ua.match(/Chrome/)) {
        const version = Number.parseInt(ua.match(/Chrome\/([\d.]+)/)[1], 10);
        return version;
      }
    }

    return -1;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\browser\\BrowserCapabilities.js", __webpack_require__(/*! ./../../node_modules/process/browser.js */ "./node_modules/process/browser.js")))

/***/ }),

/***/ "./modules/browser/index.js":
/*!**********************************!*\
  !*** ./modules/browser/index.js ***!
  \**********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _BrowserCapabilities__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BrowserCapabilities */ "./modules/browser/BrowserCapabilities.js");

/* harmony default export */ __webpack_exports__["default"] = (new _BrowserCapabilities__WEBPACK_IMPORTED_MODULE_0__["default"]());

/***/ }),

/***/ "./modules/connectivity/ConnectionQuality.js":
/*!***************************************************!*\
  !*** ./modules/connectivity/ConnectionQuality.js ***!
  \***************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return ConnectionQuality; });
/* harmony import */ var _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../service/connectivity/ConnectionQualityEvents */ "./service/connectivity/ConnectionQualityEvents.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__);




const XMPPEvents = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");

const VideoType = __webpack_require__(/*! ../../service/RTC/VideoType */ "./service/RTC/VideoType.js");

const Resolutions = __webpack_require__(/*! ../../service/RTC/Resolutions */ "./service/RTC/Resolutions.js");

const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__["getLogger"])(__filename);
/**
 * The value to use for the "type" field for messages sent by ConnectionQuality
 * over the data channel.
 */

const STATS_MESSAGE_TYPE = 'stats';
/**
 * See media/engine/simulcast.ss from webrtc.org
 */

const kSimulcastFormats = [{
  width: 1920,
  height: 1080,
  layers: 3,
  max: 5000,
  target: 4000,
  min: 800
}, {
  width: 1280,
  height: 720,
  layers: 3,
  max: 2500,
  target: 2500,
  min: 600
}, {
  width: 960,
  height: 540,
  layers: 3,
  max: 900,
  target: 900,
  min: 450
}, {
  width: 640,
  height: 360,
  layers: 2,
  max: 700,
  target: 500,
  min: 150
}, {
  width: 480,
  height: 270,
  layers: 2,
  max: 450,
  target: 350,
  min: 150
}, {
  width: 320,
  height: 180,
  layers: 1,
  max: 200,
  target: 150,
  min: 30
}];
/**
 * The maximum bitrate to use as a measurement against the participant's current
 * bitrate. This cap helps in the cases where the participant's bitrate is high
 * but not enough to fulfill high targets, such as with 1080p.
 */

const MAX_TARGET_BITRATE = 2500;
/**
 * The initial bitrate for video in kbps.
 */

let startBitrate = 800;
/**
 * The current cap (in kbps) put on the video stream (or null if there isn't
 * a cap).  If there is a cap, we'll take it into account when calculating
 * the current quality.
 */

let videoBitrateCap = null;
/**
 * Gets the expected bitrate (in kbps) in perfect network conditions.
 * @param simulcast {boolean} whether simulcast is enabled or not.
 * @param resolution {Resolution} the resolution.
 * @param millisSinceStart {number} the number of milliseconds since sending
 * video started.
 */

function getTarget(simulcast, resolution, millisSinceStart) {
  // Completely ignore the bitrate in the first 5 seconds, as the first
  // event seems to fire very early and the value is suspicious and causes
  // false positives.
  if (millisSinceStart < 15000) {
    return 1;
  }

  let target = 0;
  let height = Math.min(resolution.height, resolution.width);

  if (simulcast) {
    // Find the first format with height no bigger than ours.
    let simulcastFormat = kSimulcastFormats.find(f => f.height <= height);

    if (simulcastFormat) {
      // Sum the target fields from all simulcast layers for the given
      // resolution (e.g. 720p + 360p + 180p).
      for (height = simulcastFormat.height; height >= 180; height /= 2) {
        const targetHeight = height;
        simulcastFormat = kSimulcastFormats.find(f => f.height === targetHeight);

        if (simulcastFormat) {
          target += simulcastFormat.target;
        } else {
          break;
        }
      }
    }
  } else {
    // See GetMaxDefaultVideoBitrateKbps in
    // media/engine/webrtcvideoengine2.cc from webrtc.org
    const pixels = resolution.width * resolution.height;

    if (pixels <= 320 * 240) {
      target = 600;
    } else if (pixels <= 640 * 480) {
      target = 1700;
    } else if (pixels <= 960 * 540) {
      target = 2000;
    } else {
      target = 2500;
    }
  } // Allow for an additional 1 second for ramp up -- delay any initial drop
  // of connection quality by 1 second.


  return Math.min(target, rampUp(Math.max(0, millisSinceStart - 1000)));
}
/**
 * Gets the bitrate to which GCC would have ramped up in perfect network
 * conditions after millisSinceStart milliseconds.
 * @param millisSinceStart {number} the number of milliseconds since sending
 * video was enabled.
 */


function rampUp(millisSinceStart) {
  if (millisSinceStart > 60000) {
    return Number.MAX_SAFE_INTEGER;
  } // According to GCC the send side bandwidth estimation grows with at most
  // 8% per second.
  // https://tools.ietf.org/html/draft-ietf-rmcat-gcc-02#section-5.5


  return startBitrate * Math.pow(1.08, millisSinceStart / 1000);
}
/**
 * A class which monitors the local statistics coming from the RTC modules, and
 * calculates a "connection quality" value, in percent, for the media
 * connection. A value of 100% indicates a very good network connection, and a
 * value of 0% indicates a poor connection.
 */


class ConnectionQuality {
  /**
   *
   * @param conference
   * @param eventEmitter
   * @param options
   */
  constructor(conference, eventEmitter, options) {
    this.eventEmitter = eventEmitter;
    /**
     * The owning JitsiConference.
     */

    this._conference = conference;
    /**
     * Holds statistics about the local connection quality.
     */

    this._localStats = {
      connectionQuality: 100,
      jvbRTT: undefined
    };
    /**
     * The time this._localStats.connectionQuality was last updated.
     */

    this._lastConnectionQualityUpdate = -1;
    /**
     * Maps a participant ID to an object holding connection quality
     * statistics received from this participant.
     */

    this._remoteStats = {};
    /**
     * The time that the ICE state last changed to CONNECTED. We use this
     * to calculate how much time we as a sender have had to ramp-up.
     */

    this._timeIceConnected = -1;
    /**
     * The time that local video was unmuted. We use this to calculate how
     * much time we as a sender have had to ramp-up.
     */

    this._timeVideoUnmuted = -1;
    /**
     * The time at which a video bitrate cap was last removed.  We use
     * this to calculate how much time we, as a sender, have had to
     * ramp-up
     */

    this._timeLastBwCapRemoved = -1; // We assume a global startBitrate value for the sake of simplicity.

    if (options.config.startBitrate && options.config.startBitrate > 0) {
      startBitrate = options.config.startBitrate;
    } // TODO: consider ignoring these events and letting the user of
    // lib-jitsi-meet handle these separately.


    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["CONNECTION_INTERRUPTED"], () => {
      this._updateLocalConnectionQuality(0);

      this.eventEmitter.emit(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_0__["LOCAL_STATS_UPDATED"], this._localStats);

      this._broadcastLocalStats();
    });
    conference.room.addListener(XMPPEvents.ICE_CONNECTION_STATE_CHANGED, (jingleSession, newState) => {
      if (!jingleSession.isP2P && newState === 'connected') {
        this._timeIceConnected = window.performance.now();
      }
    }); // Listen to DataChannel message from other participants in the
    // conference, and update the _remoteStats field accordingly.

    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["ENDPOINT_MESSAGE_RECEIVED"], (participant, payload) => {
      if (payload.type === STATS_MESSAGE_TYPE) {
        this._updateRemoteStats(participant.getId(), payload.values);
      }
    }); // Listen to local statistics events originating from the RTC module
    // and update the _localStats field.
    // Oh, and by the way, the resolutions of all remote participants are
    // also piggy-backed in these "local" statistics. It's obvious, really,
    // if one carefully reads the *code* (but not the docs) in
    // UI/VideoLayout/VideoLayout.js#updateLocalConnectionStats in
    // jitsi-meet
    // TODO: We should keep track of the remote resolution in _remoteStats,
    // and notify about changes via separate events.

    conference.statistics.addConnectionStatsListener(this._updateLocalStats.bind(this)); // Save the last time we were unmuted.

    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["TRACK_MUTE_CHANGED"], track => {
      if (track.isVideoTrack()) {
        if (track.isMuted()) {
          this._timeVideoUnmuted = -1;
        } else {
          this._maybeUpdateUnmuteTime();
        }
      }
    });
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["TRACK_ADDED"], track => {
      if (track.isVideoTrack() && !track.isMuted()) {
        this._maybeUpdateUnmuteTime();
      }
    });
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["SERVER_REGION_CHANGED"], serverRegion => {
      this._localStats.serverRegion = serverRegion;
    });
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["PROPERTIES_CHANGED"], properties => {
      this._localStats.bridgeCount = Number((properties || {})['bridge-count']);
    });
  }
  /**
   * Sets _timeVideoUnmuted if it was previously unset. If it was already set,
   * doesn't change it.
   */


  _maybeUpdateUnmuteTime() {
    if (this._timeVideoUnmuted < 0) {
      this._timeVideoUnmuted = window.performance.now();
    }
  }
  /**
   * Calculates a new "connection quality" value.
   * @param videoType {VideoType} the type of the video source (camera or
   * a screen capture).
   * @param isMuted {boolean} whether the local video is muted.
   * @param resolutionName {Resolution} the input resolution used by the
   * camera.
   * @returns {*} the newly calculated connection quality.
   */


  _calculateConnectionQuality(videoType, isMuted, resolutionName) {
    // resolutionName is an index into Resolutions (where "720" is
    // "1280x720" and "960" is "960x720" ...).
    const resolution = Resolutions[resolutionName];
    let quality = 100;
    let packetLoss; // TODO: take into account packet loss for received streams

    if (this._localStats.packetLoss) {
      packetLoss = this._localStats.packetLoss.upload; // Ugly Hack Alert (UHA):
      // The packet loss for the upload direction is calculated based on
      // incoming RTCP Receiver Reports. Since we don't have RTCP
      // termination for audio, these reports come from the actual
      // receivers in the conference and therefore the reported packet
      // loss includes loss from the bridge to the receiver.
      // When we are sending video this effect is small, because the
      // number of video packets is much larger than the number of audio
      // packets (and our calculation is based on the total number of
      // received and lost packets).
      // When video is muted, however, the effect might be significant,
      // but we don't know what it is. We do know that it is positive, so
      // as a temporary solution, until RTCP termination is implemented
      // for the audio streams, we relax the packet loss checks here.

      if (isMuted) {
        packetLoss *= 0.5;
      }
    }

    if (isMuted || !resolution || videoType === VideoType.DESKTOP || this._timeIceConnected < 0 || this._timeVideoUnmuted < 0) {
      // Calculate a value based on packet loss only.
      if (packetLoss === undefined) {
        logger.error('Cannot calculate connection quality, unknown ' + 'packet loss.');
        quality = 100;
      } else if (packetLoss <= 2) {
        quality = 100; // Full 5 bars.
      } else if (packetLoss <= 4) {
        quality = 70; // 4 bars
      } else if (packetLoss <= 6) {
        quality = 50; // 3 bars
      } else if (packetLoss <= 8) {
        quality = 30; // 2 bars
      } else if (packetLoss <= 12) {
        quality = 10; // 1 bars
      } else {
        quality = 0; // Still 1 bar, but slower climb-up.
      }
    } else {
      // Calculate a value based on the sending bitrate.
      // Figure out if simulcast is in use
      const activeTPC = this._conference.getActivePeerConnection();

      const isSimulcastOn = Boolean(activeTPC && activeTPC.isSimulcastOn());
      const newVideoBitrateCap = activeTPC && activeTPC.bandwidthLimiter && activeTPC.bandwidthLimiter.getBandwidthLimit('video'); // If we had a cap set but there isn't one now, then it has
      // just been 'lifted', so we should treat this like a new
      // ramp up.

      if (!newVideoBitrateCap && videoBitrateCap) {
        this._timeLastBwCapRemoved = window.performance.now(); // Set the start bitrate to whatever we were just capped to

        startBitrate = videoBitrateCap;
      }

      videoBitrateCap = newVideoBitrateCap; // time since sending of video was enabled.

      const millisSinceStart = window.performance.now() - Math.max(this._timeVideoUnmuted, this._timeIceConnected, this._timeLastBwCapRemoved); // expected sending bitrate in perfect conditions

      let target = getTarget(isSimulcastOn, resolution, millisSinceStart);
      target = Math.min(0.9 * target, MAX_TARGET_BITRATE);

      if (videoBitrateCap) {
        target = Math.min(target, videoBitrateCap);
      }

      quality = 100 * this._localStats.bitrate.upload / target; // Whatever the bitrate, drop early if there is significant loss

      if (packetLoss && packetLoss >= 10) {
        quality = Math.min(quality, 30);
      }
    } // Make sure that the quality doesn't climb quickly


    if (this._lastConnectionQualityUpdate > 0) {
      const maxIncreasePerSecond = 2;
      const prevConnectionQuality = this._localStats.connectionQuality;
      const diffSeconds = (window.performance.now() - this._lastConnectionQualityUpdate) / 1000;
      quality = Math.min(quality, prevConnectionQuality + diffSeconds * maxIncreasePerSecond);
    }

    return Math.min(100, quality);
  }
  /**
   * Updates the localConnectionQuality value
   * @param values {number} the new value. Should be in [0, 100].
   */


  _updateLocalConnectionQuality(value) {
    this._localStats.connectionQuality = value;
    this._lastConnectionQualityUpdate = window.performance.now();
  }
  /**
   * Broadcasts the local statistics to all other participants in the
   * conference.
   */


  _broadcastLocalStats() {
    // Send only the data that remote participants care about.
    const data = {
      bitrate: this._localStats.bitrate,
      packetLoss: this._localStats.packetLoss,
      connectionQuality: this._localStats.connectionQuality,
      jvbRTT: this._localStats.jvbRTT,
      serverRegion: this._localStats.serverRegion,
      avgAudioLevels: this._localStats.localAvgAudioLevels
    };

    try {
      this._conference.broadcastEndpointMessage({
        type: STATS_MESSAGE_TYPE,
        values: data
      });
    } catch (e) {// We often hit this in the beginning of a call, before the data
      // channel is ready. It is not a big problem, because we will
      // send the statistics again after a few seconds, and the error is
      // already logged elsewhere. So just ignore it.
      // let errorMsg = "Failed to broadcast local stats";
      // logger.error(errorMsg, e);
      // GlobalOnErrorHandler.callErrorHandler(
      //    new Error(errorMsg + ": " + e));
    }
  }
  /**
   * Updates the local statistics
   * @param {TraceablePeerConnection} tpc the peerconnection which emitted
   * the stats
   * @param data new statistics
   */


  _updateLocalStats(tpc, data) {
    // Update jvbRTT
    if (!tpc.isP2P) {
      const jvbRTT = data.transport && data.transport.length && data.transport[0].rtt;
      this._localStats.jvbRTT = jvbRTT ? jvbRTT : undefined;
    } // Do not continue with processing of other stats if they do not
    // originate from the active peerconnection


    if (tpc !== this._conference.getActivePeerConnection()) {
      return;
    }

    let key;
    const updateLocalConnectionQuality = !this._conference.isConnectionInterrupted();

    const localVideoTrack = this._conference.getLocalVideoTrack();

    const videoType = localVideoTrack ? localVideoTrack.videoType : undefined;
    const isMuted = localVideoTrack ? localVideoTrack.isMuted() : true;
    const resolution = localVideoTrack ? localVideoTrack.resolution : null;

    if (!isMuted) {
      this._maybeUpdateUnmuteTime();
    } // Copy the fields already in 'data'.


    for (key in data) {
      if (data.hasOwnProperty(key)) {
        this._localStats[key] = data[key];
      }
    } // And re-calculate the connectionQuality field.


    if (updateLocalConnectionQuality) {
      this._updateLocalConnectionQuality(this._calculateConnectionQuality(videoType, isMuted, resolution));
    }

    this.eventEmitter.emit(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_0__["LOCAL_STATS_UPDATED"], this._localStats);

    this._broadcastLocalStats();
  }
  /**
   * Updates remote statistics
   * @param id the id of the remote participant
   * @param data the statistics received
   */


  _updateRemoteStats(id, data) {
    // Use only the fields we need
    this._remoteStats[id] = {
      bitrate: data.bitrate,
      packetLoss: data.packetLoss,
      connectionQuality: data.connectionQuality,
      jvbRTT: data.jvbRTT,
      serverRegion: data.serverRegion,
      avgAudioLevels: data.avgAudioLevels
    };
    this.eventEmitter.emit(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_0__["REMOTE_STATS_UPDATED"], id, this._remoteStats[id]);
  }
  /**
   * Returns the local statistics.
   * Exported only for use in jitsi-meet-torture.
   */


  getStats() {
    return this._localStats;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\connectivity\\ConnectionQuality.js"))

/***/ }),

/***/ "./modules/connectivity/IceFailedNotification.js":
/*!*******************************************************!*\
  !*** ./modules/connectivity/IceFailedNotification.js ***!
  \*******************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return IceFailedNotification; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* global __filename */

const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * A delayed ICE failed notification which is triggered only if the ICE
 * connection does not recover soon after or before the XMPP connection is
 * restored (if it was ever broken). If ICE fails while the XMPP connection is
 * not broken then the notifications will be sent after 2 seconds delay. This
 * extra delay is not intentional just a side effect of the code.
 * NOTE that this delayed task can only be used if PING is supported by the XMPP
 * server.
 */

class IceFailedNotification {
  /**
   * Creates new {@code DelayedIceFailed} task.
   * @param {JitsiConference} conference
   */
  constructor(conference) {
    this._conference = conference;
  }
  /**
   * Starts the task.
   * @param {JingleSessionPC} session - the JVB Jingle session.
   */


  start(session) {
    // The 65 seconds are greater than the default Prosody's BOSH
    // timeout of 60. This gives some time for the XMPP connection
    // to recover.
    this._conference.xmpp.ping(65000).then(() => {
      if (this._canceled) {
        return;
      }

      if (this._conference.isJvbConnectionInterrupted) {
        this._iceFailedTimeout = window.setTimeout(() => {
          logger.info('Sending ICE failed' + ' - the connection has not recovered');
          this._iceFailedTimeout = undefined;
          session.sendIceFailedNotification();
        }, 2000);
      } else {
        logger.info('ICE connection restored - not sending ICE failed');
      }
    }, error => {
      logger.error('PING error/timeout - not sending ICE failed', error);
    });
  }
  /**
   * Cancels the task.
   */


  cancel() {
    this._canceled = true;

    if (this._iceFailedTimeout) {
      window.clearTimeout(this._iceFailedTimeout);
    }
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\connectivity\\IceFailedNotification.js"))

/***/ }),

/***/ "./modules/connectivity/ParticipantConnectionStatus.js":
/*!*************************************************************!*\
  !*** ./modules/connectivity/ParticipantConnectionStatus.js ***!
  \*************************************************************/
/*! exports provided: ParticipantConnectionStatus, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ParticipantConnectionStatus", function() { return ParticipantConnectionStatus; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return ParticipantConnectionStatusHandler; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./JitsiTrackEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5__);
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

/* global __filename */








const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Default value of 500 milliseconds for
 * {@link ParticipantConnectionStatus.outOfLastNTimeout}.
 *
 * @type {number}
 */

const DEFAULT_NOT_IN_LAST_N_TIMEOUT = 500;
/**
 * Default value of 2000 milliseconds for
 * {@link ParticipantConnectionStatus.rtcMuteTimeout}.
 *
 * @type {number}
 */

const DEFAULT_RTC_MUTE_TIMEOUT = 10000;
/**
 * The time to wait a track to be restored. Track which was out of lastN
 * should be inactive and when entering lastN it becomes restoring and when
 * data is received from bridge it will become active, but if no data is
 * received for some time we set status of that participant connection to
 * interrupted.
 * @type {number}
 */

const DEFAULT_RESTORING_TIMEOUT = 10000;
/**
 * Participant connection statuses.
 *
 * @type {{
 *      ACTIVE: string,
 *      INACTIVE: string,
 *      INTERRUPTED: string,
 *      RESTORING: string
 * }}
 */

const ParticipantConnectionStatus = {
  /**
   * Status indicating that connection is currently active.
   */
  ACTIVE: 'active',

  /**
   * Status indicating that connection is currently inactive.
   * Inactive means the connection was stopped on purpose from the bridge,
   * like exiting lastN or adaptivity decided to drop video because of not
   * enough bandwidth.
   */
  INACTIVE: 'inactive',

  /**
   * Status indicating that connection is currently interrupted.
   */
  INTERRUPTED: 'interrupted',

  /**
   * Status indicating that connection is currently restoring.
   */
  RESTORING: 'restoring'
};
/**
 * Class is responsible for emitting
 * JitsiConferenceEvents.PARTICIPANT_CONN_STATUS_CHANGED events.
 */

class ParticipantConnectionStatusHandler {
  /* eslint-disable max-params*/

  /**
   * Calculates the new {@link ParticipantConnectionStatus} based on
   * the values given for some specific remote user. It is assumed that
   * the conference is currently in the JVB mode (in contrary to the P2P mode)
   * @param {boolean} isConnectionActiveByJvb true if the JVB did not get any
   * data from the user for the last 15 seconds.
   * @param {boolean} isInLastN indicates whether the user is in the last N
   * set. When set to false it means that JVB is not sending any video for
   * the user.
   * @param {boolean} isRestoringTimedout if true it means that the user has
   * been outside of last N too long to be considered
   * {@link ParticipantConnectionStatus.RESTORING}.
   * @param {boolean} isVideoMuted true if the user is video muted and we
   * should not expect to receive any video.
   * @param {boolean} isVideoTrackFrozen if the current browser support video
   * frozen detection then it will be set to true when the video track is
   * frozen. If the current browser does not support frozen detection the it's
   * always false.
   * @return {ParticipantConnectionStatus} the new connection status for
   * the user for whom the values above were provided.
   * @private
   */
  static _getNewStateForJvbMode(isConnectionActiveByJvb, isInLastN, isRestoringTimedout, isVideoMuted, isVideoTrackFrozen) {
    if (!isConnectionActiveByJvb) {
      // when there is a connection problem signaled from jvb
      // it means no media was flowing for at least 15secs, so both audio
      // and video are most likely interrupted
      return ParticipantConnectionStatus.INTERRUPTED;
    } else if (isVideoMuted) {
      // If the connection is active according to JVB and the user is
      // video muted there is no way for the connection to be inactive,
      // because the detection logic below only makes sense for video.
      return ParticipantConnectionStatus.ACTIVE;
    } // Logic when isVideoTrackFrozen is supported


    if (_browser__WEBPACK_IMPORTED_MODULE_4__["default"].supportsVideoMuteOnConnInterrupted()) {
      if (!isVideoTrackFrozen) {
        // If the video is playing we're good
        return ParticipantConnectionStatus.ACTIVE;
      } else if (isInLastN) {
        return isRestoringTimedout ? ParticipantConnectionStatus.INTERRUPTED : ParticipantConnectionStatus.RESTORING;
      }

      return ParticipantConnectionStatus.INACTIVE;
    } // Because this browser is incapable of detecting frozen video we must
    // rely on the lastN value


    return isInLastN ? ParticipantConnectionStatus.ACTIVE : ParticipantConnectionStatus.INACTIVE;
  }
  /* eslint-enable max-params*/

  /**
   * In P2P mode we don't care about any values coming from the JVB and
   * the connection status can be only active or interrupted.
   * @param {boolean} isVideoMuted the user if video muted
   * @param {boolean} isVideoTrackFrozen true if the video track for
   * the remote user is currently frozen. If the current browser does not
   * support video frozen detection then it's always false.
   * @return {ParticipantConnectionStatus}
   * @private
   */


  static _getNewStateForP2PMode(isVideoMuted, isVideoTrackFrozen) {
    if (!_browser__WEBPACK_IMPORTED_MODULE_4__["default"].supportsVideoMuteOnConnInterrupted()) {
      // There's no way to detect problems in P2P when there's no video
      // track frozen detection...
      return ParticipantConnectionStatus.ACTIVE;
    }

    return isVideoMuted || !isVideoTrackFrozen ? ParticipantConnectionStatus.ACTIVE : ParticipantConnectionStatus.INTERRUPTED;
  }
  /**
   * Creates new instance of <tt>ParticipantConnectionStatus</tt>.
   *
   * @constructor
   * @param {RTC} rtc the RTC service instance
   * @param {JitsiConference} conference parent conference instance
   * @param {Object} options
   * @param {number} [options.rtcMuteTimeout=2000] custom value for
   * {@link ParticipantConnectionStatus.rtcMuteTimeout}.
   * @param {number} [options.outOfLastNTimeout=500] custom value for
   * {@link ParticipantConnectionStatus.outOfLastNTimeout}.
   */


  constructor(rtc, conference, options) {
    this.rtc = rtc;
    this.conference = conference;
    /**
     * A map of the "endpoint ID"(which corresponds to the resource part
     * of MUC JID(nickname)) to the timeout callback IDs scheduled using
     * window.setTimeout.
     * @type {Object.<string, number>}
     */

    this.trackTimers = {};
    /**
     * This map holds the endpoint connection status received from the JVB
     * (as it might be different than the one stored in JitsiParticipant).
     * Required for getting back in sync when remote video track is removed.
     * @type {Object.<string, boolean>}
     */

    this.connStatusFromJvb = {};
    /**
     * If video track frozen detection through RTC mute event is supported,
     * we wait some time until video track is considered frozen. But because
     * when the user falls out of last N it is expected for the video to
     * freeze this timeout must be significantly reduced in "out of last N"
     * case.
     *
     * Basically this value is used instead of {@link rtcMuteTimeout} when
     * user is not in last N.
     * @type {number}
     */

    this.outOfLastNTimeout = typeof options.outOfLastNTimeout === 'number' ? options.outOfLastNTimeout : DEFAULT_NOT_IN_LAST_N_TIMEOUT;
    /**
     * How long we're going to wait after the RTC video track muted event
     * for the corresponding signalling mute event, before the connection
     * interrupted is fired. The default value is
     * {@link DEFAULT_RTC_MUTE_TIMEOUT}.
     *
     * @type {number} amount of time in milliseconds
     */

    this.rtcMuteTimeout = typeof options.rtcMuteTimeout === 'number' ? options.rtcMuteTimeout : DEFAULT_RTC_MUTE_TIMEOUT;
    /**
     * This map holds a timestamp indicating  when participant's video track
     * was RTC muted (it is assumed that each participant can have only 1
     * video track at a time). The purpose of storing the timestamp is to
     * avoid the transition to disconnected status in case of legitimate
     * video mute operation where the signalling video muted event can
     * arrive shortly after RTC muted event.
     *
     * The key is participant's ID which is the same as endpoint id in
     * the Colibri conference allocated on the JVB.
     *
     * The value is a timestamp measured in milliseconds obtained with
     * <tt>Date.now()</tt>.
     *
     * FIXME merge this logic with NO_DATA_FROM_SOURCE event
     *       implemented in JitsiLocalTrack by extending the event to
     *       the remote track and allowing to set different timeout for
     *       local and remote tracks.
     *
     * @type {Object.<string, number>}
     */

    this.rtcMutedTimestamp = {};
    logger.info(`RtcMuteTimeout set to: ${this.rtcMuteTimeout}`);
    /**
     * This map holds the timestamps indicating when participant's video
     * entered lastN set. Participants entering lastN will have connection
     * status restoring and when we start receiving video will become
     * active, but if video is not received for certain time
     * {@link DEFAULT_RESTORING_TIMEOUT} that participant connection status
     * will become interrupted.
     *
     * @type {Map<string, number>}
     */

    this.enteredLastNTimestamp = new Map();
    /**
     * A map of the "endpoint ID"(which corresponds to the resource part
     * of MUC JID(nickname)) to the restoring timeout callback IDs
     * scheduled using window.setTimeout.
     *
     * @type {Map<string, number>}
     */

    this.restoringTimers = new Map();
    /**
     * A map that holds the current connection status (along with all the internal events that happen
     * while in that state).
     *
     * The goal is to send this information to the analytics backend for post-mortem analysis.
     */

    this.connectionStatusMap = new Map();
  }
  /**
   * Gets the video frozen timeout for given user.
   * @param {string} id endpoint/participant ID
   * @return {number} how long are we going to wait since RTC video muted
   * even, before a video track is considered frozen.
   * @private
   */


  _getVideoFrozenTimeout(id) {
    return this.rtc.isInLastN(id) ? this.rtcMuteTimeout : this.outOfLastNTimeout;
  }
  /**
   * Initializes <tt>ParticipantConnectionStatus</tt> and bind required event
   * listeners.
   */


  init() {
    this._onEndpointConnStatusChanged = this.onEndpointConnStatusChanged.bind(this);
    this.rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5___default.a.ENDPOINT_CONN_STATUS_CHANGED, this._onEndpointConnStatusChanged); // Handles P2P status changes

    this._onP2PStatus = this.refreshConnectionStatusForAll.bind(this);
    this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["P2P_STATUS"], this._onP2PStatus); // Used to send analytics events for the participant that left the call.

    this._onUserLeft = this.onUserLeft.bind(this);
    this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["USER_LEFT"], this._onUserLeft); // On some browsers MediaStreamTrack trigger "onmute"/"onunmute"
    // events for video type tracks when they stop receiving data which is
    // often a sign that remote user is having connectivity issues

    if (_browser__WEBPACK_IMPORTED_MODULE_4__["default"].supportsVideoMuteOnConnInterrupted()) {
      this._onTrackRtcMuted = this.onTrackRtcMuted.bind(this);
      this.rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5___default.a.REMOTE_TRACK_MUTE, this._onTrackRtcMuted);
      this._onTrackRtcUnmuted = this.onTrackRtcUnmuted.bind(this);
      this.rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5___default.a.REMOTE_TRACK_UNMUTE, this._onTrackRtcUnmuted); // Track added/removed listeners are used to bind "mute"/"unmute"
      // event handlers

      this._onRemoteTrackAdded = this.onRemoteTrackAdded.bind(this);
      this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["TRACK_ADDED"], this._onRemoteTrackAdded);
      this._onRemoteTrackRemoved = this.onRemoteTrackRemoved.bind(this);
      this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["TRACK_REMOVED"], this._onRemoteTrackRemoved); // Listened which will be bound to JitsiRemoteTrack to listen for
      // signalling mute/unmute events.

      this._onSignallingMuteChanged = this.onSignallingMuteChanged.bind(this); // Used to send an analytics event when the video type changes.

      this._onTrackVideoTypeChanged = this.onTrackVideoTypeChanged.bind(this);
    }

    this._onLastNChanged = this._onLastNChanged.bind(this);
    this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["LAST_N_ENDPOINTS_CHANGED"], this._onLastNChanged);
    this._onLastNValueChanged = this.refreshConnectionStatusForAll.bind(this);
    this.rtc.on(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5___default.a.LASTN_VALUE_CHANGED, this._onLastNValueChanged);
  }
  /**
   * Removes all event listeners and disposes of all resources held by this
   * instance.
   */


  dispose() {
    this.rtc.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5___default.a.ENDPOINT_CONN_STATUS_CHANGED, this._onEndpointConnStatusChanged);

    if (_browser__WEBPACK_IMPORTED_MODULE_4__["default"].supportsVideoMuteOnConnInterrupted()) {
      this.rtc.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5___default.a.REMOTE_TRACK_MUTE, this._onTrackRtcMuted);
      this.rtc.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5___default.a.REMOTE_TRACK_UNMUTE, this._onTrackRtcUnmuted);
      this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["TRACK_ADDED"], this._onRemoteTrackAdded);
      this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["TRACK_REMOVED"], this._onRemoteTrackRemoved);
    }

    this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["LAST_N_ENDPOINTS_CHANGED"], this._onLastNChanged);
    this.rtc.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_5___default.a.LASTN_VALUE_CHANGED, this._onLastNValueChanged);
    this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["P2P_STATUS"], this._onP2PStatus);
    this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["USER_LEFT"], this._onUserLeft);
    const participantIds = Object.keys(this.trackTimers);

    for (const participantId of participantIds) {
      this.clearTimeout(participantId);
      this.clearRtcMutedTimestamp(participantId);
    }

    for (const id in this.connectionStatusMap) {
      if (this.connectionStatusMap.hasOwnProperty(id)) {
        this.onUserLeft(id);
      }
    } // Clear RTC connection status cache


    this.connStatusFromJvb = {};
  }
  /**
   * Handles RTCEvents.ENDPOINT_CONN_STATUS_CHANGED triggered when we receive
   * notification over the data channel from the bridge about endpoint's
   * connection status update.
   * @param {string} endpointId - The endpoint ID(MUC nickname/resource JID).
   * @param {boolean} isActive - true if the connection is OK or false otherwise.
   */


  onEndpointConnStatusChanged(endpointId, isActive) {
    logger.debug(`Detector RTCEvents.ENDPOINT_CONN_STATUS_CHANGED(${Date.now()}): ${endpointId}: ${isActive}`); // Filter out events for the local JID for now

    if (endpointId !== this.conference.myUserId()) {
      // Store the status received over the data channels
      this.connStatusFromJvb[endpointId] = isActive;
      this.figureOutConnectionStatus(endpointId);
    }
  }
  /**
   * Changes connection status.
   * @param {JitsiParticipant} participant
   * @param newStatus
   */


  _changeConnectionStatus(participant, newStatus) {
    if (participant.getConnectionStatus() !== newStatus) {
      const endpointId = participant.getId();

      participant._setConnectionStatus(newStatus);

      logger.debug(`Emit endpoint conn status(${Date.now()}) ${endpointId}: ${newStatus}`); // Log the event on CallStats

      _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendLog(JSON.stringify({
        id: 'peer.conn.status',
        participant: endpointId,
        status: newStatus
      }));
      this.conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["PARTICIPANT_CONN_STATUS_CHANGED"], endpointId, newStatus);
    }
  }
  /**
   * Reset the postponed "connection interrupted" event which was previously
   * scheduled as a timeout on RTC 'onmute' event.
   *
   * @param {string} participantId - The participant for which the "connection
   * interrupted" timeout was scheduled.
   */


  clearTimeout(participantId) {
    if (this.trackTimers[participantId]) {
      window.clearTimeout(this.trackTimers[participantId]);
      this.trackTimers[participantId] = null;
    }
  }
  /**
   * Clears the timestamp of the RTC muted event for participant's video track
   * @param {string} participantId the id of the conference participant which
   * is the same as the Colibri endpoint ID of the video channel allocated for
   * the user on the videobridge.
   */


  clearRtcMutedTimestamp(participantId) {
    this.rtcMutedTimestamp[participantId] = null;
  }
  /**
   * Bind signalling mute event listeners for video {JitsiRemoteTrack} when
   * a new one is added to the conference.
   *
   * @param {JitsiTrack} remoteTrack - The {JitsiTrack} which is being added to
   * the conference.
   */


  onRemoteTrackAdded(remoteTrack) {
    if (!remoteTrack.isLocal() && remoteTrack.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__["VIDEO"]) {
      logger.debug(`Detector on remote track added for: ${remoteTrack.getParticipantId()}`);
      remoteTrack.on(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_MUTE_CHANGED"], this._onSignallingMuteChanged);
      remoteTrack.on(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_VIDEOTYPE_CHANGED"], videoType => this._onTrackVideoTypeChanged(remoteTrack, videoType));
    }
  }
  /**
   * Removes all event listeners bound to the remote video track and clears
   * any related timeouts.
   *
   * @param {JitsiRemoteTrack} remoteTrack - The remote track which is being
   * removed from the conference.
   */


  onRemoteTrackRemoved(remoteTrack) {
    if (!remoteTrack.isLocal() && remoteTrack.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__["VIDEO"]) {
      const endpointId = remoteTrack.getParticipantId();
      logger.debug(`Detector on remote track removed: ${endpointId}`);
      remoteTrack.off(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_MUTE_CHANGED"], this._onSignallingMuteChanged);
      this.clearTimeout(endpointId);
      this.clearRtcMutedTimestamp(endpointId);
      this.figureOutConnectionStatus(endpointId);
    }
  }
  /**
   * Checks if given participant's video is considered frozen.
   * @param {JitsiParticipant} participant - The participant.
   * @return {boolean} <tt>true</tt> if the video has frozen for given
   * participant or <tt>false</tt> when it's either not considered frozen
   * (yet) or if freeze detection is not supported by the current browser.
   *
   * FIXME merge this logic with NO_DATA_FROM_SOURCE event
   *       implemented in JitsiLocalTrack by extending the event to
   *       the remote track and allowing to set different timeout for
   *       local and remote tracks.
   *
   */


  isVideoTrackFrozen(participant) {
    if (!_browser__WEBPACK_IMPORTED_MODULE_4__["default"].supportsVideoMuteOnConnInterrupted()) {
      return false;
    }

    const id = participant.getId();
    const hasAnyVideoRTCMuted = participant.hasAnyVideoTrackWebRTCMuted();
    const rtcMutedTimestamp = this.rtcMutedTimestamp[id];

    const timeout = this._getVideoFrozenTimeout(id);

    return hasAnyVideoRTCMuted && typeof rtcMutedTimestamp === 'number' && Date.now() - rtcMutedTimestamp >= timeout;
  }
  /**
   * Goes over every participant and updates connectivity status.
   * Should be called when a parameter which affects all of the participants
   * is changed (P2P for example).
   */


  refreshConnectionStatusForAll() {
    const participants = this.conference.getParticipants();

    for (const participant of participants) {
      this.figureOutConnectionStatus(participant.getId());
    }
  }
  /**
   * Figures out (and updates) the current connectivity status for
   * the participant identified by the given id.
   *
   * @param {string} id - The participant's id (MUC nickname or Colibri endpoint ID).
   */


  figureOutConnectionStatus(id) {
    const participant = this.conference.getParticipantById(id);

    if (!participant) {
      // Probably the participant is no longer in the conference
      // (at the time of writing this code, participant is
      // detached from the conference and TRACK_REMOVED events are
      // fired),
      // so we don't care, but let's print a log message for debugging purposes.
      logger.debug(`figure out conn status - no participant for: ${id}`);
      return;
    }

    const inP2PMode = this.conference.isP2PActive();

    const isRestoringTimedOut = this._isRestoringTimedout(id);

    const audioOnlyMode = this.rtc.getLastN() === 0; // NOTE Overriding videoMuted to true for audioOnlyMode should disable
    // any detection based on video playback or the last N.

    const isVideoMuted = participant.isVideoMuted() || audioOnlyMode;
    const isVideoTrackFrozen = this.isVideoTrackFrozen(participant);
    const isInLastN = this.rtc.isInLastN(id);
    let isConnActiveByJvb = this.connStatusFromJvb[id];

    if (typeof isConnActiveByJvb !== 'boolean') {
      // If no status was received from the JVB it means that it's active
      // (the bridge does not send notification unless there is a problem)
      logger.debug('Assuming connection active by JVB - no notification');
      isConnActiveByJvb = true;
    }

    const newState = inP2PMode ? ParticipantConnectionStatusHandler._getNewStateForP2PMode(isVideoMuted, isVideoTrackFrozen) : ParticipantConnectionStatusHandler._getNewStateForJvbMode(isConnActiveByJvb, isInLastN, isRestoringTimedOut, isVideoMuted, isVideoTrackFrozen); // if the new state is not restoring clear timers and timestamps
    // that we use to track the restoring state

    if (newState !== ParticipantConnectionStatus.RESTORING) {
      this._clearRestoringTimer(id);
    }

    logger.debug(`Figure out conn status for ${id}, is video muted: ${isVideoMuted} is active(jvb): ${isConnActiveByJvb} video track frozen: ${isVideoTrackFrozen} p2p mode: ${inP2PMode} is in last N: ${isInLastN} currentStatus => newStatus: ${participant.getConnectionStatus()} => ${newState}`);
    const oldConnectionStatus = this.connectionStatusMap[id] || {}; // Send an analytics event (guard on either the p2p flag or the connection status has changed
    // since the last time this code block run).

    if (!('p2p' in oldConnectionStatus) || !('connectionStatus' in oldConnectionStatus) || oldConnectionStatus.p2p !== inP2PMode || oldConnectionStatus.connectionStatus !== newState) {
      const nowMs = Date.now();
      this.maybeSendParticipantConnectionStatusEvent(id, nowMs);
      this.connectionStatusMap[id] = _objectSpread({}, oldConnectionStatus, {
        connectionStatus: newState,
        p2p: inP2PMode,
        startedMs: nowMs
      }); // sometimes (always?) we're late to hook the TRACK_VIDEOTYPE_CHANGED event and the
      // video type is not in oldConnectionStatus.

      if (!('videoType' in this.connectionStatusMap[id])) {
        const videoTracks = participant.getTracksByMediaType(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__["VIDEO"]);

        if (Array.isArray(videoTracks) && videoTracks.length !== 0) {
          this.connectionStatusMap[id].videoType = videoTracks[0].videoType;
        }
      }
    }

    this._changeConnectionStatus(participant, newState);
  }
  /**
   * Computes the duration of the current connection status for the participant with the specified id (i.e. 15 seconds
   * in the INTERRUPTED state) and sends a participant connection status event.
   * @param {string} id - The jid of the participant.
   * @param {Number} nowMs - The current time (in millis).
   * @returns {void}
   */


  maybeSendParticipantConnectionStatusEvent(id, nowMs) {
    const participantConnectionStatus = this.connectionStatusMap[id];

    if (participantConnectionStatus && 'startedMs' in participantConnectionStatus && 'videoType' in participantConnectionStatus && 'connectionStatus' in participantConnectionStatus && 'p2p' in participantConnectionStatus) {
      participantConnectionStatus.value = nowMs - participantConnectionStatus.startedMs;
      _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_7__["createParticipantConnectionStatusEvent"])(participantConnectionStatus));
    }
  }
  /**
   * On change in Last N set check all leaving and entering participants to
   * change their corresponding statuses.
   *
   * @param {Array<string>} leavingLastN - The array of ids leaving lastN.
   * @param {Array<string>} enteringLastN - The array of ids entering lastN.
   * @private
   */


  _onLastNChanged(leavingLastN = [], enteringLastN = []) {
    const now = Date.now();
    logger.debug('leaving/entering lastN', leavingLastN, enteringLastN, now);

    for (const id of leavingLastN) {
      this.enteredLastNTimestamp.delete(id);

      this._clearRestoringTimer(id);

      this.figureOutConnectionStatus(id);
    }

    for (const id of enteringLastN) {
      // store the timestamp this id is entering lastN
      this.enteredLastNTimestamp.set(id, now);
      this.figureOutConnectionStatus(id);
    }
  }
  /**
   * Clears the restoring timer for participant's video track and the
   * timestamp for entering lastN.
   *
   * @param {string} participantId - The id of the conference participant which
   * is the same as the Colibri endpoint ID of the video channel allocated for
   * the user on the videobridge.
   */


  _clearRestoringTimer(participantId) {
    const rTimer = this.restoringTimers.get(participantId);

    if (rTimer) {
      clearTimeout(rTimer);
      this.restoringTimers.delete(participantId);
    }
  }
  /**
   * Checks whether a track had stayed enough in restoring state, compares
   * current time and the time the track entered in lastN. If it hasn't
   * timedout and there is no timer added, add new timer in order to give it
   * more time to become active or mark it as interrupted on next check.
   *
   * @param {string} participantId - The id of the conference participant which
   * is the same as the Colibri endpoint ID of the video channel allocated for
   * the user on the videobridge.
   * @returns {boolean} <tt>true</tt> if the track was in restoring state
   * more than the timeout ({@link DEFAULT_RESTORING_TIMEOUT}.) in order to
   * set its status to interrupted.
   * @private
   */


  _isRestoringTimedout(participantId) {
    const enteredLastNTimestamp = this.enteredLastNTimestamp.get(participantId);

    if (enteredLastNTimestamp && Date.now() - enteredLastNTimestamp >= DEFAULT_RESTORING_TIMEOUT) {
      return true;
    } // still haven't reached timeout, if there is no timer scheduled,
    // schedule one so we can track the restoring state and change it after
    // reaching the timeout


    const rTimer = this.restoringTimers.get(participantId);

    if (!rTimer) {
      this.restoringTimers.set(participantId, setTimeout(() => this.figureOutConnectionStatus(participantId), DEFAULT_RESTORING_TIMEOUT));
    }

    return false;
  }
  /**
   * Sends a last/final participant connection status event for the participant that left the conference.
   * @param {string} id - The id of the participant that left the conference.
   * @returns {void}
   */


  onUserLeft(id) {
    this.maybeSendParticipantConnectionStatusEvent(id, Date.now());
    delete this.connectionStatusMap[id];
  }
  /**
   * Handles RTC 'onmute' event for the video track.
   *
   * @param {JitsiRemoteTrack} track - The video track for which 'onmute' event
   * will be processed.
   */


  onTrackRtcMuted(track) {
    const participantId = track.getParticipantId();
    const participant = this.conference.getParticipantById(participantId);
    logger.debug(`Detector track RTC muted: ${participantId}`, Date.now());

    if (!participant) {
      logger.error(`No participant for id: ${participantId}`);
      return;
    }

    this.rtcMutedTimestamp[participantId] = Date.now();

    if (!participant.isVideoMuted()) {
      // If the user is not muted according to the signalling we'll give
      // it some time, before the connection interrupted event is
      // triggered.
      this.clearTimeout(participantId); // The timeout is reduced when user is not in the last N

      const timeout = this._getVideoFrozenTimeout(participantId);

      this.trackTimers[participantId] = window.setTimeout(() => {
        logger.debug(`Set RTC mute timeout for: ${participantId}\
                     of ${timeout} ms`);
        this.clearTimeout(participantId);
        this.figureOutConnectionStatus(participantId);
      }, timeout);
    }
  }
  /**
   * Handles RTC 'onunmute' event for the video track.
   *
   * @param {JitsiRemoteTrack} track - The video track for which 'onunmute'
   * event will be processed.
   */


  onTrackRtcUnmuted(track) {
    const participantId = track.getParticipantId();
    logger.debug(`Detector track RTC unmuted: ${participantId}`, Date.now());
    this.clearTimeout(participantId);
    this.clearRtcMutedTimestamp(participantId);
    this.figureOutConnectionStatus(participantId);
  }
  /**
   * Here the signalling "mute"/"unmute" events are processed.
   *
   * @param {JitsiRemoteTrack} track - The remote video track for which
   * the signalling mute/unmute event will be processed.
   */


  onSignallingMuteChanged(track) {
    const participantId = track.getParticipantId();
    logger.debug(`Detector on track signalling mute changed: ${participantId}`, track.isMuted());
    this.figureOutConnectionStatus(participantId);
  }
  /**
   * Sends a participant connection status event as a result of the video type
   * changing.
   * @param {JitsiRemoteTrack} track - The track.
   * @param {VideoType} type - The video type.
   * @returns {void}
   */


  onTrackVideoTypeChanged(track, type) {
    const id = track.getParticipantId();
    const nowMs = Date.now();
    this.maybeSendParticipantConnectionStatusEvent(id, nowMs);
    this.connectionStatusMap[id] = _objectSpread({}, this.connectionStatusMap[id] || {}, {
      videoType: type,
      startedMs: nowMs
    });
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\connectivity\\ParticipantConnectionStatus.js"))

/***/ }),

/***/ "./modules/detection/ActiveDeviceDetector.js":
/*!***************************************************!*\
  !*** ./modules/detection/ActiveDeviceDetector.js ***!
  \***************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return getActiveAudioDevice; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./JitsiTrackEvents.js");
/* harmony import */ var _RTC_RTC__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../RTC/RTC */ "./modules/RTC/RTC.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");




const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename); // If after 3000 ms the detector did not find any active devices consider that there aren't any usable ones available
// i.e. audioLevel > 0.008

const DETECTION_TIMEOUT = 3000;
/**
 * Go through all audio devices on the system and return one that is active, i.e. has audio signal.
 *
 * @returns Promise<Object> - Object containing information about the found device.
 */

function getActiveAudioDevice() {
  return new Promise(resolve => {
    _RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].enumerateDevices(devices => {
      const audioDevices = devices.filter(device => device.kind === 'audioinput');
      const devicePromiseArray = [];

      for (const micDevice of audioDevices) {
        const devicePromise = _RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].obtainAudioAndVideoPermissions({
          devices: ['audio'],
          micDeviceId: micDevice.deviceId
        }).then(tracks => {
          // We expect a single device to be available when obtained from obtainAudioAndVideoPermissions
          // that's  why only take p.value[0].
          const track = tracks[0];
          const originalStream = track.getOriginalStream();
          _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__["default"].startLocalStats(originalStream, track.setAudioLevel.bind(track));
          track.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_1__["LOCAL_TRACK_STOPPED"], () => {
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__["default"].stopLocalStats(originalStream);
          });
          return track;
        });
        devicePromiseArray.push(devicePromise);
      }

      Promise.allSettled(devicePromiseArray).then(outcomeArray => {
        const successfulPromises = outcomeArray.filter(p => p.status === 'fulfilled');
        const rejectedPromises = outcomeArray.filter(p => p.status === 'rejected');
        const availableDevices = successfulPromises.map(p => p.value);
        const rejectReasons = rejectedPromises.map(p => p.value);

        for (const reason of rejectReasons) {
          logger.error('Failed to acquire audio device with error: ', reason);
        } // Setup event handlers for monitored devices.


        for (const device of availableDevices) {
          device.on(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_1__["TRACK_AUDIO_LEVEL_CHANGED"], audioLevel => {
            // This is a very naive approach but works, a more accurate one would be to use rnnoise in
            // order to limit  the number of false positives. The 0.008 constant is due to how
            // LocalStatsCollector from lib-jitsi-meet publishes audio-levels, in this case 0.008 denotes //
            // no input.
            if (audioLevel > 0.008) {
              stopActiveDevices(availableDevices);
              resolve({
                deviceId: device.deviceId,
                deviceLabel: device.track.label
              });
            }
          });
        } // Cancel the detection in case no devices was found with audioLevel > 0 in the set timeout.


        setTimeout(() => {
          stopActiveDevices(availableDevices);
          resolve({
            deviceId: '',
            deviceLabel: ''
          });
        }, DETECTION_TIMEOUT);
      });
    });
  });
}
/**
 * Stop the streams of the provided JitsiLocalTracks.
 *
 * @param {Array<JitsiLocalTrack>} deviceList - Array of JitsiLocalTracks to stop.
 * @returns {void}
 */

function stopActiveDevices(deviceList) {
  for (const device of deviceList) {
    device.stopStream();
  }
}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\detection\\ActiveDeviceDetector.js"))

/***/ }),

/***/ "./modules/detection/DetectionEvents.js":
/*!**********************************************!*\
  !*** ./modules/detection/DetectionEvents.js ***!
  \**********************************************/
/*! exports provided: DETECTOR_STATE_CHANGE, AUDIO_INPUT_STATE_CHANGE, NO_AUDIO_INPUT, VAD_NOISY_DEVICE, VAD_REPORT_PUBLISHED, VAD_SCORE_PUBLISHED, VAD_TALK_WHILE_MUTED */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DETECTOR_STATE_CHANGE", function() { return DETECTOR_STATE_CHANGE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AUDIO_INPUT_STATE_CHANGE", function() { return AUDIO_INPUT_STATE_CHANGE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NO_AUDIO_INPUT", function() { return NO_AUDIO_INPUT; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VAD_NOISY_DEVICE", function() { return VAD_NOISY_DEVICE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VAD_REPORT_PUBLISHED", function() { return VAD_REPORT_PUBLISHED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VAD_SCORE_PUBLISHED", function() { return VAD_SCORE_PUBLISHED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VAD_TALK_WHILE_MUTED", function() { return VAD_TALK_WHILE_MUTED; });
/**
 * Event triggered by a audio detector indicating that its active state has changed from active to inactive or vice
 * versa.
 * @event
 * @type {boolean} - true when service has changed to active false otherwise.
 */
const DETECTOR_STATE_CHANGE = 'detector_state_change';
/** Event triggered by {@link NoAudioSignalDetector} when the local audio device associated with a JitsiConference
 * starts receiving audio levels with the value of 0 meaning no audio is being captured on that device, or when
 * it starts receiving audio levels !== 0 after being in a state of no audio.
 * @event
 * @type {boolean} - true when the current conference audio track has audio input false otherwise.
 */

const AUDIO_INPUT_STATE_CHANGE = 'audio_input_state_changed';
/** Event triggered by NoAudioSignalDetector when the local audio device associated with a JitsiConference goes silent
 * for a period of time, meaning that the device is either broken or hardware/software muted.
 * @event
 * @type {void}
 */

const NO_AUDIO_INPUT = 'no_audio_input_detected';
/**
 *  Event generated by {@link VADNoiseDetection} when the tracked device is considered noisy.
 *  @event
 *  @type {Object}
 */

const VAD_NOISY_DEVICE = 'detection.vad_noise_device';
/**
 * Event generated by VADReportingService when if finishes creating a VAD report for the monitored devices.
 * The generated objects are of type Array<Object>, one score for each monitored device.
 * @event VAD_REPORT_PUBLISHED
 * @type Array<Object> with the following structure:
 * @property {Date} timestamp - Timestamp at which the compute took place.
 * @property {number} avgVAD - Average VAD score over monitored period of time.
 * @property {string} deviceId - Associate local audio device ID.
 */

const VAD_REPORT_PUBLISHED = 'vad-report-published';
/**
 * Event generated by {@link TrackVADEmitter} when PCM sample VAD score is available.
 *
 * @event
 * @type {Object}
 * @property {Date}   timestamp - Exact time at which processed PCM sample was generated.
 * @property {number} score - VAD score on a scale from 0 to 1 (i.e. 0.7)
 * @property {Float32Array} pcmData - Raw PCM data with which the VAD score was calculated.
 * @property {string} deviceId - Device id of the associated track.
 */

const VAD_SCORE_PUBLISHED = 'detection.vad_score_published';
/**
 *  Event generated by {@link VADTalkMutedDetection} when a user is talking while the mic is muted.
 *
 *  @event
 *  @type {Object}
 */

const VAD_TALK_WHILE_MUTED = 'detection.vad_talk_while_muted';

/***/ }),

/***/ "./modules/detection/NoAudioSignalDetection.js":
/*!*****************************************************!*\
  !*** ./modules/detection/NoAudioSignalDetection.js ***!
  \*****************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return NoAudioSignalDetection; });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DetectionEvents */ "./modules/detection/DetectionEvents.js");


 // We wait a certain time interval for constant silence input from the current device to account for
// potential abnormalities and for a better use experience i.e. don't generate event the instant
// an audio track is added to the tcr.
// Potential improvement - add this as a configurable parameter.

const SILENCE_PERIOD_MS = 4000;
/**
 * Detect if there is no audio input on the current TraceAblePeerConnection selected track. The no audio
 * state must be constant for a configured amount of time in order for the event to be triggered.
 * @fires DetectionEvents.AUDIO_INPUT_STATE_CHANGE
 * @fires DetectionEvents.NO_AUDIO_INPUT
 */

class NoAudioSignalDetection extends events__WEBPACK_IMPORTED_MODULE_0___default.a {
  /**
   * Creates new NoAudioSignalDetection.
   *
   * @param conference the JitsiConference instance that created us.
   * @constructor
   */
  constructor(conference) {
    super();
    this._conference = conference;
    this._timeoutTrigger = null;
    this._hasAudioInput = null;
    conference.statistics.addAudioLevelListener(this._audioLevel.bind(this));
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["TRACK_ADDED"], this._trackAdded.bind(this));
  }
  /**
   * Clear the timeout state.
   */


  _clearTriggerTimeout() {
    clearTimeout(this._timeoutTrigger);
    this._timeoutTrigger = null;
  }
  /**
   * Generated event triggered by a change in the current conference audio input state.
   *
   * @param {*} audioLevel - The audio level of the ssrc.
   * @fires DetectionEvents.AUDIO_INPUT_STATE_CHANGE
   */


  _handleAudioInputStateChange(audioLevel) {
    // Current audio input state of the active local track in the conference, true for audio input false for no
    // audio input.
    const status = audioLevel !== 0; // If this is the first audio event picked up or the current status is different from the previous trigger
    // the event.

    if (this._hasAudioInput === null || this._hasAudioInput !== status) {
      this._hasAudioInput = status;
      this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__["AUDIO_INPUT_STATE_CHANGE"], this._hasAudioInput);
    }
  }
  /**
   * Generate event triggered by a prolonged period of no audio input.
   *
   * @param {number} audioLevel - The audio level of the ssrc.
   * @fires DetectionEvents.NO_AUDIO_INPUT
   */


  _handleNoAudioInputDetection(audioLevel) {
    if (this._eventFired) {
      return;
    }

    if (audioLevel === 0 && !this._timeoutTrigger) {
      this._timeoutTrigger = setTimeout(() => {
        this._eventFired = true;
        this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__["NO_AUDIO_INPUT"]);
      }, SILENCE_PERIOD_MS);
    } else if (audioLevel !== 0 && this._timeoutTrigger) {
      this._clearTriggerTimeout();
    }
  }
  /**
   * Receives audio level events for all send and receive streams on the current TraceablePeerConnection.
   *
   * @param {TraceablePeerConnection} tpc - TraceablePeerConnection of the owning conference.
   * @param {number} ssrc - The synchronization source identifier (SSRC) of the endpoint/participant/stream
   * being reported.
   * @param {number} audioLevel - The audio level of the ssrc.
   * @param {boolean} isLocal - true for local/send streams or false for remote/receive streams.
   */


  _audioLevel(tpc, ssrc, audioLevel, isLocal) {
    // We are interested in the local audio streams
    if (!isLocal || !this._audioTrack) {
      return;
    } // Get currently active local tracks from the TraceablePeerConnection


    const localSSRCs = tpc.localSSRCs.get(this._audioTrack.rtcId); // Only target the current active track in the tpc. For some reason audio levels for previous
    // devices are also picked up from the PeerConnection so we filter them out.

    if (!localSSRCs || !localSSRCs.ssrcs.includes(ssrc)) {
      return;
    } // First handle audio input state change. In case the state changed to no input the no audio input event
    // can try to fire again.


    this._handleAudioInputStateChange(audioLevel);

    this._handleNoAudioInputDetection(audioLevel);
  }
  /**
   * Notifies NoAudioSignalDetection that a JitsiTrack was added to the associated JitsiConference.
   * Only take into account local audio tracks.
   *
   * @param {JitsiTrack} track - The added JitsiTrack.
   */


  _trackAdded(track) {
    if (track.isLocalAudioTrack()) {
      // Reset state for the new track.
      this._audioTrack = track;
      this._eventFired = false;

      this._clearTriggerTimeout();
    }
  }

}

/***/ }),

/***/ "./modules/detection/P2PDominantSpeakerDetection.js":
/*!**********************************************************!*\
  !*** ./modules/detection/P2PDominantSpeakerDetection.js ***!
  \**********************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return P2PDominantSpeakerDetection; });
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__);


/**
 * The value which we use to say, every sound over this threshold
 * is talking on the mic.
 * @type {number}
 */

const SPEECH_DETECT_THRESHOLD = 0.6;
/**
 * The <tt>P2PDominantSpeakerDetection</tt> is activated only when p2p is
 * currently used.
 * Listens for changes in the audio level changes of the local p2p audio track
 * or remote p2p one and fires dominant speaker events to be able to use
 * features depending on those events (speaker stats), to make them work without
 * the video bridge.
 */

class P2PDominantSpeakerDetection {
  /**
   * Creates P2PDominantSpeakerDetection
   * @param conference the JitsiConference instance that created us.
   * @constructor
   */
  constructor(conference) {
    this.conference = conference;
    conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__["TRACK_AUDIO_LEVEL_CHANGED"], this._audioLevel.bind(this));
    this.myUserID = this.conference.myUserId();
  }
  /**
   * Receives audio level events for all streams in the conference.
   *
   * @param {String} id - The participant id
   * @param {number} audioLevel - The audio level.
   */


  _audioLevel(id, audioLevel) {
    // we do not process if p2p is not active
    // or audio level is under certain threshold
    // or if the audio level is for local audio track which is muted
    if (!this.conference.isP2PActive() || audioLevel <= SPEECH_DETECT_THRESHOLD || id === this.myUserID && this.conference.getLocalAudioTrack().isMuted()) {
      return;
    }

    this.conference.rtc.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1___default.a.DOMINANT_SPEAKER_CHANGED, id);
  }

}

/***/ }),

/***/ "./modules/detection/TalkMutedDetection.js":
/*!*************************************************!*\
  !*** ./modules/detection/TalkMutedDetection.js ***!
  \*************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return TalkMutedDetection; });
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");

/**
 * The value which we use to say, every sound over this threshold
 * is talking on the mic.
 * @type {number}
 */

const SPEECH_DETECT_THRESHOLD = 0.6;
/**
 * Detect user trying to speek while is locally muted and fires an event.
 */

class TalkMutedDetection {
  /**
   * Creates TalkMutedDetection
   * @param conference the JitsiConference instance that created us.
   * @param callback the callback to call when detected that the local user is
   * talking while her microphone is muted.
   * @constructor
   */
  constructor(conference, callback) {
    /**
     * The callback to call when detected that the local user is talking
     * while her microphone is muted.
     *
     * @private
     */
    this._callback = callback;
    /**
     * The indicator which determines whether <tt>callback</tt> has been
     * invoked for the current local audio track of <tt>conference</tt> so
     * that it is invoked once only.
     *
     * @private
     */

    this._eventFired = false; // XXX I went back and forth on the subject of where to put the access
    // to statistics. On the one had, (1) statistics is likely intended to
    // be private to conference and (2) there is a desire to keep the
    // dependencies of modules to the minimum (i.e. not have
    // TalkMutedDetection depend on statistics). On the other hand, (1)
    // statistics is technically not private because
    // JitsiConferenceEventManager accesses it and (2) TalkMutedDetection
    // works exactly because it knows that there are no audio levels for
    // JitsiLocalTrack but there are audio levels for the local participant
    // through statistics.

    conference.statistics.addAudioLevelListener(this._audioLevel.bind(this));
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__["TRACK_MUTE_CHANGED"], this._trackMuteChanged.bind(this));
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__["TRACK_ADDED"], this._trackAdded.bind(this));
  }
  /* eslint-disable max-params */

  /**
   * Receives audio level events for all send and receive streams.
   *
   * @param {TraceablePeerConnection} pc - WebRTC PeerConnection object of the
   * @param {number} ssrc - The synchronization source identifier (SSRC) of
   * the endpoint/participant/stream being reported.
   * @param {number} audioLevel - The audio level of <tt>ssrc</tt>.
   * @param {boolean} isLocal - <tt>true</tt> if <tt>ssrc</tt> represents a
   * local/send stream or <tt>false</tt> for a remote/receive stream.
   */


  _audioLevel(tpc, ssrc, audioLevel, isLocal) {
    // We are interested in the local audio stream only and if event is not
    // sent yet.
    if (!isLocal || !this.audioTrack || this._eventFired) {
      return;
    }

    if (this.audioTrack.isMuted() && audioLevel > SPEECH_DETECT_THRESHOLD) {
      this._eventFired = true;

      this._callback();
    }
  }
  /* eslint-enable max-params */

  /**
   * Determines whether a specific {@link JitsiTrack} represents a local audio
   * track.
   *
   * @param {JitsiTrack} track - The <tt>JitsiTrack</tt> to be checked whether
   * it represents a local audio track.
   * @private
   * @return {boolean} - <tt>true</tt> if the specified <tt>track</tt>
   * represents a local audio track; otherwise, <tt>false</tt>.
   */


  _isLocalAudioTrack(track) {
    return track.isAudioTrack() && track.isLocal();
  }
  /**
   * Notifies this <tt>TalkMutedDetection</tt> that a {@link JitsiTrack} was
   * added to the associated {@link JitsiConference}. Looks for the local
   * audio track only.
   *
   * @param {JitsiTrack} track - The added <tt>JitsiTrack</tt>.
   * @private
   */


  _trackAdded(track) {
    if (this._isLocalAudioTrack(track)) {
      this.audioTrack = track;
    }
  }
  /**
   * Notifies this <tt>TalkMutedDetection</tt> that the mute state of a
   * {@link JitsiTrack} has changed. Looks for the local audio track only.
   *
   * @param {JitsiTrack} track - The <tt>JitsiTrack</tt> whose mute state has
   * changed.
   * @private
   */


  _trackMuteChanged(track) {
    if (this._isLocalAudioTrack(track) && track.isMuted()) {
      this._eventFired = false;
    }
  }

}

/***/ }),

/***/ "./modules/detection/TrackVADEmitter.js":
/*!**********************************************!*\
  !*** ./modules/detection/TrackVADEmitter.js ***!
  \**********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return TrackVADEmitter; });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _RTC_RTC__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../RTC/RTC */ "./modules/RTC/RTC.js");
/* harmony import */ var _webaudio_WebAudioUtils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../webaudio/WebAudioUtils */ "./modules/webaudio/WebAudioUtils.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./DetectionEvents */ "./modules/detection/DetectionEvents.js");




/**
 * Connects an audio JitsiLocalTrack to a vadProcessor using WebAudio ScriptProcessorNode.
 * Once an object is created audio from the local track flows through the ScriptProcessorNode as raw PCM.
 * The PCM is processed by the injected vad module and a voice activity detection score is obtained, the
 * score is published to consumers via an EventEmitter.
 * After work is done with this service the destroy method needs to be called for a proper cleanup.
 *
 * @fires VAD_SCORE_PUBLISHED
 */

class TrackVADEmitter extends events__WEBPACK_IMPORTED_MODULE_0___default.a {
  /**
   * Constructor.
   *
   * @param {number} procNodeSampleRate - Sample rate of the ScriptProcessorNode. Possible values  256, 512, 1024,
   *  2048, 4096, 8192, 16384. Passing other values will default to closes neighbor.
   * @param {Object} vadProcessor - VAD processor that allows us to calculate VAD score for PCM samples.
   * @param {JitsiLocalTrack} jitsiLocalTrack - JitsiLocalTrack corresponding to micDeviceId.
   */
  constructor(procNodeSampleRate, vadProcessor, jitsiLocalTrack) {
    super();
    /**
     * Sample rate of the ScriptProcessorNode.
     */

    this._procNodeSampleRate = procNodeSampleRate;
    /**
     * VAD Processor that allows us to calculate VAD score for PCM samples
     */

    this._vadProcessor = vadProcessor;
    /**
     * The JitsiLocalTrack instance.
     */

    this._localTrack = jitsiLocalTrack;
    /**
     * Buffer to hold residue PCM resulting after a ScriptProcessorNode callback
     */

    this._bufferResidue = new Float32Array([]);
    /**
     * The AudioContext instance with the preferred sample frequency.
     */

    this._audioContext = Object(_webaudio_WebAudioUtils__WEBPACK_IMPORTED_MODULE_2__["createAudioContext"])({
      sampleRate: vadProcessor.getRequiredPCMFrequency()
    });
    /**
     * PCM Sample size expected by the VAD Processor instance. We cache it here as this value is used extensively,
     * saves a couple of function calls.
     */

    this._vadSampleSize = vadProcessor.getSampleLength();
    /**
     * Event listener function that will be called by the ScriptProcessNode with raw PCM data, depending on the set
     * sample rate.
     */

    this._onAudioProcess = this._onAudioProcess.bind(this);

    this._initializeAudioContext();
  }
  /**
   * Factory method that sets up all the necessary components for the creation of the TrackVADEmitter.
   *
   * @param {string} micDeviceId - Target microphone device id.
   * @param {number} procNodeSampleRate - Sample rate of the proc node.
   * @param {Object} vadProcessor -Module that calculates the voice activity score for a certain audio PCM sample.
   * The processor needs to implement the following functions:
   * - <tt>getSampleLength()</tt> - Returns the sample size accepted by getSampleLength.
   * - <tt>getRequiredPCMFrequency()</tt> - Returns the PCM frequency at which the processor operates.
   * - <tt>calculateAudioFrameVAD(pcmSample)</tt> - Process a 32 float pcm sample of getSampleLength size.
   * @returns {Promise<TrackVADEmitter>} - Promise resolving in a new instance of TrackVADEmitter.
   */


  static create(micDeviceId, procNodeSampleRate, vadProcessor) {
    return _RTC_RTC__WEBPACK_IMPORTED_MODULE_1__["default"].obtainAudioAndVideoPermissions({
      devices: ['audio'],
      micDeviceId
    }).then(localTrack => {
      // We only expect one audio track when specifying a device id.
      if (!localTrack[0]) {
        throw new Error(`Failed to create jitsi local track for device id: ${micDeviceId}`);
      }

      return new TrackVADEmitter(procNodeSampleRate, vadProcessor, localTrack[0]); // We have no exception handling at this point as there is nothing to clean up, the vadProcessor
      // life cycle is handled by whoever created this instance.
    });
  }
  /**
   * Sets up the audio graph in the AudioContext.
   *
   * @returns {void}
   */


  _initializeAudioContext() {
    this._audioSource = this._audioContext.createMediaStreamSource(this._localTrack.stream); // TODO AudioProcessingNode is deprecated in the web audio specifications and the recommended replacement
    // is audio worklet, however at the point of implementation AudioProcessingNode was still de de facto way
    // of achieving this functionality and supported in all major browsers as opposed to audio worklet which
    // was only available in Chrome. This todo is just a reminder that we should replace AudioProcessingNode
    // with audio worklet when it's mature enough and has more browser support.
    // We don't need stereo for determining the VAD score so we create a single channel processing node.

    this._audioProcessingNode = this._audioContext.createScriptProcessor(this._procNodeSampleRate, 1, 1);
  }
  /**
   * ScriptProcessorNode callback, the input parameters contains the PCM audio that is then sent to rnnoise.
   * Rnnoise only accepts PCM samples of 480 bytes whereas the webaudio processor node can't sample at a multiple
   * of 480 thus after each _onAudioProcess callback there will remain and PCM buffer residue equal
   * to _procNodeSampleRate / 480 which will be added to the next sample buffer and so on.\
   *
   *
   * @param {AudioProcessingEvent} audioEvent - Audio event.
   * @returns {void}
   * @fires VAD_SCORE_PUBLISHED
   */


  _onAudioProcess(audioEvent) {
    // Prepend the residue PCM buffer from the previous process callback.
    const inData = audioEvent.inputBuffer.getChannelData(0);
    const completeInData = [...this._bufferResidue, ...inData];
    const sampleTimestamp = Date.now();
    let i = 0;

    for (; i + this._vadSampleSize < completeInData.length; i += this._vadSampleSize) {
      const pcmSample = completeInData.slice(i, i + this._vadSampleSize); // The VAD processor might change the values inside the array so we make a copy.

      const vadScore = this._vadProcessor.calculateAudioFrameVAD(pcmSample.slice());

      this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__["VAD_SCORE_PUBLISHED"], {
        timestamp: sampleTimestamp,
        score: vadScore,
        pcmData: pcmSample,
        deviceId: this._localTrack.getDeviceId()
      });
    }

    this._bufferResidue = completeInData.slice(i, completeInData.length);
  }
  /**
   * Connects the nodes in the AudioContext to start the flow of audio data.
   *
   * @returns {void}
   */


  _connectAudioGraph() {
    this._audioProcessingNode.onaudioprocess = this._onAudioProcess;

    this._audioSource.connect(this._audioProcessingNode);

    this._audioProcessingNode.connect(this._audioContext.destination);
  }
  /**
   * Disconnects the nodes in the AudioContext.
   *
   * @returns {void}
   */


  _disconnectAudioGraph() {
    // Even thought we disconnect the processing node it seems that some callbacks remain queued,
    // resulting in calls with and uninitialized context.
    // eslint-disable-next-line no-empty-function
    this._audioProcessingNode.onaudioprocess = () => {};

    this._audioProcessingNode.disconnect();

    this._audioSource.disconnect();
  }
  /**
   * Cleanup potentially acquired resources.
   *
   * @returns {void}
   */


  _cleanupResources() {
    this._disconnectAudioGraph();

    this._localTrack.stopStream();
  }
  /**
   * Get the associated track device ID.
   *
   * @returns {string}
   */


  getDeviceId() {
    return this._localTrack.getDeviceId();
  }
  /**
   * Get the associated track label.
   *
   * @returns {string}
   */


  getTrackLabel() {
    return this._localTrack.getDeviceLabel();
  }
  /**
   * Start the emitter by connecting the audio graph.
   *
   * @returns {void}
   */


  start() {
    this._connectAudioGraph();
  }
  /**
   * Stops the emitter by disconnecting the audio graph.
   *
   * @returns {void}
   */


  stop() {
    this._disconnectAudioGraph();

    this._bufferResidue = [];
  }
  /**
   * Destroy TrackVADEmitter instance (release resources and stop callbacks).
   *
   * @returns {void}
   */


  destroy() {
    if (this._destroyed) {
      return;
    }

    this._cleanupResources();

    this._destroyed = true;
  }

}

/***/ }),

/***/ "./modules/detection/VADAudioAnalyser.js":
/*!***********************************************!*\
  !*** ./modules/detection/VADAudioAnalyser.js ***!
  \***********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return VADAudioAnalyser; });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./DetectionEvents */ "./modules/detection/DetectionEvents.js");
/* harmony import */ var _TrackVADEmitter__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./TrackVADEmitter */ "./modules/detection/TrackVADEmitter.js");





const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__["getLogger"])(__filename);
/**
 * Sample rate of TrackVADEmitter, it defines how many audio samples are processed at a time.
 * @type {number}
 */

const VAD_EMITTER_SAMPLE_RATE = 4096;
/**
 * Connects a TrackVADEmitter to the target conference local audio track and manages various services that use
 * the data to produce audio analytics (VADTalkMutedDetection and VADNoiseDetection).
 */

class VADAudioAnalyser extends events__WEBPACK_IMPORTED_MODULE_0__["EventEmitter"] {
  /**
   * Creates <tt>VADAudioAnalyser</tt>
   * @param {JitsiConference} conference - JitsiConference instance that created us.
   * @param {Object} createVADProcessor - Function that creates a Voice activity detection processor. The processor
   * needs to implement the following functions:
   * - <tt>getSampleLength()</tt> - Returns the sample size accepted by getSampleLength.
   * - <tt>getRequiredPCMFrequency()</tt> - Returns the PCM frequency at which the processor operates.
   * - <tt>calculateAudioFrameVAD(pcmSample)</tt> - Process a 32 float pcm sample of getSampleLength size.
   * @constructor
   */
  constructor(conference, createVADProcessor) {
    super();
    /**
     * Member function that instantiates a VAD processor.
     */

    this._createVADProcessor = createVADProcessor;
    /**
     * Current {@link TrackVADEmitter}. VAD Emitter uses a {@link JitsiLocalTrack} and VAD processor to generate
     * period voice probability scores.
     */

    this._vadEmitter = null;
    /**
     * Current state of the _vadEmitter
     */

    this._isVADEmitterRunning = false;
    /**
     * Array of currently attached VAD processing services.
     */

    this._detectionServices = [];
    /**
     * Promise used to chain create and destroy operations associated with TRACK_ADDED and TRACK_REMOVED events
     * coming from the conference.
     * Because we have an async created component (VAD Processor) we need to make sure that it's initialized before
     * we destroy it ( when changing the device for instance), or when we use it from an external point of entry
     * i.e. (TRACK_MUTE_CHANGED event callback).
     */

    this._vadInitTracker = Promise.resolve();
    /**
     * Listens for {@link TrackVADEmitter} events and processes them.
     */

    this._processVADScore = this._processVADScore.bind(this);
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_ADDED"], this._trackAdded.bind(this));
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_REMOVED"], this._trackRemoved.bind(this));
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__["TRACK_MUTE_CHANGED"], this._trackMuteChanged.bind(this));
  }
  /**
   * Attach a VAD detector service to the analyser and handle it's state changes.
   *
   * @param {Object} vadTMDetector
   */


  addVADDetectionService(vadService) {
    this._detectionServices.push(vadService);

    vadService.on(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__["DETECTOR_STATE_CHANGE"], () => {
      // When the state of a detector changes check if there are any active detectors attached so that
      // the _vadEmitter doesn't run needlessly.
      const activeDetector = this._detectionServices.filter(detector => detector.isActive() === true); // If there are no active detectors running and the vadEmitter is running then stop the emitter as it is
      // uses a considerable amount of CPU. Otherwise start the service if it's stopped and there is a detector
      // that needs it.


      if (!activeDetector.length && this._isVADEmitterRunning) {
        this._stopVADEmitter();
      } else if (!this._isVADEmitterRunning) {
        this._startVADEmitter();
      }
    });
  }
  /**
   * Start the {@link TrackVADEmitter} and attach the event listener.
   * @returns {void}
   */


  _startVADEmitter() {
    this._vadEmitter.on(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__["VAD_SCORE_PUBLISHED"], this._processVADScore);

    this._vadEmitter.start();

    this._isVADEmitterRunning = true;
  }
  /**
   * Stop the {@link TrackVADEmitter} and detach the event listener.
   * @returns {void}
   */


  _stopVADEmitter() {
    this._vadEmitter.removeListener(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__["VAD_SCORE_PUBLISHED"], this._processVADScore);

    this._vadEmitter.stop();

    this._isVADEmitterRunning = false;
  }
  /**
   * Listens for {@link TrackVADEmitter} events and directs them to attached services as needed.
   *
   * @param {Object} vadScore -VAD score emitted by {@link TrackVADEmitter}
   * @param {Date}   vadScore.timestamp - Exact time at which processed PCM sample was generated.
   * @param {number} vadScore.score - VAD score on a scale from 0 to 1 (i.e. 0.7)
   * @param {Float32Array} pcmData - Raw PCM data with which the VAD score was calculated.
   * @param {string} vadScore.deviceId - Device id of the associated track.
   * @listens VAD_SCORE_PUBLISHED
   */


  _processVADScore(vadScore) {
    for (const detector of this._detectionServices) {
      detector.processVADScore(vadScore);
    }
  }
  /**
   * Change the isMuted state of all attached detection services.
   *
   * @param {boolean} isMuted
   */


  _changeDetectorsMuteState(isMuted) {
    for (const detector of this._detectionServices) {
      detector.changeMuteState(isMuted);
    }
  }
  /**
   * Notifies the detector that a track was added to the associated {@link JitsiConference}.
   * Only take into account local audio tracks.
   * @param {JitsiTrack} track - The added track.
   * @returns {void}
   * @listens TRACK_ADDED
   */


  _trackAdded(track) {
    if (track.isLocalAudioTrack()) {
      // Keep a track promise so we take into account successive TRACK_ADD events being generated so that we
      // destroy/create the processing context in the proper order.
      this._vadInitTracker = this._vadInitTracker.then(() => this._createVADProcessor()).then(vadProcessor => _TrackVADEmitter__WEBPACK_IMPORTED_MODULE_4__["default"].create(track.getDeviceId(), VAD_EMITTER_SAMPLE_RATE, vadProcessor)).then(vadEmitter => {
        logger.debug('Created VAD emitter for track: ', track.getTrackLabel());
        this._vadEmitter = vadEmitter; // Iterate through the detection services and set their appropriate mute state, depending on
        // service this will trigger a DETECTOR_STATE_CHANGE which in turn might start the _vadEmitter.

        this._changeDetectorsMuteState(track.isMuted());
      });
    }
  }
  /**
   * Notifies the detector that the mute state of a {@link JitsiConference} track has changed. Only takes into account
   * local audio tracks.
   * @param {JitsiTrack} track - The track whose mute state has changed.
   * @returns {void}
   * @listens TRACK_MUTE_CHANGED
   */


  _trackMuteChanged(track) {
    if (track.isLocalAudioTrack()) {
      // On a mute toggle reset the state.
      this._vadInitTracker = this._vadInitTracker.then(() => {
        // Set mute status for the attached detection services.
        this._changeDetectorsMuteState(track.isMuted());
      });
    }
  }
  /**
   * Notifies the detector that a track associated with the {@link JitsiConference} was removed. Only takes into
   * account local audio tracks. Cleans up resources associated with the track and resets the processing context.
   *
   * @param {JitsiTrack} track - The removed track.
   * @returns {void}
   * @listens TRACK_REMOVED
   */


  _trackRemoved(track) {
    if (track.isLocalAudioTrack()) {
      // Use the promise to make sure operations are in sequence.
      this._vadInitTracker = this._vadInitTracker.then(() => {
        logger.debug('Removing track from VAD detection - ', track.getTrackLabel()); // Track was removed, clean up and set appropriate states.

        if (this._vadEmitter) {
          this._stopVADEmitter();

          this._vadEmitter.destroy();

          this._vadEmitter = null;
        } // Reset state of detectors when active track is removed.


        for (const detector of this._detectionServices) {
          detector.reset();
        }
      });
    }
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\detection\\VADAudioAnalyser.js"))

/***/ }),

/***/ "./modules/detection/VADNoiseDetection.js":
/*!************************************************!*\
  !*** ./modules/detection/VADNoiseDetection.js ***!
  \************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return VADNoiseDetection; });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _util_MathUtil__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/MathUtil */ "./modules/util/MathUtil.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DetectionEvents */ "./modules/detection/DetectionEvents.js");



/**
 * The average value VAD needs to be under over a period of time to be considered noise.
 * @type {number}
 */

const VAD_NOISE_AVG_THRESHOLD = 0.2;
/**
 * The average values that audio input need to be over to be considered loud.
 * @type {number}
 */

const NOISY_AUDIO_LEVEL_THRESHOLD = 0.040;
/**
 * The value that a VAD score needs to be under in order for processing to begin.
 * @type {number}
 */

const VAD_SCORE_TRIGGER = 0.2;
/**
 * The value that a VAD score needs to be under in order for processing to begin.
 * @type {number}
 */

const AUDIO_LEVEL_SCORE_TRIGGER = 0.020;
/**
 * Time span over which we calculate an average score used to determine if we trigger the event.
 * @type {number}
 */

const PROCESS_TIME_FRAME_SPAN_MS = 1500;
/**
 * Detect if provided VAD score and PCM data is considered noise.
 */

class VADNoiseDetection extends events__WEBPACK_IMPORTED_MODULE_0__["EventEmitter"] {
  /**
   * Creates <tt>VADNoiseDetection</tt>
   *
   * @constructor
   */
  constructor() {
    super();
    /**
     * Flag which denotes the current state of the detection service i.e.if there is already a processing operation
     * ongoing.
     */

    this._processing = false;
    /**
     * Buffer that keeps the VAD scores for a period of time.
     */

    this._scoreArray = [];
    /**
     * Buffer that keeps audio level samples for a period of time.
     */

    this._audioLvlArray = [];
    /**
     * Current state of the service, if it's not active no processing will occur.
     */

    this._active = false;
    this._calculateNoisyScore = this._calculateNoisyScore.bind(this);
  }
  /**
   * Compute cumulative VAD score and PCM audio levels once the PROCESS_TIME_FRAME_SPAN_MS timeout has elapsed.
   * If the score is above the set threshold fire the event.
   * @returns {void}
   * @fires VAD_NOISY_DEVICE
   */


  _calculateNoisyScore() {
    const scoreAvg = Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__["calculateAverage"])(this._scoreArray);
    const audioLevelAvg = Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__["calculateAverage"])(this._audioLvlArray);

    if (scoreAvg < VAD_NOISE_AVG_THRESHOLD && audioLevelAvg > NOISY_AUDIO_LEVEL_THRESHOLD) {
      this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__["VAD_NOISY_DEVICE"]);

      this._setActiveState(false);
    } // We reset the context in case a new process phase needs to be triggered.


    this.reset();
  }
  /**
   * Record the vad score and average volume in the appropriate buffers.
   *
   * @param {number} vadScore
   * @param {number} avgAudioLvl - average audio level of the PCM sample associated with the VAD score.s
   */


  _recordValues(vadScore, avgAudioLvl) {
    this._scoreArray.push(vadScore);

    this._audioLvlArray.push(avgAudioLvl);
  }
  /**
   * Set the active state of the detection service and notify any listeners.
   *
   * @param {boolean} active
   * @fires DETECTOR_STATE_CHANGE
   */


  _setActiveState(active) {
    this._active = active;
    this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__["DETECTOR_STATE_CHANGE"], this._active);
  }
  /**
   * Change the state according to the muted status of the tracked device.
   *
   * @param {boolean} isMuted - Is the device muted or not.
   */


  changeMuteState(isMuted) {
    // This service only needs to run when the microphone is not muted.
    this._setActiveState(!isMuted);

    this.reset();
  }
  /**
   * Check whether or not the service is active or not.
   *
   * @returns {boolean}
   */


  isActive() {
    return this._active;
  }
  /**
   * Reset the processing context, clear buffers, cancel the timeout trigger.
   *
   * @returns {void}
   */


  reset() {
    this._processing = false;
    this._scoreArray = [];
    this._audioLvlArray = [];
    clearTimeout(this._processTimeout);
  }
  /**
   * Listens for {@link TrackVADEmitter} events and processes them.
   *
   * @param {Object} vadScore -VAD score emitted by {@link TrackVADEmitter}
   * @param {Date}   vadScore.timestamp - Exact time at which processed PCM sample was generated.
   * @param {number} vadScore.score - VAD score on a scale from 0 to 1 (i.e. 0.7)
   * @param {Float32Array} vadScore.pcmData - Raw PCM Data associated with the VAD score.
   * @param {string} vadScore.deviceId - Device id of the associated track.
   * @listens VAD_SCORE_PUBLISHED
   */


  processVADScore(vadScore) {
    if (!this._active) {
      return;
    } // There is a processing phase on going, add score to buffer array.


    if (this._processing) {
      // Filter and calculate sample average so we don't have to process one large array at a time.
      const posAudioLevels = Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__["filterPositiveValues"])(vadScore.pcmData);

      this._recordValues(vadScore.score, Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__["calculateAverage"])(posAudioLevels));

      return;
    } // If the VAD score for the sample is low and audio level has a high enough level we can start listening for
    // noise


    if (vadScore.score < VAD_SCORE_TRIGGER) {
      const posAudioLevels = Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__["filterPositiveValues"])(vadScore.pcmData);
      const avgAudioLvl = Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__["calculateAverage"])(posAudioLevels);

      if (avgAudioLvl > AUDIO_LEVEL_SCORE_TRIGGER) {
        this._processing = true;

        this._recordValues(vadScore.score, avgAudioLvl); // Once the preset timeout executes the final score will be calculated.


        this._processTimeout = setTimeout(this._calculateNoisyScore, PROCESS_TIME_FRAME_SPAN_MS);
      }
    }
  }

}

/***/ }),

/***/ "./modules/detection/VADTalkMutedDetection.js":
/*!****************************************************!*\
  !*** ./modules/detection/VADTalkMutedDetection.js ***!
  \****************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return VADTalkMutedDetection; });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _util_MathUtil__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/MathUtil */ "./modules/util/MathUtil.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DetectionEvents */ "./modules/detection/DetectionEvents.js");



/**
 * The threshold which the average VAD values for a span of time needs to exceed to trigger an event.
 * @type {number}
 */

const VAD_AVG_THRESHOLD = 0.6;
/**
 * The VAD score needed to trigger the processing algorithm, i.e. if a sample has the VAD score >= VAD_VOICE_LEVEL
 * we start processing all scores for a time span defined by const PROCESS_TIME_FRAME_SPAN_MS.
 * @type {number}
 */

const VAD_VOICE_LEVEL = 0.9;
/**
 * Sample rate of TrackVADEmitter, it defines how many audio samples are processed at a time.
 * @type {number}
 */

/**
 * Time span over which we calculate an average score used to determine if we trigger the event.
 * @type {number}
 */

const PROCESS_TIME_FRAME_SPAN_MS = 700;
/**
 * Detect if provided VAD score which is generated on a muted device is voice and fires an event.
 */

class VADTalkMutedDetection extends events__WEBPACK_IMPORTED_MODULE_0__["EventEmitter"] {
  /**
   * Creates <tt>VADTalkMutedDetection</tt>
   * @constructor
   */
  constructor() {
    super();
    /**
     * Flag which denotes the current state of the detection service i.e.if there is already a processing operation
     * ongoing.
     */

    this._processing = false;
    /**
     * Buffer that keeps the VAD scores for a period of time.
     */

    this._scoreArray = [];
    /**
     * Current mute state of the audio track being monitored.
     */

    this._active = false;
    this._calculateVADScore = this._calculateVADScore.bind(this);
  }
  /**
   * Compute cumulative VAD score function called once the PROCESS_TIME_FRAME_SPAN_MS timeout has elapsed.
   * @returns {void}
   * @fires VAD_TALK_WHILE_MUTED
   */


  _calculateVADScore() {
    const score = Object(_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__["calculateAverage"])(this._scoreArray);

    if (score > VAD_AVG_THRESHOLD) {
      this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__["VAD_TALK_WHILE_MUTED"]); // Event was fired. Stop event emitter and remove listeners so no residue events kick off after this point
      // and a single VAD_TALK_WHILE_MUTED is generated per mic muted state.

      this._setActiveState(false);
    } // We reset the context in case a new process phase needs to be triggered.


    this.reset();
  }
  /**
   * Set the active state of the detection service and notify any listeners.
   *
   * @param {boolean} active
   * @fires DETECTOR_STATE_CHANGE
   */


  _setActiveState(active) {
    this._active = active;
    this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__["DETECTOR_STATE_CHANGE"], this._active);
  }
  /**
   * Change the state according to the muted status of the tracked device.
   *
   * @param {boolean} isMuted - Is the device muted or not.
   */


  changeMuteState(isMuted) {
    // This service only needs to run when the microphone is muted.
    this._setActiveState(isMuted);

    this.reset();
  }
  /**
   * Check whether or not the service is active or not.
   *
   * @returns {boolean}
   */


  isActive() {
    return this._active;
  }
  /**
   * Listens for {@link TrackVADEmitter} events and processes them.
   *
   * @param {Object} vadScore -VAD score emitted by {@link TrackVADEmitter}
   * @param {Date}   vadScore.timestamp - Exact time at which processed PCM sample was generated.
   * @param {number} vadScore.score - VAD score on a scale from 0 to 1 (i.e. 0.7)
   * @param {string} vadScore.deviceId - Device id of the associated track.
   * @listens VAD_SCORE_PUBLISHED
   */


  processVADScore(vadScore) {
    if (!this._active) {
      return;
    } // There is a processing phase on going, add score to buffer array.


    if (this._processing) {
      this._scoreArray.push(vadScore.score);

      return;
    } // Because we remove all listeners on the vadEmitter once the main event is triggered,
    // there is no need to check for rogue events.


    if (vadScore.score > VAD_VOICE_LEVEL) {
      this._processing = true;

      this._scoreArray.push(vadScore.score); // Start gathering VAD scores for the configured period of time.


      this._processTimeout = setTimeout(this._calculateVADScore, PROCESS_TIME_FRAME_SPAN_MS);
    }
  }
  /**
   * Reset the processing context, clear buffer, cancel the timeout trigger.
   *
   * @returns {void}
   */


  reset() {
    this._processing = false;
    this._scoreArray = [];
    clearTimeout(this._processTimeout);
  }

}

/***/ }),

/***/ "./modules/e2ee/E2EEContext.js":
/*!*************************************!*\
  !*** ./modules/e2ee/E2EEContext.js ***!
  \*************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return E2EEcontext; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* global __filename, TransformStream */

const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename); // We use a ringbuffer of keys so we can change them and still decode packets that were
// encrypted with an old key.
// In the future when we dont rely on a globally shared key we will actually use it. For
// now set the size to 1 which means there is only a single key. This causes some
// glitches when changing the key but its ok.

const keyRingSize = 1; // We use a 96 bit IV for AES GCM. This is signalled in plain together with the
// packet. See https://developer.mozilla.org/en-US/docs/Web/API/AesGcmParams

const ivLength = 12; // We copy the first bytes of the VP8 payload unencrypted.
// For keyframes this is 10 bytes, for non-keyframes (delta) 3. See
//   https://tools.ietf.org/html/rfc6386#section-9.1
// This allows the bridge to continue detecting keyframes (only one byte needed in the JVB)
// and is also a bit easier for the VP8 decoder (i.e. it generates funny garbage pictures
// instead of being unable to decode).
// This is a bit for show and we might want to reduce to 1 unconditionally in the final version.
//
// For audio (where frame.type is not set) we do not encrypt the opus TOC byte:
//   https://tools.ietf.org/html/rfc6716#section-3.1

const unencryptedBytes = {
  key: 10,
  delta: 3,
  undefined: 1 // frame.type is not set on audio

}; // Flag to set on senders / receivers to avoid setting up the encryption transform
// more than once.

const kJitsiE2EE = Symbol('kJitsiE2EE');
/**
 * Context encapsulating the cryptography bits required for E2EE.
 * This uses the WebRTC Insertable Streams API which is explained in
 *   https://github.com/alvestrand/webrtc-media-streams/blob/master/explainer.md
 * that provides access to the encoded frames and allows them to be transformed.
 *
 * The encoded frame format is explained below in the _encodeFunction method.
 * High level design goals were:.
 * - do not require changes to existing SFUs and retain (VP8) metadata.
 * - allow the SFU to rewrite SSRCs, timestamp, pictureId.
 * - allow for the key to be rotated frequently.
 */

class E2EEcontext {
  /**
   * Build a new E2EE context instance, which will be used in a given conference.
   *
   * @param {string} options.salt - Salt to be used for key deviation.
   *      FIXME: We currently use the MUC room name for this which has the same lifetime
   *      as this context. While not (pseudo)random as recommended in
   *        https://developer.mozilla.org/en-US/docs/Web/API/Pbkdf2Params
   *      this is easily available and the same for all participants.
   *      We currently do not enforce a minimum length of 16 bytes either.
   */
  constructor(options) {
    this._options = options; // An array (ring) of keys that we use for sending and receiving.

    this._cryptoKeyRing = new Array(keyRingSize); // A pointer to the currently used key.

    this._currentKeyIndex = -1; // We keep track of how many frames we have sent per ssrc.
    // Starts with a random offset similar to the RTP sequence number.

    this._sendCounts = new Map(); // Initialize the salt and convert it once.

    const encoder = new TextEncoder();
    this._salt = encoder.encode(options.salt);
  }
  /**
   * Handles the given {@code RTCRtpReceiver} by creating a {@code TransformStream} which will injecct
   * a frame decoder.
   *
   * @param {RTCRtpReceiver} receiver - The receiver which will get the decoding function injected.
   * @param {string} kind - The kind of track this receiver belongs to.
   */


  handleReceiver(receiver, kind) {
    if (receiver[kJitsiE2EE]) {
      return;
    }

    const receiverStreams = kind === 'video' ? receiver.createEncodedVideoStreams() : receiver.createEncodedAudioStreams();
    const transform = new TransformStream({
      transform: this._decodeFunction.bind(this)
    });
    receiverStreams.readableStream.pipeThrough(transform).pipeTo(receiverStreams.writableStream);
    receiver[kJitsiE2EE] = true;
  }
  /**
   * Handles the given {@code RTCRtpSender} by creating a {@code TransformStream} which will injecct
   * a frame encoder.
   *
   * @param {RTCRtpSender} sender - The sender which will get the encoding funcction injected.
   * @param {string} kind - The kind of track this sender belongs to.
   */


  handleSender(sender, kind) {
    if (sender[kJitsiE2EE]) {
      return;
    }

    const senderStreams = kind === 'video' ? sender.createEncodedVideoStreams() : sender.createEncodedAudioStreams();
    const transform = new TransformStream({
      transform: this._encodeFunction.bind(this)
    });
    senderStreams.readableStream.pipeThrough(transform).pipeTo(senderStreams.writableStream);
    sender[kJitsiE2EE] = true;
  }
  /**
   * Sets the key to be used for E2EE.
   *
   * @param {string} value - Value to be used as the new key. May be falsy to disable end-to-end encryption.
   */


  async setKey(value) {
    let key;

    if (value) {
      const encoder = new TextEncoder();
      key = await this._deriveKey(encoder.encode(value));
    } else {
      key = false;
    }

    this._currentKeyIndex++;
    this._cryptoKeyRing[this._currentKeyIndex % this._cryptoKeyRing.length] = key;
  }
  /**
   * Derives a AES-GCM key with 128 bits from the input using PBKDF2
   * The salt is configured in the constructor of this class.
   * @param {Uint8Array} keyBytes - Value to derive key from
   */


  async _deriveKey(keyBytes) {
    // https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto/importKey
    const material = await crypto.subtle.importKey('raw', keyBytes, 'PBKDF2', false, ['deriveBits', 'deriveKey']); // https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto/deriveKey#PBKDF2

    return crypto.subtle.deriveKey({
      name: 'PBKDF2',
      salt: this._salt,
      iterations: 100000,
      hash: 'SHA-256'
    }, material, {
      name: 'AES-GCM',
      length: 128
    }, false, ['encrypt', 'decrypt']);
  }
  /**
   * Construct the IV used for AES-GCM and sent (in plain) with the packet similar to
   * https://tools.ietf.org/html/rfc7714#section-8.1
   * It concatenates
   * - the 32 bit synchronization source (SSRC) given on the encoded frame,
   * - the 32 bit rtp timestamp given on the encoded frame,
   * - a send counter that is specific to the SSRC. Starts at a random number.
   * The send counter is essentially the pictureId but we currently have to implement this ourselves.
   * There is no XOR with a salt. Note that this IV leaks the SSRC to the receiver but since this is
   * randomly generated and SFUs may not rewrite this is considered acceptable.
   * The SSRC is used to allow demultiplexing multiple streams with the same key, as described in
   *   https://tools.ietf.org/html/rfc3711#section-4.1.1
   * The RTP timestamp is 32 bits and advances by the codec clock rate (90khz for video, 48khz for
   * opus audio) every second. For video it rolls over roughly every 13 hours.
   * The send counter will advance at the frame rate (30fps for video, 50fps for 20ms opus audio)
   * every second. It will take a long time to roll over.
   *
   * See also https://developer.mozilla.org/en-US/docs/Web/API/AesGcmParams
   */


  _makeIV(synchronizationSource, timestamp) {
    const iv = new ArrayBuffer(ivLength);
    const ivView = new DataView(iv); // having to keep our own send count (similar to a picture id) is not ideal.

    if (!this._sendCounts.has(synchronizationSource)) {
      // Initialize with a random offset, similar to the RTP sequence number.
      this._sendCounts.set(synchronizationSource, Math.floor(Math.random() * 0xFFFF));
    }

    const sendCount = this._sendCounts.get(synchronizationSource);

    ivView.setUint32(0, synchronizationSource);
    ivView.setUint32(4, timestamp);
    ivView.setUint32(8, sendCount % 0xFFFF);

    this._sendCounts.set(synchronizationSource, sendCount + 1);

    return iv;
  }
  /**
   * Function that will be injected in a stream and will encrypt the given encoded frames.
   *
   * @param {RTCEncodedVideoFrame|RTCEncodedAudioFrame} encodedFrame - Encoded video frame.
   * @param {TransformStreamDefaultController} controller - TransportStreamController.
   *
   * The packet format is described below. One of the design goals was to not require
   * changes to the SFU which for video requires not encrypting the keyframe bit of VP8
   * as SFUs need to detect a keyframe (framemarking or the generic frame descriptor will
   * solve this eventually). This also "hides" that a client is using E2EE a bit.
   *
   * Note that this operates on the full frame, i.e. for VP8 the data described in
   *   https://tools.ietf.org/html/rfc6386#section-9.1
   *
   * The VP8 payload descriptor described in
   *   https://tools.ietf.org/html/rfc7741#section-4.2
   * is part of the RTP packet and not part of the frame and is not controllable by us.
   * This is fine as the SFU keeps having access to it for routing.
   *
   * The encrypted frame is formed as follows:
   * 1) Leave the first (10, 3, 1) bytes unencrypted, depending on the frame type and kind.
   * 2) Form the GCM IV for the frame as described above.
   * 3) Encrypt the rest of the frame using AES-GCM.
   * 4) Allocate space for the encrypted frame.
   * 5) Copy the unencrypted bytes to the start of the encrypted frame.
   * 6) Append the ciphertext to the encrypted frame.
   * 7) Append the IV.
   * 8) Append a single byte for the key identifier. TODO: we don't need all the bits.
   * 9) Enqueue the encrypted frame for sending.
   */


  _encodeFunction(encodedFrame, controller) {
    const keyIndex = this._currentKeyIndex % this._cryptoKeyRing.length;

    if (this._cryptoKeyRing[keyIndex]) {
      const iv = this._makeIV(encodedFrame.synchronizationSource, encodedFrame.timestamp);

      return crypto.subtle.encrypt({
        name: 'AES-GCM',
        iv,
        additionalData: new Uint8Array(encodedFrame.data, 0, unencryptedBytes[encodedFrame.type])
      }, this._cryptoKeyRing[keyIndex], new Uint8Array(encodedFrame.data, unencryptedBytes[encodedFrame.type])).then(cipherText => {
        const newData = new ArrayBuffer(unencryptedBytes[encodedFrame.type] + cipherText.byteLength + iv.byteLength + 1);
        const newUint8 = new Uint8Array(newData);
        newUint8.set(new Uint8Array(encodedFrame.data, 0, unencryptedBytes[encodedFrame.type])); // copy first bytes.

        newUint8.set(new Uint8Array(cipherText), unencryptedBytes[encodedFrame.type]); // add ciphertext.

        newUint8.set(new Uint8Array(iv), unencryptedBytes[encodedFrame.type] + cipherText.byteLength); // append IV.

        newUint8[unencryptedBytes[encodedFrame.type] + cipherText.byteLength + ivLength] = keyIndex; // set key index.

        encodedFrame.data = newData;
        return controller.enqueue(encodedFrame);
      }, e => {
        logger.error(e); // We are not enqueuing the frame here on purpose.
      });
    }
    /* NOTE WELL:
     * This will send unencrypted data (only protected by DTLS transport encryption) when no key is configured.
     * This is ok for demo purposes but should not be done once this becomes more relied upon.
     */


    controller.enqueue(encodedFrame);
  }
  /**
   * Function that will be injected in a stream and will decrypt the given encoded frames.
   *
   * @param {RTCEncodedVideoFrame|RTCEncodedAudioFrame} encodedFrame - Encoded video frame.
   * @param {TransformStreamDefaultController} controller - TransportStreamController.
   *
   * The decrypted frame is formed as follows:
   * 1) Extract the key index from the last byte of the encrypted frame.
   *    If there is no key associated with the key index, the frame is enqueued for decoding
   *    and these steps terminate.
   * 2) Determine the frame type in order to look up the number of unencrypted header bytes.
   * 2) Extract the 12-byte IV from its position near the end of the packet.
   *    Note: the IV is treated as opaque and not reconstructed from the input.
   * 3) Decrypt the encrypted frame content after the unencrypted bytes using AES-GCM.
   * 4) Allocate space for the decrypted frame.
   * 5) Copy the unencrypted bytes from the start of the encrypted frame.
   * 6) Append the plaintext to the decrypted frame.
   * 7) Enqueue the decrypted frame for decoding.
   */


  _decodeFunction(encodedFrame, controller) {
    const data = new Uint8Array(encodedFrame.data);
    const keyIndex = data[encodedFrame.data.byteLength - 1];

    if (this._cryptoKeyRing[keyIndex]) {
      const iv = new Uint8Array(encodedFrame.data, encodedFrame.data.byteLength - ivLength - 1, ivLength);
      const cipherTextStart = unencryptedBytes[encodedFrame.type];
      const cipherTextLength = encodedFrame.data.byteLength - (unencryptedBytes[encodedFrame.type] + ivLength + 1);
      return crypto.subtle.decrypt({
        name: 'AES-GCM',
        iv,
        additionalData: new Uint8Array(encodedFrame.data, 0, unencryptedBytes[encodedFrame.type])
      }, this._cryptoKeyRing[keyIndex], new Uint8Array(encodedFrame.data, cipherTextStart, cipherTextLength)).then(plainText => {
        const newData = new ArrayBuffer(unencryptedBytes[encodedFrame.type] + plainText.byteLength);
        const newUint8 = new Uint8Array(newData);
        newUint8.set(new Uint8Array(encodedFrame.data, 0, unencryptedBytes[encodedFrame.type]));
        newUint8.set(new Uint8Array(plainText), unencryptedBytes[encodedFrame.type]);
        encodedFrame.data = newData;
        return controller.enqueue(encodedFrame);
      }, e => {
        logger.error(e, encodedFrame.type); // TODO: notify the application about error status.
        // TODO: For video we need a better strategy since we do not want to based any
        // non-error frames on a garbage keyframe.

        if (encodedFrame.type === undefined) {
          // audio, replace with silence.
          // audio, replace with silence.
          const newData = new ArrayBuffer(3);
          const newUint8 = new Uint8Array(newData);
          newUint8.set([0xd8, 0xff, 0xfe]); // opus silence frame.

          encodedFrame.data = newData;
          controller.enqueue(encodedFrame);
        }
      });
    } // TODO: this just passes through to the decoder. Is that ok? If we don't know the key yet
    // we might want to buffer a bit but it is still unclear how to do that (and for how long etc).


    controller.enqueue(encodedFrame);
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\e2ee\\E2EEContext.js"))

/***/ }),

/***/ "./modules/e2eping/e2eping.js":
/*!************************************!*\
  !*** ./modules/e2eping/e2eping.js ***!
  \************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return E2ePing; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _service_e2eping_E2ePingEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/e2eping/E2ePingEvents */ "./service/e2eping/E2ePingEvents.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");
/* global __filename */





const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * The 'type' of a message which designates an e2e ping request.
 * @type {string}
 */

const E2E_PING_REQUEST = 'e2e-ping-request';
/**
 * The 'type' of a message which designates an e2e ping response.
 * @type {string}
 */

const E2E_PING_RESPONSE = 'e2e-ping-response';
/**
 * Saves e2e ping related state for a single JitsiParticipant.
 */

class ParticipantWrapper {
  /**
   * Creates a ParticipantWrapper
   * @param {JitsiParticipant} participant - The remote participant that this
   * object wraps.
   * @param {E2ePing} e2eping
   */
  constructor(participant, e2eping) {
    // The JitsiParticipant
    this.participant = participant; // The E2ePing

    this.e2eping = e2eping; // Caches the ID

    this.id = participant.getId(); // Recently sent requests

    this.requests = {}; // The ID of the last sent request. We just increment it for each new
    // request. Start at 1 so we can consider only thruthy values valid.

    this.lastRequestId = 1;
    this.clearIntervals = this.clearIntervals.bind(this);
    this.sendRequest = this.sendRequest.bind(this);
    this.handleResponse = this.handleResponse.bind(this);
    this.maybeSendAnalytics = this.maybeSendAnalytics.bind(this);
    this.sendAnalytics = this.sendAnalytics.bind(this); // If the data channel was already open (this is likely a participant
    // joining an existing conference) send a request immediately.

    if (e2eping.isDataChannelOpen) {
      this.sendRequest();
    }

    this.pingInterval = window.setInterval(this.sendRequest, e2eping.pingIntervalMs);
    this.analyticsInterval = window.setTimeout(this.maybeSendAnalytics, this.e2eping.analyticsIntervalMs);
  }
  /**
   * Clears the interval which sends pings.
   * @type {*}
   */


  clearIntervals() {
    if (this.pingInterval) {
      window.clearInterval(this.pingInterval);
    }

    if (this.analyticsInterval) {
      window.clearInterval(this.analyticsInterval);
    }
  }
  /**
   * Sends the next ping request.
   * @type {*}
   */


  sendRequest() {
    const requestId = this.lastRequestId++;
    const requestMessage = {
      type: E2E_PING_REQUEST,
      id: requestId
    };
    this.e2eping.sendMessage(requestMessage, this.id);
    this.requests[requestId] = {
      id: requestId,
      timeSent: window.performance.now()
    };
  }
  /**
   * Handles a response from this participant.
   * @type {*}
   */


  handleResponse(response) {
    const request = this.requests[response.id];

    if (request) {
      request.rtt = window.performance.now() - request.timeSent;
      this.e2eping.eventEmitter.emit(_service_e2eping_E2ePingEvents__WEBPACK_IMPORTED_MODULE_2__["E2E_RTT_CHANGED"], this.participant, request.rtt);
    }

    this.maybeSendAnalytics();
  }
  /**
   * Goes over the requests, clearing ones which we don't need anymore, and
   * if it finds at least one request with a valid RTT in the last
   * 'analyticsIntervalMs' then sends an analytics event.
   * @type {*}
   */


  maybeSendAnalytics() {
    const now = window.performance.now(); // The RTT we'll report is the minimum RTT measured in the last
    // analyticsInterval

    let rtt = Infinity;
    let request, requestId; // It's time to send analytics. Clean up all requests and find the

    for (requestId in this.requests) {
      if (this.requests.hasOwnProperty(requestId)) {
        request = this.requests[requestId];

        if (request.timeSent < now - this.e2eping.analyticsIntervalMs) {
          // An old request. We don't care about it anymore.
          delete this.requests[requestId];
        } else if (request.rtt) {
          rtt = Math.min(rtt, request.rtt);
        }
      }
    }

    if (rtt < Infinity) {
      this.sendAnalytics(rtt);
    }
  }
  /**
   * Sends an analytics event for this participant with the given RTT.
   * @type {*}
   */


  sendAnalytics(rtt) {
    _statistics_statistics__WEBPACK_IMPORTED_MODULE_4__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createE2eRttEvent"])(this.id, this.participant.getProperty('region'), rtt));
  }

}
/**
 * Implements end-to-end ping (from one conference participant to another) via
 * the jitsi-videobridge channel (either WebRTC data channel or web socket).
 *
 * TODO: use a broadcast message instead of individual pings to each remote
 * participant.
 *
 * This class:
 * 1. Sends periodic ping requests to all other participants in the
 * conference.
 * 2. Responds to ping requests from other participants.
 * 3. Fires events with the end-to-end RTT to each participant whenever a
 * response is received.
 * 4. Fires analytics events with the end-to-end RTT periodically.
 */


class E2ePing {
  /**
   * @param {JitsiConference} conference - The conference.
   * @param {Function} sendMessage - The function to use to send a message.
   * @param {Object} options
   */
  constructor(conference, options, sendMessage) {
    this.conference = conference;
    this.eventEmitter = conference.eventEmitter;
    this.sendMessage = sendMessage; // The interval at which pings will be sent (<= 0 disables sending).

    this.pingIntervalMs = 10000; // The interval at which analytics events will be sent.

    this.analyticsIntervalMs = 60000; // Maps a participant ID to its ParticipantWrapper

    this.participants = {}; // Whether the WebRTC channel has been opened or not.

    this.isDataChannelOpen = false;

    if (options && options.e2eping) {
      if (typeof options.e2eping.pingInterval === 'number') {
        this.pingIntervalMs = options.e2eping.pingInterval;
      }

      if (typeof options.e2eping.analyticsInterval === 'number') {
        this.analyticsIntervalMs = options.e2eping.analyticsInterval;
      } // We want to report at most once a ping interval.


      if (this.analyticsIntervalMs > 0 && this.analyticsIntervalMs < this.pingIntervalMs) {
        this.analyticsIntervalMs = this.pingIntervalMs;
      }
    }

    logger.info(`Initializing e2e ping; pingInterval=${this.pingIntervalMs}, analyticsInterval=${this.analyticsIntervalMs}.`);
    this.participantJoined = this.participantJoined.bind(this);
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__["USER_JOINED"], this.participantJoined);
    this.participantLeft = this.participantLeft.bind(this);
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__["USER_LEFT"], this.participantLeft);
    this.messageReceived = this.messageReceived.bind(this);
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__["ENDPOINT_MESSAGE_RECEIVED"], this.messageReceived);
    this.dataChannelOpened = this.dataChannelOpened.bind(this);
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__["DATA_CHANNEL_OPENED"], this.dataChannelOpened);
  }
  /**
   * Notifies this instance that the communications channel has been opened
   * and it can now send messages via sendMessage.
   */


  dataChannelOpened() {
    this.isDataChannelOpen = true; // We don't want to wait the whole interval before sending the first
    // request, but we can't send it immediately after the participant joins
    // either, because our data channel might not have initialized.
    // So once the data channel initializes, send requests to everyone.
    // Wait an additional 200ms to give a chance to the remote side (if it
    // also just connected as is the case for the first 2 participants in a
    // conference) to open its data channel.

    for (const id in this.participants) {
      if (this.participants.hasOwnProperty(id)) {
        const participantWrapper = this.participants[id];
        window.setTimeout(participantWrapper.sendRequest, 200);
      }
    }
  }
  /**
   * Handles a message that was received.
   *
   * @param participant - The message sender.
   * @param payload - The payload of the message.
   */


  messageReceived(participant, payload) {
    // Listen to E2E PING requests and responses from other participants
    // in the conference.
    if (payload.type === E2E_PING_REQUEST) {
      this.handleRequest(participant.getId(), payload);
    } else if (payload.type === E2E_PING_RESPONSE) {
      this.handleResponse(participant.getId(), payload);
    }
  }
  /**
   * Handles a participant joining the conference. Starts to send ping
   * requests to the participant.
   *
   * @param {String} id - The ID of the participant.
   * @param {JitsiParticipant} participant - The participant that joined.
   */


  participantJoined(id, participant) {
    if (this.pingIntervalMs <= 0) {
      return;
    }

    if (this.participants[id]) {
      logger.info(`Participant wrapper already exists for ${id}. Clearing.`);
      this.participants[id].clearIntervals();
      delete this.participants[id];
    }

    this.participants[id] = new ParticipantWrapper(participant, this);
  }
  /**
   * Handles a participant leaving the conference. Stops sending requests.
   *
   * @param {String} id - The ID of the participant.
   */


  participantLeft(id) {
    if (this.pingIntervalMs <= 0) {
      return;
    }

    if (this.participants[id]) {
      this.participants[id].clearIntervals();
      delete this.participants[id];
    }
  }
  /**
   * Handles a ping request coming from another participant.
   *
   * @param {string} participantId - The ID of the participant who sent the
   * request.
   * @param {Object} request - The request.
   */


  handleRequest(participantId, request) {
    // If it's a valid request, just send a response.
    if (request && request.id) {
      const response = {
        type: E2E_PING_RESPONSE,
        id: request.id
      };
      this.sendMessage(response, participantId);
    } else {
      logger.info(`Received an invalid e2e ping request from ${participantId}.`);
    }
  }
  /**
   * Handles a ping response coming from another participant
   * @param {string} participantId - The ID of the participant who sent the
   * response.
   * @param {Object} response - The response.
   */


  handleResponse(participantId, response) {
    const participantWrapper = this.participants[participantId];

    if (participantWrapper) {
      participantWrapper.handleResponse(response);
    }
  }
  /**
   * Stops this E2ePing (i.e. stop sending requests).
   */


  stop() {
    logger.info('Stopping e2eping');
    this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__["USER_JOINED"], this.participantJoined);
    this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__["USER_LEFT"], this.participantLeft);
    this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__["ENDPOINT_MESSAGE_RECEIVED"], this.messageReceived);
    this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__["DATA_CHANNEL_OPENED"], this.dataChannelOpened);

    for (const id in this.participants) {
      if (this.participants.hasOwnProperty(id)) {
        this.participants[id].clearIntervals();
      }
    }

    this.participants = {};
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\e2eping\\e2eping.js"))

/***/ }),

/***/ "./modules/event/Jvb121EventGenerator.js":
/*!***********************************************!*\
  !*** ./modules/event/Jvb121EventGenerator.js ***!
  \***********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return Jvb121EventGenerator; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* global __filename */


const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Emits {@link JitsiConferenceEvents.JVB121_STATUS} events based on the current
 * P2P status and the conference participants count. See the event description
 * for more info.
 */

class Jvb121EventGenerator {
  /**
   * Creates new <tt>Jvb121EventGenerator</tt> for the given conference.
   * @param {JitsiConference} conference
   */
  constructor(conference) {
    this._conference = conference;
    /**
     * Indicates whether it's a one to one JVB conference (<tt>true</tt>)
     * or a multiparty (<tt>false</tt>). Will be also <tt>false</tt> if
     * the conference is currently in the P2P mode.
     * @type {boolean}
     * @private
     */

    this._jvb121 = true;

    this._conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["USER_JOINED"], () => this.evaluateStatus());

    this._conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["USER_LEFT"], () => this.evaluateStatus());

    this._conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["P2P_STATUS"], () => this.evaluateStatus());
  }
  /**
   * Checks whether the JVB121 value should be updated and a new event
   * emitted.
   */


  evaluateStatus() {
    const oldStatus = this._jvb121;
    const newStatus = !this._conference.isP2PActive() && this._conference.getParticipantCount() <= 2;

    if (oldStatus !== newStatus) {
      this._jvb121 = newStatus;
      logger.debug(`JVB121 status ${oldStatus} => ${newStatus}`);

      this._conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["JVB121_STATUS"], oldStatus, newStatus);
    }
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\event\\Jvb121EventGenerator.js"))

/***/ }),

/***/ "./modules/proxyconnection/ProxyConnectionPC.js":
/*!******************************************************!*\
  !*** ./modules/proxyconnection/ProxyConnectionPC.js ***!
  \******************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return ProxyConnectionPC; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _RTC_RTC__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../RTC/RTC */ "./modules/RTC/RTC.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _xmpp_JingleSessionPC__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../xmpp/JingleSessionPC */ "./modules/xmpp/JingleSessionPC.js");
/* harmony import */ var _xmpp_xmpp__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../xmpp/xmpp */ "./modules/xmpp/xmpp.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./constants */ "./modules/proxyconnection/constants.js");
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }








const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * An adapter around {@code JingleSessionPC} so its logic can be re-used without
 * an XMPP connection. It is being re-used for consistency with the rest of the
 * codebase and to leverage existing peer connection event handling. Also
 * this class provides a facade to hide most of the API for
 * {@code JingleSessionPC}.
 */

class ProxyConnectionPC {
  /**
   * Initializes a new {@code ProxyConnectionPC} instance.
   *
   * @param {Object} options - Values to initialize the instance with.
   * @param {Object} [options.iceConfig] - The {@code RTCConfiguration} to use
   * for the peer connection.
   * @param {boolean} [options.isInitiator] - If true, the local client should
   * send offers. If false, the local client should send answers. Defaults to
   * false.
   * @param {Function} options.onRemoteStream - Callback to invoke when a
   * remote media stream has been received through the peer connection.
   * @param {string} options.peerJid - The jid of the remote client with which
   * the peer connection is being establish and which should receive direct
   * messages regarding peer connection updates.
   * @param {boolean} [options.receiveVideo] - Whether or not the peer
   * connection should accept incoming video streams. Defaults to false.
   * @param {Function} options.onSendMessage - Callback to invoke when a
   * message has to be sent (signaled) out.
   */
  constructor(options = {}) {
    this._options = _objectSpread({
      iceConfig: {},
      isInitiator: false,
      receiveAudio: false,
      receiveVideo: false
    }, options);
    /**
     * Instances of {@code JitsiTrack} associated with this instance of
     * {@code ProxyConnectionPC}.
     *
     * @type {Array<JitsiTrack>}
     */

    this._tracks = [];
    /**
     * The active instance of {@code JingleSessionPC}.
     *
     * @type {JingleSessionPC|null}
     */

    this._peerConnection = null; // Bind event handlers so they are only bound once for every instance.

    this._onError = this._onError.bind(this);
    this._onRemoteStream = this._onRemoteStream.bind(this);
    this._onSendMessage = this._onSendMessage.bind(this);
  }
  /**
   * Returns the jid of the remote peer with which this peer connection should
   * be established with.
   *
   * @returns {string}
   */


  getPeerJid() {
    return this._options.peerJid;
  }
  /**
   * Updates the peer connection based on the passed in jingle.
   *
   * @param {Object} $jingle - An XML jingle element, wrapped in query,
   * describing how the peer connection should be updated.
   * @returns {void}
   */


  processMessage($jingle) {
    switch ($jingle.attr('action')) {
      case _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].ACCEPT:
        this._onSessionAccept($jingle);

        break;

      case _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].INITIATE:
        this._onSessionInitiate($jingle);

        break;

      case _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].TERMINATE:
        this._onSessionTerminate($jingle);

        break;

      case _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].TRANSPORT_INFO:
        this._onTransportInfo($jingle);

        break;
    }
  }
  /**
   * Instantiates a peer connection and starts the offer/answer cycle to
   * establish a connection with a remote peer.
   *
   * @param {Array<JitsiLocalTrack>} localTracks - Initial local tracks to add
   * to add to the peer connection.
   * @returns {void}
   */


  start(localTracks = []) {
    if (this._peerConnection) {
      return;
    }

    this._tracks = this._tracks.concat(localTracks);
    this._peerConnection = this._createPeerConnection();

    this._peerConnection.invite(localTracks);
  }
  /**
   * Begins the process of disconnecting from a remote peer and cleaning up
   * the peer connection.
   *
   * @returns {void}
   */


  stop() {
    if (this._peerConnection) {
      this._peerConnection.terminate();
    }

    this._onSessionTerminate();
  }
  /**
   * Instantiates a new {@code JingleSessionPC} by stubbing out the various
   * dependencies of {@code JingleSessionPC}.
   *
   * @private
   * @returns {JingleSessionPC}
   */


  _createPeerConnection() {
    /**
     * {@code JingleSessionPC} takes in the entire jitsi-meet config.js
     * object, which may not be accessible from the caller.
     *
     * @type {Object}
     */
    const configStub = {};
    /**
     * {@code JingleSessionPC} assumes an XMPP/Strophe connection object is
     * passed through, which also has the jingle plugin initialized on it.
     * This connection object is used to signal out peer connection updates
     * via iqs, and those updates need to be piped back out to the remote
     * peer.
     *
     * @type {Object}
     */

    const connectionStub = {
      // At the time this is used for Spot and it's okay to say the connection is always connected, because if
      // spot has no signalling it will not be in a meeting where this is used.
      connected: true,
      jingle: {
        terminate: () => {
          /** no-op */
        }
      },
      sendIQ: this._onSendMessage,
      // Returns empty function, because it does not add any listeners for real
      // eslint-disable-next-line no-empty-function
      addEventListener: () => () => {}
    };
    /**
     * {@code JingleSessionPC} can take in a custom ice configuration,
     * depending on the peer connection type, peer-to-peer or other.
     * However, {@code ProxyConnectionPC} always assume a peer-to-peer
     * connection so the ice configuration is hard-coded with defaults.
     *
     * @type {Object}
     */

    const iceConfigStub = _objectSpread({
      iceServers: _xmpp_xmpp__WEBPACK_IMPORTED_MODULE_5__["DEFAULT_STUN_SERVERS"]
    }, this._options.iceConfig);
    /**
     * {@code JingleSessionPC} expects an instance of
     * {@code JitsiConference}, which has an event emitter that is used
     * to signal various connection updates that the local client should
     * act upon. The conference instance is not a dependency of a proxy
     * connection, but the emitted events can be relevant to the proxy
     * connection so the event emitter is stubbed.
     *
     * @param {string} event - The constant for the event type.
     * @type {Function}
     * @returns {void}
     */


    const emitter = event => {
      switch (event) {
        case _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default.a.CONNECTION_ICE_FAILED:
        case _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default.a.CONNECTION_FAILED:
          this._onError(_constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].CONNECTION_ERROR, event);

          break;
      }
    };
    /**
     * {@code JingleSessionPC} expects an instance of
     * {@code JitsiConference} to be passed in. {@code ProxyConnectionPC}
     * is instantiated outside of the {@code JitsiConference}, so it must be
     * stubbed to prevent errors.
     *
     * @type {Object}
     */


    const roomStub = {
      addPresenceListener: () => {
        /** no-op */
      },
      connectionTimes: [],
      eventEmitter: {
        emit: emitter
      },
      getMediaPresenceInfo: () => {
        // Errors occur if this function does not return an object
        return {};
      },
      removePresenceListener: () => {
        /** no-op */
      }
    };
    /**
     * Create an instance of {@code RTC} as it is required for peer
     * connection creation by {@code JingleSessionPC}. An existing instance
     * of {@code RTC} from elsewhere should not be re-used because it is
     * a stateful grouping of utilities.
     */

    this._rtc = new _RTC_RTC__WEBPACK_IMPORTED_MODULE_1__["default"](this, {});
    /**
     * Add the remote track listener here as {@code JingleSessionPC} has
     * {@code TraceablePeerConnection} which uses {@code RTC}'s event
     * emitter.
     */

    this._rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_2___default.a.REMOTE_TRACK_ADDED, this._onRemoteStream);

    const peerConnection = new _xmpp_JingleSessionPC__WEBPACK_IMPORTED_MODULE_4__["default"](undefined, // sid
    undefined, // localJid
    this._options.peerJid, // remoteJid
    connectionStub, // connection
    {
      offerToReceiveAudio: this._options.receiveAudio,
      offerToReceiveVideo: this._options.receiveVideo
    }, // mediaConstraints
    iceConfigStub, // iceConfig
    true, // isP2P
    this._options.isInitiator // isInitiator
    );
    /**
     * An additional initialize call is necessary to properly set instance
     * variable for calling.
     */

    peerConnection.initialize(roomStub, this._rtc, configStub);
    return peerConnection;
  }
  /**
   * Invoked when a connection related issue has been encountered.
   *
   * @param {string} errorType - The constant indicating the type of the error
   * that occured.
   * @param {string} details - Optional additional data about the error.
   * @private
   * @returns {void}
   */


  _onError(errorType, details = '') {
    this._options.onError(this._options.peerJid, errorType, details);
  }
  /**
   * Callback invoked when the peer connection has received a remote media
   * stream.
   *
   * @param {JitsiRemoteTrack} jitsiRemoteTrack - The remote media stream
   * wrapped in {@code JitsiRemoteTrack}.
   * @private
   * @returns {void}
   */


  _onRemoteStream(jitsiRemoteTrack) {
    this._tracks.push(jitsiRemoteTrack);

    this._options.onRemoteStream(jitsiRemoteTrack);
  }
  /**
   * Callback invoked when {@code JingleSessionPC} needs to signal a message
   * out to the remote peer.
   *
   * @param {XML} iq - The message to signal out.
   * @private
   * @returns {void}
   */


  _onSendMessage(iq) {
    this._options.onSendMessage(this._options.peerJid, iq);
  }
  /**
   * Callback invoked in response to an agreement to start a proxy connection.
   * The passed in jingle element should contain an SDP answer to a previously
   * sent SDP offer.
   *
   * @param {Object} $jingle - The jingle element wrapped in jQuery.
   * @private
   * @returns {void}
   */


  _onSessionAccept($jingle) {
    if (!this._peerConnection) {
      logger.error('Received an answer when no peer connection exists.');
      return;
    }

    this._peerConnection.setAnswer($jingle);
  }
  /**
   * Callback invoked in response to a request to start a proxy connection.
   * The passed in jingle element should contain an SDP offer.
   *
   * @param {Object} $jingle - The jingle element wrapped in jQuery.
   * @private
   * @returns {void}
   */


  _onSessionInitiate($jingle) {
    if (this._peerConnection) {
      logger.error('Received an offer when an offer was already sent.');
      return;
    }

    this._peerConnection = this._createPeerConnection();

    this._peerConnection.acceptOffer($jingle, () => {
      /** no-op */
    }, () => this._onError(this._options.peerJid, _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].CONNECTION_ERROR, 'session initiate error'));
  }
  /**
   * Callback invoked in response to a request to disconnect an active proxy
   * connection. Cleans up tracks and the peer connection.
   *
   * @private
   * @returns {void}
   */


  _onSessionTerminate() {
    this._tracks.forEach(track => track.dispose());

    this._tracks = [];

    if (this._peerConnection) {
      this._peerConnection.onTerminated();
    }

    if (this._rtc) {
      this._rtc.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_2___default.a.REMOTE_TRACK_ADDED, this._onRemoteStream);

      this._rtc.destroy();
    }
  }
  /**
   * Callback invoked in response to ICE candidates from the remote peer.
   * The passed in jingle element should contain an ICE candidate.
   *
   * @param {Object} $jingle - The jingle element wrapped in jQuery.
   * @private
   * @returns {void}
   */


  _onTransportInfo($jingle) {
    this._peerConnection.addIceCandidates($jingle);
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\proxyconnection\\ProxyConnectionPC.js"))

/***/ }),

/***/ "./modules/proxyconnection/ProxyConnectionService.js":
/*!***********************************************************!*\
  !*** ./modules/proxyconnection/ProxyConnectionService.js ***!
  \***********************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return ProxyConnectionService; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./service/RTC/VideoType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _RTC_RTC__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../RTC/RTC */ "./modules/RTC/RTC.js");
/* harmony import */ var _ProxyConnectionPC__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ProxyConnectionPC */ "./modules/proxyconnection/ProxyConnectionPC.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./constants */ "./modules/proxyconnection/constants.js");
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* globals $ */







const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Instantiates a new ProxyConnectionPC and ensures only one exists at a given
 * time. Currently it assumes ProxyConnectionPC is used only for screensharing
 * and assumes IQs to be used for communication.
 */

class ProxyConnectionService {
  /**
   * Initializes a new {@code ProxyConnectionService} instance.
   *
   * @param {Object} options - Values to initialize the instance with.
   * @param {boolean} [options.convertVideoToDesktop] - Whether or not proxied
   * video should be returned as a desktop stream. Defaults to false.
   * @param {Object} [options.iceConfig] - The {@code RTCConfiguration} to use
   * for the peer connection.
   * @param {JitsiConnection} [options.jitsiConnection] - The
   * {@code JitsiConnection} which will be used to fetch TURN credentials for
   * the P2P connection.
   * @param {Function} options.onRemoteStream - Callback to invoke when a
   * remote video stream has been received and converted to a
   * {@code JitsiLocakTrack}. The {@code JitsiLocakTrack} will be passed in.
   * @param {Function} options.onSendMessage - Callback to invoke when a
   * message has to be sent (signaled) out. The arguments passed in are the
   * jid to send the message to and the message
   */
  constructor(options = {}) {
    const {
      jitsiConnection
    } = options,
          otherOptions = _objectWithoutProperties(options, ["jitsiConnection"]);
    /**
     * Holds a reference to the collection of all callbacks.
     *
     * @type {Object}
     */


    this._options = _objectSpread({
      iceConfig: jitsiConnection && jitsiConnection.xmpp.connection.jingle.p2pIceConfig
    }, otherOptions);
    /**
     * The active instance of {@code ProxyConnectionService}.
     *
     * @type {ProxyConnectionPC|null}
     */

    this._peerConnection = null; // Bind event handlers so they are only bound once for every instance.

    this._onFatalError = this._onFatalError.bind(this);
    this._onSendMessage = this._onSendMessage.bind(this);
    this._onRemoteStream = this._onRemoteStream.bind(this);
  }
  /**
   * Parses a message object regarding a proxy connection to create a new
   * proxy connection or update and existing connection.
   *
   * @param {Object} message - A message object regarding establishing or
   * updating a proxy connection.
   * @param {Object} message.data - An object containing additional message
   * details.
   * @param {string} message.data.iq - The stringified iq which explains how
   * and what to update regarding the proxy connection.
   * @param {string} message.from - The message sender's full jid. Used for
   * sending replies.
   * @returns {void}
   */


  processMessage(message) {
    const peerJid = message.from;

    if (!peerJid) {
      return;
    } // If a proxy connection has already been established and messages come
    // from another peer jid then those messages should be replied to with
    // a rejection.


    if (this._peerConnection && this._peerConnection.getPeerJid() !== peerJid) {
      this._onFatalError(peerJid, _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].CONNECTION_ERROR, 'rejected');

      return;
    }

    const iq = this._convertStringToXML(message.data.iq);

    const $jingle = iq && iq.find('jingle');
    const action = $jingle && $jingle.attr('action');

    if (action === _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].INITIATE) {
      this._peerConnection = this._createPeerConnection(peerJid, {
        isInitiator: false,
        receiveVideo: true
      });
    } // Truthy check for peer connection added to protect against possibly
    // receiving actions before an ACTIONS.INITIATE.


    if (this._peerConnection) {
      this._peerConnection.processMessage($jingle);
    } // Take additional steps to ensure the peer connection is cleaned up
    // if it is to be closed.


    if (action === _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].CONNECTION_ERROR || action === _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].UNAVAILABLE || action === _constants__WEBPACK_IMPORTED_MODULE_6__["ACTIONS"].TERMINATE) {
      this._selfCloseConnection();
    }

    return;
  }
  /**
   * Instantiates and initiates a proxy peer connection.
   *
   * @param {string} peerJid - The jid of the remote client that should
   * receive messages.
   * @param {Array<JitsiLocalTrack>} localTracks - Initial media tracks to
   * send through to the peer.
   * @returns {void}
   */


  start(peerJid, localTracks = []) {
    this._peerConnection = this._createPeerConnection(peerJid, {
      isInitiator: true,
      receiveVideo: false
    });

    this._peerConnection.start(localTracks);
  }
  /**
   * Terminates any active proxy peer connection.
   *
   * @returns {void}
   */


  stop() {
    if (this._peerConnection) {
      this._peerConnection.stop();
    }

    this._peerConnection = null;
  }
  /**
   * Transforms a stringified xML into a XML wrapped in jQuery.
   *
   * @param {string} xml - The XML in string form.
   * @private
   * @returns {Object|null} A jQuery version of the xml. Null will be returned
   * if an error is encountered during transformation.
   */


  _convertStringToXML(xml) {
    try {
      const xmlDom = new DOMParser().parseFromString(xml, 'text/xml');
      return $(xmlDom);
    } catch (e) {
      logger.error('Attempted to convert incorrectly formatted xml');
      return null;
    }
  }
  /**
   * Helper for creating an instance of {@code ProxyConnectionPC}.
   *
   * @param {string} peerJid - The jid of the remote peer with which the
   * {@code ProxyConnectionPC} will be established with.
   * @param {Object} options - Additional defaults to instantiate the
   * {@code ProxyConnectionPC} with. See the constructor of ProxyConnectionPC
   * for more details.
   * @private
   * @returns {ProxyConnectionPC}
   */


  _createPeerConnection(peerJid, options = {}) {
    if (!peerJid) {
      throw new Error('Cannot create ProxyConnectionPC without a peer.');
    }

    const pcOptions = _objectSpread({
      iceConfig: this._options.iceConfig,
      onError: this._onFatalError,
      onRemoteStream: this._onRemoteStream,
      onSendMessage: this._onSendMessage,
      peerJid
    }, options);

    return new _ProxyConnectionPC__WEBPACK_IMPORTED_MODULE_5__["default"](pcOptions);
  }
  /**
   * Callback invoked when an error occurs that should cause
   * {@code ProxyConnectionPC} to be closed if the peer is currently
   * connected. Sends an error message/reply back to the peer.
   *
   * @param {string} peerJid - The peer jid with which the connection was
   * attempted or started, and to which an iq with error details should be
   * sent.
   * @param {string} errorType - The constant indicating the type of the error
   * that occured.
   * @param {string} details - Optional additional data about the error.
   * @private
   * @returns {void}
   */


  _onFatalError(peerJid, errorType, details = '') {
    logger.error('Received a proxy connection error', peerJid, errorType, details);
    const iq = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
      to: peerJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: errorType
    }).c('details').t(details).up();

    this._onSendMessage(peerJid, iq);

    if (this._peerConnection && this._peerConnection.getPeerJid() === peerJid) {
      this._selfCloseConnection();
    }
  }
  /**
   * Callback invoked when the remote peer of the {@code ProxyConnectionPC}
   * has offered a media stream. The stream is converted into a
   * {@code JitsiLocalTrack} for local usage if the {@code onRemoteStream}
   * callback is defined.
   *
   * @param {JitsiRemoteTrack} jitsiRemoteTrack - The {@code JitsiRemoteTrack}
   * for the peer's media stream.
   * @private
   * @returns {void}
   */


  _onRemoteStream(jitsiRemoteTrack) {
    if (!this._options.onRemoteStream) {
      logger.error('Remote track received without callback.');
      jitsiRemoteTrack.dispose();
      return;
    }

    const isVideo = jitsiRemoteTrack.isVideoTrack();
    let videoType;

    if (isVideo) {
      videoType = this._options.convertVideoToDesktop ? _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_3___default.a.DESKTOP : _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_3___default.a.CAMERA;
    } // Grab the webrtc media stream and pipe it through the same processing
    // that would occur for a locally obtained media stream.


    const mediaStream = jitsiRemoteTrack.getOriginalStream();
    const jitsiLocalTracks = _RTC_RTC__WEBPACK_IMPORTED_MODULE_4__["default"].newCreateLocalTracks([{
      deviceId: `proxy:${this._peerConnection.getPeerJid()}`,
      mediaType: isVideo ? _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__["VIDEO"] : _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__["AUDIO"],
      sourceType: 'proxy',
      stream: mediaStream,
      track: mediaStream.getVideoTracks()[0],
      videoType
    }]);

    this._options.onRemoteStream(jitsiLocalTracks[0]);
  }
  /**
   * Formats and forwards a message an iq to be sent to a peer jid.
   *
   * @param {string} peerJid - The jid the iq should be sent to.
   * @param {Object} iq - The iq which would be sent to the peer jid.
   * @private
   * @returns {void}
   */


  _onSendMessage(peerJid, iq) {
    if (!this._options.onSendMessage) {
      return;
    }

    try {
      const stringifiedIq = new XMLSerializer().serializeToString(iq.nodeTree || iq);

      this._options.onSendMessage(peerJid, {
        iq: stringifiedIq
      });
    } catch (e) {
      logger.error('Attempted to send an incorrectly formatted iq.');
    }
  }
  /**
   * Invoked when preemptively closing the {@code ProxyConnectionPC}.
   *
   * @private
   * @returns {void}
   */


  _selfCloseConnection() {
    this.stop();
    this._options.onConnectionClosed && this._options.onConnectionClosed();
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\proxyconnection\\ProxyConnectionService.js"))

/***/ }),

/***/ "./modules/proxyconnection/constants.js":
/*!**********************************************!*\
  !*** ./modules/proxyconnection/constants.js ***!
  \**********************************************/
/*! exports provided: ACTIONS */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTIONS", function() { return ACTIONS; });
/**
 * The know jingle actions that can be sent and should be acted upon by
 * {@code ProxyConnectionService} and {@code ProxyConnectionPC}.
 */
const ACTIONS = {
  ACCEPT: 'session-accept',
  CONNECTION_ERROR: 'connection-error-encountered',
  INITIATE: 'session-initiate',
  TERMINATE: 'session-terminate',
  TRANSPORT_INFO: 'transport-info',
  UNAVAILABLE: 'unavailable'
};

/***/ }),

/***/ "./modules/recording/JibriSession.js":
/*!*******************************************!*\
  !*** ./modules/recording/JibriSession.js ***!
  \*******************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JibriSession; });
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _recordingXMLUtils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./recordingXMLUtils */ "./modules/recording/recordingXMLUtils.js");


/**
 * Represents a recording session.
 */

class JibriSession {
  /**
   * Initializes a new JibriSession instance.
   *
   * @constructor
   */
  constructor(options = {}) {
    this._connection = options.connection;
    this._mode = options.mode;

    this._setSessionID(options.sessionID);

    this.setStatus(options.status);
  }
  /**
   * Returns the error related to the session instance, if any.
   *
   * @returns {string|undefined}
   */


  getError() {
    return this._error;
  }
  /**
   * Returns the session ID of the session instance.
   *
   * @returns {string|undefined}
   */


  getID() {
    return this._sessionID;
  }
  /**
   * Returns the initiator of the session instance.
   *
   * @returns {JitsiParticipant|undefined} The participant that started the session.
   */


  getInitiator() {
    return this._initiator;
  }
  /**
   * Returns the streaming URL of the session.
   *
   * @returns {string|undefined}
   */


  getLiveStreamViewURL() {
    return this._liveStreamViewURL;
  }
  /**
   * Returns the current status of the session.
   *
   * @returns {string|undefined}
   */


  getStatus() {
    return this._status;
  }
  /**
   * Returns the jid of the participant that stopped the session.
   *
   * @returns {JitsiParticipant|undefined} The participant that stopped the session.
   */


  getTerminator() {
    return this._terminator;
  }
  /**
   * Returns the current recording mode of the session, such as "file".
   *
   * @returns {string}
   */


  getMode() {
    return this._mode;
  }
  /**
   * Sets the last known error message related to the session.
   *
   * @param {string} error - The error string explaining why the session
   * entered an error state.
   * @returns {void}
   */


  setError(error) {
    this._error = error;
  }
  /**
   * Sets the last live stream URL for the session instance. Usually this is
   * a YouTube URL and usually this is only set for "stream" sessions.
   *
   * @param {string} url - The live stream URL associated with the session.
   * @returns {void}
   */


  setLiveStreamViewURL(url) {
    this._liveStreamViewURL = url;
  }
  /**
   * Sets the last known status for this recording session.
   *
   * @param {string} status - The new status to set.
   * @returns {void}
   */


  setStatus(status) {
    this._status = status;
  }
  /**
   * Sets the creator's jid of the session.
   * @param {JitsiParticipant} participant - The creator of the session.
   */


  setInitiator(participant) {
    this._initiator = participant;
  }
  /**
   * Sets the jid of the participant that stopped the session.
   * @param {JitsiParticipant} participant  - The participant's jid,
   * that stopped the session.
   */


  setTerminator(participant) {
    this._terminator = participant;
  }
  /**
   * Sends a message to start the actual recording.
   *
   * @param {Object} options - Additional arguments for starting the
   * recording.
   * @param {string} [options.appData] - Data specific to the app/service that
   * the result file will be uploaded.
   * @param {string} [options.broadcastId] - The broadcast ID of an
   * associated YouTube stream, used for knowing the URL from which the stream
   * can be viewed.
   * @param {string} options.focusMucJid - The JID of the focus participant
   * that controls recording.
   * @param {streamId} options.streamId - Necessary for live streaming, this
   * is the the stream key needed to start a live streaming session with the
   * streaming service provider.
   * @returns Promise
   */


  start({
    appData,
    broadcastId,
    focusMucJid,
    streamId
  }) {
    return new Promise((resolve, reject) => {
      this._connection.sendIQ(this._createIQ({
        action: 'start',
        appData,
        focusMucJid,
        broadcastId,
        streamId
      }), result => {
        // All users will eventually receive the 'pending' status
        // from the backend, but for the user initiating the session
        // it's better to give some instant feedback that recording
        // is starting so fire 'pending' here manually.
        this.setStatus('pending');

        this._setSessionID(_recordingXMLUtils__WEBPACK_IMPORTED_MODULE_1__["default"].getSessionIdFromIq(result));

        resolve();
      }, error => {
        this._setErrorFromIq(error);

        reject(error);
      });
    });
  }
  /**
   * Sends a message to actually stop the recording session.
   *
   * @param {Object} options - Additional arguments for stopping the
   * recording.
   * @param {Object} options.focusMucJid - The JID of the focus participant
   * that controls recording.
   * @returns Promise
   */


  stop({
    focusMucJid
  }) {
    return new Promise((resolve, reject) => {
      this._connection.sendIQ(this._createIQ({
        action: 'stop',
        focusMucJid
      }), resolve, reject);
    });
  }
  /**
   * Generates the message to change the status of the recording session.
   *
   * @param {string} status - The new status to which the recording session
   * should transition.
   * @param {string} [options.appData] - Data specific to the app/service that
   * the result file will be uploaded.
   * @param {string} [options.broadcastId] - The broadcast ID of an
   * associated YouTube stream, used for knowing the URL from which the stream
   * can be viewed.
   * @param {string} options.focusMucJid - The JID of the focus participant
   * that controls recording.
   * @param {streamId} options.streamId - Necessary for live streaming, this
   * is the the stream key needed to start a live streaming session with the
   * streaming service provider.
   * @returns Object - The XMPP IQ message.
   */


  _createIQ({
    action,
    appData,
    broadcastId,
    focusMucJid,
    streamId
  }) {
    return Object(strophe_js__WEBPACK_IMPORTED_MODULE_0__["$iq"])({
      to: focusMucJid,
      type: 'set'
    }).c('jibri', {
      'xmlns': 'http://jitsi.org/protocol/jibri',
      'action': action,
      'app_data': appData,
      'recording_mode': this._mode,
      'streamid': streamId,
      'you_tube_broadcast_id': broadcastId
    }).up();
  }
  /**
   * Handles the error from an iq and stores the error.
   *
   * @param {Node} errorIq - The error response from an Iq.
   * @private
   * @returns {void}
   */


  _setErrorFromIq(errorIq) {
    const error = errorIq.getElementsByTagName('error')[0];
    this.setError(error.children[0].tagName);
  }
  /**
   * Sets the known session ID for this recording session.
   *
   * @param {string} sessionID
   * @private
   * @returns {void}
   */


  _setSessionID(sessionID) {
    this._sessionID = sessionID;
  }

}

/***/ }),

/***/ "./modules/recording/RecordingManager.js":
/*!***********************************************!*\
  !*** ./modules/recording/RecordingManager.js ***!
  \***********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JibriSession__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./JibriSession */ "./modules/recording/JibriSession.js");
/* harmony import */ var _recordingXMLUtils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./recordingXMLUtils */ "./modules/recording/recordingXMLUtils.js");
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }





const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * A class responsible for starting and stopping recording sessions and emitting
 * state updates for them.
 */

class RecordingManager {
  /**
   * Initialize {@code RecordingManager} with other objects that are necessary
   * for starting a recording.
   *
   * @param {ChatRoom} chatRoom - The chat room to handle.
   * @returns {void}
   */
  constructor(chatRoom) {
    /**
     * All known recording sessions from the current conference.
     */
    this._sessions = {};
    this._chatRoom = chatRoom;
    this.onPresence = this.onPresence.bind(this);

    this._chatRoom.eventEmitter.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1___default.a.PRESENCE_RECEIVED, this.onPresence);
  }
  /**
   * Finds an existing recording session by session ID.
   *
   * @param {string} sessionID - The session ID associated with the recording.
   * @returns {JibriSession|undefined}
   */


  getSession(sessionID) {
    return this._sessions[sessionID];
  }
  /**
   * Callback to invoke to parse through a presence update to find recording
   * related updates (from Jibri participant doing the recording and the
   * focus which controls recording).
   *
   * @param {Object} event - The presence data from the pubsub event.
   * @param {Node} event.presence - An XMPP presence update.
   * @param {boolean} event.fromHiddenDomain - Whether or not the update comes
   * from a participant that is trusted but not visible, as would be the case
   * with the Jibri recorder participant.
   * @returns {void}
   */


  onPresence({
    fromHiddenDomain,
    presence
  }) {
    if (_recordingXMLUtils__WEBPACK_IMPORTED_MODULE_3__["default"].isFromFocus(presence)) {
      this._handleFocusPresence(presence);
    } else if (fromHiddenDomain) {
      this._handleJibriPresence(presence);
    }
  }
  /**
   * Start a recording session.
   *
   * @param {Object} options - Configuration for the recording.
   * @param {string} [options.appData] - Data specific to the app/service that
   * the result file will be uploaded.
   * @param {string} [optional] options.broadcastId - The channel on which a
   * live stream will occur.
   * @param {string} options.mode - The mode in which recording should be
   * started. Recognized values are "file" and "stream".
   * @param {string} [optional] options.streamId - The stream key to be used
   * for live stream broadcasting. Required for live streaming.
   * @returns {Promise} A promise for starting a recording, which will pass
   * back the session on success. The promise resolves after receiving an
   * acknowledgment of the start request success or fail.
   */


  startRecording(options) {
    const session = new _JibriSession__WEBPACK_IMPORTED_MODULE_2__["default"](_objectSpread({}, options, {
      connection: this._chatRoom.connection
    }));
    return session.start({
      appData: options.appData,
      broadcastId: options.broadcastId,
      focusMucJid: this._chatRoom.focusMucJid,
      streamId: options.streamId
    }).then(() => {
      // Only store the session and emit if the session has not been
      // added already. This is a workaround for the session getting
      // created due to a presence update to announce a "pending"
      // recording being received before JibriSession#start finishes.
      if (!this.getSession(session.getID())) {
        this._addSession(session);

        this._emitSessionUpdate(session);
      }

      return session;
    }).catch(error => {
      this._emitSessionUpdate(session);

      return Promise.reject(error);
    });
  }
  /**
   * Stop a recording session.
   *
   * @param {string} sessionID - The ID associated with the recording session
   * to be stopped.
   * @returns {Promise} The promise resolves after receiving an
   * acknowledgment of the stop request success or fail.
   */


  stopRecording(sessionID) {
    const session = this.getSession(sessionID);

    if (session) {
      return session.stop({
        focusMucJid: this._chatRoom.focusMucJid
      });
    }

    return Promise.reject(new Error('Could not find session'));
  }
  /**
   * Stores a reference to the passed in JibriSession.
   *
   * @param {string} session - The JibriSession instance to store.
   * @returns {void}
   */


  _addSession(session) {
    this._sessions[session.getID()] = session;
  }
  /**
   * Create a new instance of a recording session and stores a reference to
   * it.
   *
   * @param {string} sessionID - The session ID of the recording in progress.
   * @param {string} status - The current status of the recording session.
   * @param {string} mode - The recording mode of the session.
   * @returns {JibriSession}
   */


  _createSession(sessionID, status, mode) {
    const session = new _JibriSession__WEBPACK_IMPORTED_MODULE_2__["default"]({
      connection: this._chatRoom.connection,
      focusMucJid: this._chatRoom.focusMucJid,
      mode,
      sessionID,
      status
    });

    this._addSession(session);

    return session;
  }
  /**
   * Notifies listeners of an update to a recording session.
   *
   * @param {JibriSession} session - The session that has been updated.
   * @param {string|undefined} initiator - The jid of the initiator of the update.
   */


  _emitSessionUpdate(session, initiator) {
    this._chatRoom.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1___default.a.RECORDER_STATE_CHANGED, session, initiator);
  }
  /**
   * Parses presence to update an existing JibriSession or to create a new
   * JibriSession.
   *
   * @param {Node} presence - An XMPP presence update.
   * @returns {void}
   */


  _handleFocusPresence(presence) {
    const jibriStatus = _recordingXMLUtils__WEBPACK_IMPORTED_MODULE_3__["default"].getFocusRecordingUpdate(presence);

    if (!jibriStatus) {
      return;
    }

    const {
      error,
      initiator,
      recordingMode,
      sessionID,
      status
    } = jibriStatus; // We'll look for an existing session or create one (in case we're a
    // participant joining a call with an existing recording going on).

    let session = this.getSession(sessionID); // Handle the case where a status update is received in presence but
    // the local participant has joined while the JibriSession has already
    // ended.

    if (!session && status === 'off') {
      logger.warn('Ignoring recording presence update', 'Received a new session with status off.');
      return;
    } // Jicofo sends updates via presence, and any extension in presence
    // is sent until it is explicitly removed.  It's difficult for
    // Jicofo to know when a presence has been sent once, so it won't
    // remove jibri status extension.  This means we may receive the same
    // status update more than once, so check for that here


    if (session && session.getStatus() === status && session.getError() === error) {
      logger.warn('Ignoring duplicate presence update: ', JSON.stringify(jibriStatus));
      return;
    }

    if (!session) {
      session = this._createSession(sessionID, status, recordingMode);
    }

    session.setStatus(status);

    if (error) {
      session.setError(error);
    }

    this._emitSessionUpdate(session, initiator);
  }
  /**
   * Handles updates from the Jibri which can broadcast a YouTube URL that
   * needs to be updated in a JibriSession.
   *
   * @param {Node} presence - An XMPP presence update.
   * @returns {void}
   */


  _handleJibriPresence(presence) {
    const {
      liveStreamViewURL,
      mode,
      sessionID
    } = _recordingXMLUtils__WEBPACK_IMPORTED_MODULE_3__["default"].getHiddenDomainUpdate(presence);

    if (!sessionID) {
      logger.warn('Ignoring potential jibri presence due to no session id.');
      return;
    }

    let session = this.getSession(sessionID);

    if (!session) {
      session = this._createSession(sessionID, '', mode);
    }

    session.setLiveStreamViewURL(liveStreamViewURL);

    this._emitSessionUpdate(session);
  }

}

/* harmony default export */ __webpack_exports__["default"] = (RecordingManager);
/* WEBPACK VAR INJECTION */}.call(this, "modules\\recording\\RecordingManager.js"))

/***/ }),

/***/ "./modules/recording/recordingConstants.js":
/*!*************************************************!*\
  !*** ./modules/recording/recordingConstants.js ***!
  \*************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony default export */ __webpack_exports__["default"] = ({
  error: {
    BUSY: 'busy',
    ERROR: 'error',
    RESOURCE_CONSTRAINT: 'resource-constraint',
    SERVICE_UNAVAILABLE: 'service-unavailable'
  },
  mode: {
    FILE: 'file',
    STREAM: 'stream'
  },
  status: {
    OFF: 'off',
    ON: 'on',
    PENDING: 'pending'
  }
});

/***/ }),

/***/ "./modules/recording/recordingXMLUtils.js":
/*!************************************************!*\
  !*** ./modules/recording/recordingXMLUtils.js ***!
  \************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/**
 * A collection of utility functions for taking in XML and parsing it to return
 * certain values.
 */
/* harmony default export */ __webpack_exports__["default"] = ({
  /**
   * Parses the presence update of the focus and returns an object with the
   * statuses related to recording.
   *
   * @param {Node} presence - An XMPP presence update.
   * @returns {Object} The current presence values related to recording.
   */
  getFocusRecordingUpdate(presence) {
    const jibriStatus = presence && presence.getElementsByTagName('jibri-recording-status')[0];

    if (!jibriStatus) {
      return;
    }

    return {
      error: jibriStatus.getAttribute('failure_reason'),
      initiator: jibriStatus.getAttribute('initiator'),
      recordingMode: jibriStatus.getAttribute('recording_mode'),
      sessionID: jibriStatus.getAttribute('session_id'),
      status: jibriStatus.getAttribute('status')
    };
  },

  /**
   * Parses the presence update from a hidden domain participant and returns
   * an object with the statuses related to recording.
   *
   * @param {Node} presence - An XMPP presence update.
   * @returns {Object} The current presence values related to recording.
   */
  getHiddenDomainUpdate(presence) {
    const liveStreamViewURLContainer = presence.getElementsByTagName('live-stream-view-url')[0];
    const liveStreamViewURL = liveStreamViewURLContainer && liveStreamViewURLContainer.textContent;
    const modeContainer = presence.getElementsByTagName('mode')[0];
    const mode = modeContainer && modeContainer.textContent && modeContainer.textContent.toLowerCase();
    const sessionIDContainer = presence.getElementsByTagName('session_id')[0];
    const sessionID = sessionIDContainer && sessionIDContainer.textContent;
    return {
      liveStreamViewURL,
      mode,
      sessionID
    };
  },

  /**
   * Returns the recording session ID from a successful IQ.
   *
   * @param {Node} response - The response from the IQ.
   * @returns {string} The session ID of the recording session.
   */
  getSessionIdFromIq(response) {
    const jibri = response && response.getElementsByTagName('jibri')[0];
    return jibri && jibri.getAttribute('session_id');
  },

  /**
   * Returns the recording session ID from a presence, if it exists.
   *
   * @param {Node} presence - An XMPP presence update.
   * @returns {string|undefined} The session ID of the recording session.
   */
  getSessionId(presence) {
    const sessionIdContainer = presence.getElementsByTagName('session_id')[0];
    const sessionId = sessionIdContainer && sessionIdContainer.textContent;
    return sessionId;
  },

  /**
   * Returns whether or not a presence is from the focus.
   *
   * @param {Node} presence - An XMPP presence update.
   * @returns {boolean} True if the presence is from the focus.
   */
  isFromFocus(presence) {
    return presence.getAttribute('from').includes('focus');
  }

});

/***/ }),

/***/ "./modules/rttmonitor/rttmonitor.js":
/*!******************************************!*\
  !*** ./modules/rttmonitor/rttmonitor.js ***!
  \******************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return RttMonitor; });
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _RTC_RTCUtils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../RTC/RTCUtils */ "./modules/RTC/RTCUtils.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");





const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__["getLogger"])(__filename);
/**
 * The options to pass to createOffer (we need to offer to receive *something*
 * for the PC to gather candidates.
 */

const offerOptions = {
  offerToReceiveAudio: 1,
  offerToReceiveVideo: 0
};
/**
 * The interval at which the webrtc engine sends STUN keep alive requests.
 * @type {number}
 */

const stunKeepAliveIntervalMs = 10000;
/**
 * Wraps a PeerConnection with one specific STUN server and measures the RTT
 * to the STUN server.
 */

class PCMonitor {
  /* eslint-disable max-params */

  /**
   *
   * @param {String} region - The region of the STUN server.
   * @param {String} address - The address of the STUN server.
   * @param {number} getStatsIntervalMs how often to call getStats.
   * @param {number} delay the delay after which the PeerConnection will be
   * started (that is, createOffer and setLocalDescription will be invoked).
   *
   */
  constructor(region, address, getStatsIntervalMs, delay) {
    /* eslint-disable max-params */
    this.region = region;
    this.getStatsIntervalMs = getStatsIntervalMs;
    this.getStatsInterval = null; // What we consider the current RTT. It is Math.min(this.rtts).

    this.rtt = Infinity; // The RTT measurements we've made from the latest getStats() calls.

    this.rtts = [];
    const iceServers = [{
      'url': `stun:${address}`
    }];
    this.pc = new _RTC_RTCUtils__WEBPACK_IMPORTED_MODULE_3__["default"].RTCPeerConnectionType({
      'iceServers': iceServers
    }); // Maps a key consisting of the IP address, port and priority of a
    // candidate to some state related to it. If we have more than one
    // network interface we will might multiple srflx candidates and this
    // helps to distinguish between then.

    this.candidates = {};
    this.stopped = false;
    this.start = this.start.bind(this);
    this.stop = this.stop.bind(this);
    this.startStatsInterval = this.startStatsInterval.bind(this);
    this.handleCandidateRtt = this.handleCandidateRtt.bind(this);
    window.setTimeout(this.start, delay);
  }
  /**
   * Starts this PCMonitor. That is, invokes createOffer and
   * setLocalDescription on the PeerConnection and starts an interval which
   * calls getStats.
   */


  start() {
    if (this.stopped) {
      return;
    }

    this.pc.createOffer(offerOptions).then(offer => {
      this.pc.setLocalDescription(offer, () => {
        logger.info(`setLocalDescription success for ${this.region}`);
        this.startStatsInterval();
      }, error => {
        logger.warn(`setLocalDescription failed for ${this.region}: ${error}`);
      });
    });
  }
  /**
   * Starts an interval which invokes getStats on the PeerConnection and
   * measures the RTTs for the different candidates.
   */


  startStatsInterval() {
    this.getStatsInterval = window.setInterval(() => {
      // Note that the data that we use to measure the RTT is only
      // available in the legacy (callback based) getStats API.
      this.pc.getStats(stats => {
        const results = stats.result();

        for (let i = 0; i < results.length; ++i) {
          const res = results[i];
          const rttTotal = Number(res.stat('stunKeepaliveRttTotal')); // We recognize the results that we care for (local
          // candidates of type srflx) by the existance of the
          // stunKeepaliveRttTotal stat.

          if (rttTotal > 0) {
            const candidateKey = `${res.stat('ipAddress')}_${res.stat('portNumber')}_${res.stat('priority')}`;
            this.handleCandidateRtt(candidateKey, rttTotal, Number(res.stat('stunKeepaliveResponsesReceived')), Number(res.stat('stunKeepaliveRequestsSent')));
          }
        } // After we've measured the RTT for all candidates we,
        // update the state of the PC with the shortest one.


        let rtt = Infinity;

        for (const key in this.candidates) {
          if (this.candidates.hasOwnProperty(key) && this.candidates[key].rtt > 0) {
            rtt = Math.min(rtt, this.candidates[key].rtt);
          }
        } // We keep the last 6 measured RTTs and choose the shortest
        // one to export to analytics. This is because we often see
        // failures get a real measurement which end up as Infinity.


        this.rtts.push(rtt);

        if (this.rtts.length > 6) {
          this.rtts = this.rtts.splice(1, 7);
        }

        this.rtt = Math.min(...this.rtts);
      });
    }, this.getStatsIntervalMs);
  }
  /* eslint-disable max-params */

  /**
   * Updates the RTT for a candidate identified by "key" based on the values
   * from getStats() and the previously saved state (i.e. old values).
   *
   * @param {String} key the ID for the candidate
   * @param {number} rttTotal the value of the 'stunKeepaliveRttTotal' just
   * measured.
   * @param {number} responsesReceived the value of the
   * 'stunKeepaliveResponsesReceived' stat just measured.
   * @param {number} requestsSent the value of the 'stunKeepaliveRequestsSent'
   * stat just measured.
   */


  handleCandidateRtt(key, rttTotal, responsesReceived, requestsSent) {
    /* eslist-enable max-params */
    if (!this.candidates[key]) {
      this.candidates[key] = {
        rttTotal: 0,
        responsesReceived: 0,
        requestsSent: 0,
        rtt: NaN
      };
    }

    const rttTotalDiff = rttTotal - this.candidates[key].rttTotal;
    const responsesReceivedDiff = responsesReceived - this.candidates[key].responsesReceived; // We observe that when the difference between the number of requests
    // and responses has grown (i.q. when the value below is positive), the
    // the RTT measurements are incorrect (too low). For this reason we
    // ignore these measurement (setting rtt=NaN), but update our state.

    const requestsResponsesDiff = requestsSent - responsesReceived - (this.candidates[key].requestsSent - this.candidates[key].responsesReceived);
    let rtt = NaN;

    if (responsesReceivedDiff > 0 && requestsResponsesDiff === 0) {
      rtt = rttTotalDiff / responsesReceivedDiff;
    }

    this.candidates[key].rttTotal = rttTotal;
    this.candidates[key].responsesReceived = responsesReceived;
    this.candidates[key].requestsSent = requestsSent;
    this.candidates[key].rtt = rtt;
  }
  /**
   * Stops this PCMonitor, clearing its intervals and stopping the
   * PeerConnection.
   */


  stop() {
    if (this.getStatsInterval) {
      window.clearInterval(this.getStatsInterval);
    }

    this.pc.close();
    this.stopped = true;
  }

}
/**
 * A class which monitors the round-trip time (RTT) to a set of STUN servers.
 * The measured RTTs are sent as analytics events. It uses a separate
 * PeerConnection (represented as a PCMonitor) for each STUN server.
 */


class RttMonitor {
  /**
   * Initializes a new RttMonitor.
   * @param {Object} config the object holding the configuration.
   */
  constructor(config) {
    if (!config || !config.enabled || !_browser__WEBPACK_IMPORTED_MODULE_0__["default"].supportsLocalCandidateRttStatistics()) {
      return;
    } // Maps a region to the PCMonitor instance for that region.


    this.pcMonitors = {};
    this.startPCMonitors = this.startPCMonitors.bind(this);
    this.sendAnalytics = this.sendAnalytics.bind(this);
    this.stop = this.stop.bind(this);
    this.analyticsInterval = null;
    this.stopped = false;
    const initialDelay = config.initialDelay || 60000;
    logger.info(`Starting RTT monitor with an initial delay of ${initialDelay}`);
    window.setTimeout(() => this.startPCMonitors(config), initialDelay);
  }
  /**
   * Starts the PCMonitors according to the configuration.
   */


  startPCMonitors(config) {
    if (!config.stunServers) {
      logger.warn('No stun servers configured.');
      return;
    }

    if (this.stopped) {
      return;
    }

    const getStatsIntervalMs = config.getStatsInterval || stunKeepAliveIntervalMs;
    const analyticsIntervalMs = config.analyticsInterval || getStatsIntervalMs;
    const count = Object.keys(config.stunServers).length;
    const offset = getStatsIntervalMs / count; // We delay the initialization of each PC so that they are uniformly
    // distributed across the getStatsIntervalMs.

    let i = 0;

    for (const region in config.stunServers) {
      if (config.stunServers.hasOwnProperty(region)) {
        const address = config.stunServers[region];
        this.pcMonitors[region] = new PCMonitor(region, address, getStatsIntervalMs, offset * i);
        i++;
      }
    }

    window.setTimeout(() => {
      if (!this.stopped) {
        this.analyticsInterval = window.setInterval(this.sendAnalytics, analyticsIntervalMs);
      }
    }, 1000);
  }
  /**
   * Sends an analytics event with the measured RTT to each region/STUN
   * server.
   */


  sendAnalytics() {
    const rtts = {};

    for (const region in this.pcMonitors) {
      if (this.pcMonitors.hasOwnProperty(region)) {
        const rtt = this.pcMonitors[region].rtt;

        if (!isNaN(rtt) && rtt !== Infinity) {
          rtts[region.replace('-', '_')] = rtt;
        }
      }
    }

    if (rtts) {
      _statistics_statistics__WEBPACK_IMPORTED_MODULE_4__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createRttByRegionEvent"])(rtts));
    }
  }
  /**
   * Stops this RttMonitor, clearing all intervals and closing all
   * PeerConnections.
   */


  stop() {
    logger.info('Stopping RttMonitor.');
    this.stopped = true;

    for (const region in this.pcMonitors) {
      if (this.pcMonitors.hasOwnProperty(region)) {
        this.pcMonitors[region].stop();
      }
    }

    this.pcMonitors = {};

    if (this.analyticsInterval) {
      window.clearInterval(this.analyticsInterval);
    }
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\rttmonitor\\rttmonitor.js"))

/***/ }),

/***/ "./modules/settings/Settings.js":
/*!**************************************!*\
  !*** ./modules/settings/Settings.js ***!
  \**************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _util_UsernameGenerator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/UsernameGenerator */ "./modules/util/UsernameGenerator.js");
/* harmony import */ var _util_UsernameGenerator__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_util_UsernameGenerator__WEBPACK_IMPORTED_MODULE_1__);

const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);


let _callStatsUserName;

let _machineId;
/**
 *
 */


/* harmony default export */ __webpack_exports__["default"] = ({
  /**
   * Returns fake username for callstats
   * @returns {string} fake username for callstats
   */
  get callStatsUserName() {
    if (!_callStatsUserName) {
      const localStorage = getLocalStorage();

      if (localStorage) {
        _callStatsUserName = localStorage.getItem('callStatsUserName');
      }

      if (!_callStatsUserName) {
        _callStatsUserName = generateCallStatsUserName();

        if (localStorage) {
          localStorage.setItem('callStatsUserName', _callStatsUserName);
        }
      }
    }

    return _callStatsUserName;
  },

  /**
   * Returns current machine id.
   * @returns {string} machine id
   */
  get machineId() {
    if (!_machineId) {
      const localStorage = getLocalStorage();

      if (localStorage) {
        _machineId = localStorage.getItem('jitsiMeetId');
      }

      if (!_machineId) {
        _machineId = generateJitsiMeetId();

        if (localStorage) {
          localStorage.setItem('jitsiMeetId', _machineId);
        }
      }
    }

    return _machineId;
  },

  /**
   * Returns current session id.
   * @returns {string} current session id
   */
  get sessionId() {
    // We may update sessionId in localStorage from another JitsiConference
    // instance and that's why we should always re-read it.
    const localStorage = getLocalStorage();
    return localStorage ? localStorage.getItem('sessionId') : undefined;
  },

  /**
   * Save current session id.
   * @param {string} sessionId session id
   */
  set sessionId(sessionId) {
    const localStorage = getLocalStorage();

    if (localStorage) {
      if (sessionId) {
        localStorage.setItem('sessionId', sessionId);
      } else {
        localStorage.removeItem('sessionId');
      }
    }
  }

});
/**
 * Generate fake username for callstats.
 * @returns {string} fake random username
 */

function generateCallStatsUserName() {
  const username = _util_UsernameGenerator__WEBPACK_IMPORTED_MODULE_1___default.a.generateUsername();
  logger.log('generated callstats uid', username);
  return username;
}
/**
 * Generate unique id.
 * @returns {string} random unique id
 */


function generateJitsiMeetId() {
  const jitsiMeetId = generateUniqueId();
  logger.log('generated id', jitsiMeetId);
  return jitsiMeetId;
}
/**
 * Gets the localStorage of the browser. (Technically, gets the localStorage of
 * the global object because there may be no browser but React Native for
 * example).
 * @returns {Storage} the local Storage object (if any)
 */


function getLocalStorage() {
  let storage;

  try {
    // eslint-disable-next-line no-invalid-this
    storage = (window || this).localStorage;
  } catch (error) {
    logger.error(error);
  }

  return storage;
}
/**
 *
 */


function generateUniqueId() {
  return _p8() + _p8() + _p8() + _p8();
}
/**
 *
 */


function _p8() {
  return `${Math.random().toString(16)}000000000`.substr(2, 8);
}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\settings\\Settings.js"))

/***/ }),

/***/ "./modules/statistics/AnalyticsAdapter.js":
/*!************************************************!*\
  !*** ./modules/statistics/AnalyticsAdapter.js ***!
  \************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }




const MAX_CACHE_SIZE = 100; // eslist-disable-line no-undef

const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__["getLogger"])(__filename);
/**
 * This class provides an API to lib-jitsi-meet and its users for sending
 * analytics events. It serves as a bridge to different backend implementations
 * ("analytics handlers") and a cache for events attempted to be sent before
 * the analytics handlers were enabled.
 *
 * The API is designed to be an easy replacement for the previous version of
 * this adapter, and is meant to be extended with more convenience methods.
 *
 *
 * The API calls are translated to objects with the following structure, which
 * are then passed to the sendEvent(event) function of the underlying handlers:
 *
 * {
 *    type,
 *
 *    action,
 *    actionSubject,
 *    actionSubjectId,
 *    attributes,
 *    categories,
 *    containerId,
 *    containerType,
 *    name,
 *    objectId,
 *    objectType,
 *    source,
 *    tags
 * }
 *
 * The 'type' is one of 'operational', 'page', 'track' or 'ui', and some of the
 * other properties are considered required according to the type.
 *
 * For events with type 'page', the required properties are: name.
 *
 * For events with type 'operational' and 'ui', the required properties are:
 * action, actionSubject, source
 *
 * For events with type 'page', the required properties are:
 * action, actionSubject, source, containerType, containerId, objectType,
 * objectId
 */

class AnalyticsAdapter {
  /**
   * Creates new AnalyticsAdapter instance.
   */
  constructor() {
    this.reset();
  }
  /**
   * Reset the state to the initial one.
   *
   * @returns {void}
   */


  reset() {
    /**
     * Whether this AnalyticsAdapter has been disposed of or not. Once this
     * is set to true, the AnalyticsAdapter is disabled and does not accept
     * any more events, and it can not be re-enabled.
     * @type {boolean}
     */
    this.disposed = false;
    /**
     * The set of handlers to which events will be sent.
     * @type {Set<any>}
     */

    this.analyticsHandlers = new Set();
    /**
     * The cache of events which are not sent yet. The cache is enabled
     * while this field is truthy, and disabled otherwise.
     * @type {Array}
     */

    this.cache = [];
    /**
     * Map of properties that will be added to every event. Note that the
     * keys will be prefixed with "permanent.".
     */

    this.permanentProperties = {};
    /**
     * The name of the conference that this AnalyticsAdapter is associated
     * with.
     * @type {null}
     */

    this.conferenceName = '';
    this.addPermanentProperties({
      'user_agent': navigator.userAgent,
      'browser_name': _browser__WEBPACK_IMPORTED_MODULE_2__["default"].getName()
    });
  }
  /**
   * Dispose analytics. Clears all handlers.
   */


  dispose() {
    logger.warn('Disposing of analytics adapter.');

    if (this.analyticsHandlers && this.analyticsHandlers.size > 0) {
      this.analyticsHandlers.forEach(handler => {
        if (typeof handler.dispose === 'function') {
          handler.dispose();
        }
      });
    }

    this.setAnalyticsHandlers([]);
    this.disposed = true;
  }
  /**
   * Sets the handlers that are going to be used to send analytics. Sends any
   * cached events.
   * @param {Array} handlers the handlers
   */


  setAnalyticsHandlers(handlers) {
    if (this.disposed) {
      return;
    }

    this.analyticsHandlers = new Set(handlers);

    this._setUserProperties(); // Note that we disable the cache even if the set of handlers is empty.


    const cache = this.cache;
    this.cache = null;

    if (cache) {
      cache.forEach(event => this._sendEvent(event));
    }
  }
  /**
   * Set the user properties to the analytics handlers.
   *
   * @returns {void}
   */


  _setUserProperties() {
    this.analyticsHandlers.forEach(handler => {
      try {
        handler.setUserProperties(this.permanentProperties);
      } catch (error) {
        logger.warn('Error in setUserProperties method of one of the ' + `analytics handlers: ${error}`);
      }
    });
  }
  /**
   * Adds a set of permanent properties to this this AnalyticsAdapter.
   * Permanent properties will be added as "attributes" to events sent to
   * the underlying "analytics handlers", and their keys will be prefixed
   * by "permanent_", i.e. adding a permanent property {key: "value"} will
   * result in {"permanent_key": "value"} object to be added to the
   * "attributes" field of events.
   *
   * @param {Object} properties the properties to add
   */


  addPermanentProperties(properties) {
    this.permanentProperties = _objectSpread({}, this.permanentProperties, properties);

    this._setUserProperties();
  }
  /**
   * Sets the name of the conference that this AnalyticsAdapter is associated
   * with.
   * @param name the name to set.
   */


  setConferenceName(name) {
    this.conferenceName = name;
    this.addPermanentProperties({
      'conference_name': name
    });
  }
  /**
   * Sends an event with a given name and given properties. The first
   * parameter is either a string or an object. If it is a string, it is used
   * as the event name and the second parameter is used at the attributes to
   * attach to the event. If it is an object, it represents the whole event,
   * including any desired attributes, and the second parameter is ignored.
   *
   * @param {String|Object} eventName either a string to be used as the name
   * of the event, or an event object. If an event object is passed, the
   * properties parameters is ignored.
   * @param {Object} properties the properties/attributes to attach to the
   * event, if eventName is a string.
   */


  sendEvent(eventName, properties = {}) {
    if (this.disposed) {
      return;
    }

    let event = null;

    if (typeof eventName === 'string') {
      event = {
        type: _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["TYPE_OPERATIONAL"],
        action: eventName,
        actionSubject: eventName,
        source: eventName,
        attributes: properties
      };
    } else if (typeof eventName === 'object') {
      event = eventName;
    }

    if (!this._verifyRequiredFields(event)) {
      logger.error(`Dropping a mis-formatted event: ${JSON.stringify(event)}`);
      return;
    }

    this._sendEvent(event);
  }
  /**
   * Checks whether an event has all of the required fields set, and tries
   * to fill in some of the missing fields with reasonable default values.
   * Returns true if after this operation the event has all of the required
   * fields set, and false otherwise (if some of the required fields were not
   * set and the attempt to fill them in with a default failed).
   *
   * @param event the event object.
   * @return {boolean} true if the event (after the call to this function)
   * contains all of the required fields, and false otherwise.
   * @private
   */


  _verifyRequiredFields(event) {
    if (!event) {
      return false;
    }

    if (!event.type) {
      event.type = _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["TYPE_OPERATIONAL"];
    }

    const type = event.type;

    if (type !== _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["TYPE_OPERATIONAL"] && type !== _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["TYPE_PAGE"] && type !== _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["TYPE_UI"] && type !== _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["TYPE_TRACK"]) {
      logger.error(`Unknown event type: ${type}`);
      return false;
    }

    if (type === _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["TYPE_PAGE"]) {
      return Boolean(event.name);
    } // Try to set some reasonable default values in case some of the
    // parameters required by the handler API are missing.


    event.action = event.action || event.name || event.actionSubject;
    event.actionSubject = event.actionSubject || event.name || event.action;
    event.source = event.source || event.name || event.action || event.actionSubject;

    if (!event.action || !event.actionSubject || !event.source) {
      logger.error('Required field missing (action, actionSubject or source)');
      return false;
    } // Track events have additional required fields.


    if (type === _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["TYPE_TRACK"]) {
      event.objectType = event.objectType || 'generic-object-type';
      event.containerType = event.containerType || 'conference';

      if (event.containerType === 'conference' && !event.containerId) {
        event.containerId = this.conferenceName;
      }

      if (!event.objectType || !event.objectId || !event.containerType || !event.containerId) {
        logger.error('Required field missing (containerId, containerType, ' + 'objectId or objectType)');
        return false;
      }
    }

    return true;
  }
  /**
   * Saves an event to the cache, if the cache is enabled.
   * @param event the event to save.
   * @returns {boolean} true if the event was saved, and false otherwise (i.e.
   * if the cache was disabled).
   * @private
   */


  _maybeCacheEvent(event) {
    if (this.cache) {
      this.cache.push(event); // We limit the size of the cache, in case the user fails to ever
      // set the analytics handlers.

      if (this.cache.length > MAX_CACHE_SIZE) {
        this.cache.splice(0, 1);
      }

      return true;
    }

    return false;
  }
  /**
   *
   * @param event
   * @private
   */


  _sendEvent(event) {
    if (this._maybeCacheEvent(event)) {// The event was consumed by the cache.
    } else {
      this.analyticsHandlers.forEach(handler => {
        try {
          handler.sendEvent(event);
        } catch (e) {
          logger.warn(`Error sending analytics event: ${e}`);
        }
      });
    }
  }

}

/* harmony default export */ __webpack_exports__["default"] = (new AnalyticsAdapter());
/* WEBPACK VAR INJECTION */}.call(this, "modules\\statistics\\AnalyticsAdapter.js"))

/***/ }),

/***/ "./modules/statistics/AudioOutputProblemDetector.js":
/*!**********************************************************!*\
  !*** ./modules/statistics/AudioOutputProblemDetector.js ***!
  \**********************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return AudioOutputProblemDetector; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/connectivity/ConnectionQualityEvents */ "./service/connectivity/ConnectionQualityEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _statistics__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./statistics */ "./modules/statistics/statistics.js");






const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Number of local samples that will be used for comparison before and after the remote sample is received.
 */

const NUMBER_OF_LOCAL_SAMPLES = 2;
/**
 * Collects the average audio levels per participant from the local stats and the stats received by every remote
 * participant and compares them to detect potential audio problem for a participant.
 */

class AudioOutputProblemDetector {
  /**
   * Creates new <tt>AudioOutputProblemDetector</tt> instance.
   *
   * @param {JitsiCofnerence} conference - The conference instance to be monitored.
   */
  constructor(conference) {
    this._conference = conference;
    this._localAudioLevelCache = {};
    this._reportedParticipants = [];
    this._audioProblemCandidates = {};
    this._numberOfRemoteAudioLevelsReceived = {};
    this._onLocalAudioLevelsReport = this._onLocalAudioLevelsReport.bind(this);
    this._onRemoteAudioLevelReceived = this._onRemoteAudioLevelReceived.bind(this);
    this._clearUserData = this._clearUserData.bind(this);

    this._conference.on(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_2__["REMOTE_STATS_UPDATED"], this._onRemoteAudioLevelReceived);

    this._conference.statistics.addConnectionStatsListener(this._onLocalAudioLevelsReport);

    this._conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["USER_LEFT"], this._clearUserData);
  }
  /**
   * A listener for audio level data received by a remote participant.
   *
   * @param {string} userID - The user id of the participant that sent the data.
   * @param {number} audioLevel - The average audio level value.
   * @returns {void}
   */


  _onRemoteAudioLevelReceived(userID, {
    avgAudioLevels
  }) {
    const numberOfReports = this._numberOfRemoteAudioLevelsReceived[userID] + 1 || 0;
    this._numberOfRemoteAudioLevelsReceived[userID] = numberOfReports;

    if (this._reportedParticipants.indexOf(userID) !== -1 || userID in this._audioProblemCandidates || avgAudioLevels <= 0 || numberOfReports < 3) {
      return;
    }

    const participant = this._conference.getParticipantById(userID);

    if (participant) {
      const tracks = participant.getTracksByMediaType(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__["AUDIO"]);

      if (tracks.length > 0 && participant.isAudioMuted()) {
        // We don't need to report an error if everything seems fine with the participant and its tracks but
        // the participant is audio muted. Since those are average audio levels we potentially can receive non
        // zero values for muted track.
        return;
      }
    }

    const localAudioLevels = this._localAudioLevelCache[userID];

    if (!Array.isArray(localAudioLevels) || localAudioLevels.every(audioLevel => audioLevel === 0)) {
      this._audioProblemCandidates[userID] = {
        remoteAudioLevels: avgAudioLevels,
        localAudioLevels: []
      };
    }
  }
  /**
   * A listener for audio level data retrieved by the local stats.
   *
   * @param {TraceablePeerConnection} tpc - The <tt>TraceablePeerConnection</tt> instance used to gather the data.
   * @param {Object} avgAudioLevels - The average audio levels per participant.
   * @returns {void}
   */


  _onLocalAudioLevelsReport(tpc, {
    avgAudioLevels
  }) {
    if (tpc !== this._conference.getActivePeerConnection()) {
      return;
    }

    Object.keys(avgAudioLevels).forEach(userID => {
      if (this._reportedParticipants.indexOf(userID) !== -1) {
        return;
      }

      const localAudioLevels = this._localAudioLevelCache[userID];

      if (!Array.isArray(localAudioLevels)) {
        this._localAudioLevelCache[userID] = [];
      } else if (localAudioLevels.length >= NUMBER_OF_LOCAL_SAMPLES) {
        localAudioLevels.shift();
      }

      this._localAudioLevelCache[userID].push(avgAudioLevels[userID]);
    });
    Object.keys(this._audioProblemCandidates).forEach(userID => {
      const {
        localAudioLevels,
        remoteAudioLevels
      } = this._audioProblemCandidates[userID];
      localAudioLevels.push(avgAudioLevels[userID]);

      if (localAudioLevels.length === NUMBER_OF_LOCAL_SAMPLES) {
        if (localAudioLevels.every(audioLevel => typeof audioLevel === 'undefined' || audioLevel === 0)) {
          const localAudioLevelsString = JSON.stringify(localAudioLevels);
          _statistics__WEBPACK_IMPORTED_MODULE_5__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__["createAudioOutputProblemEvent"])(userID, localAudioLevelsString, remoteAudioLevels));
          logger.warn(`A potential problem is detected with the audio output for participant ${userID}, local audio levels: ${localAudioLevelsString}, remote audio levels: ${remoteAudioLevels}`);

          this._reportedParticipants.push(userID);

          this._clearUserData(userID);
        }

        delete this._audioProblemCandidates[userID];
      }
    });
  }
  /**
   * Clears the data stored for a participant.
   *
   * @param {string} userID - The id of the participant.
   * @returns {void}
   */


  _clearUserData(userID) {
    delete this._localAudioLevelCache[userID];
  }
  /**
   * Disposes the allocated resources.
   *
   * @returns {void}
   */


  dispose() {
    this._conference.off(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_2__["REMOTE_STATS_UPDATED"], this._onRemoteAudioLevelReceived);

    this._conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__["USER_LEFT"], this._clearUserData);

    this._conference.statistics.removeConnectionStatsListener(this._onLocalAudioLevelsReport);

    this._localAudioLevelCache = undefined;
    this._audioProblemCandidates = undefined;
    this._reportedParticipants = undefined;
    this._numberOfRemoteAudioLevelsReceived = undefined;
    this._conference = undefined;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\statistics\\AudioOutputProblemDetector.js"))

/***/ }),

/***/ "./modules/statistics/AvgRTPStatsReporter.js":
/*!***************************************************!*\
  !*** ./modules/statistics/AvgRTPStatsReporter.js ***!
  \***************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return AvgRTPStatsReporter; });
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! lodash.isequal */ "./node_modules/lodash.isequal/index.js");
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(lodash_isequal__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/connectivity/ConnectionQualityEvents */ "./service/connectivity/ConnectionQualityEvents.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _statistics__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./service/RTC/VideoType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__);
/* global __filename */









const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_2__["getLogger"])(__filename);
/**
 * This will calculate an average for one, named stat and submit it to
 * the analytics module when requested. It automatically counts the samples.
 */

class AverageStatReport {
  /**
   * Creates new <tt>AverageStatReport</tt> for given name.
   * @param {string} name that's the name of the event that will be reported
   * to the analytics module.
   */
  constructor(name) {
    this.name = name;
    this.count = 0;
    this.sum = 0;
    this.samples = [];
  }
  /**
   * Adds the next value that will be included in the average when
   * {@link calculate} is called.
   * @param {number} nextValue
   */


  addNext(nextValue) {
    if (typeof nextValue !== 'number') {
      logger.error(`${this.name} - invalid value for idx: ${this.count}`, nextValue);
    } else if (!isNaN(nextValue)) {
      this.sum += nextValue;
      this.samples.push(nextValue);
      this.count += 1;
    }
  }
  /**
   * Calculates an average for the samples collected using {@link addNext}.
   * @return {number|NaN} an average of all collected samples or <tt>NaN</tt>
   * if no samples were collected.
   */


  calculate() {
    return this.sum / this.count;
  }
  /**
   * Appends the report to the analytics "data" object. The object will be
   * set under <tt>prefix</tt> + {@link this.name} key.
   * @param {Object} report the analytics "data" object
   */


  appendReport(report) {
    report[`${this.name}_avg`] = this.calculate();
    report[`${this.name}_samples`] = JSON.stringify(this.samples);
  }
  /**
   * Clears all memory of any samples collected, so that new average can be
   * calculated using this instance.
   */


  reset() {
    this.samples = [];
    this.sum = 0;
    this.count = 0;
  }

}
/**
 * Class gathers the stats that are calculated and reported for a
 * {@link TraceablePeerConnection} even if it's not currently active. For
 * example we want to monitor RTT for the JVB connection while in P2P mode.
 */


class ConnectionAvgStats {
  /**
   * Creates new <tt>ConnectionAvgStats</tt>
   * @param {AvgRTPStatsReporter} avgRtpStatsReporter
   * @param {boolean} isP2P
   * @param {number} n the number of samples, before arithmetic mean is to be
   * calculated and values submitted to the analytics module.
   */
  constructor(avgRtpStatsReporter, isP2P, n) {
    /**
     * Is this instance for JVB or P2P connection ?
     * @type {boolean}
     */
    this.isP2P = isP2P;
    /**
     * How many samples are to be included in arithmetic mean calculation.
     * @type {number}
     * @private
     */

    this._n = n;
    /**
     * The current sample index. Starts from 0 and goes up to {@link _n})
     * when analytics report will be submitted.
     * @type {number}
     * @private
     */

    this._sampleIdx = 0;
    /**
     * Average round trip time reported by the ICE candidate pair.
     * @type {AverageStatReport}
     */

    this._avgRTT = new AverageStatReport('rtt');
    /**
     * Map stores average RTT to the JVB reported by remote participants.
     * Mapped per participant id {@link JitsiParticipant.getId}.
     *
     * This is used only when {@link ConnectionAvgStats.isP2P} equals to
     * <tt>false</tt>.
     *
     * @type {Map<string,AverageStatReport>}
     * @private
     */

    this._avgRemoteRTTMap = new Map();
    /**
     * The conference for which stats will be collected and reported.
     * @type {JitsiConference}
     * @private
     */

    this._avgRtpStatsReporter = avgRtpStatsReporter;
    /**
     * The latest average E2E RTT for the JVB connection only.
     *
     * This is used only when {@link ConnectionAvgStats.isP2P} equals to
     * <tt>false</tt>.
     *
     * @type {number}
     */

    this._avgEnd2EndRTT = undefined;

    this._onConnectionStats = (tpc, stats) => {
      if (this.isP2P === tpc.isP2P) {
        this._calculateAvgStats(stats);
      }
    };

    const conference = avgRtpStatsReporter._conference;
    conference.statistics.addConnectionStatsListener(this._onConnectionStats);

    if (!this.isP2P) {
      this._onUserLeft = id => this._avgRemoteRTTMap.delete(id);

      conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_4__["USER_LEFT"], this._onUserLeft);

      this._onRemoteStatsUpdated = (id, data) => this._processRemoteStats(id, data);

      conference.on(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_3__["REMOTE_STATS_UPDATED"], this._onRemoteStatsUpdated);
    }
  }
  /**
   * Processes next batch of stats.
   * @param {go figure} data
   * @private
   */


  _calculateAvgStats(data) {
    if (!data) {
      logger.error('No stats');
      return;
    }

    if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].supportsRTTStatistics()) {
      if (data.transport && data.transport.length) {
        this._avgRTT.addNext(data.transport[0].rtt);
      }
    }

    this._sampleIdx += 1;

    if (this._sampleIdx >= this._n) {
      if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].supportsRTTStatistics()) {
        const conference = this._avgRtpStatsReporter._conference;
        const batchReport = {
          p2p: this.isP2P,
          'conference_size': conference.getParticipantCount()
        };

        if (data.transport && data.transport.length) {
          Object.assign(batchReport, {
            'local_candidate_type': data.transport[0].localCandidateType,
            'remote_candidate_type': data.transport[0].remoteCandidateType,
            'transport_type': data.transport[0].type
          });
        }

        this._avgRTT.appendReport(batchReport);

        if (this.isP2P) {
          // Report RTT diff only for P2P.
          const jvbEnd2EndRTT = this._avgRtpStatsReporter.jvbStatsMonitor._avgEnd2EndRTT;

          if (!isNaN(jvbEnd2EndRTT)) {
            // eslint-disable-next-line dot-notation
            batchReport['rtt_diff'] = this._avgRTT.calculate() - jvbEnd2EndRTT;
          }
        } else {
          // Report end to end RTT only for JVB.
          const avgRemoteRTT = this._calculateAvgRemoteRTT();

          const avgLocalRTT = this._avgRTT.calculate();

          this._avgEnd2EndRTT = avgLocalRTT + avgRemoteRTT;

          if (!isNaN(avgLocalRTT) && !isNaN(avgRemoteRTT)) {
            // eslint-disable-next-line dot-notation
            batchReport['end2end_rtt_avg'] = this._avgEnd2EndRTT;
          }
        }

        _statistics__WEBPACK_IMPORTED_MODULE_7__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createRtpStatsEvent"])(batchReport));
      }

      this._resetAvgStats();
    }
  }
  /**
   * Calculates arithmetic mean of all RTTs towards the JVB reported by
   * participants.
   * @return {number|NaN} NaN if not available (not enough data)
   * @private
   */


  _calculateAvgRemoteRTT() {
    let count = 0,
        sum = 0; // FIXME should we ignore RTT for participant
    // who "is having connectivity issues" ?

    for (const remoteAvg of this._avgRemoteRTTMap.values()) {
      const avg = remoteAvg.calculate();

      if (!isNaN(avg)) {
        sum += avg;
        count += 1;
        remoteAvg.reset();
      }
    }

    return sum / count;
  }
  /**
   * Processes {@link ConnectionQualityEvents.REMOTE_STATS_UPDATED} to analyse
   * RTT towards the JVB reported by each participant.
   * @param {string} id {@link JitsiParticipant.getId}
   * @param {go figure in ConnectionQuality.js} data
   * @private
   */


  _processRemoteStats(id, data) {
    const validData = typeof data.jvbRTT === 'number';

    let rttAvg = this._avgRemoteRTTMap.get(id);

    if (!rttAvg && validData) {
      rttAvg = new AverageStatReport(`${id}_stat_rtt`);

      this._avgRemoteRTTMap.set(id, rttAvg);
    }

    if (validData) {
      rttAvg.addNext(data.jvbRTT);
    } else if (rttAvg) {
      this._avgRemoteRTTMap.delete(id);
    }
  }
  /**
   * Reset cache of all averages and {@link _sampleIdx}.
   * @private
   */


  _resetAvgStats() {
    this._avgRTT.reset();

    if (this._avgRemoteRTTMap) {
      this._avgRemoteRTTMap.clear();
    }

    this._sampleIdx = 0;
  }
  /**
   *
   */


  dispose() {
    const conference = this._avgRtpStatsReporter._conference;
    conference.statistics.removeConnectionStatsListener(this._onConnectionStats);

    if (!this.isP2P) {
      conference.off(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_3__["REMOTE_STATS_UPDATED"], this._onRemoteStatsUpdated);
      conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_4__["USER_LEFT"], this._onUserLeft);
    }
  }

}
/**
 * Reports average RTP statistics values (arithmetic mean) to the analytics
 * module for things like bit rate, bandwidth, packet loss etc. It keeps track
 * of the P2P vs JVB conference modes and submits the values under different
 * namespaces (the events for P2P mode have 'p2p.' prefix). Every switch between
 * P2P mode resets the data collected so far and averages are calculated from
 * scratch.
 */


class AvgRTPStatsReporter {
  /**
   * Creates new instance of <tt>AvgRTPStatsReporter</tt>
   * @param {JitsiConference} conference
   * @param {number} n the number of samples, before arithmetic mean is to be
   * calculated and values submitted to the analytics module.
   */
  constructor(conference, n) {
    /**
     * How many {@link ConnectionQualityEvents.LOCAL_STATS_UPDATED} samples
     * are to be included in arithmetic mean calculation.
     * @type {number}
     * @private
     */
    this._n = n;

    if (n > 0) {
      logger.info(`Avg RTP stats will be calculated every ${n} samples`);
    } else {
      logger.info('Avg RTP stats reports are disabled.'); // Do not initialize

      return;
    }
    /**
     * The current sample index. Starts from 0 and goes up to {@link _n})
     * when analytics report will be submitted.
     * @type {number}
     * @private
     */


    this._sampleIdx = 0;
    /**
     * The conference for which stats will be collected and reported.
     * @type {JitsiConference}
     * @private
     */

    this._conference = conference;
    /**
     * Average audio upload bitrate
     * XXX What are the units?
     * @type {AverageStatReport}
     * @private
     */

    this._avgAudioBitrateUp = new AverageStatReport('bitrate_audio_upload');
    /**
     * Average audio download bitrate
     * XXX What are the units?
     * @type {AverageStatReport}
     * @private
     */

    this._avgAudioBitrateDown = new AverageStatReport('bitrate_audio_download');
    /**
     * Average video upload bitrate
     * XXX What are the units?
     * @type {AverageStatReport}
     * @private
     */

    this._avgVideoBitrateUp = new AverageStatReport('bitrate_video_upload');
    /**
     * Average video download bitrate
     * XXX What are the units?
     * @type {AverageStatReport}
     * @private
     */

    this._avgVideoBitrateDown = new AverageStatReport('bitrate_video_download');
    /**
     * Average upload bandwidth
     * XXX What are the units?
     * @type {AverageStatReport}
     * @private
     */

    this._avgBandwidthUp = new AverageStatReport('bandwidth_upload');
    /**
     * Average download bandwidth
     * XXX What are the units?
     * @type {AverageStatReport}
     * @private
     */

    this._avgBandwidthDown = new AverageStatReport('bandwidth_download');
    /**
     * Average total packet loss
     * XXX What are the units?
     * @type {AverageStatReport}
     * @private
     */

    this._avgPacketLossTotal = new AverageStatReport('packet_loss_total');
    /**
     * Average upload packet loss
     * XXX What are the units?
     * @type {AverageStatReport}
     * @private
     */

    this._avgPacketLossUp = new AverageStatReport('packet_loss_upload');
    /**
     * Average download packet loss
     * XXX What are the units?
     * @type {AverageStatReport}
     * @private
     */

    this._avgPacketLossDown = new AverageStatReport('packet_loss_download');
    /**
     * Average FPS for remote videos
     * @type {AverageStatReport}
     * @private
     */

    this._avgRemoteFPS = new AverageStatReport('framerate_remote');
    /**
     * Average FPS for remote screen streaming videos (reported only if not
     * a <tt>NaN</tt>).
     * @type {AverageStatReport}
     * @private
     */

    this._avgRemoteScreenFPS = new AverageStatReport('framerate_screen_remote');
    /**
     * Average FPS for local video (camera)
     * @type {AverageStatReport}
     * @private
     */

    this._avgLocalFPS = new AverageStatReport('framerate_local');
    /**
     * Average FPS for local screen streaming video (reported only if not
     * a <tt>NaN</tt>).
     * @type {AverageStatReport}
     * @private
     */

    this._avgLocalScreenFPS = new AverageStatReport('framerate_screen_local');
    /**
     * Average pixels for remote screen streaming videos (reported only if
     * not a <tt>NaN</tt>).
     * @type {AverageStatReport}
     * @private
     */

    this._avgRemoteCameraPixels = new AverageStatReport('pixels_remote');
    /**
     * Average pixels for remote screen streaming videos (reported only if
     * not a <tt>NaN</tt>).
     * @type {AverageStatReport}
     * @private
     */

    this._avgRemoteScreenPixels = new AverageStatReport('pixels_screen_remote');
    /**
     * Average pixels for local video (camera)
     * @type {AverageStatReport}
     * @private
     */

    this._avgLocalCameraPixels = new AverageStatReport('pixels_local');
    /**
     * Average pixels for local screen streaming video (reported only if not
     * a <tt>NaN</tt>).
     * @type {AverageStatReport}
     * @private
     */

    this._avgLocalScreenPixels = new AverageStatReport('pixels_screen_local');
    /**
     * Average connection quality as defined by
     * the {@link ConnectionQuality} module.
     * @type {AverageStatReport}
     * @private
     */

    this._avgCQ = new AverageStatReport('connection_quality');
    this._cachedTransportStats = undefined;

    this._onLocalStatsUpdated = data => {
      this._calculateAvgStats(data);

      this._maybeSendTransportAnalyticsEvent(data);
    };

    conference.on(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_3__["LOCAL_STATS_UPDATED"], this._onLocalStatsUpdated);

    this._onP2PStatusChanged = () => {
      logger.debug('Resetting average stats calculation');

      this._resetAvgStats();

      this.jvbStatsMonitor._resetAvgStats();

      this.p2pStatsMonitor._resetAvgStats();
    };

    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_4__["P2P_STATUS"], this._onP2PStatusChanged);

    this._onJvb121StatusChanged = (oldStatus, newStatus) => {
      // We want to reset only on the transition from false => true,
      // because otherwise those stats are resetted on JVB <=> P2P
      // transition.
      if (newStatus === true) {
        logger.info('Resetting JVB avg RTP stats');

        this._resetAvgJvbStats();
      }
    };

    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_4__["JVB121_STATUS"], this._onJvb121StatusChanged);
    this.jvbStatsMonitor = new ConnectionAvgStats(this, false
    /* JVB */
    , n);
    this.p2pStatsMonitor = new ConnectionAvgStats(this, true
    /* P2P */
    , n);
  }
  /**
   * Processes next batch of stats reported on
   * {@link ConnectionQualityEvents.LOCAL_STATS_UPDATED}.
   * @param {go figure} data
   * @private
   */


  _calculateAvgStats(data) {
    if (!data) {
      logger.error('No stats');
      return;
    }

    const isP2P = this._conference.isP2PActive();

    const confSize = this._conference.getParticipantCount();

    if (!isP2P && confSize < 2) {
      // There's no point in collecting stats for a JVB conference of 1.
      // That happens for short period of time after everyone leaves
      // the room, until Jicofo terminates the session.
      return;
    }
    /* Uncomment to figure out stats structure
    for (const key in data) {
        if (data.hasOwnProperty(key)) {
            logger.info(`local stat ${key}: `, data[key]);
        }
    } */


    const bitrate = data.bitrate;
    const bandwidth = data.bandwidth;
    const packetLoss = data.packetLoss;
    const frameRate = data.framerate;
    const resolution = data.resolution;

    if (!bitrate) {
      logger.error('No "bitrate"');
      return;
    } else if (!bandwidth) {
      logger.error('No "bandwidth"');
      return;
    } else if (!packetLoss) {
      logger.error('No "packetloss"');
      return;
    } else if (!frameRate) {
      logger.error('No "framerate"');
      return;
    } else if (!resolution) {
      logger.error('No resolution');
      return;
    }

    this._avgAudioBitrateUp.addNext(bitrate.audio.upload);

    this._avgAudioBitrateDown.addNext(bitrate.audio.download);

    this._avgVideoBitrateUp.addNext(bitrate.video.upload);

    this._avgVideoBitrateDown.addNext(bitrate.video.download);

    if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].supportsBandwidthStatistics()) {
      this._avgBandwidthUp.addNext(bandwidth.upload);

      this._avgBandwidthDown.addNext(bandwidth.download);
    }

    this._avgPacketLossUp.addNext(packetLoss.upload);

    this._avgPacketLossDown.addNext(packetLoss.download);

    this._avgPacketLossTotal.addNext(packetLoss.total);

    this._avgCQ.addNext(data.connectionQuality);

    if (frameRate) {
      this._avgRemoteFPS.addNext(this._calculateAvgVideoFps(frameRate, false
      /* remote */
      , _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__["CAMERA"]));

      this._avgRemoteScreenFPS.addNext(this._calculateAvgVideoFps(frameRate, false
      /* remote */
      , _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__["DESKTOP"]));

      this._avgLocalFPS.addNext(this._calculateAvgVideoFps(frameRate, true
      /* local */
      , _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__["CAMERA"]));

      this._avgLocalScreenFPS.addNext(this._calculateAvgVideoFps(frameRate, true
      /* local */
      , _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__["DESKTOP"]));
    }

    if (resolution) {
      this._avgRemoteCameraPixels.addNext(this._calculateAvgVideoPixels(resolution, false
      /* remote */
      , _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__["CAMERA"]));

      this._avgRemoteScreenPixels.addNext(this._calculateAvgVideoPixels(resolution, false
      /* remote */
      , _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__["DESKTOP"]));

      this._avgLocalCameraPixels.addNext(this._calculateAvgVideoPixels(resolution, true
      /* local */
      , _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__["CAMERA"]));

      this._avgLocalScreenPixels.addNext(this._calculateAvgVideoPixels(resolution, true
      /* local */
      , _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_8__["DESKTOP"]));
    }

    this._sampleIdx += 1;

    if (this._sampleIdx >= this._n) {
      const batchReport = {
        p2p: isP2P,
        'conference_size': confSize
      };

      if (data.transport && data.transport.length) {
        Object.assign(batchReport, {
          'local_candidate_type': data.transport[0].localCandidateType,
          'remote_candidate_type': data.transport[0].remoteCandidateType,
          'transport_type': data.transport[0].type
        });
      }

      this._avgAudioBitrateUp.appendReport(batchReport);

      this._avgAudioBitrateDown.appendReport(batchReport);

      this._avgVideoBitrateUp.appendReport(batchReport);

      this._avgVideoBitrateDown.appendReport(batchReport);

      if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].supportsBandwidthStatistics()) {
        this._avgBandwidthUp.appendReport(batchReport);

        this._avgBandwidthDown.appendReport(batchReport);
      }

      this._avgPacketLossUp.appendReport(batchReport);

      this._avgPacketLossDown.appendReport(batchReport);

      this._avgPacketLossTotal.appendReport(batchReport);

      this._avgRemoteFPS.appendReport(batchReport);

      if (!isNaN(this._avgRemoteScreenFPS.calculate())) {
        this._avgRemoteScreenFPS.appendReport(batchReport);
      }

      this._avgLocalFPS.appendReport(batchReport);

      if (!isNaN(this._avgLocalScreenFPS.calculate())) {
        this._avgLocalScreenFPS.appendReport(batchReport);
      }

      this._avgRemoteCameraPixels.appendReport(batchReport);

      if (!isNaN(this._avgRemoteScreenPixels.calculate())) {
        this._avgRemoteScreenPixels.appendReport(batchReport);
      }

      this._avgLocalCameraPixels.appendReport(batchReport);

      if (!isNaN(this._avgLocalScreenPixels.calculate())) {
        this._avgLocalScreenPixels.appendReport(batchReport);
      }

      this._avgCQ.appendReport(batchReport);

      _statistics__WEBPACK_IMPORTED_MODULE_7__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createRtpStatsEvent"])(batchReport));

      this._resetAvgStats();
    }
  }
  /**
   * Calculates average number of pixels for the report
   *
   * @param {map} peerResolutions a map of peer resolutions
   * @param {boolean} isLocal if the average is to be calculated for the local
   * video or <tt>false</tt> if for remote videos.
   * @param {VideoType} videoType
   * @return {number|NaN} average number of pixels or <tt>NaN</tt> if there
   * are no samples.
   * @private
   */


  _calculateAvgVideoPixels(peerResolutions, isLocal, videoType) {
    let peerPixelsSum = 0;
    let peerCount = 0;

    const myID = this._conference.myUserId();

    for (const peerID of Object.keys(peerResolutions)) {
      if (isLocal ? peerID === myID : peerID !== myID) {
        const participant = isLocal ? null : this._conference.getParticipantById(peerID);
        const videosResolution = peerResolutions[peerID]; // Do not continue without participant for non local peerID

        if ((isLocal || participant) && videosResolution) {
          const peerAvgPixels = this._calculatePeerAvgVideoPixels(videosResolution, participant, videoType);

          if (!isNaN(peerAvgPixels)) {
            peerPixelsSum += peerAvgPixels;
            peerCount += 1;
          }
        }
      }
    }

    return peerPixelsSum / peerCount;
  }
  /**
   * Calculate average pixels for either remote or local participant
   * @param {object} videos maps resolution per video SSRC
   * @param {JitsiParticipant|null} participant remote participant or
   * <tt>null</tt> for local video pixels calculation.
   * @param {VideoType} videoType the type of the video for which an average
   * will be calculated.
   * @return {number|NaN} average video pixels of all participant's videos or
   * <tt>NaN</tt> if currently not available
   * @private
   */


  _calculatePeerAvgVideoPixels(videos, participant, videoType) {
    let ssrcs = Object.keys(videos).map(ssrc => Number(ssrc));
    let videoTracks = null; // NOTE that this method is supposed to be called for the stats
    // received from the current peerconnection.

    const tpc = this._conference.getActivePeerConnection();

    if (participant) {
      videoTracks = participant.getTracksByMediaType(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]);

      if (videoTracks) {
        ssrcs = ssrcs.filter(ssrc => videoTracks.find(track => !track.isMuted() && track.getSSRC() === ssrc && track.videoType === videoType));
      }
    } else {
      videoTracks = this._conference.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]);
      ssrcs = ssrcs.filter(ssrc => videoTracks.find(track => !track.isMuted() && tpc.getLocalSSRC(track) === ssrc && track.videoType === videoType));
    }

    let peerPixelsSum = 0;
    let peerSsrcCount = 0;

    for (const ssrc of ssrcs) {
      const peerSsrcPixels = Number(videos[ssrc].height) * Number(videos[ssrc].width); // FPS is reported as 0 for users with no video

      if (!isNaN(peerSsrcPixels) && peerSsrcPixels > 0) {
        peerPixelsSum += peerSsrcPixels;
        peerSsrcCount += 1;
      }
    }

    return peerPixelsSum / peerSsrcCount;
  }
  /**
   * Calculates average FPS for the report
   * @param {go figure} frameRate
   * @param {boolean} isLocal if the average is to be calculated for the local
   * video or <tt>false</tt> if for remote videos.
   * @param {VideoType} videoType
   * @return {number|NaN} average FPS or <tt>NaN</tt> if there are no samples.
   * @private
   */


  _calculateAvgVideoFps(frameRate, isLocal, videoType) {
    let peerFpsSum = 0;
    let peerCount = 0;

    const myID = this._conference.myUserId();

    for (const peerID of Object.keys(frameRate)) {
      if (isLocal ? peerID === myID : peerID !== myID) {
        const participant = isLocal ? null : this._conference.getParticipantById(peerID);
        const videosFps = frameRate[peerID]; // Do not continue without participant for non local peerID

        if ((isLocal || participant) && videosFps) {
          const peerAvgFPS = this._calculatePeerAvgVideoFps(videosFps, participant, videoType);

          if (!isNaN(peerAvgFPS)) {
            peerFpsSum += peerAvgFPS;
            peerCount += 1;
          }
        }
      }
    }

    return peerFpsSum / peerCount;
  }
  /**
   * Calculate average FPS for either remote or local participant
   * @param {object} videos maps FPS per video SSRC
   * @param {JitsiParticipant|null} participant remote participant or
   * <tt>null</tt> for local FPS calculation.
   * @param {VideoType} videoType the type of the video for which an average
   * will be calculated.
   * @return {number|NaN} average FPS of all participant's videos or
   * <tt>NaN</tt> if currently not available
   * @private
   */


  _calculatePeerAvgVideoFps(videos, participant, videoType) {
    let ssrcs = Object.keys(videos).map(ssrc => Number(ssrc));
    let videoTracks = null; // NOTE that this method is supposed to be called for the stats
    // received from the current peerconnection.

    const tpc = this._conference.getActivePeerConnection();

    if (participant) {
      videoTracks = participant.getTracksByMediaType(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]);

      if (videoTracks) {
        ssrcs = ssrcs.filter(ssrc => videoTracks.find(track => !track.isMuted() && track.getSSRC() === ssrc && track.videoType === videoType));
      }
    } else {
      videoTracks = this._conference.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]);
      ssrcs = ssrcs.filter(ssrc => videoTracks.find(track => !track.isMuted() && tpc.getLocalSSRC(track) === ssrc && track.videoType === videoType));
    }

    let peerFpsSum = 0;
    let peerSsrcCount = 0;

    for (const ssrc of ssrcs) {
      const peerSsrcFps = Number(videos[ssrc]); // FPS is reported as 0 for users with no video

      if (!isNaN(peerSsrcFps) && peerSsrcFps > 0) {
        peerFpsSum += peerSsrcFps;
        peerSsrcCount += 1;
      }
    }

    return peerFpsSum / peerSsrcCount;
  }
  /**
   * Sends the 'transport.stats' analytics event whenever we detect that
   * there is a change in the local or remote candidate type on the transport
   * that is currently selected.
   * @param {*} data
   * @private
   */


  _maybeSendTransportAnalyticsEvent(data) {
    if (!data || !data.transport || !data.transport.length) {
      return;
    }

    const transportStats = {
      p2p: data.transport[0].p2p,
      'local_candidate_type': data.transport[0].localCandidateType,
      'remote_candidate_type': data.transport[0].remoteCandidateType,
      'transport_type': data.transport[0].type
    };

    if (!this._cachedTransportStats || !lodash_isequal__WEBPACK_IMPORTED_MODULE_0___default()(transportStats, this._cachedTransportStats)) {
      this._cachedTransportStats = transportStats;
      _statistics__WEBPACK_IMPORTED_MODULE_7__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["createTransportStatsEvent"])(transportStats));
    }
  }
  /**
   * Resets the stats related to JVB connection. Must not be called when in
   * P2P mode, because then the {@link AverageStatReport} instances are
   * tracking P2P stats. Note that this should never happen unless something
   * is wrong with the P2P and JVB121 events.
   * @private
   */


  _resetAvgJvbStats() {
    this._resetAvgStats();

    this.jvbStatsMonitor._resetAvgStats();
  }
  /**
   * Reset cache of all averages and {@link _sampleIdx}.
   * @private
   */


  _resetAvgStats() {
    this._avgAudioBitrateUp.reset();

    this._avgAudioBitrateDown.reset();

    this._avgVideoBitrateUp.reset();

    this._avgVideoBitrateDown.reset();

    this._avgBandwidthUp.reset();

    this._avgBandwidthDown.reset();

    this._avgPacketLossUp.reset();

    this._avgPacketLossDown.reset();

    this._avgPacketLossTotal.reset();

    this._avgRemoteFPS.reset();

    this._avgRemoteScreenFPS.reset();

    this._avgLocalFPS.reset();

    this._avgLocalScreenFPS.reset();

    this._avgRemoteCameraPixels.reset();

    this._avgRemoteScreenPixels.reset();

    this._avgLocalCameraPixels.reset();

    this._avgLocalScreenPixels.reset();

    this._avgCQ.reset();

    this._sampleIdx = 0;
  }
  /**
   * Unregisters all event listeners and stops working.
   */


  dispose() {
    this._conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_4__["P2P_STATUS"], this._onP2PStatusChanged);

    this._conference.off(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_3__["LOCAL_STATS_UPDATED"], this._onLocalStatsUpdated);

    this._conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_4__["JVB121_STATUS"], this._onJvb121StatusChanged);

    this.jvbStatsMonitor.dispose();
    this.p2pStatsMonitor.dispose();
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\statistics\\AvgRTPStatsReporter.js"))

/***/ }),

/***/ "./modules/statistics/CallStats.js":
/*!*****************************************!*\
  !*** ./modules/statistics/CallStats.js ***!
  \*****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return CallStats; });
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1__);
/* global callstats */



const logger = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js").getLogger(__filename);
/**
 * We define enumeration of wrtcFuncNames as we need them before
 * callstats is initialized to queue events.
 * @const
 * @see http://www.callstats.io/api/#enumeration-of-wrtcfuncnames
 */


const wrtcFuncNames = {
  createOffer: 'createOffer',
  createAnswer: 'createAnswer',
  setLocalDescription: 'setLocalDescription',
  setRemoteDescription: 'setRemoteDescription',
  addIceCandidate: 'addIceCandidate',
  getUserMedia: 'getUserMedia',
  iceConnectionFailure: 'iceConnectionFailure',
  signalingError: 'signalingError',
  applicationLog: 'applicationLog'
};
/**
 * We define enumeration of fabricEvent as we need them before
 * callstats is initialized to queue events.
 * @const
 * @see http://www.callstats.io/api/#enumeration-of-fabricevent
 */

const fabricEvent = {
  fabricHold: 'fabricHold',
  fabricResume: 'fabricResume',
  audioMute: 'audioMute',
  audioUnmute: 'audioUnmute',
  videoPause: 'videoPause',
  videoResume: 'videoResume',
  fabricUsageEvent: 'fabricUsageEvent',
  fabricStats: 'fabricStats',
  fabricTerminated: 'fabricTerminated',
  screenShareStart: 'screenShareStart',
  screenShareStop: 'screenShareStop',
  dominantSpeaker: 'dominantSpeaker',
  activeDeviceList: 'activeDeviceList'
};
/**
 * The user id to report to callstats as destination.
 * @type {string}
 */

const DEFAULT_REMOTE_USER = 'jitsi';
/**
 * Type of pending reports, can be event or an error.
 * @type {{ERROR: string, EVENT: string}}
 */

const reportType = {
  ERROR: 'error',
  EVENT: 'event',
  MST_WITH_USERID: 'mstWithUserID'
};
/**
 * Set of currently existing {@link CallStats} instances.
 * @type {Set<CallStats>}
 */

let _fabrics;
/**
 * An instance of this class is a wrapper for the CallStats API fabric. A fabric
 * reports one peer connection the the CallStats backend and is allocated with
 * {@link callstats.addNewFabric}. It has a bunch of instance methods for
 * reporting various events. A fabric is considered disposed when
 * {@link CallStats.sendTerminateEvent} is executed.
 *
 * Currently only one backend instance can be created ever and it's done using
 * {@link CallStats.initBackend}. At the time of this writing there is no way to
 * explicitly shutdown the backend, but it's supposed to close it's connection
 * automatically, after all fabrics have been terminated.
 */


class CallStats {
  /**
   * A callback passed to {@link callstats.addNewFabric}.
   * @param {string} error 'success' means ok
   * @param {string} msg some more details
   * @private
   */
  static _addNewFabricCallback(error, msg) {
    if (CallStats.backend && error !== 'success') {
      logger.error(`Monitoring status: ${error} msg: ${msg}`);
    }
  }
  /**
   * Callback passed to {@link callstats.initialize} (backend initialization)
   * @param {string} error 'success' means ok
   * @param {String} msg
   * @private
   */


  static _initCallback(error, msg) {
    logger.log(`CallStats Status: err=${error} msg=${msg}`); // there is no lib, nothing to report to

    if (error !== 'success') {
      return;
    }

    CallStats.backendInitialized = true; // I hate that

    let atLeastOneFabric = false;
    let defaultInstance = null;

    for (const callStatsInstance of CallStats.fabrics.values()) {
      if (!callStatsInstance.hasFabric) {
        logger.debug('addNewFabric - initCallback');

        if (callStatsInstance._addNewFabric()) {
          atLeastOneFabric = true;

          if (!defaultInstance) {
            defaultInstance = callStatsInstance;
          }
        }
      }
    }

    if (!atLeastOneFabric) {
      return;
    }

    CallStats._emptyReportQueue(defaultInstance);
  }
  /**
   * Empties report queue.
   *
   * @param {CallStats} csInstance - The callstats instance.
   * @private
   */


  static _emptyReportQueue(csInstance) {
    // There is no conference ID nor a PeerConnection available when some of
    // the events are scheduled on the reportsQueue, so those will be
    // reported on the first initialized fabric.
    const defaultConfID = csInstance.confID;
    const defaultPC = csInstance.peerconnection; // notify callstats about failures if there were any

    for (const report of CallStats.reportsQueue) {
      if (report.type === reportType.ERROR) {
        const errorData = report.data;

        CallStats._reportError(csInstance, errorData.type, errorData.error, errorData.pc || defaultPC);
      } else if (report.type === reportType.EVENT) {
        // if we have and event to report and we failed to add
        // fabric this event will not be reported anyway, returning
        // an error
        const eventData = report.data;
        CallStats.backend.sendFabricEvent(report.pc || defaultPC, eventData.event, defaultConfID, eventData.eventData);
      } else if (report.type === reportType.MST_WITH_USERID) {
        const data = report.data;
        CallStats.backend.associateMstWithUserID(report.pc || defaultPC, data.callStatsId, defaultConfID, data.ssrc, data.usageLabel, data.containerId);
      }
    }

    CallStats.reportsQueue.length = 0;
  }
  /* eslint-disable max-params */

  /**
   * Reports an error to callstats.
   *
   * @param {CallStats} [cs]
   * @param type the type of the error, which will be one of the wrtcFuncNames
   * @param error the error
   * @param pc the peerconnection
   * @private
   */


  static _reportError(cs, type, error, pc) {
    let _error = error;

    if (!_error) {
      logger.warn('No error is passed!');
      _error = new Error('Unknown error');
    }

    if (CallStats.backendInitialized && cs) {
      CallStats.backend.reportError(pc, cs.confID, type, _error);
    } else {
      CallStats.reportsQueue.push({
        type: reportType.ERROR,
        data: {
          error: _error,
          pc,
          type
        }
      });
    } // else just ignore it

  }
  /* eslint-enable max-params */

  /**
   * Reports an error to callstats.
   *
   * @param {CallStats} cs
   * @param event the type of the event, which will be one of the fabricEvent
   * @param eventData additional data to pass to event
   * @private
   */


  static _reportEvent(cs, event, eventData) {
    const pc = cs && cs.peerconnection;
    const confID = cs && cs.confID;

    if (CallStats.backendInitialized && cs) {
      CallStats.backend.sendFabricEvent(pc, event, confID, eventData);
    } else {
      CallStats.reportsQueue.push({
        confID,
        pc,
        type: reportType.EVENT,
        data: {
          event,
          eventData
        }
      });
    }
  }
  /**
   * Wraps some of the CallStats API method and logs their calls with
   * arguments on the debug logging level. Also wraps some of the backend
   * methods execution into try catch blocks to not crash the app in case
   * there is a problem with the backend itself.
   * @param {callstats} theBackend
   * @private
   */


  static _traceAndCatchBackendCalls(theBackend) {
    const tryCatchMethods = ['associateMstWithUserID', 'sendFabricEvent', 'sendUserFeedback' // 'reportError', - this one needs special handling - see code below
    ];

    for (const methodName of tryCatchMethods) {
      const originalMethod = theBackend[methodName];

      theBackend[methodName] = function (...theArguments) {
        try {
          return originalMethod.apply(theBackend, theArguments);
        } catch (e) {
          _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default.a.callErrorHandler(e);
        }
      };
    }

    const debugMethods = ['associateMstWithUserID', 'sendFabricEvent', 'sendUserFeedback' // 'reportError', - this one needs special handling - see code below
    ];

    for (const methodName of debugMethods) {
      const originalMethod = theBackend[methodName];

      theBackend[methodName] = function (...theArguments) {
        logger.debug(methodName, theArguments);
        originalMethod.apply(theBackend, theArguments);
      };
    }

    const originalReportError = theBackend.reportError;
    /* eslint-disable max-params */

    theBackend.reportError = function (pc, cs, type, ...args) {
      // Logs from the logger are submitted on the applicationLog event
      // "type". Logging the arguments on the logger will create endless
      // loop, because it will put all the logs to the logger queue again.
      if (type === wrtcFuncNames.applicationLog) {
        // NOTE otherArguments are not logged to the console on purpose
        // to not log the whole log batch
        // FIXME check the current logging level (currently not exposed
        // by the logger implementation)
        // NOTE it is not safe to log whole objects on react-native as
        // those contain too many circular references and may crash
        // the app.
        if (!_browser__WEBPACK_IMPORTED_MODULE_0__["default"].isReactNative()) {
          console && console.debug('reportError', pc, cs, type);
        }
      } else {
        logger.debug('reportError', pc, cs, type, ...args);
      }

      try {
        originalReportError.call(theBackend, pc, cs, type, ...args);
      } catch (exception) {
        if (type === wrtcFuncNames.applicationLog) {
          console && console.error('reportError', exception);
        } else {
          _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default.a.callErrorHandler(exception);
        }
      }
    };
    /* eslint-enable max-params */

  }
  /**
   * Returns the Set with the currently existing {@link CallStats} instances.
   * Lazily initializes the Set to allow any Set polyfills to be applied.
   * @type {Set<CallStats>}
   */


  static get fabrics() {
    if (!_fabrics) {
      _fabrics = new Set();
    }

    return _fabrics;
  }
  /**
   * Initializes the CallStats backend. Should be called only if
   * {@link CallStats.isBackendInitialized} returns <tt>false</tt>.
   * @param {object} options
   * @param {String} options.callStatsID CallStats credentials - ID
   * @param {String} options.callStatsSecret CallStats credentials - secret
   * @param {string} options.aliasName the <tt>aliasName</tt> part of
   * the <tt>userID</tt> aka endpoint ID, see CallStats docs for more info.
   * @param {string} options.userName the <tt>userName</tt> part of
   * the <tt>userID</tt> aka display name, see CallStats docs for more info.
   *
   */


  static initBackend(options) {
    if (CallStats.backend) {
      throw new Error('CallStats backend has been initialized already!');
    }

    try {
      const CallStatsBackend = callstats;
      CallStats.backend = new CallStatsBackend();

      CallStats._traceAndCatchBackendCalls(CallStats.backend);

      CallStats.userID = {
        aliasName: options.aliasName,
        userName: options.userName
      };
      CallStats.callStatsID = options.callStatsID;
      CallStats.callStatsSecret = options.callStatsSecret;
      let configParams;

      if (options.applicationName) {
        configParams = {
          applicationVersion: `${options.applicationName} (${_browser__WEBPACK_IMPORTED_MODULE_0__["default"].getName()})`
        };
      }

      if (options.confID) {
        // we first check is there a tenant in the confID
        const match = options.confID.match(/.*\/(.*)\/.*/); // if there is no tenant, we will just set '/'

        configParams.siteID = match && match[1] || '/';
      } // userID is generated or given by the origin server


      CallStats.backend.initialize(CallStats.callStatsID, CallStats.callStatsSecret, CallStats.userID, CallStats._initCallback, undefined, configParams);
      const getWiFiStatsMethod = options.getWiFiStatsMethod;

      if (getWiFiStatsMethod) {
        CallStats.backend.attachWifiStatsHandler(getWiFiStatsMethod);
        getWiFiStatsMethod().then(result => {
          if (result) {
            logger.info('Reported wifi addresses:', JSON.parse(result).addresses);
          }
        }).catch(() => {}); // eslint-disable-line no-empty-function
      }

      return true;
    } catch (e) {
      // The callstats.io API failed to initialize (e.g. because its
      // download did not succeed in general or on time). Further attempts
      // to utilize it cannot possibly succeed.
      _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default.a.callErrorHandler(e);
      CallStats.backend = null;
      logger.error(e);
      return false;
    }
  }
  /**
   * Checks if the CallStats backend has been created. It does not mean that
   * it has been initialized, but only that the API instance has been
   * allocated successfully.
   * @return {boolean} <tt>true</tt> if backend exists or <tt>false</tt>
   * otherwise
   */


  static isBackendInitialized() {
    return Boolean(CallStats.backend);
  }
  /**
   * Notifies CallStats about active device.
   * @param {{deviceList: {String:String}}} devicesData list of devices with
   * their data
   * @param {CallStats} cs callstats instance related to the event
   */


  static sendActiveDeviceListEvent(devicesData, cs) {
    CallStats._reportEvent(cs, fabricEvent.activeDeviceList, devicesData);
  }
  /**
   * Notifies CallStats that there is a log we want to report.
   *
   * @param {Error} e error to send or {String} message
   * @param {CallStats} cs callstats instance related to the error (optional)
   */


  static sendApplicationLog(e, cs) {
    try {
      CallStats._reportError(cs, wrtcFuncNames.applicationLog, e, cs && cs.peerconnection);
    } catch (error) {
      // If sendApplicationLog fails it should not be printed to
      // the logger, because it will try to push the logs again
      // (through sendApplicationLog) and an endless loop is created.
      if (console && typeof console.error === 'function') {
        // FIXME send analytics event as well
        console.error('sendApplicationLog failed', error);
      }
    }
  }
  /**
   * Sends the given feedback through CallStats.
   *
   * @param {string} conferenceID the conference ID for which the feedback
   * will be reported.
   * @param overall an integer between 1 and 5 indicating the
   * user feedback
   * @param comment detailed feedback from the user.
   */


  static sendFeedback(conferenceID, overall, comment) {
    return new Promise((resolve, reject) => {
      if (CallStats.backend) {
        CallStats.backend.sendUserFeedback(conferenceID, {
          userID: CallStats.userID,
          overall,
          comment
        }, (status, message) => {
          if (status === 'success') {
            resolve(message);
          } else {
            reject(message);
          }
        });
      } else {
        const reason = 'Failed to submit feedback to CallStats - no backend';
        logger.error(reason);
        reject(reason);
      }
    });
  }
  /**
   * Notifies CallStats that getUserMedia failed.
   *
   * @param {Error} e error to send
   * @param {CallStats} cs callstats instance related to the error (optional)
   */


  static sendGetUserMediaFailed(e, cs) {
    CallStats._reportError(cs, wrtcFuncNames.getUserMedia, e, null);
  }
  /**
   * Notifies CallStats for mute events
   * @param mute {boolean} true for muted and false for not muted
   * @param type {String} "audio"/"video"
   * @param {CallStats} cs callstats instance related to the event
   */


  static sendMuteEvent(mute, type, cs) {
    let event;

    if (type === 'video') {
      event = mute ? fabricEvent.videoPause : fabricEvent.videoResume;
    } else {
      event = mute ? fabricEvent.audioMute : fabricEvent.audioUnmute;
    }

    CallStats._reportEvent(cs, event);
  }
  /**
   * Creates new CallStats instance that handles all callstats API calls for
   * given {@link TraceablePeerConnection}. Each instance is meant to handle
   * one CallStats fabric added with 'addFabric' API method for the
   * {@link TraceablePeerConnection} instance passed in the constructor.
   * @param {TraceablePeerConnection} tpc
   * @param {Object} options
   * @param {string} options.confID the conference ID that wil be used to
   * report the session.
   * @param {string} [options.remoteUserID='jitsi'] the remote user ID to
   * which given <tt>tpc</tt> is connected.
   */


  constructor(tpc, options) {
    this.confID = options.confID;
    this.tpc = tpc;
    this.peerconnection = tpc.peerconnection;
    this.remoteUserID = options.remoteUserID || DEFAULT_REMOTE_USER;
    this.hasFabric = false;
    CallStats.fabrics.add(this);

    if (CallStats.backendInitialized) {
      this._addNewFabric(); // if this is the first fabric let's try to empty the
      // report queue. Reports all events that we recorded between
      // backend initialization and receiving the first fabric


      if (CallStats.fabrics.size === 1) {
        CallStats._emptyReportQueue(this);
      }
    }
  }
  /**
   * Initializes CallStats fabric by calling "addNewFabric" for
   * the peer connection associated with this instance.
   * @return {boolean} true if the call was successful or false otherwise.
   */


  _addNewFabric() {
    logger.info('addNewFabric', this.remoteUserID);

    try {
      const fabricAttributes = {
        remoteEndpointType: this.tpc.isP2P ? CallStats.backend.endpointType.peer : CallStats.backend.endpointType.server
      };
      const ret = CallStats.backend.addNewFabric(this.peerconnection, this.remoteUserID, CallStats.backend.fabricUsage.multiplex, this.confID, fabricAttributes, CallStats._addNewFabricCallback);
      this.hasFabric = true;
      const success = ret.status === 'success';

      if (!success) {
        logger.error('callstats fabric not initilized', ret.message);
      }

      return success;
    } catch (error) {
      _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default.a.callErrorHandler(error);
      return false;
    }
  }
  /* eslint-disable max-params */

  /**
   * Lets CallStats module know where is given SSRC rendered by providing
   * renderer tag ID.
   * If the lib is not initialized yet queue the call for later, when it's
   * ready.
   * @param {number} ssrc the SSRC of the stream
   * @param {boolean} isLocal indicates whether this the stream is local
   * @param {string|null} streamEndpointId if the stream is not local the it
   * needs to contain the stream owner's ID
   * @param {string} usageLabel meaningful usage label of this stream like
   *        'microphone', 'camera' or 'screen'.
   * @param {string} containerId  the id of media 'audio' or 'video' tag which
   *        renders the stream.
   */


  associateStreamWithVideoTag(ssrc, isLocal, streamEndpointId, usageLabel, containerId) {
    if (!CallStats.backend) {
      return;
    }

    const callStatsId = isLocal ? CallStats.userID : streamEndpointId;

    if (CallStats.backendInitialized) {
      CallStats.backend.associateMstWithUserID(this.peerconnection, callStatsId, this.confID, ssrc, usageLabel, containerId);
    } else {
      CallStats.reportsQueue.push({
        type: reportType.MST_WITH_USERID,
        pc: this.peerconnection,
        data: {
          callStatsId,
          containerId,
          ssrc,
          usageLabel
        }
      });
    }
  }
  /* eslint-enable max-params */

  /**
   * Notifies CallStats that we are the new dominant speaker in the
   * conference.
   */


  sendDominantSpeakerEvent() {
    CallStats._reportEvent(this, fabricEvent.dominantSpeaker);
  }
  /**
   * Notifies CallStats that the fabric for the underlying peerconnection was
   * closed and no evens should be reported, after this call.
   */


  sendTerminateEvent() {
    if (CallStats.backendInitialized) {
      CallStats.backend.sendFabricEvent(this.peerconnection, CallStats.backend.fabricEvent.fabricTerminated, this.confID);
    }

    CallStats.fabrics.delete(this);
  }
  /**
   * Notifies CallStats for ice connection failed
   */


  sendIceConnectionFailedEvent() {
    CallStats._reportError(this, wrtcFuncNames.iceConnectionFailure, null, this.peerconnection);
  }
  /**
   * Notifies CallStats that peer connection failed to create offer.
   *
   * @param {Error} e error to send
   */


  sendCreateOfferFailed(e) {
    CallStats._reportError(this, wrtcFuncNames.createOffer, e, this.peerconnection);
  }
  /**
   * Notifies CallStats that peer connection failed to create answer.
   *
   * @param {Error} e error to send
   */


  sendCreateAnswerFailed(e) {
    CallStats._reportError(this, wrtcFuncNames.createAnswer, e, this.peerconnection);
  }
  /**
   * Sends either resume or hold event for the fabric associated with
   * the underlying peerconnection.
   * @param {boolean} isResume true to resume or false to hold
   */


  sendResumeOrHoldEvent(isResume) {
    CallStats._reportEvent(this, isResume ? fabricEvent.fabricResume : fabricEvent.fabricHold);
  }
  /**
   * Notifies CallStats for screen sharing events
   * @param {boolean} start true for starting screen sharing and
   * false for not stopping
   * @param {string|null} ssrc - optional ssrc value, used only when
   * starting screen sharing.
   */


  sendScreenSharingEvent(start, ssrc) {
    let eventData;

    if (ssrc) {
      eventData = {
        ssrc
      };
    }

    CallStats._reportEvent(this, start ? fabricEvent.screenShareStart : fabricEvent.screenShareStop, eventData);
  }
  /**
   * Notifies CallStats that peer connection failed to set local description.
   *
   * @param {Error} e error to send
   */


  sendSetLocalDescFailed(e) {
    CallStats._reportError(this, wrtcFuncNames.setLocalDescription, e, this.peerconnection);
  }
  /**
   * Notifies CallStats that peer connection failed to set remote description.
   *
   * @param {Error} e error to send
   */


  sendSetRemoteDescFailed(e) {
    CallStats._reportError(this, wrtcFuncNames.setRemoteDescription, e, this.peerconnection);
  }
  /**
   * Notifies CallStats that peer connection failed to add ICE candidate.
   *
   * @param {Error} e error to send
   */


  sendAddIceCandidateFailed(e) {
    CallStats._reportError(this, wrtcFuncNames.addIceCandidate, e, this.peerconnection);
  }

}
/**
 * The CallStats API backend instance
 * @type {callstats}
 */

CallStats.backend = null; // some errors/events may happen before CallStats init
// in this case we accumulate them in this array
// and send them to callstats on init

CallStats.reportsQueue = [];
/**
 * Whether the library was successfully initialized(the backend) using its
 * initialize method.
 * @type {boolean}
 */

CallStats.backendInitialized = false;
/**
 * Part of the CallStats credentials - application ID
 * @type {string}
 */

CallStats.callStatsID = null;
/**
 * Part of the CallStats credentials - application secret
 * @type {string}
 */

CallStats.callStatsSecret = null;
/**
 * Local CallStats user ID structure. Can be set only once when
 * {@link backend} is initialized, so it's static for the time being.
 * See CallStats API for more info:
 * https://www.callstats.io/api/#userid
 * @type {object}
 */

CallStats.userID = null;
/* WEBPACK VAR INJECTION */}.call(this, "modules\\statistics\\CallStats.js"))

/***/ }),

/***/ "./modules/statistics/LocalStatsCollector.js":
/*!***************************************************!*\
  !*** ./modules/statistics/LocalStatsCollector.js ***!
  \***************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return LocalStatsCollector; });
/**
 * Provides statistics for the local stream.
 */

/**
 * Size of the webaudio analyzer buffer.
 * @type {number}
 */
const WEBAUDIO_ANALYZER_FFT_SIZE = 2048;
/**
 * Value of the webaudio analyzer smoothing time parameter.
 * @type {number}
 */

const WEBAUDIO_ANALYZER_SMOOTING_TIME = 0.8;
window.AudioContext = window.AudioContext || window.webkitAudioContext;
let context = null;

if (window.AudioContext) {
  context = new AudioContext(); // XXX Not all browsers define a suspend method on AudioContext. As the
  // invocation is at the (ES6 module) global execution level, it breaks the
  // loading of the lib-jitsi-meet library in such browsers and, consequently,
  // the loading of the very Web app that uses the lib-jitsi-meet library. For
  // example, Google Chrome 40 on Android does not define the method but we
  // still want to be able to load the lib-jitsi-meet library there and
  // display a page which notifies the user that the Web app is not supported
  // there.

  context.suspend && context.suspend();
}
/**
 * Converts time domain data array to audio level.
 * @param samples the time domain data array.
 * @returns {number} the audio level
 */


function timeDomainDataToAudioLevel(samples) {
  let maxVolume = 0;
  const length = samples.length;

  for (let i = 0; i < length; i++) {
    if (maxVolume < samples[i]) {
      maxVolume = samples[i];
    }
  }

  return parseFloat(((maxVolume - 127) / 128).toFixed(3));
}
/**
 * Animates audio level change
 * @param newLevel the new audio level
 * @param lastLevel the last audio level
 * @returns {Number} the audio level to be set
 */


function animateLevel(newLevel, lastLevel) {
  let value = 0;
  const diff = lastLevel - newLevel;

  if (diff > 0.2) {
    value = lastLevel - 0.2;
  } else if (diff < -0.4) {
    value = lastLevel + 0.4;
  } else {
    value = newLevel;
  }

  return parseFloat(value.toFixed(3));
}
/**
 * <tt>LocalStatsCollector</tt> calculates statistics for the local stream.
 *
 * @param stream the local stream
 * @param interval stats refresh interval given in ms.
 * @param callback function that receives the audio levels.
 * @constructor
 */


function LocalStatsCollector(stream, interval, callback) {
  this.stream = stream;
  this.intervalId = null;
  this.intervalMilis = interval;
  this.audioLevel = 0;
  this.callback = callback;
}
/**
 * Starts the collecting the statistics.
 */

LocalStatsCollector.prototype.start = function () {
  if (!LocalStatsCollector.isLocalStatsSupported()) {
    return;
  }

  context.resume();
  const analyser = context.createAnalyser();
  analyser.smoothingTimeConstant = WEBAUDIO_ANALYZER_SMOOTING_TIME;
  analyser.fftSize = WEBAUDIO_ANALYZER_FFT_SIZE;
  const source = context.createMediaStreamSource(this.stream);
  source.connect(analyser);
  const self = this;
  this.intervalId = setInterval(() => {
    const array = new Uint8Array(analyser.frequencyBinCount);
    analyser.getByteTimeDomainData(array);
    const audioLevel = timeDomainDataToAudioLevel(array);

    if (audioLevel !== self.audioLevel) {
      self.audioLevel = animateLevel(audioLevel, self.audioLevel);
      self.callback(self.audioLevel);
    }
  }, this.intervalMilis);
};
/**
 * Stops collecting the statistics.
 */


LocalStatsCollector.prototype.stop = function () {
  if (this.intervalId) {
    clearInterval(this.intervalId);
    this.intervalId = null;
  }
};
/**
 * Checks if the environment has the necessary conditions to support
 * collecting stats from local streams.
 *
 * @returns {boolean}
 */


LocalStatsCollector.isLocalStatsSupported = function () {
  return Boolean(context);
};

/***/ }),

/***/ "./modules/statistics/RTPStatsCollector.js":
/*!*************************************************!*\
  !*** ./modules/statistics/RTPStatsCollector.js ***!
  \*************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return StatsCollector; });
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var js_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! js-utils */ "./node_modules/js-utils/index.js");
/* harmony import */ var _service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/statistics/Events */ "./service/statistics/Events.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");





const GlobalOnErrorHandler = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");

const logger = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js").getLogger(__filename);
/**
 * The lib-jitsi-meet browser-agnostic names of the browser-specific keys
 * reported by RTCPeerConnection#getStats mapped by browser.
 */


const KEYS_BY_BROWSER_TYPE = {};
KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].FIREFOX] = {
  'ssrc': 'ssrc',
  'packetsReceived': 'packetsReceived',
  'packetsLost': 'packetsLost',
  'packetsSent': 'packetsSent',
  'bytesReceived': 'bytesReceived',
  'bytesSent': 'bytesSent',
  'framerateMean': 'framerateMean',
  'ip': 'address',
  'port': 'port',
  'protocol': 'protocol'
};
KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].CHROME] = {
  'receiveBandwidth': 'googAvailableReceiveBandwidth',
  'sendBandwidth': 'googAvailableSendBandwidth',
  'remoteAddress': 'googRemoteAddress',
  'transportType': 'googTransportType',
  'localAddress': 'googLocalAddress',
  'activeConnection': 'googActiveConnection',
  'ssrc': 'ssrc',
  'packetsReceived': 'packetsReceived',
  'packetsSent': 'packetsSent',
  'packetsLost': 'packetsLost',
  'bytesReceived': 'bytesReceived',
  'bytesSent': 'bytesSent',
  'googFrameHeightReceived': 'googFrameHeightReceived',
  'googFrameWidthReceived': 'googFrameWidthReceived',
  'googFrameHeightSent': 'googFrameHeightSent',
  'googFrameWidthSent': 'googFrameWidthSent',
  'googFrameRateReceived': 'googFrameRateReceived',
  'googFrameRateSent': 'googFrameRateSent',
  'audioInputLevel': 'audioInputLevel',
  'audioOutputLevel': 'audioOutputLevel',
  'currentRoundTripTime': 'googRtt',
  'remoteCandidateType': 'googRemoteCandidateType',
  'localCandidateType': 'googLocalCandidateType',
  'ip': 'ip',
  'port': 'port',
  'protocol': 'protocol'
};
KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].OPERA] = KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].CHROME];
KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].NWJS] = KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].CHROME];
KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].ELECTRON] = KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].CHROME];
KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].SAFARI] = KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].CHROME];
KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].REACT_NATIVE] = KEYS_BY_BROWSER_TYPE[js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].CHROME];
/**
 * Calculates packet lost percent using the number of lost packets and the
 * number of all packet.
 * @param lostPackets the number of lost packets
 * @param totalPackets the number of all packets.
 * @returns {number} packet loss percent
 */

function calculatePacketLoss(lostPackets, totalPackets) {
  if (!totalPackets || totalPackets <= 0 || !lostPackets || lostPackets <= 0) {
    return 0;
  }

  return Math.round(lostPackets / totalPackets * 100);
}
/**
 * Holds "statistics" for a single SSRC.
 * @constructor
 */


function SsrcStats() {
  this.loss = {};
  this.bitrate = {
    download: 0,
    upload: 0
  };
  this.resolution = {};
  this.framerate = 0;
}
/**
 * Sets the "loss" object.
 * @param loss the value to set.
 */


SsrcStats.prototype.setLoss = function (loss) {
  this.loss = loss || {};
};
/**
 * Sets resolution that belong to the ssrc represented by this instance.
 * @param resolution new resolution value to be set.
 */


SsrcStats.prototype.setResolution = function (resolution) {
  this.resolution = resolution || {};
};
/**
 * Adds the "download" and "upload" fields from the "bitrate" parameter to
 * the respective fields of the "bitrate" field of this object.
 * @param bitrate an object holding the values to add.
 */


SsrcStats.prototype.addBitrate = function (bitrate) {
  this.bitrate.download += bitrate.download;
  this.bitrate.upload += bitrate.upload;
};
/**
 * Resets the bit rate for given <tt>ssrc</tt> that belong to the peer
 * represented by this instance.
 */


SsrcStats.prototype.resetBitrate = function () {
  this.bitrate.download = 0;
  this.bitrate.upload = 0;
};
/**
 * Sets the "framerate".
 * @param framerate the value to set.
 */


SsrcStats.prototype.setFramerate = function (framerate) {
  this.framerate = framerate || 0;
};
/**
 *
 */


function ConferenceStats() {
  /**
   * The bandwidth
   * @type {{}}
   */
  this.bandwidth = {};
  /**
   * The bit rate
   * @type {{}}
   */

  this.bitrate = {};
  /**
   * The packet loss rate
   * @type {{}}
   */

  this.packetLoss = null;
  /**
   * Array with the transport information.
   * @type {Array}
   */

  this.transport = [];
}
/* eslint-disable max-params */

/**
 * <tt>StatsCollector</tt> registers for stats updates of given
 * <tt>peerconnection</tt> in given <tt>interval</tt>. On each update particular
 * stats are extracted and put in {@link SsrcStats} objects. Once the processing
 * is done <tt>audioLevelsUpdateCallback</tt> is called with <tt>this</tt>
 * instance as an event source.
 *
 * @param peerconnection WebRTC PeerConnection object.
 * @param audioLevelsInterval
 * @param statsInterval stats refresh interval given in ms.
 * @param eventEmitter
 * @constructor
 */


function StatsCollector(peerconnection, audioLevelsInterval, statsInterval, eventEmitter) {
  // StatsCollector depends entirely on the format of the reports returned by
  // RTCPeerConnection#getStats. Given that the value of
  // browser#getName() is very unlikely to change at runtime, it
  // makes sense to discover whether StatsCollector supports the executing
  // browser as soon as possible. Otherwise, (1) getStatValue would have to
  // needlessly check a "static" condition multiple times very very often and
  // (2) the lack of support for the executing browser would be discovered and
  // reported multiple times very very often too late in the execution in some
  // totally unrelated callback.

  /**
   * The browser type supported by this StatsCollector. In other words, the
   * type of the browser which initialized this StatsCollector
   * instance.
   * @private
   */
  this._browserType = _browser__WEBPACK_IMPORTED_MODULE_0__["default"].getName();
  const keys = KEYS_BY_BROWSER_TYPE[this._browserType];

  if (!keys) {
    // eslint-disable-next-line no-throw-literal
    throw `The browser type '${this._browserType}' isn't supported!`;
  }
  /**
   * Whether to use the Promise-based getStats API or not.
   * @type {boolean}
   */


  this._usesPromiseGetStats = _browser__WEBPACK_IMPORTED_MODULE_0__["default"].isSafari() || _browser__WEBPACK_IMPORTED_MODULE_0__["default"].isFirefox();
  /**
   * The function which is to be used to retrieve the value associated in a
   * report returned by RTCPeerConnection#getStats with a lib-jitsi-meet
   * browser-agnostic name/key.
   *
   * @function
   * @private
   */

  this._getStatValue = this._usesPromiseGetStats ? this._defineNewGetStatValueMethod(keys) : this._defineGetStatValueMethod(keys);
  this.peerconnection = peerconnection;
  this.baselineAudioLevelsReport = null;
  this.currentAudioLevelsReport = null;
  this.currentStatsReport = null;
  this.previousStatsReport = null;
  this.audioLevelReportHistory = {};
  this.audioLevelsIntervalId = null;
  this.eventEmitter = eventEmitter;
  this.conferenceStats = new ConferenceStats(); // Updates stats interval

  this.audioLevelsIntervalMilis = audioLevelsInterval;
  this.statsIntervalId = null;
  this.statsIntervalMilis = statsInterval;
  /**
   * Maps SSRC numbers to {@link SsrcStats}.
   * @type {Map<number,SsrcStats}
   */

  this.ssrc2stats = new Map();
}
/* eslint-enable max-params */

/**
 * Stops stats updates.
 */

StatsCollector.prototype.stop = function () {
  if (this.audioLevelsIntervalId) {
    clearInterval(this.audioLevelsIntervalId);
    this.audioLevelsIntervalId = null;
  }

  if (this.statsIntervalId) {
    clearInterval(this.statsIntervalId);
    this.statsIntervalId = null;
  }
};
/**
 * Callback passed to <tt>getStats</tt> method.
 * @param error an error that occurred on <tt>getStats</tt> call.
 */


StatsCollector.prototype.errorCallback = function (error) {
  GlobalOnErrorHandler.callErrorHandler(error);
  logger.error('Get stats error', error);
  this.stop();
};
/**
 * Starts stats updates.
 */


StatsCollector.prototype.start = function (startAudioLevelStats) {
  const self = this;

  if (startAudioLevelStats) {
    this.audioLevelsIntervalId = setInterval(() => {
      // Interval updates
      self.peerconnection.getStats(report => {
        let results = null;

        if (!report || !report.result || typeof report.result !== 'function') {
          results = report;
        } else {
          results = report.result();
        }

        self.currentAudioLevelsReport = results;

        if (this._usesPromiseGetStats) {
          self.processNewAudioLevelReport();
        } else {
          self.processAudioLevelReport();
        }

        self.baselineAudioLevelsReport = self.currentAudioLevelsReport;
      }, error => self.errorCallback(error));
    }, self.audioLevelsIntervalMilis);
  }

  this.statsIntervalId = setInterval(() => {
    // Interval updates
    self.peerconnection.getStats(report => {
      let results = null;

      if (!report || !report.result || typeof report.result !== 'function') {
        // firefox
        results = report;
      } else {
        // chrome
        results = report.result();
      }

      self.currentStatsReport = results;

      try {
        if (this._usesPromiseGetStats) {
          self.processNewStatsReport();
        } else {
          self.processStatsReport();
        }
      } catch (e) {
        GlobalOnErrorHandler.callErrorHandler(e);
        logger.error(`Unsupported key:${e}`, e);
      }

      self.previousStatsReport = self.currentStatsReport;
    }, error => self.errorCallback(error));
  }, self.statsIntervalMilis);
};
/**
 * Defines a function which (1) is to be used as a StatsCollector method and (2)
 * gets the value from a specific report returned by RTCPeerConnection#getStats
 * associated with a lib-jitsi-meet browser-agnostic name.
 *
 * @param {Object.<string,string>} keys the map of LibJitsi browser-agnostic
 * names to RTCPeerConnection#getStats browser-specific keys
 */


StatsCollector.prototype._defineGetStatValueMethod = function (keys) {
  // Define the function which converts a lib-jitsi-meet browser-asnostic name
  // to a browser-specific key of a report returned by
  // RTCPeerConnection#getStats.
  const keyFromName = function (name) {
    const key = keys[name];

    if (key) {
      return key;
    } // eslint-disable-next-line no-throw-literal


    throw `The property '${name}' isn't supported!`;
  }; // Define the function which retrieves the value from a specific report
  // returned by RTCPeerConnection#getStats associated with a given
  // browser-specific key.


  let itemStatByKey;

  switch (this._browserType) {
    case js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].CHROME:
    case js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].OPERA:
    case js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].NWJS:
    case js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].ELECTRON:
      // TODO What about other types of browser which are based on Chrome such
      // as NW.js? Every time we want to support a new type browser we have to
      // go and add more conditions (here and in multiple other places).
      // Cannot we do a feature detection instead of a browser type check? For
      // example, if item has a stat property of type function, then it's very
      // likely that whoever defined it wanted you to call it in order to
      // retrieve the value associated with a specific key.
      itemStatByKey = (item, key) => item.stat(key);

      break;

    case js_utils__WEBPACK_IMPORTED_MODULE_1__["browsers"].REACT_NATIVE:
      // The implementation provided by react-native-webrtc follows the
      // Objective-C WebRTC API: RTCStatsReport has a values property of type
      // Array in which each element is a key-value pair.
      itemStatByKey = function (item, key) {
        let value;
        item.values.some(pair => {
          if (pair.hasOwnProperty(key)) {
            value = pair[key];
            return true;
          }

          return false;
        });
        return value;
      };

      break;

    default:
      itemStatByKey = (item, key) => item[key];

  } // Compose the 2 functions defined above to get a function which retrieves
  // the value from a specific report returned by RTCPeerConnection#getStats
  // associated with a specific lib-jitsi-meet browser-agnostic name.


  return (item, name) => itemStatByKey(item, keyFromName(name));
};
/**
 * Obtains a stat value from given stat and converts it to a non-negative
 * number. If the value is either invalid or negative then 0 will be returned.
 * @param report
 * @param {string} name
 * @return {number}
 * @private
 */


StatsCollector.prototype.getNonNegativeStat = function (report, name) {
  let value = this._getStatValue(report, name);

  if (typeof value !== 'number') {
    value = Number(value);
  }

  if (isNaN(value)) {
    return 0;
  }

  return Math.max(0, value);
};
/* eslint-disable no-continue */

/**
 * Stats processing logic.
 */


StatsCollector.prototype.processStatsReport = function () {
  if (!this.previousStatsReport) {
    return;
  }

  const getStatValue = this._getStatValue;
  const byteSentStats = {};

  for (const idx in this.currentStatsReport) {
    if (!this.currentStatsReport.hasOwnProperty(idx)) {
      continue;
    }

    const now = this.currentStatsReport[idx]; // The browser API may return "undefined" values in the array

    if (!now) {
      continue;
    }

    try {
      const receiveBandwidth = getStatValue(now, 'receiveBandwidth');
      const sendBandwidth = getStatValue(now, 'sendBandwidth');

      if (receiveBandwidth || sendBandwidth) {
        this.conferenceStats.bandwidth = {
          'download': Math.round(receiveBandwidth / 1000),
          'upload': Math.round(sendBandwidth / 1000)
        };
      }
    } catch (e) {
      /* not supported*/
    }

    if (now.type === 'googCandidatePair') {
      let active, ip, localCandidateType, localip, remoteCandidateType, rtt, type;

      try {
        active = getStatValue(now, 'activeConnection');

        if (!active) {
          continue;
        }

        ip = getStatValue(now, 'remoteAddress');
        type = getStatValue(now, 'transportType');
        localip = getStatValue(now, 'localAddress');
        localCandidateType = getStatValue(now, 'localCandidateType');
        remoteCandidateType = getStatValue(now, 'remoteCandidateType');
        rtt = this.getNonNegativeStat(now, 'currentRoundTripTime');
      } catch (e) {
        /* not supported*/
      }

      if (!ip || !type || !localip || active !== 'true') {
        continue;
      } // Save the address unless it has been saved already.


      const conferenceStatsTransport = this.conferenceStats.transport;

      if (!conferenceStatsTransport.some(t => t.ip === ip && t.type === type && t.localip === localip)) {
        conferenceStatsTransport.push({
          ip,
          type,
          localip,
          p2p: this.peerconnection.isP2P,
          localCandidateType,
          remoteCandidateType,
          rtt
        });
      }

      continue;
    }

    if (now.type === 'candidatepair') {
      // we need succeeded and selected pairs only
      if (now.state !== 'succeeded' || !now.selected) {
        continue;
      }

      const local = this.currentStatsReport[now.localCandidateId];
      const remote = this.currentStatsReport[now.remoteCandidateId];
      this.conferenceStats.transport.push({
        ip: `${remote.ipAddress}:${remote.portNumber}`,
        type: local.transport,
        localip: `${local.ipAddress}:${local.portNumber}`,
        p2p: this.peerconnection.isP2P,
        localCandidateType: local.candidateType,
        remoteCandidateType: remote.candidateType
      });
    }

    if (now.type !== 'ssrc' && now.type !== 'outboundrtp' && now.type !== 'inboundrtp' && now.type !== 'track') {
      continue;
    }

    const before = this.previousStatsReport[idx];
    let ssrc = this.getNonNegativeStat(now, 'ssrc'); // If type="track", take the first SSRC from ssrcIds.

    if (now.type === 'track' && Array.isArray(now.ssrcIds)) {
      ssrc = Number(now.ssrcIds[0]);
    }

    if (!before || !ssrc) {
      continue;
    } // isRemote is available only in FF and is ignored in case of chrome
    // according to the spec
    // https://www.w3.org/TR/webrtc-stats/#dom-rtcrtpstreamstats-isremote
    // when isRemote is true indicates that the measurements were done at
    // the remote endpoint and reported in an RTCP RR/XR.
    // Fixes a problem where we are calculating local stats wrong adding
    // the sent bytes to the local download bitrate.
    // In new W3 stats spec, type="track" has a remoteSource boolean
    // property.


    if (now.isRemote === true || now.remoteSource === true) {
      continue;
    }

    let ssrcStats = this.ssrc2stats.get(ssrc);

    if (!ssrcStats) {
      ssrcStats = new SsrcStats();
      this.ssrc2stats.set(ssrc, ssrcStats);
    }

    let isDownloadStream = true;
    let key = 'packetsReceived';
    let packetsNow = getStatValue(now, key);

    if (typeof packetsNow === 'undefined' || packetsNow === null || packetsNow === '') {
      isDownloadStream = false;
      key = 'packetsSent';
      packetsNow = getStatValue(now, key);

      if (typeof packetsNow === 'undefined' || packetsNow === null) {
        logger.warn('No packetsReceived nor packetsSent stat found');
      }
    }

    if (!packetsNow || packetsNow < 0) {
      packetsNow = 0;
    }

    const packetsBefore = this.getNonNegativeStat(before, key);
    const packetsDiff = Math.max(0, packetsNow - packetsBefore);
    const packetsLostNow = this.getNonNegativeStat(now, 'packetsLost');
    const packetsLostBefore = this.getNonNegativeStat(before, 'packetsLost');
    const packetsLostDiff = Math.max(0, packetsLostNow - packetsLostBefore);
    ssrcStats.setLoss({
      packetsTotal: packetsDiff + packetsLostDiff,
      packetsLost: packetsLostDiff,
      isDownloadStream
    });
    const bytesReceivedNow = this.getNonNegativeStat(now, 'bytesReceived');
    const bytesReceivedBefore = this.getNonNegativeStat(before, 'bytesReceived');
    const bytesReceived = Math.max(0, bytesReceivedNow - bytesReceivedBefore);
    let bytesSent = 0; // TODO: clean this mess up!

    let nowBytesTransmitted = getStatValue(now, 'bytesSent');

    if (typeof nowBytesTransmitted === 'number' || typeof nowBytesTransmitted === 'string') {
      nowBytesTransmitted = Number(nowBytesTransmitted);

      if (!isNaN(nowBytesTransmitted)) {
        byteSentStats[ssrc] = nowBytesTransmitted;

        if (nowBytesTransmitted > 0) {
          bytesSent = nowBytesTransmitted - getStatValue(before, 'bytesSent');
        }
      }
    }

    bytesSent = Math.max(0, bytesSent);
    const timeMs = now.timestamp - before.timestamp;
    let bitrateReceivedKbps = 0,
        bitrateSentKbps = 0;

    if (timeMs > 0) {
      // TODO is there any reason to round here?
      bitrateReceivedKbps = Math.round(bytesReceived * 8 / timeMs);
      bitrateSentKbps = Math.round(bytesSent * 8 / timeMs);
    }

    ssrcStats.addBitrate({
      'download': bitrateReceivedKbps,
      'upload': bitrateSentKbps
    });
    const resolution = {
      height: null,
      width: null
    };

    try {
      let height, width;

      if ((height = getStatValue(now, 'googFrameHeightReceived')) && (width = getStatValue(now, 'googFrameWidthReceived'))) {
        resolution.height = height;
        resolution.width = width;
      } else if ((height = getStatValue(now, 'googFrameHeightSent')) && (width = getStatValue(now, 'googFrameWidthSent'))) {
        resolution.height = height;
        resolution.width = width;
      }
    } catch (e) {}
    /* not supported*/
    // Tries to get frame rate


    let frameRate;

    try {
      frameRate = getStatValue(now, 'googFrameRateReceived') || getStatValue(now, 'googFrameRateSent') || 0;
    } catch (e) {
      // if it fails with previous properties(chrome),
      // let's try with another one (FF)
      try {
        frameRate = this.getNonNegativeStat(now, 'framerateMean');
      } catch (err) {
        /* not supported*/
      }
    }

    ssrcStats.setFramerate(Math.round(frameRate || 0));

    if (resolution.height && resolution.width) {
      ssrcStats.setResolution(resolution);
    } else {
      ssrcStats.setResolution(null);
    }
  }

  this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__["BYTE_SENT_STATS"], this.peerconnection, byteSentStats);

  this._processAndEmitReport();
};
/**
 *
 */


StatsCollector.prototype._processAndEmitReport = function () {
  // process stats
  const totalPackets = {
    download: 0,
    upload: 0
  };
  const lostPackets = {
    download: 0,
    upload: 0
  };
  let bitrateDownload = 0;
  let bitrateUpload = 0;
  const resolutions = {};
  const framerates = {};
  let audioBitrateDownload = 0;
  let audioBitrateUpload = 0;
  let videoBitrateDownload = 0;
  let videoBitrateUpload = 0;

  for (const [ssrc, ssrcStats] of this.ssrc2stats) {
    // process packet loss stats
    const loss = ssrcStats.loss;
    const type = loss.isDownloadStream ? 'download' : 'upload';
    totalPackets[type] += loss.packetsTotal;
    lostPackets[type] += loss.packetsLost; // process bitrate stats

    bitrateDownload += ssrcStats.bitrate.download;
    bitrateUpload += ssrcStats.bitrate.upload; // collect resolutions and framerates

    const track = this.peerconnection.getTrackBySSRC(ssrc);

    if (track) {
      if (track.isAudioTrack()) {
        audioBitrateDownload += ssrcStats.bitrate.download;
        audioBitrateUpload += ssrcStats.bitrate.upload;
      } else {
        videoBitrateDownload += ssrcStats.bitrate.download;
        videoBitrateUpload += ssrcStats.bitrate.upload;
      }

      const participantId = track.getParticipantId();

      if (participantId) {
        const resolution = ssrcStats.resolution;

        if (resolution.width && resolution.height && resolution.width !== -1 && resolution.height !== -1) {
          const userResolutions = resolutions[participantId] || {};
          userResolutions[ssrc] = resolution;
          resolutions[participantId] = userResolutions;
        }

        if (ssrcStats.framerate !== 0) {
          const userFramerates = framerates[participantId] || {};
          userFramerates[ssrc] = ssrcStats.framerate;
          framerates[participantId] = userFramerates;
        }
      } else {
        logger.error(`No participant ID returned by ${track}`);
      }
    }

    ssrcStats.resetBitrate();
  }

  this.conferenceStats.bitrate = {
    'upload': bitrateUpload,
    'download': bitrateDownload
  };
  this.conferenceStats.bitrate.audio = {
    'upload': audioBitrateUpload,
    'download': audioBitrateDownload
  };
  this.conferenceStats.bitrate.video = {
    'upload': videoBitrateUpload,
    'download': videoBitrateDownload
  };
  this.conferenceStats.packetLoss = {
    total: calculatePacketLoss(lostPackets.download + lostPackets.upload, totalPackets.download + totalPackets.upload),
    download: calculatePacketLoss(lostPackets.download, totalPackets.download),
    upload: calculatePacketLoss(lostPackets.upload, totalPackets.upload)
  };
  const avgAudioLevels = {};
  let localAvgAudioLevels;
  Object.keys(this.audioLevelReportHistory).forEach(ssrc => {
    const {
      data,
      isLocal
    } = this.audioLevelReportHistory[ssrc];
    const avgAudioLevel = data.reduce((sum, currentValue) => sum + currentValue) / data.length;

    if (isLocal) {
      localAvgAudioLevels = avgAudioLevel;
    } else {
      const track = this.peerconnection.getTrackBySSRC(Number(ssrc));

      if (track) {
        const participantId = track.getParticipantId();

        if (participantId) {
          avgAudioLevels[participantId] = avgAudioLevel;
        }
      }
    }
  });
  this.audioLevelReportHistory = {};
  this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__["CONNECTION_STATS"], this.peerconnection, {
    'bandwidth': this.conferenceStats.bandwidth,
    'bitrate': this.conferenceStats.bitrate,
    'packetLoss': this.conferenceStats.packetLoss,
    'resolution': resolutions,
    'framerate': framerates,
    'transport': this.conferenceStats.transport,
    localAvgAudioLevels,
    avgAudioLevels
  });
  this.conferenceStats.transport = [];
};
/**
 * Stats processing logic.
 */


StatsCollector.prototype.processAudioLevelReport = function () {
  if (!this.baselineAudioLevelsReport) {
    return;
  }

  const getStatValue = this._getStatValue;

  for (const idx in this.currentAudioLevelsReport) {
    if (!this.currentAudioLevelsReport.hasOwnProperty(idx)) {
      continue;
    }

    const now = this.currentAudioLevelsReport[idx];

    if (now.type !== 'ssrc' && now.type !== 'track') {
      continue;
    }

    const before = this.baselineAudioLevelsReport[idx];
    let ssrc = this.getNonNegativeStat(now, 'ssrc');

    if (!ssrc && Array.isArray(now.ssrcIds)) {
      ssrc = Number(now.ssrcIds[0]);
    }

    if (!before) {
      logger.warn(`${ssrc} not enough data`);
      continue;
    }

    if (!ssrc) {
      if (Date.now() - now.timestamp < 3000) {
        logger.warn('No ssrc: ');
      }

      continue;
    } // Audio level


    let audioLevel;

    try {
      audioLevel = getStatValue(now, 'audioInputLevel') || getStatValue(now, 'audioOutputLevel');
    } catch (e) {
      /* not supported*/
      logger.warn('Audio Levels are not available in the statistics.');
      clearInterval(this.audioLevelsIntervalId);
      return;
    }

    if (audioLevel) {
      let isLocal; // If type="ssrc" (legacy) check whether they are received packets.

      if (now.type === 'ssrc') {
        isLocal = !getStatValue(now, 'packetsReceived'); // If type="track", check remoteSource boolean property.
      } else {
        isLocal = !now.remoteSource;
      } // According to the W3C WebRTC Stats spec, audioLevel should be in
      // 0..1 range (0 == silence). However browsers don't behave that
      // way so we must convert it to 0..1.
      // TODO: Can't find specs about what this value really is, but it
      // seems to vary between 0 and around 32k.


      audioLevel = audioLevel / 32767;

      if (!(ssrc in this.audioLevelReportHistory)) {
        this.audioLevelReportHistory[ssrc] = {
          isLocal,
          data: []
        };
      }

      this.audioLevelReportHistory[ssrc].data.push(audioLevel);
      this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__["AUDIO_LEVEL"], this.peerconnection, ssrc, audioLevel, isLocal);
    }
  }
};
/* eslint-enable no-continue */

/**
 * New promised based getStats report processing.
 * Tested with chrome, firefox and safari. Not switching it on for chrome as
 * frameRate stat is missing and calculating it using framesSent,
 * gives values double the values seen in webrtc-internals.
 * https://w3c.github.io/webrtc-stats/
 */

/**
 * Defines a function which (1) is to be used as a StatsCollector method and (2)
 * gets the value from a specific report returned by RTCPeerConnection#getStats
 * associated with a lib-jitsi-meet browser-agnostic name in case of using
 * Promised based getStats.
 *
 * @param {Object.<string,string>} keys the map of LibJitsi browser-agnostic
 * names to RTCPeerConnection#getStats browser-specific keys
 */


StatsCollector.prototype._defineNewGetStatValueMethod = function (keys) {
  // Define the function which converts a lib-jitsi-meet browser-asnostic name
  // to a browser-specific key of a report returned by
  // RTCPeerConnection#getStats.
  const keyFromName = function (name) {
    const key = keys[name];

    if (key) {
      return key;
    } // eslint-disable-next-line no-throw-literal


    throw `The property '${name}' isn't supported!`;
  }; // Compose the 2 functions defined above to get a function which retrieves
  // the value from a specific report returned by RTCPeerConnection#getStats
  // associated with a specific lib-jitsi-meet browser-agnostic name.


  return (item, name) => item[keyFromName(name)];
};
/**
 * Converts the value to a non-negative number.
 * If the value is either invalid or negative then 0 will be returned.
 * @param {*} v
 * @return {number}
 * @private
 */


StatsCollector.prototype.getNonNegativeValue = function (v) {
  let value = v;

  if (typeof value !== 'number') {
    value = Number(value);
  }

  if (isNaN(value)) {
    return 0;
  }

  return Math.max(0, value);
};
/**
 * Calculates bitrate between before and now using a supplied field name and its
 * value in the stats.
 * @param {RTCInboundRtpStreamStats|RTCSentRtpStreamStats} now the current stats
 * @param {RTCInboundRtpStreamStats|RTCSentRtpStreamStats} before the
 * previous stats.
 * @param fieldName the field to use for calculations.
 * @return {number} the calculated bitrate between now and before.
 * @private
 */


StatsCollector.prototype._calculateBitrate = function (now, before, fieldName) {
  const bytesNow = this.getNonNegativeValue(now[fieldName]);
  const bytesBefore = this.getNonNegativeValue(before[fieldName]);
  const bytesProcessed = Math.max(0, bytesNow - bytesBefore);
  const timeMs = now.timestamp - before.timestamp;
  let bitrateKbps = 0;

  if (timeMs > 0) {
    // TODO is there any reason to round here?
    bitrateKbps = Math.round(bytesProcessed * 8 / timeMs);
  }

  return bitrateKbps;
};
/**
 * Stats processing new getStats logic.
 */


StatsCollector.prototype.processNewStatsReport = function () {
  if (!this.previousStatsReport) {
    return;
  }

  const getStatValue = this._getStatValue;
  const byteSentStats = {};
  this.currentStatsReport.forEach(now => {
    // RTCIceCandidatePairStats
    // https://w3c.github.io/webrtc-stats/#candidatepair-dict*
    if (now.type === 'candidate-pair' && now.nominated && now.state === 'succeeded') {
      const availableIncomingBitrate = now.availableIncomingBitrate;
      const availableOutgoingBitrate = now.availableOutgoingBitrate;

      if (availableIncomingBitrate || availableOutgoingBitrate) {
        this.conferenceStats.bandwidth = {
          'download': Math.round(availableIncomingBitrate / 1000),
          'upload': Math.round(availableOutgoingBitrate / 1000)
        };
      }

      const remoteUsedCandidate = this.currentStatsReport.get(now.remoteCandidateId);
      const localUsedCandidate = this.currentStatsReport.get(now.localCandidateId); // RTCIceCandidateStats
      // https://w3c.github.io/webrtc-stats/#icecandidate-dict*
      // safari currently does not provide ice candidates in stats

      if (remoteUsedCandidate && localUsedCandidate) {
        const remoteIpAddress = getStatValue(remoteUsedCandidate, 'ip');
        const remotePort = getStatValue(remoteUsedCandidate, 'port');
        const ip = `${remoteIpAddress}:${remotePort}`;
        const localIpAddress = getStatValue(localUsedCandidate, 'ip');
        const localPort = getStatValue(localUsedCandidate, 'port');
        const localIp = `${localIpAddress}:${localPort}`;
        const type = getStatValue(remoteUsedCandidate, 'protocol'); // Save the address unless it has been saved already.

        const conferenceStatsTransport = this.conferenceStats.transport;

        if (!conferenceStatsTransport.some(t => t.ip === ip && t.type === type && t.localip === localIp)) {
          conferenceStatsTransport.push({
            ip,
            type,
            localIp,
            p2p: this.peerconnection.isP2P,
            localCandidateType: localUsedCandidate.candidateType,
            remoteCandidateType: remoteUsedCandidate.candidateType,
            networkType: localUsedCandidate.networkType,
            rtt: now.currentRoundTripTime * 1000
          });
        }
      } // RTCReceivedRtpStreamStats
      // https://w3c.github.io/webrtc-stats/#receivedrtpstats-dict*
      // RTCSentRtpStreamStats
      // https://w3c.github.io/webrtc-stats/#sentrtpstats-dict*

    } else if (now.type === 'inbound-rtp' || now.type === 'outbound-rtp') {
      const before = this.previousStatsReport.get(now.id);
      const ssrc = this.getNonNegativeValue(now.ssrc);

      if (!before || !ssrc) {
        return;
      }

      let ssrcStats = this.ssrc2stats.get(ssrc);

      if (!ssrcStats) {
        ssrcStats = new SsrcStats();
        this.ssrc2stats.set(ssrc, ssrcStats);
      }

      let isDownloadStream = true;
      let key = 'packetsReceived';

      if (now.type === 'outbound-rtp') {
        isDownloadStream = false;
        key = 'packetsSent';
      }

      let packetsNow = now[key];

      if (!packetsNow || packetsNow < 0) {
        packetsNow = 0;
      }

      const packetsBefore = this.getNonNegativeValue(before[key]);
      const packetsDiff = Math.max(0, packetsNow - packetsBefore);
      const packetsLostNow = this.getNonNegativeValue(now.packetsLost);
      const packetsLostBefore = this.getNonNegativeValue(before.packetsLost);
      const packetsLostDiff = Math.max(0, packetsLostNow - packetsLostBefore);
      ssrcStats.setLoss({
        packetsTotal: packetsDiff + packetsLostDiff,
        packetsLost: packetsLostDiff,
        isDownloadStream
      });

      if (now.type === 'inbound-rtp') {
        ssrcStats.addBitrate({
          'download': this._calculateBitrate(now, before, 'bytesReceived'),
          'upload': 0
        }); // RTCInboundRtpStreamStats
        // https://w3c.github.io/webrtc-stats/#inboundrtpstats-dict*
        // TODO: can we use framesDecoded for frame rate, available
        // in chrome
      } else {
        byteSentStats[ssrc] = this.getNonNegativeValue(now.bytesSent);
        ssrcStats.addBitrate({
          'download': 0,
          'upload': this._calculateBitrate(now, before, 'bytesSent')
        }); // RTCOutboundRtpStreamStats
        // https://w3c.github.io/webrtc-stats/#outboundrtpstats-dict*
        // TODO: can we use framesEncoded for frame rate, available
        // in chrome
      } // FF has framerateMean out of spec


      const framerateMean = now.framerateMean;

      if (framerateMean) {
        ssrcStats.setFramerate(Math.round(framerateMean || 0));
      } // track for resolution
      // RTCVideoHandlerStats
      // https://w3c.github.io/webrtc-stats/#vststats-dict*
      // RTCMediaHandlerStats
      // https://w3c.github.io/webrtc-stats/#mststats-dict*

    } else if (now.type === 'track') {
      const resolution = {
        height: now.frameHeight,
        width: now.frameWidth
      }; // Tries to get frame rate

      let frameRate = now.framesPerSecond;

      if (!frameRate) {
        // we need to calculate it
        const before = this.previousStatsReport.get(now.id);

        if (before) {
          const timeMs = now.timestamp - before.timestamp;

          if (timeMs > 0 && now.framesSent) {
            const numberOfFramesSinceBefore = now.framesSent - before.framesSent;
            frameRate = numberOfFramesSinceBefore / timeMs * 1000;
          }
        }

        if (!frameRate) {
          return;
        }
      }

      const trackIdentifier = now.trackIdentifier;
      const ssrc = this.peerconnection.getSsrcByTrackId(trackIdentifier);

      if (!ssrc) {
        return;
      }

      let ssrcStats = this.ssrc2stats.get(ssrc);

      if (!ssrcStats) {
        ssrcStats = new SsrcStats();
        this.ssrc2stats.set(ssrc, ssrcStats);
      }

      ssrcStats.setFramerate(Math.round(frameRate || 0));

      if (resolution.height && resolution.width) {
        ssrcStats.setResolution(resolution);
      } else {
        ssrcStats.setResolution(null);
      }
    }
  });
  this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__["BYTE_SENT_STATS"], this.peerconnection, byteSentStats);

  this._processAndEmitReport();
};
/**
 * Stats processing logic.
 */


StatsCollector.prototype.processNewAudioLevelReport = function () {
  if (!this.baselineAudioLevelsReport) {
    return;
  }

  this.currentAudioLevelsReport.forEach(now => {
    if (now.type !== 'track') {
      return;
    } // Audio level


    const audioLevel = now.audioLevel;

    if (!audioLevel) {
      return;
    }

    const trackIdentifier = now.trackIdentifier;
    const ssrc = this.peerconnection.getSsrcByTrackId(trackIdentifier);

    if (ssrc) {
      const isLocal = ssrc === this.peerconnection.getLocalSSRC(this.peerconnection.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__["AUDIO"]));
      this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__["AUDIO_LEVEL"], this.peerconnection, ssrc, audioLevel, isLocal);
    }
  });
};
/**
 * End new promised based getStats processing methods.
 */
/* WEBPACK VAR INJECTION */}.call(this, "modules\\statistics\\RTPStatsCollector.js"))

/***/ }),

/***/ "./modules/statistics/SpeakerStats.js":
/*!********************************************!*\
  !*** ./modules/statistics/SpeakerStats.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * A model for keeping track of each user's total
 * time as a dominant speaker. The model also
 * keeps track of the user's last known name
 * in case the user has left the meeting,
 * which is also tracked.
 */
class SpeakerStats {
  /**
   * Initializes a new SpeakerStats instance.
   *
   * @constructor
   * @param {string} userId - The id of the user being tracked.
   * @param {string} displayName - The name of the user being tracked.
   * @param {boolean} isLocalStats - True if the stats model tracks
   * the local user.
   * @returns {void}
   */
  constructor(userId, displayName, isLocalStats) {
    this._userId = userId;
    this.setDisplayName(displayName);
    this._isLocalStats = isLocalStats || false;
    this.setDominantSpeaker(false);
    this.totalDominantSpeakerTime = 0;
    this._dominantSpeakerStart = 0;
    this._hasLeft = false;
  }
  /**
   * Get the user id being tracked.
   *
   * @returns {string} The user id.
   */


  getUserId() {
    return this._userId;
  }
  /**
   * Get the name of the user being tracked.
   *
   * @returns {string} The user name.
   */


  getDisplayName() {
    return this.displayName;
  }
  /**
   * Updates the last known name of the user being tracked.
   *
   * @param {string} - The user name.
   * @returns {void}
   */


  setDisplayName(newName) {
    this.displayName = newName;
  }
  /**
   * Returns true if the stats are tracking the local user.
   *
   * @returns {boolean}
   */


  isLocalStats() {
    return this._isLocalStats;
  }
  /**
   * Returns true if the tracked user is currently a dominant speaker.
   *
   * @returns {boolean}
   */


  isDominantSpeaker() {
    return this._dominantSpeakerStart > 0;
  }
  /**
   * Returns true if the tracked user is currently a dominant speaker.
   *
   * @param {boolean} - If true, the user will being accumulating time
   * as dominant speaker. If false, the user will not accumulate time
   * and will record any time accumulated since starting as dominant speaker.
   * @returns {void}
   */


  setDominantSpeaker(isNowDominantSpeaker) {
    if (!this.isDominantSpeaker() && isNowDominantSpeaker) {
      this._dominantSpeakerStart = Date.now();
    } else if (this.isDominantSpeaker() && !isNowDominantSpeaker) {
      const now = Date.now();
      const timeElapsed = now - this._dominantSpeakerStart;
      this.totalDominantSpeakerTime += timeElapsed;
      this._dominantSpeakerStart = 0;
    }
  }
  /**
   * Get how long the tracked user has been dominant speaker.
   *
   * @returns {number} - The speaker time in milliseconds.
   */


  getTotalDominantSpeakerTime() {
    let total = this.totalDominantSpeakerTime;

    if (this.isDominantSpeaker()) {
      total += Date.now() - this._dominantSpeakerStart;
    }

    return total;
  }
  /**
   * Get whether or not the user is still in the meeting.
   *
   * @returns {boolean} True if the user is no longer in the meeting.
   */


  hasLeft() {
    return this._hasLeft;
  }
  /**
   * Set the user as having left the meeting.
   *
   * @returns {void}
   */


  markAsHasLeft() {
    this._hasLeft = true;
    this.setDominantSpeaker(false);
  }

}

module.exports = SpeakerStats;

/***/ }),

/***/ "./modules/statistics/SpeakerStatsCollector.js":
/*!*****************************************************!*\
  !*** ./modules/statistics/SpeakerStatsCollector.js ***!
  \*****************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return SpeakerStatsCollector; });
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./JitsiConferenceEvents.js");
/* harmony import */ var _SpeakerStats__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./SpeakerStats */ "./modules/statistics/SpeakerStats.js");
/* harmony import */ var _SpeakerStats__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_SpeakerStats__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__);



/**
 * A collection for tracking speaker stats. Attaches listeners
 * to the conference to automatically update on tracked events.
 */

class SpeakerStatsCollector {
  /**
   * Initializes a new SpeakerStatsCollector instance.
   *
   * @constructor
   * @param {JitsiConference} conference - The conference to track.
   * @returns {void}
   */
  constructor(conference) {
    this.stats = {
      users: {// userId: SpeakerStats
      },
      dominantSpeakerId: null
    };
    const userId = conference.myUserId();
    this.stats.users[userId] = new _SpeakerStats__WEBPACK_IMPORTED_MODULE_1___default.a(userId, null, true);
    this.conference = conference;
    conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__["DOMINANT_SPEAKER_CHANGED"], this._onDominantSpeaker.bind(this));
    conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__["USER_JOINED"], this._onUserJoin.bind(this));
    conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__["USER_LEFT"], this._onUserLeave.bind(this));
    conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__["DISPLAY_NAME_CHANGED"], this._onDisplayNameChange.bind(this));

    if (conference.xmpp) {
      conference.xmpp.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2___default.a.SPEAKER_STATS_RECEIVED, this._updateStats.bind(this));
    }
  }
  /**
   * Reacts to dominant speaker change events by changing its speaker stats
   * models to reflect the current dominant speaker.
   *
   * @param {string} dominantSpeakerId - The user id of the new
   * dominant speaker.
   * @returns {void}
   * @private
   */


  _onDominantSpeaker(dominantSpeakerId) {
    const oldDominantSpeaker = this.stats.users[this.stats.dominantSpeakerId];
    const newDominantSpeaker = this.stats.users[dominantSpeakerId];
    oldDominantSpeaker && oldDominantSpeaker.setDominantSpeaker(false);
    newDominantSpeaker && newDominantSpeaker.setDominantSpeaker(true);
    this.stats.dominantSpeakerId = dominantSpeakerId;
  }
  /**
   * Reacts to user join events by creating a new SpeakerStats model.
   *
   * @param {string} userId - The user id of the new user.
   * @param {JitsiParticipant} - The JitsiParticipant model for the new user.
   * @returns {void}
   * @private
   */


  _onUserJoin(userId, participant) {
    if (participant.isHidden()) {
      return;
    }

    if (!this.stats.users[userId]) {
      this.stats.users[userId] = new _SpeakerStats__WEBPACK_IMPORTED_MODULE_1___default.a(userId, participant.getDisplayName());
    }
  }
  /**
   * Reacts to user leave events by updating the associated user's
   * SpeakerStats model.
   *
   * @param {string} userId - The user id of the user that left.
   * @returns {void}
   * @private
   */


  _onUserLeave(userId) {
    const savedUser = this.stats.users[userId];

    if (savedUser) {
      savedUser.markAsHasLeft();
    }
  }
  /**
   * Reacts to user name change events by updating the last known name
   * tracked in the associated SpeakerStats model.
   *
   * @param {string} userId - The user id of the user that left.
   * @returns {void}
   * @private
   */


  _onDisplayNameChange(userId, newName) {
    const savedUser = this.stats.users[userId];

    if (savedUser) {
      savedUser.setDisplayName(newName);
    }
  }
  /**
   * Return a copy of the tracked SpeakerStats models.
   *
   * @returns {Object} The keys are the user ids and the values are the
   * associated user's SpeakerStats model.
   * @private
   */


  getStats() {
    return this.stats.users;
  }
  /**
   * Updates of the current stats is requested, passing the new values.
   *
   * @param {Object} newStats - The new values used to update current one.
   * @private
   */


  _updateStats(newStats) {
    for (const userId in newStats) {
      // eslint-disable-line guard-for-in
      let speakerStatsToUpdate;
      const newParticipant = this.conference.getParticipantById(userId); // we want to ignore hidden participants

      if (!newParticipant || !newParticipant.isHidden()) {
        if (this.stats.users[userId]) {
          speakerStatsToUpdate = this.stats.users[userId];

          if (!speakerStatsToUpdate.getDisplayName()) {
            speakerStatsToUpdate.setDisplayName(newStats[userId].displayName);
          }
        } else {
          speakerStatsToUpdate = new _SpeakerStats__WEBPACK_IMPORTED_MODULE_1___default.a(userId, newStats[userId].displayName);
          this.stats.users[userId] = speakerStatsToUpdate;
          speakerStatsToUpdate.markAsHasLeft();
        }
      }

      speakerStatsToUpdate.totalDominantSpeakerTime = newStats[userId].totalDominantSpeakerTime;
    }
  }

}

/***/ }),

/***/ "./modules/statistics/statistics.js":
/*!******************************************!*\
  !*** ./modules/statistics/statistics.js ***!
  \******************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return Statistics; });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var _AnalyticsAdapter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AnalyticsAdapter */ "./modules/statistics/AnalyticsAdapter.js");
/* harmony import */ var _CallStats__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./CallStats */ "./modules/statistics/CallStats.js");
/* harmony import */ var _LocalStatsCollector__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./LocalStatsCollector */ "./modules/statistics/LocalStatsCollector.js");
/* harmony import */ var _RTPStatsCollector__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./RTPStatsCollector */ "./modules/statistics/RTPStatsCollector.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _util_ScriptUtil__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/ScriptUtil */ "./modules/util/ScriptUtil.js");
/* harmony import */ var _util_ScriptUtil__WEBPACK_IMPORTED_MODULE_7___default = /*#__PURE__*/__webpack_require__.n(_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_7__);
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../JitsiTrackError */ "./JitsiTrackError.js");
/* harmony import */ var _service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../../service/statistics/Events */ "./service/statistics/Events.js");











const logger = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js").getLogger(__filename);
/**
 * Stores all active {@link Statistics} instances.
 * @type {Set<Statistics>}
 */


let _instances;
/**
 * True if callstats API is loaded
 */


let isCallstatsLoaded = false;
/**
 * Since callstats.io is a third party, we cannot guarantee the quality of their
 * service. More specifically, their server may take noticeably long time to
 * respond. Consequently, it is in our best interest (in the sense that the
 * intergration of callstats.io is pretty important to us but not enough to
 * allow it to prevent people from joining a conference) to (1) start
 * downloading their API as soon as possible and (2) do the downloading
 * asynchronously.
 *
 * @param {StatisticsOptions} options - Options to use for downloading and
 * initializing callstats backend.
 */

function loadCallStatsAPI(options) {
  if (!isCallstatsLoaded) {
    _util_ScriptUtil__WEBPACK_IMPORTED_MODULE_7___default.a.loadScript(options.customScriptUrl || 'https://api.callstats.io/static/callstats-ws.min.js',
    /* async */
    true,
    /* prepend */
    true,
    /* relativeURL */
    undefined,
    /* loadCallback */
    () => _initCallStatsBackend(options));
    isCallstatsLoaded = true;
  }
}
/**
 * Initializes Callstats backend.
 *
 * @param {StatisticsOptions} options - The options to use for initializing
 * callstats backend.
 * @private
 */


function _initCallStatsBackend(options) {
  if (_CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].isBackendInitialized()) {
    return;
  }

  if (!_CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].initBackend({
    callStatsID: options.callStatsID,
    callStatsSecret: options.callStatsSecret,
    userName: options.userName,
    aliasName: options.aliasName,
    applicationName: options.applicationName,
    getWiFiStatsMethod: options.getWiFiStatsMethod,
    confID: options.confID
  })) {
    logger.error('CallStats Backend initialization failed bad');
  }
}
/**
 * callstats strips any additional fields from Error except for "name", "stack",
 * "message" and "constraintName". So we need to bundle additional information
 * from JitsiTrackError into error passed to callstats to preserve valuable
 * information about error.
 * @param {JitsiTrackError} error
 */


function formatJitsiTrackErrorForCallStats(error) {
  const err = new Error(); // Just copy original stack from error

  err.stack = error.stack; // Combine name from error's name plus (possibly) name of original GUM error

  err.name = (error.name || 'Unknown error') + (error.gum && error.gum.error && error.gum.error.name ? ` - ${error.gum.error.name}` : ''); // Put all constraints into this field. For constraint failed errors we will
  // still know which exactly constraint failed as it will be a part of
  // message.

  err.constraintName = error.gum && error.gum.constraints ? JSON.stringify(error.gum.constraints) : ''; // Just copy error's message.

  err.message = error.message;
  return err;
}
/**
 * Init statistic options
 * @param options
 */


Statistics.init = function (options) {
  Statistics.audioLevelsEnabled = !options.disableAudioLevels;

  if (typeof options.pcStatsInterval === 'number') {
    Statistics.pcStatsInterval = options.pcStatsInterval;
  }

  if (typeof options.audioLevelsInterval === 'number') {
    Statistics.audioLevelsInterval = options.audioLevelsInterval;
  }

  Statistics.disableThirdPartyRequests = options.disableThirdPartyRequests;
};
/**
 * The options to configure Statistics.
 * @typedef {Object} StatisticsOptions
 * @property {string} applicationName - The application name to pass to
 * callstats.
 * @property {string} aliasName - The alias name to use when initializing callstats.
 * @property {string} userName - The user name to use when initializing callstats.
 * @property {string} callStatsConfIDNamespace - A namespace to prepend the
 * callstats conference ID with.
 * @property {string} confID - The callstats conference ID to use.
 * @property {string} callStatsID - Callstats credentials - the id.
 * @property {string} callStatsSecret - Callstats credentials - the secret.
 * @property {string} customScriptUrl - A custom lib url to use when downloading
 * callstats library.
 * @property {string} roomName - The room name we are currently in.
 */

/**
 *
 * @param xmpp
 * @param {StatisticsOptions} options - The options to use creating the
 * Statistics.
 */


function Statistics(xmpp, options) {
  /**
   * {@link RTPStats} mapped by {@link TraceablePeerConnection.id} which
   * collect RTP statistics for each peerconnection.
   * @type {Map<string, RTPStats}
   */
  this.rtpStatsMap = new Map();
  this.eventEmitter = new events__WEBPACK_IMPORTED_MODULE_0___default.a();
  this.xmpp = xmpp;
  this.options = options || {};
  this.callStatsIntegrationEnabled = this.options.callStatsID && this.options.callStatsSecret // Even though AppID and AppSecret may be specified, the integration
  // of callstats.io may be disabled because of globally-disallowed
  // requests to any third parties.
  && Statistics.disableThirdPartyRequests !== true;

  if (this.callStatsIntegrationEnabled) {
    this.callStatsApplicationLogsDisabled = this.options.callStatsApplicationLogsDisabled;

    if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isReactNative()) {
      _initCallStatsBackend(this.options);
    } else {
      loadCallStatsAPI(this.options);
    }

    if (!this.options.confID) {
      logger.warn('"confID" is not defined');
    }

    if (!this.options.callStatsConfIDNamespace) {
      logger.warn('"callStatsConfIDNamespace" is not defined');
    }
  }
  /**
   * Stores {@link CallStats} instances for each
   * {@link TraceablePeerConnection} (one {@link CallStats} instance serves
   * one TPC). The instances are mapped by {@link TraceablePeerConnection.id}.
   * @type {Map<number, CallStats>}
   */


  this.callsStatsInstances = new Map();
  Statistics.instances.add(this);
}
Statistics.audioLevelsEnabled = false;
Statistics.audioLevelsInterval = 200;
Statistics.pcStatsInterval = 10000;
Statistics.disableThirdPartyRequests = false;
Statistics.analytics = _AnalyticsAdapter__WEBPACK_IMPORTED_MODULE_2__["default"];
Object.defineProperty(Statistics, 'instances', {
  /**
   * Returns the Set holding all active {@link Statistics} instances. Lazily
   * initializes the Set to allow any Set polyfills to be applied.
   * @type {Set<Statistics>}
   */
  get() {
    if (!_instances) {
      _instances = new Set();
    }

    return _instances;
  }

});
/**
 * Starts collecting RTP stats for given peerconnection.
 * @param {TraceablePeerConnection} peerconnection
 */

Statistics.prototype.startRemoteStats = function (peerconnection) {
  this.stopRemoteStats(peerconnection);

  try {
    const rtpStats = new _RTPStatsCollector__WEBPACK_IMPORTED_MODULE_5__["default"](peerconnection, Statistics.audioLevelsInterval, Statistics.pcStatsInterval, this.eventEmitter);
    rtpStats.start(Statistics.audioLevelsEnabled);
    this.rtpStatsMap.set(peerconnection.id, rtpStats);
  } catch (e) {
    logger.error(`Failed to start collecting remote statistics: ${e}`);
  }
};

Statistics.localStats = [];

Statistics.startLocalStats = function (stream, callback) {
  if (!Statistics.audioLevelsEnabled) {
    return;
  }

  const localStats = new _LocalStatsCollector__WEBPACK_IMPORTED_MODULE_4__["default"](stream, Statistics.audioLevelsInterval, callback);
  this.localStats.push(localStats);
  localStats.start();
};

Statistics.prototype.addAudioLevelListener = function (listener) {
  if (!Statistics.audioLevelsEnabled) {
    return;
  }

  this.eventEmitter.on(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["AUDIO_LEVEL"], listener);
};

Statistics.prototype.removeAudioLevelListener = function (listener) {
  if (!Statistics.audioLevelsEnabled) {
    return;
  }

  this.eventEmitter.removeListener(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["AUDIO_LEVEL"], listener);
};

Statistics.prototype.addBeforeDisposedListener = function (listener) {
  this.eventEmitter.on(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["BEFORE_DISPOSED"], listener);
};

Statistics.prototype.removeBeforeDisposedListener = function (listener) {
  this.eventEmitter.removeListener(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["BEFORE_DISPOSED"], listener);
};

Statistics.prototype.addConnectionStatsListener = function (listener) {
  this.eventEmitter.on(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["CONNECTION_STATS"], listener);
};

Statistics.prototype.removeConnectionStatsListener = function (listener) {
  this.eventEmitter.removeListener(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["CONNECTION_STATS"], listener);
};

Statistics.prototype.addByteSentStatsListener = function (listener) {
  this.eventEmitter.on(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["BYTE_SENT_STATS"], listener);
};

Statistics.prototype.removeByteSentStatsListener = function (listener) {
  this.eventEmitter.removeListener(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["BYTE_SENT_STATS"], listener);
};

Statistics.prototype.dispose = function () {
  try {
    // NOTE Before reading this please see the comment in stopCallStats...
    //
    // Here we prevent from emitting the event twice in case it will be
    // triggered from stopCallStats.
    // If the event is triggered from here it means that the logs will not
    // be submitted anyway (because there is no CallStats instance), but
    // we're doing that for the sake of some kind of consistency.
    if (!this.callsStatsInstances.size) {
      this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["BEFORE_DISPOSED"]);
    }

    for (const callStats of this.callsStatsInstances.values()) {
      this.stopCallStats(callStats.tpc);
    }

    for (const tpcId of this.rtpStatsMap.keys()) {
      this._stopRemoteStats(tpcId);
    }

    if (this.eventEmitter) {
      this.eventEmitter.removeAllListeners();
    }
  } finally {
    Statistics.instances.delete(this);
  }
};

Statistics.stopLocalStats = function (stream) {
  if (!Statistics.audioLevelsEnabled) {
    return;
  }

  for (let i = 0; i < Statistics.localStats.length; i++) {
    if (Statistics.localStats[i].stream === stream) {
      const localStats = Statistics.localStats.splice(i, 1);
      localStats[0].stop();
      break;
    }
  }
};
/**
 * Stops remote RTP stats for given peerconnection ID.
 * @param {string} tpcId {@link TraceablePeerConnection.id}
 * @private
 */


Statistics.prototype._stopRemoteStats = function (tpcId) {
  const rtpStats = this.rtpStatsMap.get(tpcId);

  if (rtpStats) {
    rtpStats.stop();
    this.rtpStatsMap.delete(tpcId);
  }
};
/**
 * Stops collecting RTP stats for given peerconnection
 * @param {TraceablePeerConnection} tpc
 */


Statistics.prototype.stopRemoteStats = function (tpc) {
  this._stopRemoteStats(tpc.id);
}; // CALSTATS METHODS

/**
 * Initializes the callstats.io API.
 * @param {TraceablePeerConnection} tpc the {@link TraceablePeerConnection}
 * instance for which CalStats will be started.
 * @param {string} remoteUserID
 */


Statistics.prototype.startCallStats = function (tpc, remoteUserID) {
  if (!this.callStatsIntegrationEnabled) {
    return;
  } else if (this.callsStatsInstances.has(tpc.id)) {
    logger.error('CallStats instance for ${tpc} exists already');
    return;
  }

  logger.info(`Starting CallStats for ${tpc}...`);
  const newInstance = new _CallStats__WEBPACK_IMPORTED_MODULE_3__["default"](tpc, {
    confID: this._getCallStatsConfID(),
    remoteUserID
  });
  this.callsStatsInstances.set(tpc.id, newInstance);
};
/**
 * Obtains the list of *all* {@link CallStats} instances collected from every
 * valid {@link Statistics} instance.
 * @return {Set<CallStats>}
 * @private
 */


Statistics._getAllCallStatsInstances = function () {
  const csInstances = new Set();

  for (const statistics of Statistics.instances) {
    for (const cs of statistics.callsStatsInstances.values()) {
      csInstances.add(cs);
    }
  }

  return csInstances;
};
/**
 * Constructs the CallStats conference ID based on the options currently
 * configured in this instance.
 * @return {string}
 * @private
 */


Statistics.prototype._getCallStatsConfID = function () {
  // The conference ID is case sensitive!!!
  return this.options.callStatsConfIDNamespace ? `${this.options.callStatsConfIDNamespace}/${this.options.roomName}` : this.options.roomName;
};
/**
 * Removes the callstats.io instances.
 */


Statistics.prototype.stopCallStats = function (tpc) {
  const callStatsInstance = this.callsStatsInstances.get(tpc.id);

  if (callStatsInstance) {
    // FIXME the original purpose of adding BEFORE_DISPOSED event was to be
    // able to submit the last log batch from jitsi-meet to CallStats. After
    // recent changes we dispose the CallStats earlier
    // (before Statistics.dispose), so we need to emit this event here to
    // give this last chance for final log batch submission.
    //
    // Eventually there should be a separate module called "log storage"
    // which should emit proper events when it's underlying
    // CallStats instance is going away.
    if (this.callsStatsInstances.size === 1) {
      this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_9__["BEFORE_DISPOSED"]);
    }

    this.callsStatsInstances.delete(tpc.id); // The fabric needs to be terminated when being stopped

    callStatsInstance.sendTerminateEvent();
  }
};
/**
 * Returns true if the callstats integration is enabled, otherwise returns
 * false.
 *
 * @returns true if the callstats integration is enabled, otherwise returns
 * false.
 */


Statistics.prototype.isCallstatsEnabled = function () {
  return this.callStatsIntegrationEnabled;
};
/**
 * Logs either resume or hold event for the given peer connection.
 * @param {TraceablePeerConnection} tpc the connection for which event will be
 * reported
 * @param {boolean} isResume true for resume or false for hold
 */


Statistics.prototype.sendConnectionResumeOrHoldEvent = function (tpc, isResume) {
  const instance = this.callsStatsInstances.get(tpc.id);

  if (instance) {
    instance.sendResumeOrHoldEvent(isResume);
  }
};
/**
 * Notifies CallStats and analytics (if present) for ice connection failed
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */


Statistics.prototype.sendIceConnectionFailedEvent = function (tpc) {
  const instance = this.callsStatsInstances.get(tpc.id);

  if (instance) {
    instance.sendIceConnectionFailedEvent();
  }
};
/**
 * Notifies CallStats for mute events
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 * @param {boolean} muted true for muted and false for not muted
 * @param {String} type "audio"/"video"
 */


Statistics.prototype.sendMuteEvent = function (tpc, muted, type) {
  const instance = tpc && this.callsStatsInstances.get(tpc.id);
  _CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].sendMuteEvent(muted, type, instance);
};
/**
 * Notifies CallStats for screen sharing events
 * @param start {boolean} true for starting screen sharing and
 * false for not stopping
 * @param {string|null} ssrc - optional ssrc value, used only when
 * starting screen sharing.
 */


Statistics.prototype.sendScreenSharingEvent = function (start, ssrc) {
  for (const cs of this.callsStatsInstances.values()) {
    cs.sendScreenSharingEvent(start, ssrc);
  }
};
/**
 * Notifies the statistics module that we are now the dominant speaker of the
 * conference.
 * @param {String} roomJid - The room jid where the speaker event occurred.
 */


Statistics.prototype.sendDominantSpeakerEvent = function (roomJid) {
  for (const cs of this.callsStatsInstances.values()) {
    cs.sendDominantSpeakerEvent();
  } // xmpp send dominant speaker event


  this.xmpp.sendDominantSpeakerEvent(roomJid);
};
/**
 * Notifies about active device.
 * @param {{deviceList: {String:String}}} devicesData - list of devices with
 *      their data
 */


Statistics.sendActiveDeviceListEvent = function (devicesData) {
  const globalSet = Statistics._getAllCallStatsInstances();

  if (globalSet.size) {
    for (const cs of globalSet) {
      _CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].sendActiveDeviceListEvent(devicesData, cs);
    }
  } else {
    _CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].sendActiveDeviceListEvent(devicesData, null);
  }
};
/* eslint-disable max-params */

/**
 * Lets the underlying statistics module know where is given SSRC rendered by
 * providing renderer tag ID.
 * @param {TraceablePeerConnection} tpc the connection to which the stream
 * belongs to
 * @param {number} ssrc the SSRC of the stream
 * @param {boolean} isLocal
 * @param {string} userId
 * @param {string} usageLabel  meaningful usage label of this stream like
 *        'microphone', 'camera' or 'screen'.
 * @param {string} containerId the id of media 'audio' or 'video' tag which
 *        renders the stream.
 */


Statistics.prototype.associateStreamWithVideoTag = function (tpc, ssrc, isLocal, userId, usageLabel, containerId) {
  const instance = this.callsStatsInstances.get(tpc.id);

  if (instance) {
    instance.associateStreamWithVideoTag(ssrc, isLocal, userId, usageLabel, containerId);
  }
};
/* eslint-enable max-params */

/**
 * Notifies CallStats that getUserMedia failed.
 *
 * @param {Error} e error to send
 */


Statistics.sendGetUserMediaFailed = function (e) {
  const error = e instanceof _JitsiTrackError__WEBPACK_IMPORTED_MODULE_8__["default"] ? formatJitsiTrackErrorForCallStats(e) : e;

  const globalSet = Statistics._getAllCallStatsInstances();

  if (globalSet.size) {
    for (const cs of globalSet) {
      _CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].sendGetUserMediaFailed(error, cs);
    }
  } else {
    _CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].sendGetUserMediaFailed(error, null);
  }
};
/**
 * Notifies CallStats that peer connection failed to create offer.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */


Statistics.prototype.sendCreateOfferFailed = function (e, tpc) {
  const instance = this.callsStatsInstances.get(tpc.id);

  if (instance) {
    instance.sendCreateOfferFailed(e);
  }
};
/**
 * Notifies CallStats that peer connection failed to create answer.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occured.
 */


Statistics.prototype.sendCreateAnswerFailed = function (e, tpc) {
  const instance = this.callsStatsInstances.get(tpc.id);

  if (instance) {
    instance.sendCreateAnswerFailed(e);
  }
};
/**
 * Notifies CallStats that peer connection failed to set local description.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */


Statistics.prototype.sendSetLocalDescFailed = function (e, tpc) {
  const instance = this.callsStatsInstances.get(tpc.id);

  if (instance) {
    instance.sendSetLocalDescFailed(e);
  }
};
/**
 * Notifies CallStats that peer connection failed to set remote description.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */


Statistics.prototype.sendSetRemoteDescFailed = function (e, tpc) {
  const instance = this.callsStatsInstances.get(tpc.id);

  if (instance) {
    instance.sendSetRemoteDescFailed(e);
  }
};
/**
 * Notifies CallStats that peer connection failed to add ICE candidate.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */


Statistics.prototype.sendAddIceCandidateFailed = function (e, tpc) {
  const instance = this.callsStatsInstances.get(tpc.id);

  if (instance) {
    instance.sendAddIceCandidateFailed(e);
  }
};
/**
 * Adds to CallStats an application log.
 *
 * @param {String} m a log message to send or an {Error} object to be reported
 */


Statistics.sendLog = function (m) {
  const globalSubSet = new Set(); // FIXME we don't want to duplicate logs over P2P instance, but
  // here we should go over instances and call this method for each
  // unique conference ID rather than selecting the first one.
  // We don't have such use case though, so leaving as is for now.

  for (const stats of Statistics.instances) {
    if (stats.callStatsApplicationLogsDisabled) {
      return;
    }

    if (stats.callsStatsInstances.size) {
      globalSubSet.add(stats.callsStatsInstances.values().next().value);
    }
  }

  if (globalSubSet.size) {
    for (const csPerStats of globalSubSet) {
      _CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].sendApplicationLog(m, csPerStats);
    }
  } else {
    _CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].sendApplicationLog(m, null);
  }
};
/**
 * Sends the given feedback through CallStats.
 *
 * @param overall an integer between 1 and 5 indicating the user's rating.
 * @param comment the comment from the user.
 * @returns {Promise} Resolves when callstats feedback has been submitted
 * successfully.
 */


Statistics.prototype.sendFeedback = function (overall, comment) {
  // Statistics.analytics.sendEvent is currently fire and forget, without
  // confirmation of successful send.
  Statistics.analytics.sendEvent(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__["FEEDBACK"], {
    rating: overall,
    comment
  });
  return _CallStats__WEBPACK_IMPORTED_MODULE_3__["default"].sendFeedback(this._getCallStatsConfID(), overall, comment);
};

Statistics.LOCAL_JID = __webpack_require__(/*! ../../service/statistics/constants */ "./service/statistics/constants.js").LOCAL_JID;
/**
 * Reports global error to CallStats.
 *
 * @param {Error} error
 */

Statistics.reportGlobalError = function (error) {
  if (error instanceof _JitsiTrackError__WEBPACK_IMPORTED_MODULE_8__["default"] && error.gum) {
    Statistics.sendGetUserMediaFailed(error);
  } else {
    Statistics.sendLog(error);
  }
};
/**
 * Sends event to analytics and logs a message to the logger/console. Console
 * messages might also be logged to callstats automatically.
 *
 * @param {string | Object} event the event name, or an object which
 * represents the entire event.
 * @param {Object} properties properties to attach to the event (if an event
 * name as opposed to an event object is provided).
 */


Statistics.sendAnalyticsAndLog = function (event, properties = {}) {
  if (!event) {
    logger.warn('No event or event name given.');
    return;
  }

  let eventToLog; // Also support an API with a single object as an event.

  if (typeof event === 'object') {
    eventToLog = event;
  } else {
    eventToLog = {
      name: event,
      properties
    };
  }

  logger.log(JSON.stringify(eventToLog)); // We do this last, because it may modify the object which is passed.

  this.analytics.sendEvent(event, properties);
};
/**
 * Sends event to analytics.
 *
 * @param {string | Object} eventName the event name, or an object which
 * represents the entire event.
 * @param {Object} properties properties to attach to the event
 */


Statistics.sendAnalytics = function (eventName, properties = {}) {
  this.analytics.sendEvent(eventName, properties);
};
/* WEBPACK VAR INJECTION */}.call(this, "modules\\statistics\\statistics.js"))

/***/ }),

/***/ "./modules/transcription/audioRecorder.js":
/*!************************************************!*\
  !*** ./modules/transcription/audioRecorder.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* global MediaRecorder, MediaStream */
const RecordingResult = __webpack_require__(/*! ./recordingResult */ "./modules/transcription/recordingResult.js");
/**
 * Possible audio formats MIME types
 */


const AUDIO_WEBM = 'audio/webm'; // Supported in chrome

const AUDIO_OGG = 'audio/ogg'; // Supported in firefox

/**
 * A TrackRecorder object holds all the information needed for recording a
 * single JitsiTrack (either remote or local)
 * @param track The JitsiTrack the object is going to hold
 */

const TrackRecorder = function (track) {
  // The JitsiTrack holding the stream
  this.track = track; // The MediaRecorder recording the stream

  this.recorder = null; // The array of data chunks recorded from the stream
  // acts as a buffer until the data is stored on disk

  this.data = null; // the name of the person of the JitsiTrack. This can be undefined and/or
  // not unique

  this.name = null; // the time of the start of the recording

  this.startTime = null;
};
/**
 * Starts the recording of a JitsiTrack in a TrackRecorder object.
 * This will also define the timestamp and try to update the name
 * @param trackRecorder the TrackRecorder to start
 */


function startRecorder(trackRecorder) {
  if (trackRecorder.recorder === undefined) {
    throw new Error('Passed an object to startRecorder which is not a ' + 'TrackRecorder object');
  }

  trackRecorder.recorder.start();
  trackRecorder.startTime = new Date();
}
/**
 * Stops the recording of a JitsiTrack in a TrackRecorder object.
 * This will also try to update the name
 * @param trackRecorder the TrackRecorder to stop
 */


function stopRecorder(trackRecorder) {
  if (trackRecorder.recorder === undefined) {
    throw new Error('Passed an object to stopRecorder which is not a ' + 'TrackRecorder object');
  }

  trackRecorder.recorder.stop();
}
/**
 * Determines which kind of audio recording the browser supports
 * chrome supports "audio/webm" and firefox supports "audio/ogg"
 */


function determineCorrectFileType() {
  if (MediaRecorder.isTypeSupported(AUDIO_WEBM)) {
    return AUDIO_WEBM;
  } else if (MediaRecorder.isTypeSupported(AUDIO_OGG)) {
    return AUDIO_OGG;
  }

  throw new Error('unable to create a MediaRecorder with the right mimetype!');
}
/**
 * main exported object of the file, holding all
 * relevant functions and variables for the outside world
 * @param jitsiConference the jitsiConference which this object
 * is going to record
 */


function AudioRecorder(jitsiConference) {
  // array of TrackRecorders, where each trackRecorder
  // holds the JitsiTrack, MediaRecorder and recorder data
  this.recorders = []; // get which file type is supported by the current browser

  this.fileType = determineCorrectFileType(); // boolean flag for active recording

  this.isRecording = false; // the jitsiconference the object is recording

  this.jitsiConference = jitsiConference;
}
/**
 * Add the the exported module so that it can be accessed by other files
 */


AudioRecorder.determineCorrectFileType = determineCorrectFileType;
/**
 * Adds a new TrackRecorder object to the array.
 *
 * @param track the track potentially holding an audio stream
 */

AudioRecorder.prototype.addTrack = function (track) {
  if (track.isAudioTrack()) {
    // create the track recorder
    const trackRecorder = this.instantiateTrackRecorder(track); // push it to the local array of all recorders

    this.recorders.push(trackRecorder); // update the name of the trackRecorders

    this.updateNames(); // If we're already recording, immediately start recording this new
    // track.

    if (this.isRecording) {
      startRecorder(trackRecorder);
    }
  }
};
/**
 * Creates a TrackRecorder object. Also creates the MediaRecorder and
 * data array for the trackRecorder.
 * @param track the JitsiTrack holding the audio MediaStream(s)
 */


AudioRecorder.prototype.instantiateTrackRecorder = function (track) {
  const trackRecorder = new TrackRecorder(track); // Create a new stream which only holds the audio track

  const originalStream = trackRecorder.track.getOriginalStream();
  const stream = createEmptyStream();
  originalStream.getAudioTracks().forEach(t => stream.addTrack(t)); // Create the MediaRecorder

  trackRecorder.recorder = new MediaRecorder(stream, {
    mimeType: this.fileType
  }); // array for holding the recorder data. Resets it when
  // audio already has been recorder once

  trackRecorder.data = []; // function handling a dataEvent, e.g the stream gets new data

  trackRecorder.recorder.ondataavailable = function (dataEvent) {
    if (dataEvent.data.size > 0) {
      trackRecorder.data.push(dataEvent.data);
    }
  };

  return trackRecorder;
};
/**
 * Notifies the module that a specific track has stopped, e.g participant left
 * the conference.
 * if the recording has not started yet, the TrackRecorder will be removed from
 * the array. If the recording has started, the recorder will stop recording
 * but not removed from the array so that the recorded stream can still be
 * accessed
 *
 * @param {JitsiTrack} track the JitsiTrack to remove from the recording session
 */


AudioRecorder.prototype.removeTrack = function (track) {
  if (track.isVideoTrack()) {
    return;
  }

  const array = this.recorders;
  let i;

  for (i = 0; i < array.length; i++) {
    if (array[i].track.getParticipantId() === track.getParticipantId()) {
      const recorderToRemove = array[i];

      if (this.isRecording) {
        stopRecorder(recorderToRemove);
      } else {
        // remove the TrackRecorder from the array
        array.splice(i, 1);
      }
    }
  } // make sure the names are up to date


  this.updateNames();
};
/**
 * Tries to update the name value of all TrackRecorder in the array.
 * If it hasn't changed,it will keep the exiting name. If it changes to a
 * undefined value, the old value will also be kept.
 */


AudioRecorder.prototype.updateNames = function () {
  const conference = this.jitsiConference;
  this.recorders.forEach(trackRecorder => {
    if (trackRecorder.track.isLocal()) {
      trackRecorder.name = 'the transcriber';
    } else {
      const id = trackRecorder.track.getParticipantId();
      const participant = conference.getParticipantById(id);
      const newName = participant.getDisplayName();

      if (newName !== 'undefined') {
        trackRecorder.name = newName;
      }
    }
  });
};
/**
 * Starts the audio recording of every local and remote track
 */


AudioRecorder.prototype.start = function () {
  if (this.isRecording) {
    throw new Error('audiorecorder is already recording');
  } // set boolean isRecording flag to true so if new participants join the
  // conference, that track can instantly start recording as well


  this.isRecording = true; // start all the mediaRecorders

  this.recorders.forEach(trackRecorder => startRecorder(trackRecorder)); // log that recording has started

  console.log(`Started the recording of the audio. There are currently ${this.recorders.length} recorders active.`);
};
/**
 * Stops the audio recording of every local and remote track
 */


AudioRecorder.prototype.stop = function () {
  // set the boolean flag to false
  this.isRecording = false; // stop all recorders

  this.recorders.forEach(trackRecorder => stopRecorder(trackRecorder));
  console.log('stopped recording');
};
/**
 * link hacking to download all recorded audio streams
 */


AudioRecorder.prototype.download = function () {
  this.recorders.forEach(trackRecorder => {
    const blob = new Blob(trackRecorder.data, {
      type: this.fileType
    });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    document.body.appendChild(a);
    a.style = 'display: none';
    a.href = url;
    a.download = `test.${this.fileType.split('/')[1]}`;
    a.click();
    window.URL.revokeObjectURL(url);
  });
};
/**
 * returns the audio files of all recorders as an array of objects,
 * which include the name of the owner of the track and the starting time stamp
 * @returns {Array} an array of RecordingResult objects
 */


AudioRecorder.prototype.getRecordingResults = function () {
  if (this.isRecording) {
    throw new Error('cannot get blobs because the AudioRecorder is still recording!');
  } // make sure the names are up to date before sending them off


  this.updateNames();
  const array = [];
  this.recorders.forEach(recorder => array.push(new RecordingResult(new Blob(recorder.data, {
    type: this.fileType
  }), recorder.name, recorder.startTime)));
  return array;
};
/**
 * Gets the mime type of the recorder audio
 * @returns {String} the mime type of the recorder audio
 */


AudioRecorder.prototype.getFileType = function () {
  return this.fileType;
};
/**
 * Creates a empty MediaStream object which can be used
 * to add MediaStreamTracks to
 * @returns MediaStream
 */


function createEmptyStream() {
  if (typeof MediaStream !== 'undefined') {
    return new MediaStream();
  }

  throw new Error('cannot create a clean mediaStream');
}
/**
 * export the main object AudioRecorder
 */


module.exports = AudioRecorder;

/***/ }),

/***/ "./modules/transcription/recordingResult.js":
/*!**************************************************!*\
  !*** ./modules/transcription/recordingResult.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/* eslint-disable max-params */

/**
 * This object stores variables needed around the recording of an audio stream
 * and passing this recording along with additional information along to
 * different processes
 * @param blob the recording audio stream as a single blob
 * @param name the name of the person of the audio stream
 * @param startTime the time in UTC when recording of the audiostream started
 * @param wordArray the recorder audio stream transcribed as an array of Word
 *                  objects
 */
const RecordingResult = function (blob, name, startTime, wordArray) {
  this.blob = blob;
  this.name = name;
  this.startTime = startTime;
  this.wordArray = wordArray;
};
/* eslint-enable max-params */


module.exports = RecordingResult;

/***/ }),

/***/ "./modules/transcription/transcriber.js":
/*!**********************************************!*\
  !*** ./modules/transcription/transcriber.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

const AudioRecorder = __webpack_require__(/*! ./audioRecorder */ "./modules/transcription/audioRecorder.js");

const SphinxService = __webpack_require__(/*! ./transcriptionServices/SphinxTranscriptionService */ "./modules/transcription/transcriptionServices/SphinxTranscriptionService.js");

const BEFORE_STATE = 'before';
const RECORDING_STATE = 'recording';
const TRANSCRIBING_STATE = 'transcribing';
const FINISHED_STATE = 'finished'; // the amount of characters each line in the transcription will have

const MAXIMUM_SENTENCE_LENGTH = 80;
/**
 * This is the main object for handing the Transcription. It interacts with
 * the audioRecorder to record every person in a conference and sends the
 * recorder audio to a transcriptionService. The returned speech-to-text result
 * will be merged to create a transcript
 * @param {AudioRecorder} audioRecorder An audioRecorder recording a conference
 */

function Transcriber() {
  // the object which can record all audio in the conference
  this.audioRecorder = new AudioRecorder(); // this object can send the recorder audio to a speech-to-text service

  this.transcriptionService = new SphinxService(); // holds a counter to keep track if merging can start

  this.counter = null; // holds the date when transcription started which makes it possible
  // to calculate the offset between recordings

  this.startTime = null; // will hold the transcription once it is completed

  this.transcription = null; // this will be a method which will be called once the transcription is done
  // with the transcription as parameter

  this.callback = null; // stores all the retrieved speech-to-text results to merge together
  // this value will store an Array<Word> object

  this.results = []; // Stores the current state of the transcription process

  this.state = BEFORE_STATE; // Used in the updateTranscription method to add a new line when the
  // sentence becomes to long

  this.lineLength = 0;
}
/**
 * Method to start the transcription process. It will tell the audioRecorder
 * to start storing all audio streams and record the start time for merging
 * purposes
 */


Transcriber.prototype.start = function start() {
  if (this.state !== BEFORE_STATE) {
    throw new Error(`The transcription can only start when it's in the "${BEFORE_STATE}" state. It's currently in the "${this.state}" state`);
  }

  this.state = RECORDING_STATE;
  this.audioRecorder.start();
  this.startTime = new Date();
};
/**
 * Method to stop the transcription process. It will tell the audioRecorder to
 * stop, and get all the recorded audio to send it to the transcription service

 * @param callback a callback which will receive the transcription
 */


Transcriber.prototype.stop = function stop(callback) {
  if (this.state !== RECORDING_STATE) {
    throw new Error(`The transcription can only stop when it's in the "${RECORDING_STATE}" state. It's currently in the "${this.state}" state`);
  } // stop the recording


  console.log('stopping recording and sending audio files');
  this.audioRecorder.stop(); // and send all recorded audio the the transcription service

  const callBack = blobCallBack.bind(null, this);
  this.audioRecorder.getRecordingResults().forEach(recordingResult => {
    this.transcriptionService.send(recordingResult, callBack);
    this.counter++;
  }); // set the state to "transcribing" so that maybeMerge() functions correctly

  this.state = TRANSCRIBING_STATE; // and store the callback for later

  this.callback = callback;
};
/**
 * This method gets the answer from the transcription service, calculates the
 * offset and adds is to every Word object. It will also start the merging
 * when every send request has been received
 *
 * note: Make sure to bind this as a Transcription object
 * @param {Transcriber} transcriber the transcriber instance
 * @param {RecordingResult} answer a RecordingResult object with a defined
 * WordArray
 */


function blobCallBack(transcriber, answer) {
  console.log('retrieved an answer from the transcription service. The answer has an' + ` array of length: ${answer.wordArray.length}`); // first add the offset between the start of the transcription and
  // the start of the recording to all start and end times

  if (answer.wordArray.length > 0) {
    let offset = answer.startTime.getUTCMilliseconds() - transcriber.startTime.getUTCMilliseconds(); // transcriber time will always be earlier

    if (offset < 0) {
      offset = 0; // presume 0 if it somehow not earlier
    }

    let array = '[';
    answer.wordArray.forEach(wordObject => {
      wordObject.begin += offset;
      wordObject.end += offset;
      array += `${wordObject.word},`;
    });
    array += ']';
    console.log(array); // give a name value to the Array object so that the merging can access
    // the name value without having to use the whole recordingResult object
    // in the algorithm

    answer.wordArray.name = answer.name;
  } // then store the array and decrease the counter


  transcriber.results.push(answer.wordArray);
  transcriber.counter--;
  console.log(`current counter: ${transcriber.counter}`); // and check if all results have been received.

  transcriber.maybeMerge();
}
/**
 * this method will check if the counter is zero. If it is, it will call
 * the merging method
 */


Transcriber.prototype.maybeMerge = function () {
  if (this.state === TRANSCRIBING_STATE && this.counter === 0) {
    // make sure to include the events in the result arrays before
    // merging starts
    this.merge();
  }
};
/**
 * This method will merge all speech-to-text arrays together in one
 * readable transcription string
 */


Transcriber.prototype.merge = function () {
  console.log(`starting merge process!\n The length of the array: ${this.results.length}`);
  this.transcription = ''; // the merging algorithm will look over all Word objects who are at pos 0 in
  // every array. It will then select the one closest in time to the
  // previously placed word, while removing the selected word from its array
  // note: words can be skipped the skipped word's begin and end time somehow
  // end up between the closest word start and end time

  const arrays = this.results; // arrays of Word objects

  const potentialWords = []; // array of the first Word objects
  // check if any arrays are already empty and remove them

  hasPopulatedArrays(arrays); // populate all the potential Words for a first time

  arrays.forEach(array => pushWordToSortedArray(potentialWords, array)); // keep adding words to transcription until all arrays are exhausted

  while (hasPopulatedArrays(arrays)) {
    // first select the lowest array;
    let lowestWordArray = arrays[0];
    arrays.forEach(wordArray => {
      if (wordArray[0].begin < lowestWordArray[0].begin) {
        lowestWordArray = wordArray;
      }
    }); // put the word in the transcription

    let wordToAdd = lowestWordArray.shift();
    this.updateTranscription(wordToAdd, lowestWordArray.name); // keep going until a word in another array has a smaller time
    // or the array is empty

    while (lowestWordArray.length > 0) {
      let foundSmaller = false;
      const wordToCompare = lowestWordArray[0].begin;
      arrays.forEach(wordArray => {
        if (wordArray[0].begin < wordToCompare) {
          foundSmaller = true;
        }
      }); // add next word if no smaller time has been found

      if (foundSmaller) {
        break;
      }

      wordToAdd = lowestWordArray.shift();
      this.updateTranscription(wordToAdd, null);
    }
  } // set the state to finished and do the necessary left-over tasks


  this.state = FINISHED_STATE;

  if (this.callback) {
    this.callback(this.transcription);
  }
};
/**
 * Appends a word object to the transcription. It will make a new line with a
 * name if a name is specified
 * @param {Word} word the Word object holding the word to append
 * @param {String|null} name the name of a new speaker. Null if not applicable
 */


Transcriber.prototype.updateTranscription = function (word, name) {
  if (name !== undefined && name !== null) {
    this.transcription += `\n${name}:`;
    this.lineLength = name.length + 1; // +1 for the semi-colon
  }

  if (this.lineLength + word.word.length > MAXIMUM_SENTENCE_LENGTH) {
    this.transcription += '\n    ';
    this.lineLength = 4; // because of the 4 spaces after the new line
  }

  this.transcription += ` ${word.word}`;
  this.lineLength += word.word.length + 1; // +1 for the space
};
/**
 * Check if the given 2 dimensional array has any non-zero Word-arrays in them.
 * All zero-element arrays inside will be removed
 * If any non-zero-element arrays are found, the method will return true.
 * otherwise it will return false
 * @param {Array<Array>} twoDimensionalArray the array to check
 * @returns {boolean} true if any non-zero arrays inside, otherwise false
 */


function hasPopulatedArrays(twoDimensionalArray) {
  for (let i = 0; i < twoDimensionalArray.length; i++) {
    if (twoDimensionalArray[i].length === 0) {
      twoDimensionalArray.splice(i, 1);
    }
  }

  return twoDimensionalArray.length > 0;
}
/**
 * Push a word to the right location in a sorted array. The array is sorted
 * from lowest to highest start time. Every word is stored in an object which
 * includes the name of the person saying the word.
 *
 * @param {Array<Word>} array the sorted array to push to
 * @param {Word} word the word to push into the array
 */


function pushWordToSortedArray(array, word) {
  if (array.length === 0) {
    array.push(word);
  } else {
    if (array[array.length - 1].begin <= word.begin) {
      array.push(word);
      return;
    }

    for (let i = 0; i < array.length; i++) {
      if (word.begin < array[i].begin) {
        array.splice(i, 0, word);
        return;
      }
    }

    array.push(word); // fail safe
  }
}
/**
 * Gives the transcriber a JitsiTrack holding an audioStream to transcribe.
 * The JitsiTrack is given to the audioRecorder. If it doesn't hold an
 * audiostream, it will not be added by the audioRecorder
 * @param {JitsiTrack} track the track to give to the audioRecorder
 */


Transcriber.prototype.addTrack = function (track) {
  this.audioRecorder.addTrack(track);
};
/**
 * Remove the given track from the auioRecorder
 * @param track
 */


Transcriber.prototype.removeTrack = function (track) {
  this.audioRecorder.removeTrack(track);
};
/**
 * Will return the created transcription if it's avialable or throw an error
 * when it's not done yet
 * @returns {String} the transcription as a String
 */


Transcriber.prototype.getTranscription = function () {
  if (this.state !== FINISHED_STATE) {
    throw new Error(`The transcription can only be retrieved when it's in the "${FINISHED_STATE}" state. It's currently in the "${this.state}" state`);
  }

  return this.transcription;
};
/**
 * Returns the current state of the transcription process
 */


Transcriber.prototype.getState = function () {
  return this.state;
};
/**
 * Resets the state to the "before" state, such that it's again possible to
 * call the start method
 */


Transcriber.prototype.reset = function () {
  this.state = BEFORE_STATE;
  this.counter = null;
  this.transcription = null;
  this.startTime = null;
  this.callback = null;
  this.results = [];
  this.lineLength = 0;
};

module.exports = Transcriber;

/***/ }),

/***/ "./modules/transcription/transcriptionServices/AbstractTranscriptionService.js":
/*!*************************************************************************************!*\
  !*** ./modules/transcription/transcriptionServices/AbstractTranscriptionService.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * Abstract class representing an interface to implement a speech-to-text
 * service on.
 */
const TranscriptionService = function () {
  throw new Error('TranscriptionService is abstract and cannot be' + 'created');
};
/**
 * This method can be used to send the recorder audio stream and
 * retrieve the answer from the transcription service from the callback
 *
 * @param {RecordingResult} recordingResult a recordingResult object which
 * includes the recorded audio stream as a blob
 * @param {Function} callback  which will retrieve the a RecordingResult with
 *        the answer as a WordArray
 */


TranscriptionService.prototype.send = function send(recordingResult, callback) {
  this.sendRequest(recordingResult.blob, response => {
    if (this.verify(response)) {
      recordingResult.wordArray = this.formatResponse(response);
    } else {
      console.log('the retrieved response from the server is not valid!');
      recordingResult.wordArray = [];
    }

    callback(recordingResult);
  });
};
/**
 * Abstract method which will rend the recorder audio stream to the implemented
 * transcription service and will retrieve an answer, which will be
 * called on the given callback method
 *
 * @param {Blob} audioBlob the recorded audio stream as a single Blob
 * @param {function} callback function which will retrieve the answer
 *                            from the service
 */
// eslint-disable-next-line no-unused-vars


TranscriptionService.prototype.sendRequest = function (audioBlob, callback) {
  throw new Error('TranscriptionService.sendRequest is abstract');
};
/**
 * Abstract method which will parse the output from the implemented
 * transcription service to the expected format
 *
 * The transcriber class expect an array of word objects, where each word
 * object is one transcribed word by the service.
 *
 * The expected output of this method is an array of word objects, in
 * the correct order. That is, the first object in the array is the first word
 * being said, and the last word in the array is the last word being said
 *
 * @param response the answer from the speech-to-text server which needs to be
 *                 formatted
 * @return {Array<Word>} an array of Word objects
 */
// eslint-disable-next-line no-unused-vars


TranscriptionService.prototype.formatResponse = function (response) {
  throw new Error('TranscriptionService.format is abstract');
};
/**
 * Abstract method which will verify that the response from the server is valid
 *
 * @param response the response from the server
 * @return {boolean} true if response is valid, false otherwise
 */
// eslint-disable-next-line no-unused-vars


TranscriptionService.prototype.verify = function (response) {
  throw new Error('TranscriptionService.verify is abstract');
};

module.exports = TranscriptionService;

/***/ }),

/***/ "./modules/transcription/transcriptionServices/SphinxTranscriptionService.js":
/*!***********************************************************************************!*\
  !*** ./modules/transcription/transcriptionServices/SphinxTranscriptionService.js ***!
  \***********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* global config */
const TranscriptionService = __webpack_require__(/*! ./AbstractTranscriptionService */ "./modules/transcription/transcriptionServices/AbstractTranscriptionService.js");

const Word = __webpack_require__(/*! ../word */ "./modules/transcription/word.js");

const audioRecorder = __webpack_require__(/*! ./../audioRecorder */ "./modules/transcription/audioRecorder.js");
/**
 * Implements a TranscriptionService for a Sphinx4 http server
 */


const SphinxService = function () {
  // set the correct url
  this.url = getURL();
};
/**
 * Subclass of AbstractTranscriptionService
 */


SphinxService.prototype = Object.create(TranscriptionService.prototype);
/**
 * Set the right constructor
 */

SphinxService.constructor = SphinxService;
/**
 * Overrides the sendRequest method from AbstractTranscriptionService
 * it will send the audio stream the a Sphinx4 server to get the transcription
 *
 * @param audioFileBlob the recorder audio stream an a single Blob
 * @param callback the callback function retrieving the server response
 */

SphinxService.prototype.sendRequest = function (audioFileBlob, callback) {
  console.log(`sending an audio file  to ${this.url}`);
  console.log(`the audio file being sent: ${audioFileBlob}`);
  const request = new XMLHttpRequest();

  request.onreadystatechange = function () {
    if (request.readyState === XMLHttpRequest.DONE && request.status === 200) {
      callback(request.responseText);
    } else if (request.readyState === XMLHttpRequest.DONE) {
      throw new Error(`unable to accept response from sphinx server. status: ${request.status}`);
    } // if not ready no point to throw an error

  };

  request.open('POST', this.url);
  request.setRequestHeader('Content-Type', audioRecorder.determineCorrectFileType());
  request.send(audioFileBlob);
  console.log(`send ${audioFileBlob}`);
};
/**
 * Overrides the formatResponse method from AbstractTranscriptionService
 * It will parse the answer from the server in the expected format
 *
 * @param response the JSON body retrieved from the Sphinx4 server
 */


SphinxService.prototype.formatResponse = function (response) {
  const result = JSON.parse(response).objects; // make sure to delete the session id object, which is always
  // the first value in the JSON array

  result.shift();
  const array = [];
  result.forEach(word => word.filler || array.push(new Word(word.word, word.start, word.end)));
  return array;
};
/**
 * checks wether the reply is empty, or doesn't contain a correct JSON object
 * @param response the server response
 * @return {boolean} whether the response is valid
 */


SphinxService.prototype.verify = function (response) {
  console.log(`response from server:${response.toString()}`); // test if server responded with a string object

  if (typeof response !== 'string') {
    return false;
  } // test if the string can be parsed into valid JSON


  let json;

  try {
    json = JSON.parse(response);
  } catch (error) {
    console.log(error);
    return false;
  } // check if the JSON has a "objects" value


  if (json.objects === undefined) {
    return false;
  } // get the "objects" value and check for a session ID


  const array = json.objects;

  if (!(array[0] && array[0]['session-id'])) {
    return false;
  } // everything seems to be in order


  return true;
};
/**
 * Gets the URL to the Sphinx4 server from the config file. If it's not there,
 * it will throw an error
 *
 * @returns {string} the URL to the sphinx4 server
 */


function getURL() {
  const message = 'config does not contain an url to a Sphinx4 https server';

  if (config.sphinxURL === undefined) {
    console.log(message);
  } else {
    const toReturn = config.sphinxURL;

    if (toReturn.includes !== undefined && toReturn.includes('https://')) {
      return toReturn;
    }

    console.log(message);
  }
}

module.exports = SphinxService;

/***/ }),

/***/ "./modules/transcription/word.js":
/*!***************************************!*\
  !*** ./modules/transcription/word.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * An object representing a transcribed word, with some additional information
 * @param word the word
 * @param begin the time the word was started being uttered
 * @param end the time the word stopped being uttered
 */
const Word = function (word, begin, end) {
  this.word = word;
  this.begin = begin;
  this.end = end;
};
/**
 * Get the string representation of the word
 * @returns {*} the word as a string
 */


Word.prototype.getWord = function () {
  return this.word;
};
/**
 * Get the time the word started being uttered
 * @returns {*} the start time as an integer
 */


Word.prototype.getBeginTime = function () {
  return this.begin;
};
/**
 * Get the time the word stopped being uttered
 * @returns {*} the end time as an integer
 */


Word.prototype.getEndTime = function () {
  return this.end;
};

module.exports = Word;

/***/ }),

/***/ "./modules/util/AsyncQueue.js":
/*!************************************!*\
  !*** ./modules/util/AsyncQueue.js ***!
  \************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return AsyncQueue; });
/* harmony import */ var async__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! async */ "./node_modules/async/lib/async.js");
/* harmony import */ var async__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(async__WEBPACK_IMPORTED_MODULE_0__);

/**
 * A queue for async task execution.
 */

class AsyncQueue {
  /**
   * Creates new instance.
   */
  constructor() {
    this._queue = async__WEBPACK_IMPORTED_MODULE_0___default.a.queue(this._processQueueTasks.bind(this), 1);
    this._stopped = false;
  }
  /**
   * Removes any pending tasks from the queue.
   */


  clear() {
    this._queue.kill();
  }
  /**
   * Internal task processing implementation which makes things work.
   */


  _processQueueTasks(task, finishedCallback) {
    task(finishedCallback);
  }
  /**
   * The 'task' function will be given a callback it MUST call with either:
   *  1) No arguments if it was successful or
   *  2) An error argument if there was an error
   * If the task wants to process the success or failure of the task, it
   * should pass the {@code callback} to the push function, e.g.:
   * queue.push(task, (err) => {
   *     if (err) {
   *         // error handling
   *     } else {
   *         // success handling
   *     }
   * });
   *
   * @param {function} task - The task to be executed. See the description above.
   * @param {function} [callback] - Optional callback to be called after the task has been executed.
   */


  push(task, callback) {
    if (this._stopped) {
      callback && callback(new Error('The queue has been stopped'));
      return;
    }

    this._queue.push(task, callback);
  }
  /**
   * Shutdowns the queue. All already queued tasks will execute, but no future tasks can be added. If a task is added
   * after the queue has been shutdown then the callback will be called with an error.
   */


  shutdown() {
    this._stopped = true;
  }

}

/***/ }),

/***/ "./modules/util/AuthUtil.js":
/*!**********************************!*\
  !*** ./modules/util/AuthUtil.js ***!
  \**********************************/
/*! no static exports found */
/***/ (function(module, exports) {

const AuthUtil = {
  /**
   * Creates the URL pointing to JWT token authentication service. It is
   * formatted from the 'urlPattern' argument which can contain the following
   * constants:
   * '{room}' - name of the conference room passed as <tt>roomName</tt>
   * argument to this method.
   * '{roleUpgrade}' - will contain 'true' if the URL will be used for
   * the role upgrade scenario, where user connects from anonymous domain and
   * then gets upgraded to the moderator by logging-in from the popup window.
   *
   * @param urlPattern a URL pattern pointing to the login service
   * @param roomName the name of the conference room for which the user will
   * be authenticated
   * @param {bool} roleUpgrade <tt>true</tt> if the URL will be used for role
   * upgrade scenario, where the user logs-in from the popup window in order
   * to have the moderator rights granted
   *
   * @returns {string|null} the URL pointing to JWT login service or
   * <tt>null</tt> if 'urlPattern' is not a string and the URL can not be
   * constructed.
   */
  getTokenAuthUrl(urlPattern, roomName, roleUpgrade) {
    const url = urlPattern;

    if (typeof url !== 'string') {
      return null;
    }

    return url.replace('{room}', roomName).replace('{roleUpgrade}', roleUpgrade === true);
  }

};
module.exports = AuthUtil;

/***/ }),

/***/ "./modules/util/EventEmitterForwarder.js":
/*!***********************************************!*\
  !*** ./modules/util/EventEmitterForwarder.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * Implements utility to forward events from one eventEmitter to another.
 * @param src {object} instance of EventEmitter or another class that implements
 * addListener method which will register listener to EventEmitter instance.
 * @param dest {object} instance of EventEmitter or another class that
 * implements emit method which will emit an event.
 */
function EventEmitterForwarder(src, dest) {
  if (!src || !dest || typeof src.addListener !== 'function' || typeof dest.emit !== 'function') {
    throw new Error('Invalid arguments passed to EventEmitterForwarder');
  }

  this.src = src;
  this.dest = dest;
}
/**
 * Adds event to be forwarded from src to dest.
 * @param srcEvent {string} the event that EventEmitterForwarder is listening
 * for.
 * @param dstEvent {string} the event that will be fired from dest.
 * @param arguments all other passed arguments are going to be fired with
 * dstEvent.
 */


EventEmitterForwarder.prototype.forward = function (...args) {
  const srcEvent = args[0]; // This will be the "this" value for emit function.

  args[0] = this.dest; // Using bind.apply to pass the arguments as Array-like object ("arguments")

  this.src.addListener(srcEvent, Function.prototype.bind.apply(this.dest.emit, args));
};

module.exports = EventEmitterForwarder;

/***/ }),

/***/ "./modules/util/GlobalOnErrorHandler.js":
/*!**********************************************!*\
  !*** ./modules/util/GlobalOnErrorHandler.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * This utility class defines custom onerror and onunhandledrejection functions.
 * The custom error handlers respect the previously-defined error handlers.
 * GlobalOnErrorHandler class provides utilities to add many custom error
 * handlers and to execute the error handlers directly.
 */

/**
 * List with global error handlers that will be executed.
 */
const handlers = []; // If an old handler exists, also fire its events.

const oldOnErrorHandler = window.onerror;
/**
 * Custom error handler that calls the old global error handler and executes
 * all handlers that were previously added.
 */

function JitsiGlobalErrorHandler(...args) {
  handlers.forEach(handler => handler(...args));
  oldOnErrorHandler && oldOnErrorHandler(...args);
} // If an old handler exists, also fire its events.


const oldOnUnhandledRejection = window.onunhandledrejection;
/**
 * Custom handler that calls the old global handler and executes all handlers
 * that were previously added. This handler handles rejected Promises.
 */

function JitsiGlobalUnhandledRejection(event) {
  handlers.forEach(handler => handler(null, null, null, null, event.reason));
  oldOnUnhandledRejection && oldOnUnhandledRejection(event);
} // Setting the custom error handlers.


window.onerror = JitsiGlobalErrorHandler;
window.onunhandledrejection = JitsiGlobalUnhandledRejection;
const GlobalOnErrorHandler = {
  /**
   * Adds new error handlers.
   * @param handler the new handler.
   */
  addHandler(handler) {
    handlers.push(handler);
  },

  /**
   * Calls the global error handler if there is one.
   * @param error the error to pass to the error handler
   */
  callErrorHandler(error) {
    const errHandler = window.onerror;

    if (!errHandler) {
      return;
    }

    errHandler(null, null, null, null, error);
  },

  /**
   * Calls the global rejection handler if there is one.
   * @param error the error to pass to the rejection handler.
   */
  callUnhandledRejectionHandler(error) {
    const errHandler = window.onunhandledrejection;

    if (!errHandler) {
      return;
    }

    errHandler(error);
  }

};
module.exports = GlobalOnErrorHandler;

/***/ }),

/***/ "./modules/util/Listenable.js":
/*!************************************!*\
  !*** ./modules/util/Listenable.js ***!
  \************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return Listenable; });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);

/**
 * The class implements basic event operations - add/remove listener.
 * NOTE: The purpose of the class is to be extended in order to add
 * this functionality to other classes.
 */

class Listenable {
  /**
   * Creates new instance.
   * @param {EventEmitter} eventEmitter
   * @constructor
   */
  constructor(eventEmitter = new events__WEBPACK_IMPORTED_MODULE_0___default.a()) {
    this.eventEmitter = eventEmitter; // aliases for addListener/removeListener

    this.addEventListener = this.on = this.addListener;
    this.removeEventListener = this.off = this.removeListener;
  }
  /**
   * Adds new listener.
   * @param {String} eventName the name of the event
   * @param {Function} listener the listener.
   * @returns {Function} - The unsubscribe function.
   */


  addListener(eventName, listener) {
    this.eventEmitter.addListener(eventName, listener);
    return () => this.removeEventListener(eventName, listener);
  }
  /**
   * Removes listener.
   * @param {String} eventName the name of the event that triggers the
   * listener
   * @param {Function} listener the listener.
   */


  removeListener(eventName, listener) {
    this.eventEmitter.removeListener(eventName, listener);
  }

}

/***/ }),

/***/ "./modules/util/MathUtil.js":
/*!**********************************!*\
  !*** ./modules/util/MathUtil.js ***!
  \**********************************/
/*! exports provided: safeCounterIncrement, calculateAverage, filterPositiveValues */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "safeCounterIncrement", function() { return safeCounterIncrement; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "calculateAverage", function() { return calculateAverage; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "filterPositiveValues", function() { return filterPositiveValues; });
/**
 * The method will increase the given number by 1. If the given counter is equal
 * or greater to {@link Number.MAX_SAFE_INTEGER} then it will be rolled back to
 * 1.
 * @param {number} number - An integer counter value to be incremented.
 * @return {number} the next counter value increased by 1 (see the description
 * above for exception).
 */
function safeCounterIncrement(number) {
  let nextValue = number;

  if (number >= Number.MAX_SAFE_INTEGER) {
    nextValue = 0;
  }

  return nextValue + 1;
}
/**
 * Calculates the average value of am Array of numbers.
 *
 * @param {Float32Array} valueArray - Array of numbers.
 * @returns {number} - Number array average.
 */

function calculateAverage(valueArray) {
  return valueArray.length > 0 ? valueArray.reduce((a, b) => a + b) / valueArray.length : 0;
}
/**
 * Returns only the positive values from an array of numbers.
 *
 * @param {Float32Array} valueArray - Array of vad scores.
 * @returns {Array} - Array of positive numbers.
 */

function filterPositiveValues(valueArray) {
  return valueArray.filter(value => value >= 0);
}

/***/ }),

/***/ "./modules/util/RandomUtil.js":
/*!************************************!*\
  !*** ./modules/util/RandomUtil.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * @const
 */
const ALPHANUM = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';
/**
 * Hexadecimal digits.
 * @const
 */

const HEX_DIGITS = '0123456789abcdef';
/**
 * Generates random int within the range [min, max]
 * @param min the minimum value for the generated number
 * @param max the maximum value for the generated number
 * @returns random int number
 */

function randomInt(min, max) {
  return Math.floor(Math.random() * (max - min + 1)) + min;
}
/**
 * Get random element from array or string.
 * @param {Array|string} arr source
 * @returns array element or string character
 */


function randomElement(arr) {
  return arr[randomInt(0, arr.length - 1)];
}
/**
 * Generate random alphanumeric string.
 * @param {number} length expected string length
 * @returns {string} random string of specified length
 */


function randomAlphanumStr(length) {
  let result = '';

  for (let i = 0; i < length; i += 1) {
    result += randomElement(ALPHANUM);
  }

  return result;
}
/**
 * Exported interface.
 */


const RandomUtil = {
  /**
   * Returns a random hex digit.
   * @returns {*}
   */
  randomHexDigit() {
    return randomElement(HEX_DIGITS);
  },

  /**
   * Returns a random string of hex digits with length 'len'.
   * @param len the length.
   */
  randomHexString(len) {
    let ret = '';

    while (len--) {
      // eslint-disable-line no-param-reassign
      ret += this.randomHexDigit();
    }

    return ret;
  },

  randomElement,
  randomAlphanumStr,
  randomInt
};
module.exports = RandomUtil;

/***/ }),

/***/ "./modules/util/Retry.js":
/*!*******************************!*\
  !*** ./modules/util/Retry.js ***!
  \*******************************/
/*! exports provided: getJitterDelay */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getJitterDelay", function() { return getJitterDelay; });
/**
* Gets next timeout using the full jitter pattern.
*
* NOTE that there are no checks for argument correctness, so either do the math or use defaults.
*
* @param {number} retry - The retry number.
* @param {number} minDelay - The minimal delay in milliseconds.
* @param {number} base - The exponent base.
* @returns {number} - The amount of waiting before trying another time given in milliseconds.
* @private
*/
function getJitterDelay(retry, minDelay = 500, base = 2) {
  return Math.floor(Math.random() * (Math.pow(base, retry) * 1000 - minDelay) + minDelay);
}

/***/ }),

/***/ "./modules/util/ScriptUtil.js":
/*!************************************!*\
  !*** ./modules/util/ScriptUtil.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

const currentExecutingScript = __webpack_require__(/*! current-executing-script */ "./node_modules/current-executing-script/dist/currentExecutingScript.js");
/* eslint-disable max-params */

/**
 * Implements utility functions which facilitate the dealing with scripts such
 * as the download and execution of a JavaScript file.
 */


const ScriptUtil = {
  /**
   * Loads a script from a specific source.
   *
   * @param src the source from the which the script is to be (down)loaded
   * @param async true to asynchronously load the script or false to
   * synchronously load the script
   * @param prepend true to schedule the loading of the script as soon as
   * possible or false to schedule the loading of the script at the end of the
   * scripts known at the time
   * @param relativeURL whether we need load the library from url relative
   * to the url that lib-jitsi-meet was loaded. Useful when sourcing the
   * library from different location than the app that is using it
   * @param loadCallback on load callback function
   * @param errorCallback callback to be called on error loading the script
   */
  loadScript(src, async, prepend, relativeURL, loadCallback, errorCallback) {
    const d = document;
    const tagName = 'script';
    const script = d.createElement(tagName);
    const referenceNode = d.getElementsByTagName(tagName)[0];
    script.async = async;

    if (relativeURL) {
      // finds the src url of the current loaded script
      // and use it as base of the src supplied argument
      const scriptEl = currentExecutingScript();

      if (scriptEl) {
        const scriptSrc = scriptEl.src;
        const baseScriptSrc = scriptSrc.substring(0, scriptSrc.lastIndexOf('/') + 1);

        if (scriptSrc && baseScriptSrc) {
          // eslint-disable-next-line no-param-reassign
          src = baseScriptSrc + src;
        }
      }
    }

    if (loadCallback) {
      script.onload = loadCallback;
    }

    if (errorCallback) {
      script.onerror = errorCallback;
    }

    script.src = src;

    if (prepend) {
      referenceNode.parentNode.insertBefore(script, referenceNode);
    } else {
      referenceNode.parentNode.appendChild(script);
    }
  }

};
/* eslint-enable max-params */

module.exports = ScriptUtil;

/***/ }),

/***/ "./modules/util/StringUtils.js":
/*!*************************************!*\
  !*** ./modules/util/StringUtils.js ***!
  \*************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * Implements a simple hash code for a string (see
 * https://en.wikipedia.org/wiki/Java_hashCode()).
 *
 * @param {string} The string to return a hash of.
 * @return {Number} the integer hash code of the string.
 */
function integerHash(string) {
  if (!string) {
    return 0;
  }

  let char,
      hash = 0,
      i;

  for (i = 0; i < string.length; i++) {
    char = string.charCodeAt(i);
    hash += char * Math.pow(31, string.length - 1 - i);
    hash = Math.abs(hash | 0); // eslint-disable-line no-bitwise
  }

  return hash;
}

module.exports = {
  integerHash
};

/***/ }),

/***/ "./modules/util/UsernameGenerator.js":
/*!*******************************************!*\
  !*** ./modules/util/UsernameGenerator.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

const RandomUtil = __webpack_require__(/*! ./RandomUtil */ "./modules/util/RandomUtil.js");
/**
 * from faker.js - Copyright (c) 2014-2015 Matthew Bergman & Marak Squires
 * MIT License
 * http://github.com/marak/faker.js/
 *
 * @const
 */


const names = ['Aaliyah', 'Aaron', 'Abagail', 'Abbey', 'Abbie', 'Abbigail', 'Abby', 'Abdiel', 'Abdul', 'Abdullah', 'Abe', 'Abel', 'Abelardo', 'Abigail', 'Abigale', 'Abigayle', 'Abner', 'Abraham', 'Ada', 'Adah', 'Adalberto', 'Adaline', 'Adam', 'Adan', 'Addie', 'Addison', 'Adela', 'Adelbert', 'Adele', 'Adelia', 'Adeline', 'Adell', 'Adella', 'Adelle', 'Aditya', 'Adolf', 'Adolfo', 'Adolph', 'Adolphus', 'Adonis', 'Adrain', 'Adrian', 'Adriana', 'Adrianna', 'Adriel', 'Adrien', 'Adrienne', 'Afton', 'Aglae', 'Agnes', 'Agustin', 'Agustina', 'Ahmad', 'Ahmed', 'Aida', 'Aidan', 'Aiden', 'Aileen', 'Aisha', 'Aiyana', 'Akeem', 'Al', 'Alaina', 'Alan', 'Alana', 'Alanis', 'Alanna', 'Alayna', 'Alba', 'Albert', 'Alberta', 'Albertha', 'Alberto', 'Albin', 'Albina', 'Alda', 'Alden', 'Alec', 'Aleen', 'Alejandra', 'Alejandrin', 'Alek', 'Alena', 'Alene', 'Alessandra', 'Alessandro', 'Alessia', 'Aletha', 'Alex', 'Alexa', 'Alexander', 'Alexandra', 'Alexandre', 'Alexandrea', 'Alexandria', 'Alexandrine', 'Alexandro', 'Alexane', 'Alexanne', 'Alexie', 'Alexis', 'Alexys', 'Alexzander', 'Alf', 'Alfonso', 'Alfonzo', 'Alford', 'Alfred', 'Alfreda', 'Alfredo', 'Ali', 'Alia', 'Alice', 'Alicia', 'Alisa', 'Alisha', 'Alison', 'Alivia', 'Aliya', 'Aliyah', 'Aliza', 'Alize', 'Allan', 'Allen', 'Allene', 'Allie', 'Allison', 'Ally', 'Alphonso', 'Alta', 'Althea', 'Alva', 'Alvah', 'Alvena', 'Alvera', 'Alverta', 'Alvina', 'Alvis', 'Alyce', 'Alycia', 'Alysa', 'Alysha', 'Alyson', 'Alysson', 'Amalia', 'Amanda', 'Amani', 'Amara', 'Amari', 'Amaya', 'Amber', 'Ambrose', 'Amelia', 'Amelie', 'Amely', 'America', 'Americo', 'Amie', 'Amina', 'Amir', 'Amira', 'Amiya', 'Amos', 'Amparo', 'Amy', 'Amya', 'Ana', 'Anabel', 'Anabelle', 'Anahi', 'Anais', 'Anastacio', 'Anastasia', 'Anderson', 'Andre', 'Andreane', 'Andreanne', 'Andres', 'Andrew', 'Andy', 'Angel', 'Angela', 'Angelica', 'Angelina', 'Angeline', 'Angelita', 'Angelo', 'Angie', 'Angus', 'Anibal', 'Anika', 'Anissa', 'Anita', 'Aniya', 'Aniyah', 'Anjali', 'Anna', 'Annabel', 'Annabell', 'Annabelle', 'Annalise', 'Annamae', 'Annamarie', 'Anne', 'Annetta', 'Annette', 'Annie', 'Ansel', 'Ansley', 'Anthony', 'Antoinette', 'Antone', 'Antonetta', 'Antonette', 'Antonia', 'Antonietta', 'Antonina', 'Antonio', 'Antwan', 'Antwon', 'Anya', 'April', 'Ara', 'Araceli', 'Aracely', 'Arch', 'Archibald', 'Ardella', 'Arden', 'Ardith', 'Arely', 'Ari', 'Ariane', 'Arianna', 'Aric', 'Ariel', 'Arielle', 'Arjun', 'Arlene', 'Arlie', 'Arlo', 'Armand', 'Armando', 'Armani', 'Arnaldo', 'Arne', 'Arno', 'Arnold', 'Arnoldo', 'Arnulfo', 'Aron', 'Art', 'Arthur', 'Arturo', 'Arvel', 'Arvid', 'Arvilla', 'Aryanna', 'Asa', 'Asha', 'Ashlee', 'Ashleigh', 'Ashley', 'Ashly', 'Ashlynn', 'Ashton', 'Ashtyn', 'Asia', 'Assunta', 'Astrid', 'Athena', 'Aubree', 'Aubrey', 'Audie', 'Audra', 'Audreanne', 'Audrey', 'August', 'Augusta', 'Augustine', 'Augustus', 'Aurelia', 'Aurelie', 'Aurelio', 'Aurore', 'Austen', 'Austin', 'Austyn', 'Autumn', 'Ava', 'Avery', 'Avis', 'Axel', 'Ayana', 'Ayden', 'Ayla', 'Aylin', 'Baby', 'Bailee', 'Bailey', 'Barbara', 'Barney', 'Baron', 'Barrett', 'Barry', 'Bart', 'Bartholome', 'Barton', 'Baylee', 'Beatrice', 'Beau', 'Beaulah', 'Bell', 'Bella', 'Belle', 'Ben', 'Benedict', 'Benjamin', 'Bennett', 'Bennie', 'Benny', 'Benton', 'Berenice', 'Bernadette', 'Bernadine', 'Bernard', 'Bernardo', 'Berneice', 'Bernhard', 'Bernice', 'Bernie', 'Berniece', 'Bernita', 'Berry', 'Bert', 'Berta', 'Bertha', 'Bertram', 'Bertrand', 'Beryl', 'Bessie', 'Beth', 'Bethany', 'Bethel', 'Betsy', 'Bette', 'Bettie', 'Betty', 'Bettye', 'Beulah', 'Beverly', 'Bianka', 'Bill', 'Billie', 'Billy', 'Birdie', 'Blair', 'Blaise', 'Blake', 'Blanca', 'Blanche', 'Blaze', 'Bo', 'Bobbie', 'Bobby', 'Bonita', 'Bonnie', 'Boris', 'Boyd', 'Brad', 'Braden', 'Bradford', 'Bradley', 'Bradly', 'Brady', 'Braeden', 'Brain', 'Brandi', 'Brando', 'Brandon', 'Brandt', 'Brandy', 'Brandyn', 'Brannon', 'Branson', 'Brant', 'Braulio', 'Braxton', 'Brayan', 'Breana', 'Breanna', 'Breanne', 'Brenda', 'Brendan', 'Brenden', 'Brendon', 'Brenna', 'Brennan', 'Brennon', 'Brent', 'Bret', 'Brett', 'Bria', 'Brian', 'Briana', 'Brianne', 'Brice', 'Bridget', 'Bridgette', 'Bridie', 'Brielle', 'Brigitte', 'Brionna', 'Brisa', 'Britney', 'Brittany', 'Brock', 'Broderick', 'Brody', 'Brook', 'Brooke', 'Brooklyn', 'Brooks', 'Brown', 'Bruce', 'Bryana', 'Bryce', 'Brycen', 'Bryon', 'Buck', 'Bud', 'Buddy', 'Buford', 'Bulah', 'Burdette', 'Burley', 'Burnice', 'Buster', 'Cade', 'Caden', 'Caesar', 'Caitlyn', 'Cale', 'Caleb', 'Caleigh', 'Cali', 'Calista', 'Callie', 'Camden', 'Cameron', 'Camila', 'Camilla', 'Camille', 'Camren', 'Camron', 'Camryn', 'Camylle', 'Candace', 'Candelario', 'Candice', 'Candida', 'Candido', 'Cara', 'Carey', 'Carissa', 'Carlee', 'Carleton', 'Carley', 'Carli', 'Carlie', 'Carlo', 'Carlos', 'Carlotta', 'Carmel', 'Carmela', 'Carmella', 'Carmelo', 'Carmen', 'Carmine', 'Carol', 'Carolanne', 'Carole', 'Carolina', 'Caroline', 'Carolyn', 'Carolyne', 'Carrie', 'Carroll', 'Carson', 'Carter', 'Cary', 'Casandra', 'Casey', 'Casimer', 'Casimir', 'Casper', 'Cassandra', 'Cassandre', 'Cassidy', 'Cassie', 'Catalina', 'Caterina', 'Catharine', 'Catherine', 'Cathrine', 'Cathryn', 'Cathy', 'Cayla', 'Ceasar', 'Cecelia', 'Cecil', 'Cecile', 'Cecilia', 'Cedrick', 'Celestine', 'Celestino', 'Celia', 'Celine', 'Cesar', 'Chad', 'Chadd', 'Chadrick', 'Chaim', 'Chance', 'Chandler', 'Chanel', 'Chanelle', 'Charity', 'Charlene', 'Charles', 'Charley', 'Charlie', 'Charlotte', 'Chase', 'Chasity', 'Chauncey', 'Chaya', 'Chaz', 'Chelsea', 'Chelsey', 'Chelsie', 'Chesley', 'Chester', 'Chet', 'Cheyanne', 'Cheyenne', 'Chloe', 'Chris', 'Christ', 'Christa', 'Christelle', 'Christian', 'Christiana', 'Christina', 'Christine', 'Christop', 'Christophe', 'Christopher', 'Christy', 'Chyna', 'Ciara', 'Cicero', 'Cielo', 'Cierra', 'Cindy', 'Citlalli', 'Clair', 'Claire', 'Clara', 'Clarabelle', 'Clare', 'Clarissa', 'Clark', 'Claud', 'Claude', 'Claudia', 'Claudie', 'Claudine', 'Clay', 'Clemens', 'Clement', 'Clementina', 'Clementine', 'Clemmie', 'Cleo', 'Cleora', 'Cleta', 'Cletus', 'Cleve', 'Cleveland', 'Clifford', 'Clifton', 'Clint', 'Clinton', 'Clotilde', 'Clovis', 'Cloyd', 'Clyde', 'Coby', 'Cody', 'Colby', 'Cole', 'Coleman', 'Colin', 'Colleen', 'Collin', 'Colt', 'Colten', 'Colton', 'Columbus', 'Concepcion', 'Conner', 'Connie', 'Connor', 'Conor', 'Conrad', 'Constance', 'Constantin', 'Consuelo', 'Cooper', 'Cora', 'Coralie', 'Corbin', 'Cordelia', 'Cordell', 'Cordia', 'Cordie', 'Corene', 'Corine', 'Cornelius', 'Cornell', 'Corrine', 'Cortez', 'Cortney', 'Cory', 'Coty', 'Courtney', 'Coy', 'Craig', 'Crawford', 'Creola', 'Cristal', 'Cristian', 'Cristina', 'Cristobal', 'Cristopher', 'Cruz', 'Crystal', 'Crystel', 'Cullen', 'Curt', 'Curtis', 'Cydney', 'Cynthia', 'Cyril', 'Cyrus', 'Dagmar', 'Dahlia', 'Daija', 'Daisha', 'Daisy', 'Dakota', 'Dale', 'Dallas', 'Dallin', 'Dalton', 'Damaris', 'Dameon', 'Damian', 'Damien', 'Damion', 'Damon', 'Dan', 'Dana', 'Dandre', 'Dane', 'D\'angelo', 'Dangelo', 'Danial', 'Daniela', 'Daniella', 'Danielle', 'Danika', 'Dannie', 'Danny', 'Dante', 'Danyka', 'Daphne', 'Daphnee', 'Daphney', 'Darby', 'Daren', 'Darian', 'Dariana', 'Darien', 'Dario', 'Darion', 'Darius', 'Darlene', 'Daron', 'Darrel', 'Darrell', 'Darren', 'Darrick', 'Darrin', 'Darrion', 'Darron', 'Darryl', 'Darwin', 'Daryl', 'Dashawn', 'Dasia', 'Dave', 'David', 'Davin', 'Davion', 'Davon', 'Davonte', 'Dawn', 'Dawson', 'Dax', 'Dayana', 'Dayna', 'Dayne', 'Dayton', 'Dean', 'Deangelo', 'Deanna', 'Deborah', 'Declan', 'Dedric', 'Dedrick', 'Dee', 'Deion', 'Deja', 'Dejah', 'Dejon', 'Dejuan', 'Delaney', 'Delbert', 'Delfina', 'Delia', 'Delilah', 'Dell', 'Della', 'Delmer', 'Delores', 'Delpha', 'Delphia', 'Delphine', 'Delta', 'Demarco', 'Demarcus', 'Demario', 'Demetris', 'Demetrius', 'Demond', 'Dena', 'Denis', 'Dennis', 'Deon', 'Deondre', 'Deontae', 'Deonte', 'Dereck', 'Derek', 'Derick', 'Deron', 'Derrick', 'Deshaun', 'Deshawn', 'Desiree', 'Desmond', 'Dessie', 'Destany', 'Destin', 'Destinee', 'Destiney', 'Destini', 'Destiny', 'Devan', 'Devante', 'Deven', 'Devin', 'Devon', 'Devonte', 'Devyn', 'Dewayne', 'Dewitt', 'Dexter', 'Diamond', 'Diana', 'Dianna', 'Diego', 'Dillan', 'Dillon', 'Dimitri', 'Dina', 'Dino', 'Dion', 'Dixie', 'Dock', 'Dolly', 'Dolores', 'Domenic', 'Domenica', 'Domenick', 'Domenico', 'Domingo', 'Dominic', 'Dominique', 'Don', 'Donald', 'Donato', 'Donavon', 'Donna', 'Donnell', 'Donnie', 'Donny', 'Dora', 'Dorcas', 'Dorian', 'Doris', 'Dorothea', 'Dorothy', 'Dorris', 'Dortha', 'Dorthy', 'Doug', 'Douglas', 'Dovie', 'Doyle', 'Drake', 'Drew', 'Duane', 'Dudley', 'Dulce', 'Duncan', 'Durward', 'Dustin', 'Dusty', 'Dwight', 'Dylan', 'Earl', 'Earlene', 'Earline', 'Earnest', 'Earnestine', 'Easter', 'Easton', 'Ebba', 'Ebony', 'Ed', 'Eda', 'Edd', 'Eddie', 'Eden', 'Edgar', 'Edgardo', 'Edison', 'Edmond', 'Edmund', 'Edna', 'Eduardo', 'Edward', 'Edwardo', 'Edwin', 'Edwina', 'Edyth', 'Edythe', 'Effie', 'Efrain', 'Efren', 'Eileen', 'Einar', 'Eino', 'Eladio', 'Elaina', 'Elbert', 'Elda', 'Eldon', 'Eldora', 'Eldred', 'Eldridge', 'Eleanora', 'Eleanore', 'Eleazar', 'Electa', 'Elena', 'Elenor', 'Elenora', 'Eleonore', 'Elfrieda', 'Eli', 'Elian', 'Eliane', 'Elias', 'Eliezer', 'Elijah', 'Elinor', 'Elinore', 'Elisa', 'Elisabeth', 'Elise', 'Eliseo', 'Elisha', 'Elissa', 'Eliza', 'Elizabeth', 'Ella', 'Ellen', 'Ellie', 'Elliot', 'Elliott', 'Ellis', 'Ellsworth', 'Elmer', 'Elmira', 'Elmo', 'Elmore', 'Elna', 'Elnora', 'Elody', 'Eloisa', 'Eloise', 'Elouise', 'Eloy', 'Elroy', 'Elsa', 'Else', 'Elsie', 'Elta', 'Elton', 'Elva', 'Elvera', 'Elvie', 'Elvis', 'Elwin', 'Elwyn', 'Elyse', 'Elyssa', 'Elza', 'Emanuel', 'Emelia', 'Emelie', 'Emely', 'Emerald', 'Emerson', 'Emery', 'Emie', 'Emil', 'Emile', 'Emilia', 'Emiliano', 'Emilie', 'Emilio', 'Emily', 'Emma', 'Emmalee', 'Emmanuel', 'Emmanuelle', 'Emmet', 'Emmett', 'Emmie', 'Emmitt', 'Emmy', 'Emory', 'Ena', 'Enid', 'Enoch', 'Enola', 'Enos', 'Enrico', 'Enrique', 'Ephraim', 'Era', 'Eriberto', 'Eric', 'Erica', 'Erich', 'Erick', 'Ericka', 'Erik', 'Erika', 'Erin', 'Erling', 'Erna', 'Ernest', 'Ernestina', 'Ernestine', 'Ernesto', 'Ernie', 'Ervin', 'Erwin', 'Eryn', 'Esmeralda', 'Esperanza', 'Esta', 'Esteban', 'Estefania', 'Estel', 'Estell', 'Estella', 'Estelle', 'Estevan', 'Esther', 'Estrella', 'Etha', 'Ethan', 'Ethel', 'Ethelyn', 'Ethyl', 'Ettie', 'Eudora', 'Eugene', 'Eugenia', 'Eula', 'Eulah', 'Eulalia', 'Euna', 'Eunice', 'Eusebio', 'Eva', 'Evalyn', 'Evan', 'Evangeline', 'Evans', 'Eve', 'Eveline', 'Evelyn', 'Everardo', 'Everett', 'Everette', 'Evert', 'Evie', 'Ewald', 'Ewell', 'Ezekiel', 'Ezequiel', 'Ezra', 'Fabian', 'Fabiola', 'Fae', 'Fannie', 'Fanny', 'Fatima', 'Faustino', 'Fausto', 'Favian', 'Fay', 'Faye', 'Federico', 'Felicia', 'Felicita', 'Felicity', 'Felipa', 'Felipe', 'Felix', 'Felton', 'Fermin', 'Fern', 'Fernando', 'Ferne', 'Fidel', 'Filiberto', 'Filomena', 'Finn', 'Fiona', 'Flavie', 'Flavio', 'Fleta', 'Fletcher', 'Flo', 'Florence', 'Florencio', 'Florian', 'Florida', 'Florine', 'Flossie', 'Floy', 'Floyd', 'Ford', 'Forest', 'Forrest', 'Foster', 'Frances', 'Francesca', 'Francesco', 'Francis', 'Francisca', 'Francisco', 'Franco', 'Frank', 'Frankie', 'Franz', 'Fred', 'Freda', 'Freddie', 'Freddy', 'Frederic', 'Frederick', 'Frederik', 'Frederique', 'Fredrick', 'Fredy', 'Freeda', 'Freeman', 'Freida', 'Frida', 'Frieda', 'Friedrich', 'Fritz', 'Furman', 'Gabe', 'Gabriel', 'Gabriella', 'Gabrielle', 'Gaetano', 'Gage', 'Gail', 'Gardner', 'Garett', 'Garfield', 'Garland', 'Garnet', 'Garnett', 'Garret', 'Garrett', 'Garrick', 'Garrison', 'Garry', 'Garth', 'Gaston', 'Gavin', 'Gay', 'Gayle', 'Gaylord', 'Gene', 'General', 'Genesis', 'Genevieve', 'Gennaro', 'Genoveva', 'Geo', 'Geoffrey', 'George', 'Georgette', 'Georgiana', 'Georgianna', 'Geovanni', 'Geovanny', 'Geovany', 'Gerald', 'Geraldine', 'Gerard', 'Gerardo', 'Gerda', 'Gerhard', 'Germaine', 'German', 'Gerry', 'Gerson', 'Gertrude', 'Gia', 'Gianni', 'Gideon', 'Gilbert', 'Gilberto', 'Gilda', 'Giles', 'Gillian', 'Gina', 'Gino', 'Giovani', 'Giovanna', 'Giovanni', 'Giovanny', 'Gisselle', 'Giuseppe', 'Gladyce', 'Gladys', 'Glen', 'Glenda', 'Glenna', 'Glennie', 'Gloria', 'Godfrey', 'Golda', 'Golden', 'Gonzalo', 'Gordon', 'Grace', 'Gracie', 'Graciela', 'Grady', 'Graham', 'Grant', 'Granville', 'Grayce', 'Grayson', 'Green', 'Greg', 'Gregg', 'Gregoria', 'Gregorio', 'Gregory', 'Greta', 'Gretchen', 'Greyson', 'Griffin', 'Grover', 'Guadalupe', 'Gudrun', 'Guido', 'Guillermo', 'Guiseppe', 'Gunnar', 'Gunner', 'Gus', 'Gussie', 'Gust', 'Gustave', 'Guy', 'Gwen', 'Gwendolyn', 'Hadley', 'Hailee', 'Hailey', 'Hailie', 'Hal', 'Haleigh', 'Haley', 'Halie', 'Halle', 'Hallie', 'Hank', 'Hanna', 'Hannah', 'Hans', 'Hardy', 'Harley', 'Harmon', 'Harmony', 'Harold', 'Harrison', 'Harry', 'Harvey', 'Haskell', 'Hassan', 'Hassie', 'Hattie', 'Haven', 'Hayden', 'Haylee', 'Hayley', 'Haylie', 'Hazel', 'Hazle', 'Heath', 'Heather', 'Heaven', 'Heber', 'Hector', 'Heidi', 'Helen', 'Helena', 'Helene', 'Helga', 'Hellen', 'Helmer', 'Heloise', 'Henderson', 'Henri', 'Henriette', 'Henry', 'Herbert', 'Herman', 'Hermann', 'Hermina', 'Herminia', 'Herminio', 'Hershel', 'Herta', 'Hertha', 'Hester', 'Hettie', 'Hilario', 'Hilbert', 'Hilda', 'Hildegard', 'Hillard', 'Hillary', 'Hilma', 'Hilton', 'Hipolito', 'Hiram', 'Hobart', 'Holden', 'Hollie', 'Hollis', 'Holly', 'Hope', 'Horace', 'Horacio', 'Hortense', 'Hosea', 'Houston', 'Howard', 'Howell', 'Hoyt', 'Hubert', 'Hudson', 'Hugh', 'Hulda', 'Humberto', 'Hunter', 'Hyman', 'Ian', 'Ibrahim', 'Icie', 'Ida', 'Idell', 'Idella', 'Ignacio', 'Ignatius', 'Ike', 'Ila', 'Ilene', 'Iliana', 'Ima', 'Imani', 'Imelda', 'Immanuel', 'Imogene', 'Ines', 'Irma', 'Irving', 'Irwin', 'Isaac', 'Isabel', 'Isabell', 'Isabella', 'Isabelle', 'Isac', 'Isadore', 'Isai', 'Isaiah', 'Isaias', 'Isidro', 'Ismael', 'Isobel', 'Isom', 'Israel', 'Issac', 'Itzel', 'Iva', 'Ivah', 'Ivory', 'Ivy', 'Izabella', 'Izaiah', 'Jabari', 'Jace', 'Jacey', 'Jacinthe', 'Jacinto', 'Jack', 'Jackeline', 'Jackie', 'Jacklyn', 'Jackson', 'Jacky', 'Jaclyn', 'Jacquelyn', 'Jacques', 'Jacynthe', 'Jada', 'Jade', 'Jaden', 'Jadon', 'Jadyn', 'Jaeden', 'Jaida', 'Jaiden', 'Jailyn', 'Jaime', 'Jairo', 'Jakayla', 'Jake', 'Jakob', 'Jaleel', 'Jalen', 'Jalon', 'Jalyn', 'Jamaal', 'Jamal', 'Jamar', 'Jamarcus', 'Jamel', 'Jameson', 'Jamey', 'Jamie', 'Jamil', 'Jamir', 'Jamison', 'Jammie', 'Jan', 'Jana', 'Janae', 'Jane', 'Janelle', 'Janessa', 'Janet', 'Janice', 'Janick', 'Janie', 'Janis', 'Janiya', 'Jannie', 'Jany', 'Jaquan', 'Jaquelin', 'Jaqueline', 'Jared', 'Jaren', 'Jarod', 'Jaron', 'Jarred', 'Jarrell', 'Jarret', 'Jarrett', 'Jarrod', 'Jarvis', 'Jasen', 'Jasmin', 'Jason', 'Jasper', 'Jaunita', 'Javier', 'Javon', 'Javonte', 'Jay', 'Jayce', 'Jaycee', 'Jayda', 'Jayde', 'Jayden', 'Jaydon', 'Jaylan', 'Jaylen', 'Jaylin', 'Jaylon', 'Jayme', 'Jayne', 'Jayson', 'Jazlyn', 'Jazmin', 'Jazmyn', 'Jazmyne', 'Jean', 'Jeanette', 'Jeanie', 'Jeanne', 'Jed', 'Jedediah', 'Jedidiah', 'Jeff', 'Jefferey', 'Jeffery', 'Jeffrey', 'Jeffry', 'Jena', 'Jenifer', 'Jennie', 'Jennifer', 'Jennings', 'Jennyfer', 'Jensen', 'Jerad', 'Jerald', 'Jeramie', 'Jeramy', 'Jerel', 'Jeremie', 'Jeremy', 'Jermain', 'Jermaine', 'Jermey', 'Jerod', 'Jerome', 'Jeromy', 'Jerrell', 'Jerrod', 'Jerrold', 'Jerry', 'Jess', 'Jesse', 'Jessica', 'Jessie', 'Jessika', 'Jessy', 'Jessyca', 'Jesus', 'Jett', 'Jettie', 'Jevon', 'Jewel', 'Jewell', 'Jillian', 'Jimmie', 'Jimmy', 'Jo', 'Joan', 'Joana', 'Joanie', 'Joanne', 'Joannie', 'Joanny', 'Joany', 'Joaquin', 'Jocelyn', 'Jodie', 'Jody', 'Joe', 'Joel', 'Joelle', 'Joesph', 'Joey', 'Johan', 'Johann', 'Johanna', 'Johathan', 'John', 'Johnathan', 'Johnathon', 'Johnnie', 'Johnny', 'Johnpaul', 'Johnson', 'Jolie', 'Jon', 'Jonas', 'Jonatan', 'Jonathan', 'Jonathon', 'Jordan', 'Jordane', 'Jordi', 'Jordon', 'Jordy', 'Jordyn', 'Jorge', 'Jose', 'Josefa', 'Josefina', 'Joseph', 'Josephine', 'Josh', 'Joshua', 'Joshuah', 'Josiah', 'Josiane', 'Josianne', 'Josie', 'Josue', 'Jovan', 'Jovani', 'Jovanny', 'Jovany', 'Joy', 'Joyce', 'Juana', 'Juanita', 'Judah', 'Judd', 'Jude', 'Judge', 'Judson', 'Judy', 'Jules', 'Julia', 'Julian', 'Juliana', 'Julianne', 'Julie', 'Julien', 'Juliet', 'Julio', 'Julius', 'June', 'Junior', 'Junius', 'Justen', 'Justice', 'Justina', 'Justine', 'Juston', 'Justus', 'Justyn', 'Juvenal', 'Juwan', 'Kacey', 'Kaci', 'Kacie', 'Kade', 'Kaden', 'Kadin', 'Kaela', 'Kaelyn', 'Kaia', 'Kailee', 'Kailey', 'Kailyn', 'Kaitlin', 'Kaitlyn', 'Kale', 'Kaleb', 'Kaleigh', 'Kaley', 'Kali', 'Kallie', 'Kameron', 'Kamille', 'Kamren', 'Kamron', 'Kamryn', 'Kane', 'Kara', 'Kareem', 'Karelle', 'Karen', 'Kari', 'Kariane', 'Karianne', 'Karina', 'Karine', 'Karl', 'Karlee', 'Karley', 'Karli', 'Karlie', 'Karolann', 'Karson', 'Kasandra', 'Kasey', 'Kassandra', 'Katarina', 'Katelin', 'Katelyn', 'Katelynn', 'Katharina', 'Katherine', 'Katheryn', 'Kathleen', 'Kathlyn', 'Kathryn', 'Kathryne', 'Katlyn', 'Katlynn', 'Katrina', 'Katrine', 'Kattie', 'Kavon', 'Kay', 'Kaya', 'Kaycee', 'Kayden', 'Kayla', 'Kaylah', 'Kaylee', 'Kayleigh', 'Kayley', 'Kayli', 'Kaylie', 'Kaylin', 'Keagan', 'Keanu', 'Keara', 'Keaton', 'Keegan', 'Keeley', 'Keely', 'Keenan', 'Keira', 'Keith', 'Kellen', 'Kelley', 'Kelli', 'Kellie', 'Kelly', 'Kelsi', 'Kelsie', 'Kelton', 'Kelvin', 'Ken', 'Kendall', 'Kendra', 'Kendrick', 'Kenna', 'Kennedi', 'Kennedy', 'Kenneth', 'Kennith', 'Kenny', 'Kenton', 'Kenya', 'Kenyatta', 'Kenyon', 'Keon', 'Keshaun', 'Keshawn', 'Keven', 'Kevin', 'Kevon', 'Keyon', 'Keyshawn', 'Khalid', 'Khalil', 'Kian', 'Kiana', 'Kianna', 'Kiara', 'Kiarra', 'Kiel', 'Kiera', 'Kieran', 'Kiley', 'Kim', 'Kimberly', 'King', 'Kip', 'Kira', 'Kirk', 'Kirsten', 'Kirstin', 'Kitty', 'Kobe', 'Koby', 'Kody', 'Kolby', 'Kole', 'Korbin', 'Korey', 'Kory', 'Kraig', 'Kris', 'Krista', 'Kristian', 'Kristin', 'Kristina', 'Kristofer', 'Kristoffer', 'Kristopher', 'Kristy', 'Krystal', 'Krystel', 'Krystina', 'Kurt', 'Kurtis', 'Kyla', 'Kyle', 'Kylee', 'Kyleigh', 'Kyler', 'Kylie', 'Kyra', 'Lacey', 'Lacy', 'Ladarius', 'Lafayette', 'Laila', 'Laisha', 'Lamar', 'Lambert', 'Lamont', 'Lance', 'Landen', 'Lane', 'Laney', 'Larissa', 'Laron', 'Larry', 'Larue', 'Laura', 'Laurel', 'Lauren', 'Laurence', 'Lauretta', 'Lauriane', 'Laurianne', 'Laurie', 'Laurine', 'Laury', 'Lauryn', 'Lavada', 'Lavern', 'Laverna', 'Laverne', 'Lavina', 'Lavinia', 'Lavon', 'Lavonne', 'Lawrence', 'Lawson', 'Layla', 'Layne', 'Lazaro', 'Lea', 'Leann', 'Leanna', 'Leanne', 'Leatha', 'Leda', 'Lee', 'Leif', 'Leila', 'Leilani', 'Lela', 'Lelah', 'Leland', 'Lelia', 'Lempi', 'Lemuel', 'Lenna', 'Lennie', 'Lenny', 'Lenora', 'Lenore', 'Leo', 'Leola', 'Leon', 'Leonard', 'Leonardo', 'Leone', 'Leonel', 'Leonie', 'Leonor', 'Leonora', 'Leopold', 'Leopoldo', 'Leora', 'Lera', 'Lesley', 'Leslie', 'Lesly', 'Lessie', 'Lester', 'Leta', 'Letha', 'Letitia', 'Levi', 'Lew', 'Lewis', 'Lexi', 'Lexie', 'Lexus', 'Lia', 'Liam', 'Liana', 'Libbie', 'Libby', 'Lila', 'Lilian', 'Liliana', 'Liliane', 'Lilla', 'Lillian', 'Lilliana', 'Lillie', 'Lilly', 'Lily', 'Lilyan', 'Lina', 'Lincoln', 'Linda', 'Lindsay', 'Lindsey', 'Linnea', 'Linnie', 'Linwood', 'Lionel', 'Lisa', 'Lisandro', 'Lisette', 'Litzy', 'Liza', 'Lizeth', 'Lizzie', 'Llewellyn', 'Lloyd', 'Logan', 'Lois', 'Lola', 'Lolita', 'Loma', 'Lon', 'London', 'Lonie', 'Lonnie', 'Lonny', 'Lonzo', 'Lora', 'Loraine', 'Loren', 'Lorena', 'Lorenz', 'Lorenza', 'Lorenzo', 'Lori', 'Lorine', 'Lorna', 'Lottie', 'Lou', 'Louie', 'Louisa', 'Lourdes', 'Louvenia', 'Lowell', 'Loy', 'Loyal', 'Loyce', 'Lucas', 'Luciano', 'Lucie', 'Lucienne', 'Lucile', 'Lucinda', 'Lucio', 'Lucious', 'Lucius', 'Lucy', 'Ludie', 'Ludwig', 'Lue', 'Luella', 'Luigi', 'Luis', 'Luisa', 'Lukas', 'Lula', 'Lulu', 'Luna', 'Lupe', 'Lura', 'Lurline', 'Luther', 'Luz', 'Lyda', 'Lydia', 'Lyla', 'Lynn', 'Lyric', 'Lysanne', 'Mabel', 'Mabelle', 'Mable', 'Mac', 'Macey', 'Maci', 'Macie', 'Mack', 'Mackenzie', 'Macy', 'Madaline', 'Madalyn', 'Maddison', 'Madeline', 'Madelyn', 'Madelynn', 'Madge', 'Madie', 'Madilyn', 'Madisen', 'Madison', 'Madisyn', 'Madonna', 'Madyson', 'Mae', 'Maegan', 'Maeve', 'Mafalda', 'Magali', 'Magdalen', 'Magdalena', 'Maggie', 'Magnolia', 'Magnus', 'Maia', 'Maida', 'Maiya', 'Major', 'Makayla', 'Makenna', 'Makenzie', 'Malachi', 'Malcolm', 'Malika', 'Malinda', 'Mallie', 'Mallory', 'Malvina', 'Mandy', 'Manley', 'Manuel', 'Manuela', 'Mara', 'Marc', 'Marcel', 'Marcelina', 'Marcelino', 'Marcella', 'Marcelle', 'Marcellus', 'Marcelo', 'Marcia', 'Marco', 'Marcos', 'Marcus', 'Margaret', 'Margarete', 'Margarett', 'Margaretta', 'Margarette', 'Margarita', 'Marge', 'Margie', 'Margot', 'Margret', 'Marguerite', 'Maria', 'Mariah', 'Mariam', 'Marian', 'Mariana', 'Mariane', 'Marianna', 'Marianne', 'Mariano', 'Maribel', 'Marie', 'Mariela', 'Marielle', 'Marietta', 'Marilie', 'Marilou', 'Marilyne', 'Marina', 'Mario', 'Marion', 'Marisa', 'Marisol', 'Maritza', 'Marjolaine', 'Marjorie', 'Marjory', 'Mark', 'Markus', 'Marlee', 'Marlen', 'Marlene', 'Marley', 'Marlin', 'Marlon', 'Marques', 'Marquis', 'Marquise', 'Marshall', 'Marta', 'Martin', 'Martina', 'Martine', 'Marty', 'Marvin', 'Mary', 'Maryam', 'Maryjane', 'Maryse', 'Mason', 'Mateo', 'Mathew', 'Mathias', 'Mathilde', 'Matilda', 'Matilde', 'Matt', 'Matteo', 'Mattie', 'Maud', 'Maude', 'Maudie', 'Maureen', 'Maurice', 'Mauricio', 'Maurine', 'Maverick', 'Mavis', 'Max', 'Maxie', 'Maxime', 'Maximilian', 'Maximillia', 'Maximillian', 'Maximo', 'Maximus', 'Maxine', 'Maxwell', 'May', 'Maya', 'Maybell', 'Maybelle', 'Maye', 'Maymie', 'Maynard', 'Mayra', 'Mazie', 'Mckayla', 'Mckenna', 'Mckenzie', 'Meagan', 'Meaghan', 'Meda', 'Megane', 'Meggie', 'Meghan', 'Mekhi', 'Melany', 'Melba', 'Melisa', 'Melissa', 'Mellie', 'Melody', 'Melvin', 'Melvina', 'Melyna', 'Melyssa', 'Mercedes', 'Meredith', 'Merl', 'Merle', 'Merlin', 'Merritt', 'Mertie', 'Mervin', 'Meta', 'Mia', 'Micaela', 'Micah', 'Michael', 'Michaela', 'Michale', 'Micheal', 'Michel', 'Michele', 'Michelle', 'Miguel', 'Mikayla', 'Mike', 'Mikel', 'Milan', 'Miles', 'Milford', 'Miller', 'Millie', 'Milo', 'Milton', 'Mina', 'Minerva', 'Minnie', 'Miracle', 'Mireille', 'Mireya', 'Misael', 'Missouri', 'Misty', 'Mitchel', 'Mitchell', 'Mittie', 'Modesta', 'Modesto', 'Mohamed', 'Mohammad', 'Mohammed', 'Moises', 'Mollie', 'Molly', 'Mona', 'Monica', 'Monique', 'Monroe', 'Monserrat', 'Monserrate', 'Montana', 'Monte', 'Monty', 'Morgan', 'Moriah', 'Morris', 'Mortimer', 'Morton', 'Mose', 'Moses', 'Moshe', 'Mossie', 'Mozell', 'Mozelle', 'Muhammad', 'Muriel', 'Murl', 'Murphy', 'Murray', 'Mustafa', 'Mya', 'Myah', 'Mylene', 'Myles', 'Myra', 'Myriam', 'Myrl', 'Myrna', 'Myron', 'Myrtice', 'Myrtie', 'Myrtis', 'Myrtle', 'Nadia', 'Nakia', 'Name', 'Nannie', 'Naomi', 'Naomie', 'Napoleon', 'Narciso', 'Nash', 'Nasir', 'Nat', 'Natalia', 'Natalie', 'Natasha', 'Nathan', 'Nathanael', 'Nathanial', 'Nathaniel', 'Nathen', 'Nayeli', 'Neal', 'Ned', 'Nedra', 'Neha', 'Neil', 'Nelda', 'Nella', 'Nelle', 'Nellie', 'Nels', 'Nelson', 'Neoma', 'Nestor', 'Nettie', 'Neva', 'Newell', 'Newton', 'Nia', 'Nicholas', 'Nicholaus', 'Nichole', 'Nick', 'Nicklaus', 'Nickolas', 'Nico', 'Nicola', 'Nicolas', 'Nicole', 'Nicolette', 'Nigel', 'Nikita', 'Nikki', 'Nikko', 'Niko', 'Nikolas', 'Nils', 'Nina', 'Noah', 'Noble', 'Noe', 'Noel', 'Noelia', 'Noemi', 'Noemie', 'Noemy', 'Nola', 'Nolan', 'Nona', 'Nora', 'Norbert', 'Norberto', 'Norene', 'Norma', 'Norris', 'Norval', 'Norwood', 'Nova', 'Novella', 'Nya', 'Nyah', 'Nyasia', 'Obie', 'Oceane', 'Ocie', 'Octavia', 'Oda', 'Odell', 'Odessa', 'Odie', 'Ofelia', 'Okey', 'Ola', 'Olaf', 'Ole', 'Olen', 'Oleta', 'Olga', 'Olin', 'Oliver', 'Ollie', 'Oma', 'Omari', 'Omer', 'Ona', 'Onie', 'Opal', 'Ophelia', 'Ora', 'Oral', 'Oran', 'Oren', 'Orie', 'Orin', 'Orion', 'Orland', 'Orlando', 'Orlo', 'Orpha', 'Orrin', 'Orval', 'Orville', 'Osbaldo', 'Osborne', 'Oscar', 'Osvaldo', 'Oswald', 'Oswaldo', 'Otha', 'Otho', 'Otilia', 'Otis', 'Ottilie', 'Ottis', 'Otto', 'Ova', 'Owen', 'Ozella', 'Pablo', 'Paige', 'Palma', 'Pamela', 'Pansy', 'Paolo', 'Paris', 'Parker', 'Pascale', 'Pasquale', 'Pat', 'Patience', 'Patricia', 'Patrick', 'Patsy', 'Pattie', 'Paul', 'Paula', 'Pauline', 'Paxton', 'Payton', 'Pearl', 'Pearlie', 'Pearline', 'Pedro', 'Peggie', 'Penelope', 'Percival', 'Percy', 'Perry', 'Pete', 'Peter', 'Petra', 'Peyton', 'Philip', 'Phoebe', 'Phyllis', 'Pierce', 'Pierre', 'Pietro', 'Pink', 'Pinkie', 'Piper', 'Polly', 'Porter', 'Precious', 'Presley', 'Preston', 'Price', 'Prince', 'Princess', 'Priscilla', 'Providenci', 'Prudence', 'Queen', 'Queenie', 'Quentin', 'Quincy', 'Quinn', 'Quinten', 'Quinton', 'Rachael', 'Rachel', 'Rachelle', 'Rae', 'Raegan', 'Rafael', 'Rafaela', 'Raheem', 'Rahsaan', 'Rahul', 'Raina', 'Raleigh', 'Ralph', 'Ramiro', 'Ramon', 'Ramona', 'Randal', 'Randall', 'Randi', 'Randy', 'Ransom', 'Raoul', 'Raphael', 'Raphaelle', 'Raquel', 'Rashad', 'Rashawn', 'Rasheed', 'Raul', 'Raven', 'Ray', 'Raymond', 'Raymundo', 'Reagan', 'Reanna', 'Reba', 'Rebeca', 'Rebecca', 'Rebeka', 'Rebekah', 'Reece', 'Reed', 'Reese', 'Regan', 'Reggie', 'Reginald', 'Reid', 'Reilly', 'Reina', 'Reinhold', 'Remington', 'Rene', 'Renee', 'Ressie', 'Reta', 'Retha', 'Retta', 'Reuben', 'Reva', 'Rex', 'Rey', 'Reyes', 'Reymundo', 'Reyna', 'Reynold', 'Rhea', 'Rhett', 'Rhianna', 'Rhiannon', 'Rhoda', 'Ricardo', 'Richard', 'Richie', 'Richmond', 'Rick', 'Rickey', 'Rickie', 'Ricky', 'Rico', 'Rigoberto', 'Riley', 'Rita', 'River', 'Robb', 'Robbie', 'Robert', 'Roberta', 'Roberto', 'Robin', 'Robyn', 'Rocio', 'Rocky', 'Rod', 'Roderick', 'Rodger', 'Rodolfo', 'Rodrick', 'Rodrigo', 'Roel', 'Rogelio', 'Roger', 'Rogers', 'Rolando', 'Rollin', 'Roma', 'Romaine', 'Roman', 'Ron', 'Ronaldo', 'Ronny', 'Roosevelt', 'Rory', 'Rosa', 'Rosalee', 'Rosalia', 'Rosalind', 'Rosalinda', 'Rosalyn', 'Rosamond', 'Rosanna', 'Rosario', 'Roscoe', 'Rose', 'Rosella', 'Roselyn', 'Rosemarie', 'Rosemary', 'Rosendo', 'Rosetta', 'Rosie', 'Rosina', 'Roslyn', 'Ross', 'Rossie', 'Rowan', 'Rowena', 'Rowland', 'Roxane', 'Roxanne', 'Roy', 'Royal', 'Royce', 'Rozella', 'Ruben', 'Rubie', 'Ruby', 'Rubye', 'Rudolph', 'Rudy', 'Rupert', 'Russ', 'Russel', 'Russell', 'Rusty', 'Ruth', 'Ruthe', 'Ruthie', 'Ryan', 'Ryann', 'Ryder', 'Rylan', 'Rylee', 'Ryleigh', 'Ryley', 'Sabina', 'Sabrina', 'Sabryna', 'Sadie', 'Sadye', 'Sage', 'Saige', 'Sallie', 'Sally', 'Salma', 'Salvador', 'Salvatore', 'Sam', 'Samanta', 'Samantha', 'Samara', 'Samir', 'Sammie', 'Sammy', 'Samson', 'Sandra', 'Sandrine', 'Sandy', 'Sanford', 'Santa', 'Santiago', 'Santina', 'Santino', 'Santos', 'Sarah', 'Sarai', 'Sarina', 'Sasha', 'Saul', 'Savanah', 'Savanna', 'Savannah', 'Savion', 'Scarlett', 'Schuyler', 'Scot', 'Scottie', 'Scotty', 'Seamus', 'Sean', 'Sebastian', 'Sedrick', 'Selena', 'Selina', 'Selmer', 'Serena', 'Serenity', 'Seth', 'Shad', 'Shaina', 'Shakira', 'Shana', 'Shane', 'Shanel', 'Shanelle', 'Shania', 'Shanie', 'Shaniya', 'Shanna', 'Shannon', 'Shanny', 'Shanon', 'Shany', 'Sharon', 'Shaun', 'Shawn', 'Shawna', 'Shaylee', 'Shayna', 'Shayne', 'Shea', 'Sheila', 'Sheldon', 'Shemar', 'Sheridan', 'Sherman', 'Sherwood', 'Shirley', 'Shyann', 'Shyanne', 'Sibyl', 'Sid', 'Sidney', 'Sienna', 'Sierra', 'Sigmund', 'Sigrid', 'Sigurd', 'Silas', 'Sim', 'Simeon', 'Simone', 'Sincere', 'Sister', 'Skye', 'Skyla', 'Skylar', 'Sofia', 'Soledad', 'Solon', 'Sonia', 'Sonny', 'Sonya', 'Sophia', 'Sophie', 'Spencer', 'Stacey', 'Stacy', 'Stan', 'Stanford', 'Stanley', 'Stanton', 'Stefan', 'Stefanie', 'Stella', 'Stephan', 'Stephania', 'Stephanie', 'Stephany', 'Stephen', 'Stephon', 'Sterling', 'Steve', 'Stevie', 'Stewart', 'Stone', 'Stuart', 'Summer', 'Sunny', 'Susan', 'Susana', 'Susanna', 'Susie', 'Suzanne', 'Sven', 'Syble', 'Sydnee', 'Sydney', 'Sydni', 'Sydnie', 'Sylvan', 'Sylvester', 'Sylvia', 'Tabitha', 'Tad', 'Talia', 'Talon', 'Tamara', 'Tamia', 'Tania', 'Tanner', 'Tanya', 'Tara', 'Taryn', 'Tate', 'Tatum', 'Tatyana', 'Taurean', 'Tavares', 'Taya', 'Taylor', 'Teagan', 'Ted', 'Telly', 'Terence', 'Teresa', 'Terrance', 'Terrell', 'Terrence', 'Terrill', 'Terry', 'Tess', 'Tessie', 'Tevin', 'Thad', 'Thaddeus', 'Thalia', 'Thea', 'Thelma', 'Theo', 'Theodora', 'Theodore', 'Theresa', 'Therese', 'Theresia', 'Theron', 'Thomas', 'Thora', 'Thurman', 'Tia', 'Tiana', 'Tianna', 'Tiara', 'Tierra', 'Tiffany', 'Tillman', 'Timmothy', 'Timmy', 'Timothy', 'Tina', 'Tito', 'Titus', 'Tobin', 'Toby', 'Tod', 'Tom', 'Tomas', 'Tomasa', 'Tommie', 'Toney', 'Toni', 'Tony', 'Torey', 'Torrance', 'Torrey', 'Toy', 'Trace', 'Tracey', 'Tracy', 'Travis', 'Travon', 'Tre', 'Tremaine', 'Tremayne', 'Trent', 'Trenton', 'Tressa', 'Tressie', 'Treva', 'Trever', 'Trevion', 'Trevor', 'Trey', 'Trinity', 'Trisha', 'Tristian', 'Tristin', 'Triston', 'Troy', 'Trudie', 'Trycia', 'Trystan', 'Turner', 'Twila', 'Tyler', 'Tyra', 'Tyree', 'Tyreek', 'Tyrel', 'Tyrell', 'Tyrese', 'Tyrique', 'Tyshawn', 'Tyson', 'Ubaldo', 'Ulices', 'Ulises', 'Una', 'Unique', 'Urban', 'Uriah', 'Uriel', 'Ursula', 'Vada', 'Valentin', 'Valentina', 'Valentine', 'Valerie', 'Vallie', 'Van', 'Vance', 'Vanessa', 'Vaughn', 'Veda', 'Velda', 'Vella', 'Velma', 'Velva', 'Vena', 'Verda', 'Verdie', 'Vergie', 'Verla', 'Verlie', 'Vern', 'Verna', 'Verner', 'Vernice', 'Vernie', 'Vernon', 'Verona', 'Veronica', 'Vesta', 'Vicenta', 'Vicente', 'Vickie', 'Vicky', 'Victor', 'Victoria', 'Vida', 'Vidal', 'Vilma', 'Vince', 'Vincent', 'Vincenza', 'Vincenzo', 'Vinnie', 'Viola', 'Violet', 'Violette', 'Virgie', 'Virgil', 'Virginia', 'Virginie', 'Vita', 'Vito', 'Viva', 'Vivian', 'Viviane', 'Vivianne', 'Vivien', 'Vivienne', 'Vladimir', 'Wade', 'Waino', 'Waldo', 'Walker', 'Wallace', 'Walter', 'Walton', 'Wanda', 'Ward', 'Warren', 'Watson', 'Wava', 'Waylon', 'Wayne', 'Webster', 'Weldon', 'Wellington', 'Wendell', 'Wendy', 'Werner', 'Westley', 'Weston', 'Whitney', 'Wilber', 'Wilbert', 'Wilburn', 'Wiley', 'Wilford', 'Wilfred', 'Wilfredo', 'Wilfrid', 'Wilhelm', 'Wilhelmine', 'Will', 'Willa', 'Willard', 'William', 'Willie', 'Willis', 'Willow', 'Willy', 'Wilma', 'Wilmer', 'Wilson', 'Wilton', 'Winfield', 'Winifred', 'Winnifred', 'Winona', 'Winston', 'Woodrow', 'Wyatt', 'Wyman', 'Xander', 'Xavier', 'Xzavier', 'Yadira', 'Yasmeen', 'Yasmin', 'Yasmine', 'Yazmin', 'Yesenia', 'Yessenia', 'Yolanda', 'Yoshiko', 'Yvette', 'Yvonne', 'Zachariah', 'Zachary', 'Zachery', 'Zack', 'Zackary', 'Zackery', 'Zakary', 'Zander', 'Zane', 'Zaria', 'Zechariah', 'Zelda', 'Zella', 'Zelma', 'Zena', 'Zetta', 'Zion', 'Zita', 'Zoe', 'Zoey', 'Zoie', 'Zoila', 'Zola', 'Zora', 'Zula'];
/**
 * Generate random username.
 * @returns {string} random username
 */

function generateUsername() {
  const name = RandomUtil.randomElement(names);
  const suffix = RandomUtil.randomAlphanumStr(3);
  return `${name}-${suffix}`;
}

module.exports = {
  generateUsername
};

/***/ }),

/***/ "./modules/version/ComponentsVersions.js":
/*!***********************************************!*\
  !*** ./modules/version/ComponentsVersions.js ***!
  \***********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return ComponentsVersions; });
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");


const logger = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js").getLogger(__filename);
/**
 * Creates new instance of <tt>ComponentsVersions</tt> which will be discovering
 * the versions of conferencing system components in given
 * <tt>JitsiConference</tt>.
 * @param conference <tt>JitsiConference</tt> instance which will be used to
 *        listen for focus presence updates.
 * @constructor
 */


function ComponentsVersions(conference) {
  this.versions = {};
  this.conference = conference;
  this.conference.addCommandListener('versions', this.processVersions.bind(this));
}

ComponentsVersions.prototype.processVersions = function (versions, mucResource, mucJid) {
  if (!this.conference._isFocus(mucJid)) {
    logger.warn(`Received versions not from the focus user: ${versions}`, mucJid);
    return;
  }

  const log = [];
  versions.children.forEach(component => {
    const name = component.attributes.name;
    const version = component.value;

    if (this.versions[name] !== version) {
      this.versions[name] = version;
      logger.info(`Got ${name} version: ${version}`);
      log.push({
        id: 'component_version',
        component: name,
        version
      });
    }
  }); // logs versions to stats

  if (log.length > 0) {
    _statistics_statistics__WEBPACK_IMPORTED_MODULE_0__["default"].sendLog(JSON.stringify(log));
  }
};
/**
 * Obtains the version of conferencing system component.
 * @param componentName the name of the component for which we want to obtain
 *        the version.
 * @returns {String} which describes the version of the component identified by
 *          given <tt>componentName</tt> or <tt>undefined</tt> if not found.
 */


ComponentsVersions.prototype.getComponentVersion = function (componentName) {
  return this.versions[componentName];
};
/* WEBPACK VAR INJECTION */}.call(this, "modules\\version\\ComponentsVersions.js"))

/***/ }),

/***/ "./modules/videosipgw/JitsiVideoSIPGWSession.js":
/*!******************************************************!*\
  !*** ./modules/videosipgw/JitsiVideoSIPGWSession.js ***!
  \******************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JitsiVideoSIPGWSession; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Listenable */ "./modules/util/Listenable.js");
/* harmony import */ var _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./VideoSIPGWConstants */ "./modules/videosipgw/VideoSIPGWConstants.js");




const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * The event name for current sip video session state changed.
 * @type {string} event name for sip video session state changed.
 */

const STATE_CHANGED = 'STATE_CHANGED';
/**
 * Jitsi video SIP GW session. Holding its state and able to start/stop it.
 * When session is in OFF or FAILED stated it cannot be used anymore.
 */

class JitsiVideoSIPGWSession extends _util_Listenable__WEBPACK_IMPORTED_MODULE_2__["default"] {
  /**
   * Creates new session with the desired sip address and display name.
   *
   * @param {string} sipAddress - The sip address to use when
   * starting the session.
   * @param {string} displayName - The display name to use for
   * that participant.
   * @param {ChatRoom} chatRoom - The chat room this session is bound to.
   */
  constructor(sipAddress, displayName, chatRoom) {
    super();
    this.sipAddress = sipAddress;
    this.displayName = displayName;
    this.chatRoom = chatRoom;
    /*
     * The initial state is undefined. Initial state cannot be STATE_OFF,
     * the session enters this state when it was in STATE_ON and was stopped
     * and such session cannot be used anymore.
     *
     * @type {VideoSIPGWConstants|undefined}
     */

    this.state = undefined;
  }
  /**
   * Stops the current session.
   */


  stop() {
    if (this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__["STATE_OFF"] || this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__["STATE_FAILED"]) {
      logger.warn('Video SIP GW session already stopped or failed!');
      return;
    }

    this._sendJibriIQ('stop');
  }
  /**
   * Starts a new session. Sends an iq to the focus.
   */


  start() {
    // if state is off, this session was active for some reason
    // and we should create new one, rather than reusing it
    if (this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__["STATE_ON"] || this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__["STATE_OFF"] || this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__["STATE_PENDING"] || this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__["STATE_RETRYING"]) {
      logger.warn('Video SIP GW session already started!');
      return;
    }

    this._sendJibriIQ('start');
  }
  /**
   * Changes the state of this session.
   *
   * @param {string} newState - The new {VideoSIPGWConstants} state to set.
   * @param {string} [optional] failureReason - The reason why a failure state
   * was entered.
   * @returns {void}
   */


  setState(newState, failureReason) {
    if (newState === this.state) {
      return;
    }

    const oldState = this.state;
    this.state = newState;
    this.eventEmitter.emit(STATE_CHANGED, {
      address: this.sipAddress,
      failureReason,
      oldState,
      newState: this.state,
      displayName: this.displayName
    });
  }
  /**
   * Subscribes the passed listener to the event for state change of this
   * session.
   *
   * @param {Function} listener - The function that will receive the event.
   */


  addStateListener(listener) {
    this.addListener(STATE_CHANGED, listener);
  }
  /**
   * Unsubscribes the passed handler.
   *
   * @param {Function} listener - The function to be removed.
   */


  removeStateListener(listener) {
    this.removeListener(STATE_CHANGED, listener);
  }
  /**
   * Sends a jibri command using an iq.
   *
   * @private
   * @param {string} action - The action to send ('start' or 'stop').
   */


  _sendJibriIQ(action) {
    const attributes = {
      'xmlns': 'http://jitsi.org/protocol/jibri',
      'action': action,
      sipaddress: this.sipAddress
    };
    attributes.displayname = this.displayName;
    const iq = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
      to: this.chatRoom.focusMucJid,
      type: 'set'
    }).c('jibri', attributes).up();
    logger.debug(`${action} video SIP GW session`, iq.nodeTree);
    this.chatRoom.connection.sendIQ(iq, () => {}, // eslint-disable-line no-empty-function
    error => {
      logger.error(`Failed to ${action} video SIP GW session, error: `, error);
      this.setState(_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__["STATE_FAILED"]);
    });
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\videosipgw\\JitsiVideoSIPGWSession.js"))

/***/ }),

/***/ "./modules/videosipgw/VideoSIPGW.js":
/*!******************************************!*\
  !*** ./modules/videosipgw/VideoSIPGW.js ***!
  \******************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return VideoSIPGW; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiVideoSIPGWSession__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./JitsiVideoSIPGWSession */ "./modules/videosipgw/JitsiVideoSIPGWSession.js");
/* harmony import */ var _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./VideoSIPGWConstants */ "./modules/videosipgw/VideoSIPGWConstants.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__);

const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);



/**
 * Main video SIP GW handler. Stores references of all created sessions.
 */

class VideoSIPGW {
  /**
   * Creates new handler.
   *
   * @param {ChatRoom} chatRoom - Tha chat room to handle.
   */
  constructor(chatRoom) {
    this.chatRoom = chatRoom;
    this.eventEmitter = chatRoom.eventEmitter;
    logger.debug('creating VideoSIPGW');
    this.sessions = {};
    this.sessionStateChangeListener = this.sessionStateChanged.bind(this); // VideoSIPGW, JitsiConference and ChatRoom are not reusable and no
    // more than one VideoSIPGW can be created per JitsiConference,
    // so we don't bother to cleanup

    chatRoom.addPresenceListener('jibri-sip-call-state', this.handleJibriSIPState.bind(this));
  }
  /**
   * Handles presence nodes with name: jibri-sip-call-state.
   *
   * @param {Object} node the presence node Object to handle.
   * Object representing part of the presence received over xmpp.
   */


  handleJibriSIPState(node) {
    const attributes = node.attributes;

    if (!attributes) {
      return;
    }

    logger.debug('Handle video sip gw state : ', attributes);
    const newState = attributes.state;

    if (newState === this.state) {
      return;
    }

    switch (newState) {
      case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_2__["STATE_ON"]:
      case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_2__["STATE_OFF"]:
      case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_2__["STATE_PENDING"]:
      case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_2__["STATE_RETRYING"]:
      case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_2__["STATE_FAILED"]:
        {
          const address = attributes.sipaddress;

          if (!address) {
            return;
          } // find the corresponding session and set its state


          const session = this.sessions[address];

          if (session) {
            session.setState(newState, attributes.failure_reason);
          } else {
            logger.warn('Video SIP GW session not found:', address);
          }
        }
    }
  }
  /**
   * Creates new session and stores its reference if it does not exist or
   * returns an error otherwise.
   *
   * @param {string} sipAddress - The sip address to use.
   * @param {string} displayName - The display name to use.
   * @returns {JitsiVideoSIPGWSession|Error}
   */


  createVideoSIPGWSession(sipAddress, displayName) {
    if (this.sessions[sipAddress]) {
      logger.warn('There was already a Video SIP GW session for address', sipAddress);
      return new Error(_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_2__["ERROR_SESSION_EXISTS"]);
    }

    const session = new _JitsiVideoSIPGWSession__WEBPACK_IMPORTED_MODULE_1__["default"](sipAddress, displayName, this.chatRoom);
    session.addStateListener(this.sessionStateChangeListener);
    this.sessions[sipAddress] = session;
    return session;
  }
  /**
   * Listener for session state changed. When a session goes to off or failed
   * we delete its reference.
   *
   * @param {options} event - { address, oldState, newState, displayName }
   */


  sessionStateChanged(event) {
    const address = event.address;

    if (event.newState === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_2__["STATE_OFF"] || event.newState === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_2__["STATE_FAILED"]) {
      const session = this.sessions[address];

      if (!session) {
        logger.error('Missing Video SIP GW session with address:', address);
        return;
      }

      session.removeStateListener(this.sessionStateChangeListener);
      delete this.sessions[address];
    }

    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default.a.VIDEO_SIP_GW_SESSION_STATE_CHANGED, event);
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\videosipgw\\VideoSIPGW.js"))

/***/ }),

/***/ "./modules/videosipgw/VideoSIPGWConstants.js":
/*!***************************************************!*\
  !*** ./modules/videosipgw/VideoSIPGWConstants.js ***!
  \***************************************************/
/*! exports provided: STATUS_AVAILABLE, STATUS_UNDEFINED, STATUS_BUSY, STATE_ON, STATE_OFF, STATE_PENDING, STATE_RETRYING, STATE_FAILED, ERROR_NO_CONNECTION, ERROR_SESSION_EXISTS */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STATUS_AVAILABLE", function() { return STATUS_AVAILABLE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STATUS_UNDEFINED", function() { return STATUS_UNDEFINED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STATUS_BUSY", function() { return STATUS_BUSY; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STATE_ON", function() { return STATE_ON; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STATE_OFF", function() { return STATE_OFF; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STATE_PENDING", function() { return STATE_PENDING; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STATE_RETRYING", function() { return STATE_RETRYING; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "STATE_FAILED", function() { return STATE_FAILED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ERROR_NO_CONNECTION", function() { return ERROR_NO_CONNECTION; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ERROR_SESSION_EXISTS", function() { return ERROR_SESSION_EXISTS; });
/**
 * Status that video SIP GW service is available.
 * @type {string}
 */
const STATUS_AVAILABLE = 'available';
/**
 * Status that video SIP GW service is not available.
 * @type {string}
 */

const STATUS_UNDEFINED = 'undefined';
/**
 * Status that video SIP GW service is available but there are no free nodes
 * at the moment to serve new requests.
 * @type {string}
 */

const STATUS_BUSY = 'busy';
/**
 * Video SIP GW session state, currently running.
 * @type {string}
 */

const STATE_ON = 'on';
/**
 * Video SIP GW session state, currently stopped and not running.
 * @type {string}
 */

const STATE_OFF = 'off';
/**
 * Video SIP GW session state, currently is starting.
 * @type {string}
 */

const STATE_PENDING = 'pending';
/**
 * Video SIP GW session state, has observed some issues and is retrying at the
 * moment.
 * @type {string}
 */

const STATE_RETRYING = 'retrying';
/**
 * Video SIP GW session state, tried to start but it failed.
 * @type {string}
 */

const STATE_FAILED = 'failed';
/**
 * Error on trying to create video SIP GW session in conference where
 * there is no room connection (hasn't joined or has left the room).
 * @type {string}
 */

const ERROR_NO_CONNECTION = 'error_no_connection';
/**
 * Error on trying to create video SIP GW session with address for which
 * there is an already created session.
 * @type {string}
 */

const ERROR_SESSION_EXISTS = 'error_session_already_exists';

/***/ }),

/***/ "./modules/webaudio/AudioMixer.js":
/*!****************************************!*\
  !*** ./modules/webaudio/AudioMixer.js ***!
  \****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return AudioMixer; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _WebAudioUtils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WebAudioUtils */ "./modules/webaudio/WebAudioUtils.js");
/* global
    __filename
*/


const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * The AudioMixer, as the name implies, mixes a number of MediaStreams containing audio tracks into a single
 * MediaStream.
 */

class AudioMixer {
  /**
   * Create AudioMixer instance.
   */
  constructor() {
    this._started = false;
    this._streamsToMix = [];
    this._streamMSSArray = [];
  }
  /**
   * Add audio MediaStream to be mixed, if the stream doesn't contain any audio tracks it will be ignored.
   *
   * @param {MediaStream} stream - MediaStream to be mixed.
   */


  addMediaStream(stream) {
    if (!stream.getAudioTracks()) {
      logger.warn('Added MediaStream doesn\'t contain audio tracks.');
    }

    this._streamsToMix.push(stream);
  }
  /**
   * At this point a WebAudio ChannelMergerNode is created and and the two associated MediaStreams are connected to
   * it; the resulting mixed MediaStream is returned.
   *
   * @returns {MediaStream} - MediaStream containing added streams mixed together, or null if no MediaStream
   * is added.
   */


  start() {
    // If the mixer was already started just return the existing mixed stream.
    if (this._started) {
      return this._mixedMSD.stream;
    }

    this._audioContext = Object(_WebAudioUtils__WEBPACK_IMPORTED_MODULE_1__["createAudioContext"])();

    if (!this._streamsToMix.length) {
      logger.warn('No MediaStream\'s added to AudioMixer, nothing will happen.');
      return null;
    }

    this._started = true;
    this._mixedMSD = this._audioContext.createMediaStreamDestination();

    for (const stream of this._streamsToMix) {
      const streamMSS = this._audioContext.createMediaStreamSource(stream);

      streamMSS.connect(this._mixedMSD); // Maintain a list of MediaStreamAudioSourceNode so we can disconnect them on reset.

      this._streamMSSArray.push(streamMSS);
    }

    return this._mixedMSD.stream;
  }
  /**
   * Disconnect MediaStreamAudioSourceNode and clear references.
   *
   * @returns {void}
   */


  reset() {
    this._started = false;
    this._streamsToMix = []; // Clean up created MediaStreamAudioSourceNode.

    for (const streamMSS of this._streamMSSArray) {
      streamMSS.disconnect();
    }

    this._streamMSSArray = [];

    if (this._audioContext) {
      this._audioContext = undefined;
    }
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\webaudio\\AudioMixer.js"))

/***/ }),

/***/ "./modules/webaudio/WebAudioUtils.js":
/*!*******************************************!*\
  !*** ./modules/webaudio/WebAudioUtils.js ***!
  \*******************************************/
/*! exports provided: createAudioContext */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createAudioContext", function() { return createAudioContext; });
/**
 * Adapter that creates AudioContext objects depending on the browser.
 *
 * @returns {AudioContext} - Return a new AudioContext or undefined if the browser does not support it.
 */
function createAudioContext(options) {
  const AudioContextImpl = window.AudioContext || window.webkitAudioContext;

  if (!AudioContextImpl) {
    return undefined;
  }

  return new AudioContextImpl(options);
}

/***/ }),

/***/ "./modules/xmpp/Caps.js":
/*!******************************!*\
  !*** ./modules/xmpp/Caps.js ***!
  \******************************/
/*! exports provided: ERROR_FEATURE_VERSION_MISMATCH, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ERROR_FEATURE_VERSION_MISMATCH", function() { return ERROR_FEATURE_VERSION_MISMATCH; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return Caps; });
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Listenable */ "./modules/util/Listenable.js");
/* global $ */
 // eslint-disable-line camelcase




const logger = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js").getLogger(__filename);
/**
 * The property
 */


const IDENTITY_PROPERTIES = ['category', 'type', 'lang', 'name'];
const IDENTITY_PROPERTIES_FOR_COMPARE = ['category', 'type', 'lang'];
const HASH = 'sha-1';
const ERROR_FEATURE_VERSION_MISMATCH = 'Feature version mismatch';
/**
 *
 * @param a
 * @param b
 */

function compareIdentities(a, b) {
  let res = 0;
  IDENTITY_PROPERTIES_FOR_COMPARE.some(key => (res = a[key] > b[key] && 1 || a[key] < b[key] && -1) !== 0);
  return res;
}
/**
 * Produces a sha-1 from provided identity and features values.
 *
 * @param {Array<Object>} identities - The identity objects.
 * @param {Array<string>} features - The features.
 * @returns {string}
 */


function generateSha(identities, features) {
  const sortedIdentities = identities.sort(compareIdentities).reduce((accumulatedValue, identity) => `${IDENTITY_PROPERTIES.reduce((tmp, key, idx) => tmp + (idx === 0 ? '' : '/') + (identity[key] ? identity[key] : ''), '')}<`, '');
  const sortedFeatures = features.sort().reduce((tmp, feature) => `${tmp + feature}<`, '');
  return Object(strophe_js__WEBPACK_IMPORTED_MODULE_0__["b64_sha1"])(sortedIdentities + sortedFeatures);
}
/**
 * Implements xep-0115 ( http://xmpp.org/extensions/xep-0115.html )
 */


class Caps extends _util_Listenable__WEBPACK_IMPORTED_MODULE_2__["default"] {
  /**
   * Constructs new Caps instance.
   * @param {Strophe.Connection} connection the strophe connection object
   * @param {String} node the value of the node attribute of the "c" xml node
   * that will be sent to the other participants
   */
  constructor(connection = {}, node = 'http://jitsi.org/jitsimeet') {
    super();
    this.node = node;
    this.disco = connection.disco;

    if (!this.disco) {
      throw new Error('Missing strophe-plugins ' + '(disco plugin is required)!');
    }

    this.versionToCapabilities = Object.create(null);
    this.jidToVersion = Object.create(null);
    this.version = '';
    this.rooms = new Set();
    const emuc = connection.emuc;
    emuc.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1___default.a.EMUC_ROOM_ADDED, room => this._addChatRoom(room));
    emuc.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1___default.a.EMUC_ROOM_REMOVED, room => this._removeChatRoom(room));
    Object.keys(emuc.rooms).forEach(jid => {
      this._addChatRoom(emuc.rooms[jid]);
    });
    strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].addNamespace('CAPS', 'http://jabber.org/protocol/caps');
    this.disco.addFeature(strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].NS.CAPS);
    connection.addHandler(this._handleCaps.bind(this), strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].NS.CAPS);
    this._onMucMemberLeft = this._removeJidToVersionEntry.bind(this);
  }
  /**
   * Adds new feature to the list of supported features for the local
   * participant
   * @param {String} feature the name of the feature.
   * @param {boolean} submit if true - new presence with updated "c" node
   * will be sent.
   */


  addFeature(feature, submit = false) {
    this.disco.addFeature(feature);

    this._generateVersion();

    if (submit) {
      this.submit();
    }
  }
  /**
   * Removes a feature from the list of supported features for the local
   * participant
   * @param {String} feature the name of the feature.
   * @param {boolean} submit if true - new presence with updated "c" node
   * will be sent.
   */


  removeFeature(feature, submit = false) {
    this.disco.removeFeature(feature);

    this._generateVersion();

    if (submit) {
      this.submit();
    }
  }
  /**
   * Sends new presence stanza for every room from the list of rooms.
   */


  submit() {
    this.rooms.forEach(room => room.sendPresence());
  }
  /**
   * Returns a set with the features for a participant.
   * @param {String} jid the jid of the participant
   * @param {int} timeout the timeout in ms for reply from the participant.
   * @returns {Promise<Set<String>, Error>}
   */


  getFeatures(jid, timeout = 5000) {
    const user = jid in this.jidToVersion ? this.jidToVersion[jid] : null;

    if (!user || !(user.version in this.versionToCapabilities)) {
      const node = user ? `${user.node}#${user.version}` : null;
      return this._getDiscoInfo(jid, node, timeout).then(({
        features,
        identities
      }) => {
        if (user) {
          const sha = generateSha(Array.from(identities), Array.from(features));
          const receivedNode = `${user.node}#${sha}`;

          if (receivedNode === node) {
            this.versionToCapabilities[receivedNode] = features;
            return features;
          } // Check once if it has been cached asynchronously.


          if (this.versionToCapabilities[receivedNode]) {
            return this.versionToCapabilities[receivedNode];
          }

          logger.error(`Expected node ${node} but received ${receivedNode}`);
          return Promise.reject(ERROR_FEATURE_VERSION_MISMATCH);
        }
      });
    }

    return Promise.resolve(this.versionToCapabilities[user.version]);
  }
  /**
   * Returns a set with the features for a host.
   * @param {String} jid the jid of the host
   * @param {int} timeout the timeout in ms for reply from the host.
   * @returns {Promise<Set<String>, Error>}
   */


  getFeaturesAndIdentities(jid, timeout = 5000) {
    return this._getDiscoInfo(jid, null, timeout);
  }
  /**
   * Returns a set with the features and identities for a host.
   * @param {String} jid the jid of the host
   * @param {String|null} node the node to query
   * @param {int} timeout the timeout in ms for reply from the host.
   * @returns {Promise<Object>}
   * @private
   */


  _getDiscoInfo(jid, node, timeout) {
    return new Promise((resolve, reject) => this.disco.info(jid, node, response => {
      const features = new Set();
      const identities = new Set();
      $(response).find('>query>feature').each((_, el) => features.add(el.getAttribute('var')));
      $(response).find('>query>identity').each((_, el) => identities.add({
        type: el.getAttribute('type'),
        name: el.getAttribute('name'),
        category: el.getAttribute('category')
      }));
      resolve({
        features,
        identities
      });
    }, reject, timeout));
  }
  /**
   * Adds ChatRoom instance to the list of rooms. Adds listeners to the room
   * and adds "c" element to the presences of the room.
   * @param {ChatRoom} room the room.
   */


  _addChatRoom(room) {
    this.rooms.add(room);
    room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1___default.a.MUC_MEMBER_LEFT, this._onMucMemberLeft);

    this._fixChatRoomPresenceMap(room);
  }
  /**
   * Removes ChatRoom instance from the list of rooms. Removes listeners
   * added from the Caps class.
   * @param {ChatRoom} room the room.
   */


  _removeChatRoom(room) {
    this.rooms.delete(room);
    room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1___default.a.MUC_MEMBER_LEFT, this._onMucMemberLeft);
  }
  /**
   * Creates/updates the "c" xml node into the presence of the passed room.
   * @param {ChatRoom} room the room.
   */


  _fixChatRoomPresenceMap(room) {
    room.addToPresence('c', {
      attributes: {
        xmlns: strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].NS.CAPS,
        hash: HASH,
        node: this.node,
        ver: this.version
      }
    });
  }
  /**
   * Handles this.version changes.
   */


  _notifyVersionChanged() {
    // update the version for all rooms
    this.rooms.forEach(room => this._fixChatRoomPresenceMap(room));
  }
  /**
   * Generates the value for the "ver" attribute.
   */


  _generateVersion() {
    this.version = generateSha(this.disco._identities, this.disco._features);

    this._notifyVersionChanged();
  }
  /**
   * Parses the "c" xml node from presence.
   * @param {DOMElement} stanza the presence packet
   */


  _handleCaps(stanza) {
    const from = stanza.getAttribute('from');
    const caps = stanza.querySelector('c');
    const version = caps.getAttribute('ver');
    const node = caps.getAttribute('node');
    const oldVersion = this.jidToVersion[from];
    this.jidToVersion[from] = {
      version,
      node
    };

    if (oldVersion && oldVersion.version !== version) {
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1___default.a.PARTCIPANT_FEATURES_CHANGED, from);
    } // return true to not remove the handler from Strophe


    return true;
  }
  /**
   * Removes entry from this.jidToVersion map.
   * @param {String} jid the jid to be removed.
   */


  _removeJidToVersionEntry(jid) {
    if (jid in this.jidToVersion) {
      delete this.jidToVersion[jid];
    }
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\Caps.js"))

/***/ }),

/***/ "./modules/xmpp/ChatRoom.js":
/*!**********************************!*\
  !*** ./modules/xmpp/ChatRoom.js ***!
  \**********************************/
/*! exports provided: parser, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parser", function() { return parser; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return ChatRoom; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _JitsiTranscriptionStatus__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../JitsiTranscriptionStatus */ "./JitsiTranscriptionStatus.js");
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Listenable */ "./modules/util/Listenable.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__);
/* harmony import */ var _moderator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./moderator */ "./modules/xmpp/moderator.js");
/* harmony import */ var _XmppConnection__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./XmppConnection */ "./modules/xmpp/XmppConnection.js");
/* global $, __filename */









const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
const parser = {
  packet2JSON(xmlElement, nodes) {
    for (const child of Array.from(xmlElement.children)) {
      const node = {
        attributes: {},
        children: [],
        tagName: child.tagName
      };

      for (const attr of Array.from(child.attributes)) {
        node.attributes[attr.name] = attr.value;
      }

      const text = strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getText(child);

      if (text) {
        // Using Strophe.getText will do work for traversing all direct
        // child text nodes but returns an escaped value, which is not
        // desirable at this point.
        node.value = strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].xmlunescape(text);
      }

      nodes.push(node);
      this.packet2JSON(child, node.children);
    }
  },

  json2packet(nodes, packet) {
    for (let i = 0; i < nodes.length; i++) {
      const node = nodes[i];

      if (node) {
        packet.c(node.tagName, node.attributes);

        if (node.value) {
          packet.t(node.value);
        }

        if (node.children) {
          this.json2packet(node.children, packet);
        }

        packet.up();
      }
    } // packet.up();

  }

};
/**
 * Returns array of JS objects from the presence JSON associated with the passed
 / nodeName
 * @param pres the presence JSON
 * @param nodeName the name of the node (videomuted, audiomuted, etc)
 */

function filterNodeFromPresenceJSON(pres, nodeName) {
  const res = [];

  for (let i = 0; i < pres.length; i++) {
    if (pres[i].tagName === nodeName) {
      res.push(pres[i]);
    }
  }

  return res;
} // XXX As ChatRoom constructs XMPP stanzas and Strophe is build around the idea
// of chaining function calls, allow long function call chains.

/* eslint-disable newline-per-chained-call */

/**
 *
 */


class ChatRoom extends _util_Listenable__WEBPACK_IMPORTED_MODULE_4__["default"] {
  /* eslint-disable max-params */

  /**
   *
   * @param {XmppConnection} connection - The XMPP connection instance.
   * @param jid
   * @param password
   * @param XMPP
   * @param options
   * @param {boolean} options.disableFocus - when set to {@code false} will
   * not invite Jicofo into the room. This is intended to be used only by
   * jitsi-meet-spot.
   */
  constructor(connection, jid, password, XMPP, options) {
    super();
    this.xmpp = XMPP;
    this.connection = connection;
    this.roomjid = strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getBareJidFromJid(jid);
    this.myroomjid = jid;
    this.password = password;
    logger.info(`Joined MUC as ${this.myroomjid}`);
    this.members = {};
    this.presMap = {};
    this.presHandlers = {};
    this._removeConnListeners = [];
    this.joined = false;
    this.role = null;
    this.focusMucJid = null;
    this.noBridgeAvailable = false;
    this.options = options || {};
    this.moderator = new _moderator__WEBPACK_IMPORTED_MODULE_7__["default"](this.roomjid, this.xmpp, this.eventEmitter, {
      connection: this.xmpp.options,
      conference: this.options
    });
    this.initPresenceMap(options);
    this.lastPresences = {};
    this.phoneNumber = null;
    this.phonePin = null;
    this.connectionTimes = {};
    this.participantPropertyListener = null;
    this.locked = false;
    this.transcriptionStatus = _JitsiTranscriptionStatus__WEBPACK_IMPORTED_MODULE_3__["OFF"];
  }
  /* eslint-enable max-params */

  /**
   *
   */


  initPresenceMap(options = {}) {
    this.presMap.to = this.myroomjid;
    this.presMap.xns = 'http://jabber.org/protocol/muc';
    this.presMap.nodes = [];

    if (options.statsId) {
      this.presMap.nodes.push({
        'tagName': 'stats-id',
        'value': options.statsId
      });
    } // We need to broadcast 'videomuted' status from the beginning, cause
    // Jicofo makes decisions based on that. Initialize it with 'false'
    // here.


    this.addVideoInfoToPresence(false);

    if (options.deploymentInfo && options.deploymentInfo.userRegion) {
      this.presMap.nodes.push({
        'tagName': 'region',
        'attributes': {
          id: options.deploymentInfo.userRegion,
          xmlns: 'http://jitsi.org/jitsi-meet'
        }
      });
    }
  }
  /**
   * Joins the chat room.
   * @param password
   * @returns {Promise} - resolved when join completes. At the time of this
   * writing it's never rejected.
   */


  join(password) {
    this.password = password;
    return new Promise(resolve => {
      this.options.disableFocus && logger.info('Conference focus disabled');
      const preJoin = this.options.disableFocus ? Promise.resolve() : this.moderator.allocateConferenceFocus();
      preJoin.then(() => {
        this.sendPresence(true);

        this._removeConnListeners.push(this.connection.addEventListener(_XmppConnection__WEBPACK_IMPORTED_MODULE_8__["default"].Events.CONN_STATUS_CHANGED, this.onConnStatusChanged.bind(this)));

        resolve();
      });
    });
  }
  /**
   *
   * @param fromJoin
   */


  sendPresence(fromJoin) {
    const to = this.presMap.to;

    if (!this.connection || !this.connection.connected || !to || !this.joined && !fromJoin) {
      // Too early to send presence - not initialized
      return;
    }

    const pres = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$pres"])({
      to
    }); // xep-0045 defines: "including in the initial presence stanza an empty
    // <x/> element qualified by the 'http://jabber.org/protocol/muc'
    // namespace" and subsequent presences should not include that or it can
    // be considered as joining, and server can send us the message history
    // for the room on every presence

    if (fromJoin) {
      pres.c('x', {
        xmlns: this.presMap.xns
      });

      if (this.password) {
        pres.c('password').t(this.password).up();
      }

      pres.up();
    }

    parser.json2packet(this.presMap.nodes, pres);
    this.connection.send(pres);

    if (fromJoin) {
      // XXX We're pressed for time here because we're beginning a complex
      // and/or lengthy conference-establishment process which supposedly
      // involves multiple RTTs. We don't have the time to wait for
      // Strophe to decide to send our IQ.
      this.connection.flush();
    }
  }
  /**
   * Sends the presence unavailable, signaling the server
   * we want to leave the room.
   */


  doLeave() {
    logger.log('do leave', this.myroomjid);
    const pres = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$pres"])({
      to: this.myroomjid,
      type: 'unavailable'
    });
    this.presMap.length = 0; // XXX Strophe is asynchronously sending by default. Unfortunately, that
    // means that there may not be enough time to send the unavailable
    // presence. Switching Strophe to synchronous sending is not much of an
    // option because it may lead to a noticeable delay in navigating away
    // from the current location. As a compromise, we will try to increase
    // the chances of sending the unavailable presence within the short time
    // span that we have upon unloading by invoking flush() on the
    // connection. We flush() once before sending/queuing the unavailable
    // presence in order to attemtp to have the unavailable presence at the
    // top of the send queue. We flush() once more after sending/queuing the
    // unavailable presence in order to attempt to have it sent as soon as
    // possible.
    // FIXME do not use Strophe.Connection in the ChatRoom directly

    !this.connection.isUsingWebSocket && this.connection.flush();
    this.connection.send(pres);
    this.connection.flush();
  }
  /**
   *
   */


  discoRoomInfo() {
    // https://xmpp.org/extensions/xep-0045.html#disco-roominfo
    const getInfo = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
      type: 'get',
      to: this.roomjid
    }).c('query', {
      xmlns: strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].NS.DISCO_INFO
    });
    this.connection.sendIQ(getInfo, result => {
      const locked = $(result).find('>query>feature[var="muc_passwordprotected"]').length === 1;

      if (locked !== this.locked) {
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_LOCK_CHANGED, locked);
        this.locked = locked;
      }

      const meetingIdValEl = $(result).find('>query>x[type="result"]>field[var="muc#roominfo_meetingId"]>value');

      if (meetingIdValEl.length) {
        this.setMeetingId(meetingIdValEl.text());
      } else {
        logger.trace('No meeting ID from backend');
      }
    }, error => {
      _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default.a.callErrorHandler(error);
      logger.error('Error getting room info: ', error);
    });
  }
  /**
   * Sets the meeting unique Id (received from the backend).
   *
   * @param {string} meetingId - The new meetings id.
   * @returns {void}
   */


  setMeetingId(meetingId) {
    if (this.meetingId !== meetingId) {
      if (this.meetingId) {
        logger.warn(`Meeting Id changed from:${this.meetingId} to:${meetingId}`);
      }

      this.meetingId = meetingId;
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MEETING_ID_SET, meetingId);
    }
  }
  /**
   *
   */


  createNonAnonymousRoom() {
    // http://xmpp.org/extensions/xep-0045.html#createroom-reserved
    const getForm = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
      type: 'get',
      to: this.roomjid
    }).c('query', {
      xmlns: 'http://jabber.org/protocol/muc#owner'
    }).c('x', {
      xmlns: 'jabber:x:data',
      type: 'submit'
    });
    const self = this;
    this.connection.sendIQ(getForm, form => {
      if (!$(form).find('>query>x[xmlns="jabber:x:data"]' + '>field[var="muc#roomconfig_whois"]').length) {
        const errmsg = 'non-anonymous rooms not supported';
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default.a.callErrorHandler(new Error(errmsg));
        logger.error(errmsg);
        return;
      }

      const formSubmit = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
        to: self.roomjid,
        type: 'set'
      }).c('query', {
        xmlns: 'http://jabber.org/protocol/muc#owner'
      });
      formSubmit.c('x', {
        xmlns: 'jabber:x:data',
        type: 'submit'
      });
      formSubmit.c('field', {
        'var': 'FORM_TYPE'
      }).c('value').t('http://jabber.org/protocol/muc#roomconfig').up().up();
      formSubmit.c('field', {
        'var': 'muc#roomconfig_whois'
      }).c('value').t('anyone').up().up();
      self.connection.sendIQ(formSubmit);
    }, error => {
      _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default.a.callErrorHandler(error);
      logger.error('Error getting room configuration form: ', error);
    });
  }
  /**
   * Handles Xmpp Connection status updates.
   *
   * @param {Strophe.Status} status - The Strophe connection status.
   */


  onConnStatusChanged(status) {
    // Send cached presence when the XMPP connection is re-established.
    if (status === _XmppConnection__WEBPACK_IMPORTED_MODULE_8__["default"].Status.CONNECTED) {
      this.sendPresence();
    }
  }
  /**
   *
   * @param pres
   */


  onPresence(pres) {
    const from = pres.getAttribute('from');
    const member = {};
    const statusEl = pres.getElementsByTagName('status')[0];

    if (statusEl) {
      member.status = statusEl.textContent || '';
    }

    let hasStatusUpdate = false;
    let hasVersionUpdate = false;
    const xElement = pres.getElementsByTagNameNS('http://jabber.org/protocol/muc#user', 'x')[0];
    const mucUserItem = xElement && xElement.getElementsByTagName('item')[0];
    member.affiliation = mucUserItem && mucUserItem.getAttribute('affiliation');
    member.role = mucUserItem && mucUserItem.getAttribute('role'); // Focus recognition

    const jid = mucUserItem && mucUserItem.getAttribute('jid');
    member.jid = jid;
    member.isFocus = jid && jid.indexOf(`${this.moderator.getFocusUserJid()}/`) === 0;
    member.isHiddenDomain = jid && jid.indexOf('@') > 0 && this.options.hiddenDomain === jid.substring(jid.indexOf('@') + 1, jid.indexOf('/'));
    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.PRESENCE_RECEIVED, {
      fromHiddenDomain: member.isHiddenDomain,
      presence: pres
    });
    const xEl = pres.querySelector('x');

    if (xEl) {
      xEl.remove();
    }

    const nodes = [];
    parser.packet2JSON(pres, nodes);
    this.lastPresences[from] = nodes; // process nodes to extract data needed for MUC_JOINED and
    // MUC_MEMBER_JOINED events

    const extractIdentityInformation = node => {
      const identity = {};
      const userInfo = node.children.find(c => c.tagName === 'user');

      if (userInfo) {
        identity.user = {};

        for (const tag of ['id', 'name', 'avatar']) {
          const child = userInfo.children.find(c => c.tagName === tag);

          if (child) {
            identity.user[tag] = child.value;
          }
        }
      }

      const groupInfo = node.children.find(c => c.tagName === 'group');

      if (groupInfo) {
        identity.group = groupInfo.value;
      }

      return identity;
    };

    for (let i = 0; i < nodes.length; i++) {
      const node = nodes[i];

      switch (node.tagName) {
        case 'bot':
          {
            const {
              attributes
            } = node;

            if (!attributes) {
              break;
            }

            const {
              type
            } = attributes;
            member.botType = type;
            break;
          }

        case 'nick':
          member.nick = node.value;
          break;

        case 'userId':
          member.id = node.value;
          break;

        case 'stats-id':
          member.statsID = node.value;
          break;

        case 'identity':
          member.identity = extractIdentityInformation(node);
          break;

        case 'stat':
          {
            const {
              attributes
            } = node;

            if (!attributes) {
              break;
            }

            const {
              name
            } = attributes;

            if (name === 'version') {
              member.version = attributes.value;
            }

            break;
          }
      }
    }

    if (from === this.myroomjid) {
      const newRole = member.affiliation === 'owner' ? member.role : 'none';

      if (this.role !== newRole) {
        this.role = newRole;
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.LOCAL_ROLE_CHANGED, this.role);
      }

      if (!this.joined) {
        this.joined = true;
        const now = this.connectionTimes['muc.joined'] = window.performance.now();
        logger.log('(TIME) MUC joined:\t', now); // set correct initial state of locked

        if (this.password) {
          this.locked = true;
        } // Re-send presence in case any presence updates were added,
        // but blocked from sending, during the join process.


        this.sendPresence();
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_JOINED); // Now let's check the disco-info to retrieve the
        // meeting Id if any

        this.discoRoomInfo();
      }
    } else if (jid === undefined) {
      logger.info('Ignoring member with undefined JID');
    } else if (this.members[from] === undefined) {
      // new participant
      this.members[from] = member;
      logger.log('entered', from, member);
      hasStatusUpdate = member.status !== undefined;
      hasVersionUpdate = member.version !== undefined;

      if (member.isFocus) {
        this._initFocus(from, jid);
      } else {
        // identity is being added to member joined, so external
        // services can be notified for that (currently identity is
        // not used inside library)
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_MEMBER_JOINED, from, member.nick, member.role, member.isHiddenDomain, member.statsID, member.status, member.identity, member.botType); // we are reporting the status with the join
        // so we do not want a second event about status update

        hasStatusUpdate = false;
      }
    } else {
      // Presence update for existing participant
      // Watch role change:
      const memberOfThis = this.members[from];

      if (memberOfThis.role !== member.role) {
        memberOfThis.role = member.role;
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_ROLE_CHANGED, from, member.role);
      } // fire event that botType had changed


      if (memberOfThis.botType !== member.botType) {
        memberOfThis.botType = member.botType;
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_MEMBER_BOT_TYPE_CHANGED, from, member.botType);
      }

      if (member.isFocus) {
        // From time to time first few presences of the focus are not
        // containing it's jid. That way we can mark later the focus
        // member instead of not marking it at all and not starting the
        // conference.
        // FIXME: Maybe there is a better way to handle this issue. It
        // seems there is some period of time in prosody that the
        // configuration form is received but not applied. And if any
        // participant joins during that period of time the first
        // presence from the focus won't contain
        // <item jid="focus..." />.
        memberOfThis.isFocus = true;

        this._initFocus(from, jid);
      } // store the new display name


      if (member.displayName) {
        memberOfThis.displayName = member.displayName;
      } // update stored status message to be able to detect changes


      if (memberOfThis.status !== member.status) {
        hasStatusUpdate = true;
        memberOfThis.status = member.status;
      }

      if (memberOfThis.version !== member.version) {
        hasVersionUpdate = true;
        memberOfThis.version = member.version;
      }
    } // after we had fired member or room joined events, lets fire events
    // for the rest info we got in presence


    for (let i = 0; i < nodes.length; i++) {
      const node = nodes[i];

      switch (node.tagName) {
        case 'nick':
          if (!member.isFocus) {
            const displayName = this.xmpp.options.displayJids ? strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getResourceFromJid(from) : member.nick;
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.DISPLAY_NAME_CHANGED, from, displayName);
          }

          break;

        case 'bridgeNotAvailable':
          if (member.isFocus && !this.noBridgeAvailable) {
            this.noBridgeAvailable = true;
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.BRIDGE_DOWN);
          }

          break;

        case 'conference-properties':
          if (member.isFocus) {
            const properties = {};

            for (let j = 0; j < node.children.length; j++) {
              const {
                attributes
              } = node.children[j];

              if (attributes && attributes.key) {
                properties[attributes.key] = attributes.value;
              }
            }

            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.CONFERENCE_PROPERTIES_CHANGED, properties);
          }

          break;

        case 'transcription-status':
          {
            const {
              attributes
            } = node;

            if (!attributes) {
              break;
            }

            const {
              status
            } = attributes;

            if (status && status !== this.transcriptionStatus) {
              this.transcriptionStatus = status;
              this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.TRANSCRIPTION_STATUS_CHANGED, status);
            }

            break;
          }

        case 'call-control':
          {
            const att = node.attributes;

            if (!att) {
              break;
            }

            this.phoneNumber = att.phone || null;
            this.phonePin = att.pin || null;
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.PHONE_NUMBER_CHANGED);
            break;
          }

        default:
          this.processNode(node, from);
      }
    } // Trigger status message update if necessary


    if (hasStatusUpdate) {
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.PRESENCE_STATUS, from, member.status);
    }

    if (hasVersionUpdate) {
      logger.info(`Received version for ${jid}: ${member.version}`);
    }
  }
  /**
   * Initialize some properties when the focus participant is verified.
   * @param from jid of the focus
   * @param mucJid the jid of the focus in the muc
   */


  _initFocus(from, mucJid) {
    this.focusMucJid = from;
    logger.info(`Ignore focus: ${from}, real JID: ${mucJid}`);
  }
  /**
   * Sets the special listener to be used for "command"s whose name starts
   * with "jitsi_participant_".
   */


  setParticipantPropertyListener(listener) {
    this.participantPropertyListener = listener;
  }
  /**
   *
   * @param node
   * @param from
   */


  processNode(node, from) {
    // make sure we catch all errors coming from any handler
    // otherwise we can remove the presence handler from strophe
    try {
      let tagHandlers = this.presHandlers[node.tagName];

      if (node.tagName.startsWith('jitsi_participant_')) {
        tagHandlers = [this.participantPropertyListener];
      }

      if (tagHandlers) {
        tagHandlers.forEach(handler => {
          handler(node, strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getResourceFromJid(from), from);
        });
      }
    } catch (e) {
      _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default.a.callErrorHandler(e);
      logger.error(`Error processing:${node.tagName} node.`, e);
    }
  }
  /**
   * Send text message to the other participants in the conference
   * @param message
   * @param elementName
   * @param nickname
   */


  sendMessage(message, elementName, nickname) {
    const msg = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$msg"])({
      to: this.roomjid,
      type: 'groupchat'
    }); // We are adding the message in a packet extension. If this element
    // is different from 'body', we add a custom namespace.
    // e.g. for 'json-message' extension of message stanza.

    if (elementName === 'body') {
      msg.c(elementName, message).up();
    } else {
      msg.c(elementName, {
        xmlns: 'http://jitsi.org/jitmeet'
      }, message).up();
    }

    if (nickname) {
      msg.c('nick', {
        xmlns: 'http://jabber.org/protocol/nick'
      }).t(nickname).up().up();
    }

    this.connection.send(msg);
    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.SENDING_CHAT_MESSAGE, message);
  }
  /* eslint-disable max-params */

  /**
   * Send private text message to another participant of the conference
   * @param id id/muc resource of the receiver
   * @param message
   * @param elementName
   * @param nickname
   */


  sendPrivateMessage(id, message, elementName, nickname) {
    const msg = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$msg"])({
      to: `${this.roomjid}/${id}`,
      type: 'chat'
    }); // We are adding the message in packet. If this element is different
    // from 'body', we add our custom namespace for the same.
    // e.g. for 'json-message' message extension.

    if (elementName === 'body') {
      msg.c(elementName, message).up();
    } else {
      msg.c(elementName, {
        xmlns: 'http://jitsi.org/jitmeet'
      }, message).up();
    }

    if (nickname) {
      msg.c('nick', {
        xmlns: 'http://jabber.org/protocol/nick'
      }).t(nickname).up().up();
    }

    this.connection.send(msg);
    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.SENDING_PRIVATE_CHAT_MESSAGE, message);
  }
  /* eslint-enable max-params */

  /**
   *
   * @param subject
   */


  setSubject(subject) {
    const msg = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$msg"])({
      to: this.roomjid,
      type: 'groupchat'
    });
    msg.c('subject', subject);
    this.connection.send(msg);
  }
  /**
   * Called when participant leaves.
   * @param jid the jid of the participant that leaves
   * @param skipEvents optional params to skip any events, including check
   * whether this is the focus that left
   */


  onParticipantLeft(jid, skipEvents) {
    delete this.lastPresences[jid];

    if (skipEvents) {
      return;
    }

    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_MEMBER_LEFT, jid);
    this.moderator.onMucMemberLeft(jid);
  }
  /**
   *
   * @param pres
   * @param from
   */


  onPresenceUnavailable(pres, from) {
    // ignore presence
    if ($(pres).find('>ignore[xmlns="http://jitsi.org/jitmeet/"]').length) {
      return true;
    } // room destroyed ?


    if ($(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]' + '>destroy').length) {
      let reason;
      const reasonSelect = $(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]' + '>destroy>reason');

      if (reasonSelect.length) {
        reason = reasonSelect.text();
      }

      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_DESTROYED, reason);
      this.connection.emuc.doLeave(this.roomjid);
      return true;
    } // Status code 110 indicates that this notification is "self-presence".


    const isSelfPresence = $(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]>' + 'status[code="110"]').length;
    const isKick = $(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]' + '>status[code="307"]').length;
    const membersKeys = Object.keys(this.members);

    if (isKick) {
      const actorSelect = $(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]>item>actor');
      let actorNick;

      if (actorSelect.length) {
        actorNick = actorSelect.attr('nick');
      } // if no member is found this is the case we had kicked someone
      // and we are not in the list of members


      if (membersKeys.find(jid => strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getResourceFromJid(jid) === actorNick)) {
        // we first fire the kicked so we can show the participant
        // who kicked, before notifying that participant left
        // we fire kicked for us and for any participant kicked
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.KICKED, isSelfPresence, actorNick, strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getResourceFromJid(from));
      }
    }

    if (!isSelfPresence) {
      delete this.members[from];
      this.onParticipantLeft(from, false);
    } else if (membersKeys.length > 0) {
      // If the status code is 110 this means we're leaving and we would
      // like to remove everyone else from our view, so we trigger the
      // event.
      membersKeys.forEach(jid => {
        const member = this.members[jid];
        delete this.members[jid];
        this.onParticipantLeft(jid, member.isFocus);
      });
      this.connection.emuc.doLeave(this.roomjid); // we fire muc_left only if this is not a kick,
      // kick has both statuses 110 and 307.

      if (!isKick) {
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_LEFT);
      }
    }
  }
  /**
   *
   * @param msg
   * @param from
   */


  onMessage(msg, from) {
    const nick = $(msg).find('>nick[xmlns="http://jabber.org/protocol/nick"]').text() || strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getResourceFromJid(from);
    const type = msg.getAttribute('type');

    if (type === 'error') {
      const errorMsg = $(msg).find('>error>text').text();
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.CHAT_ERROR_RECEIVED, errorMsg);
      return true;
    }

    const txt = $(msg).find('>body').text();
    const subject = $(msg).find('>subject');

    if (subject.length) {
      const subjectText = subject.text();

      if (subjectText || subjectText === '') {
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.SUBJECT_CHANGED, subjectText);
        logger.log(`Subject is changed to ${subjectText}`);
      }
    } // xep-0203 delay


    let stamp = $(msg).find('>delay').attr('stamp');

    if (!stamp) {
      // or xep-0091 delay, UTC timestamp
      stamp = $(msg).find('>[xmlns="jabber:x:delay"]').attr('stamp');

      if (stamp) {
        // the format is CCYYMMDDThh:mm:ss
        const dateParts = stamp.match(/(\d{4})(\d{2})(\d{2}T\d{2}:\d{2}:\d{2})/);
        stamp = `${dateParts[1]}-${dateParts[2]}-${dateParts[3]}Z`;
      }
    }

    if (from === this.roomjid && $(msg).find('>x[xmlns="http://jabber.org/protocol/muc#user"]>status[code="104"]').length) {
      this.discoRoomInfo();
    }

    const jsonMessage = $(msg).find('>json-message').text();
    const parsedJson = this.xmpp.tryParseJSONAndVerify(jsonMessage); // We emit this event if the message is a valid json, and is not
    // delivered after a delay, i.e. stamp is undefined.
    // e.g. - subtitles should not be displayed if delayed.

    if (parsedJson && stamp === undefined) {
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.JSON_MESSAGE_RECEIVED, from, parsedJson);
      return;
    }

    if (txt) {
      if (type === 'chat') {
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.PRIVATE_MESSAGE_RECEIVED, from, nick, txt, this.myroomjid, stamp);
      } else if (type === 'groupchat') {
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MESSAGE_RECEIVED, from, nick, txt, this.myroomjid, stamp);
      }
    }
  }
  /**
   *
   * @param pres
   * @param from
   */


  onPresenceError(pres, from) {
    if ($(pres).find('>error[type="auth"]' + '>not-authorized[' + 'xmlns="urn:ietf:params:xml:ns:xmpp-stanzas"]').length) {
      logger.log('on password required', from);
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.PASSWORD_REQUIRED);
    } else if ($(pres).find('>error[type="cancel"]' + '>not-allowed[' + 'xmlns="urn:ietf:params:xml:ns:xmpp-stanzas"]').length) {
      const toDomain = strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getDomainFromJid(pres.getAttribute('to'));

      if (toDomain === this.xmpp.options.hosts.anonymousdomain) {
        // enter the room by replying with 'not-authorized'. This would
        // result in reconnection from authorized domain.
        // We're either missing Jicofo/Prosody config for anonymous
        // domains or something is wrong.
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.ROOM_JOIN_ERROR);
      } else {
        logger.warn('onPresError ', pres);
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.ROOM_CONNECT_NOT_ALLOWED_ERROR);
      }
    } else if ($(pres).find('>error>service-unavailable').length) {
      logger.warn('Maximum users limit for the room has been reached', pres);
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.ROOM_MAX_USERS_ERROR);
    } else {
      logger.warn('onPresError ', pres);
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.ROOM_CONNECT_ERROR);
    }
  }
  /**
   *
   * @param jid
   */


  kick(jid) {
    const kickIQ = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
      to: this.roomjid,
      type: 'set'
    }).c('query', {
      xmlns: 'http://jabber.org/protocol/muc#admin'
    }).c('item', {
      nick: strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getResourceFromJid(jid),
      role: 'none'
    }).c('reason').t('You have been kicked.').up().up().up();
    this.connection.sendIQ(kickIQ, result => logger.log('Kick participant with jid: ', jid, result), error => logger.log('Kick participant error: ', error));
  }
  /* eslint-disable max-params */

  /**
   *
   * @param key
   * @param onSuccess
   * @param onError
   * @param onNotSupported
   */


  lockRoom(key, onSuccess, onError, onNotSupported) {
    // http://xmpp.org/extensions/xep-0045.html#roomconfig
    this.connection.sendIQ(Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
      to: this.roomjid,
      type: 'get'
    }).c('query', {
      xmlns: 'http://jabber.org/protocol/muc#owner'
    }), res => {
      if ($(res).find('>query>x[xmlns="jabber:x:data"]' + '>field[var="muc#roomconfig_roomsecret"]').length) {
        const formsubmit = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
          to: this.roomjid,
          type: 'set'
        }).c('query', {
          xmlns: 'http://jabber.org/protocol/muc#owner'
        });
        formsubmit.c('x', {
          xmlns: 'jabber:x:data',
          type: 'submit'
        });
        formsubmit.c('field', {
          'var': 'FORM_TYPE'
        }).c('value').t('http://jabber.org/protocol/muc#roomconfig').up().up();
        formsubmit.c('field', {
          'var': 'muc#roomconfig_roomsecret'
        }).c('value').t(key).up().up();
        formsubmit.c('field', {
          'var': 'muc#roomconfig_passwordprotectedroom'
        }).c('value').t(key === null || key.length === 0 ? '0' : '1').up().up(); // Fixes a bug in prosody 0.9.+
        // https://prosody.im/issues/issue/373

        formsubmit.c('field', {
          'var': 'muc#roomconfig_whois'
        }).c('value').t('anyone').up().up();
        this.connection.sendIQ(formsubmit, onSuccess, onError);
      } else {
        onNotSupported();
      }
    }, onError);
  }
  /* eslint-enable max-params */

  /**
   *
   * @param key
   * @param values
   */


  addToPresence(key, values) {
    values.tagName = key;
    this.removeFromPresence(key);
    this.presMap.nodes.push(values);
  }
  /**
   * Retreives a value from the presence map.
   *
   * @param {string} key - The key to find the value for.
   * @returns {Object?}
   */


  getFromPresence(key) {
    return this.presMap.nodes.find(node => key === node.tagName);
  }
  /**
   *
   * @param key
   */


  removeFromPresence(key) {
    const nodes = this.presMap.nodes.filter(node => key !== node.tagName);
    this.presMap.nodes = nodes;
  }
  /**
   *
   * @param name
   * @param handler
   */


  addPresenceListener(name, handler) {
    if (typeof handler !== 'function') {
      throw new Error('"handler" is not a function');
    }

    let tagHandlers = this.presHandlers[name];

    if (!tagHandlers) {
      this.presHandlers[name] = tagHandlers = [];
    }

    if (tagHandlers.indexOf(handler) === -1) {
      tagHandlers.push(handler);
    } else {
      logger.warn(`Trying to add the same handler more than once for: ${name}`);
    }
  }
  /**
   *
   * @param name
   * @param handler
   */


  removePresenceListener(name, handler) {
    const tagHandlers = this.presHandlers[name];
    const handlerIdx = tagHandlers ? tagHandlers.indexOf(handler) : -1; // eslint-disable-next-line no-negated-condition

    if (handlerIdx !== -1) {
      tagHandlers.splice(handlerIdx, 1);
    } else {
      logger.warn(`Handler for: ${name} was not registered`);
    }
  }
  /**
   * Checks if the user identified by given <tt>mucJid</tt> is the conference
   * focus.
   * @param mucJid the full MUC address of the user to be checked.
   * @returns {boolean|null} <tt>true</tt> if MUC user is the conference focus
   * or <tt>false</tt> if is not. When given <tt>mucJid</tt> does not exist in
   * the MUC then <tt>null</tt> is returned.
   */


  isFocus(mucJid) {
    const member = this.members[mucJid];

    if (member) {
      return member.isFocus;
    }

    return null;
  }
  /**
   *
   */


  isModerator() {
    return this.role === 'moderator';
  }
  /**
   *
   * @param peerJid
   */


  getMemberRole(peerJid) {
    if (this.members[peerJid]) {
      return this.members[peerJid].role;
    }

    return null;
  }
  /**
   *
   * @param mute
   * @param callback
   */


  setVideoMute(mute, callback) {
    this.sendVideoInfoPresence(mute);

    if (callback) {
      callback(mute);
    }
  }
  /**
   *
   * @param mute
   * @param callback
   */


  setAudioMute(mute, callback) {
    return this.sendAudioInfoPresence(mute, callback);
  }
  /**
   *
   * @param mute
   */


  addAudioInfoToPresence(mute) {
    this.removeFromPresence('audiomuted');
    this.addToPresence('audiomuted', {
      attributes: {
        'xmlns': 'http://jitsi.org/jitmeet/audio'
      },
      value: mute.toString()
    });
  }
  /**
   *
   * @param mute
   * @param callback
   */


  sendAudioInfoPresence(mute, callback) {
    this.addAudioInfoToPresence(mute); // FIXME resend presence on CONNECTED

    this.sendPresence();

    if (callback) {
      callback();
    }
  }
  /**
   *
   * @param mute
   */


  addVideoInfoToPresence(mute) {
    this.removeFromPresence('videomuted');
    this.addToPresence('videomuted', {
      attributes: {
        'xmlns': 'http://jitsi.org/jitmeet/video'
      },
      value: mute.toString()
    });
  }
  /**
   *
   * @param mute
   */


  sendVideoInfoPresence(mute) {
    this.addVideoInfoToPresence(mute);
    this.sendPresence();
  }
  /**
   * Obtains the info about given media advertised in the MUC presence of
   * the participant identified by the given endpoint JID.
   * @param {string} endpointId the endpoint ID mapped to the participant
   * which corresponds to MUC nickname.
   * @param {MediaType} mediaType the type of the media for which presence
   * info will be obtained.
   * @return {PeerMediaInfo} presenceInfo an object with media presence
   * info or <tt>null</tt> either if there is no presence available or if
   * the media type given is invalid.
   */


  getMediaPresenceInfo(endpointId, mediaType) {
    // Will figure out current muted status by looking up owner's presence
    const pres = this.lastPresences[`${this.roomjid}/${endpointId}`];

    if (!pres) {
      // No presence available
      return null;
    }

    const data = {
      muted: false,
      // unmuted by default
      videoType: undefined // no video type by default

    };
    let mutedNode = null;

    if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["AUDIO"]) {
      mutedNode = filterNodeFromPresenceJSON(pres, 'audiomuted');
    } else if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__["VIDEO"]) {
      mutedNode = filterNodeFromPresenceJSON(pres, 'videomuted');
      const videoTypeNode = filterNodeFromPresenceJSON(pres, 'videoType');

      if (videoTypeNode.length > 0) {
        data.videoType = videoTypeNode[0].value;
      }
    } else {
      logger.error(`Unsupported media type: ${mediaType}`);
      return null;
    }

    data.muted = mutedNode.length > 0 && mutedNode[0].value === 'true';
    return data;
  }
  /**
   * Returns true if the SIP calls are supported and false otherwise
   */


  isSIPCallingSupported() {
    if (this.moderator) {
      return this.moderator.isSipGatewayEnabled();
    }

    return false;
  }
  /**
   * Dials a number.
   * @param number the number
   */


  dial(number) {
    return this.connection.rayo.dial(number, 'fromnumber', strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getBareJidFromJid(this.myroomjid), this.password, this.focusMucJid);
  }
  /**
   * Hangup an existing call
   */


  hangup() {
    return this.connection.rayo.hangup();
  }
  /**
   * Returns the phone number for joining the conference.
   */


  getPhoneNumber() {
    return this.phoneNumber;
  }
  /**
   * Returns the pin for joining the conference with phone.
   */


  getPhonePin() {
    return this.phonePin;
  }
  /**
   * Returns the meeting unique ID if any came from backend.
   *
   * @returns {string} - The meeting ID.
   */


  getMeetingId() {
    return this.meetingId;
  }
  /**
   * Mutes remote participant.
   * @param jid of the participant
   * @param mute
   */


  muteParticipant(jid, mute) {
    logger.info('set mute', mute);
    const iqToFocus = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
      to: this.focusMucJid,
      type: 'set'
    }).c('mute', {
      xmlns: 'http://jitsi.org/jitmeet/audio',
      jid
    }).t(mute.toString()).up();
    this.connection.sendIQ(iqToFocus, result => logger.log('set mute', result), error => logger.log('set mute error', error));
  }
  /**
   * TODO: Document
   * @param iq
   */


  onMute(iq) {
    const from = iq.getAttribute('from');

    if (from !== this.focusMucJid) {
      logger.warn('Ignored mute from non focus peer');
      return;
    }

    const mute = $(iq).find('mute');

    if (mute.length && mute.text() === 'true') {
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.AUDIO_MUTED_BY_FOCUS, mute.attr('actor'));
    } else {
      // XXX Why do we support anything but muting? Why do we encode the
      // value in the text of the element? Why do we use a separate XML
      // namespace?
      logger.warn('Ignoring a mute request which does not explicitly ' + 'specify a positive mute command.');
    }
  }
  /**
   * Leaves the room. Closes the jingle session.
   * @returns {Promise} which is resolved if XMPPEvents.MUC_LEFT is received
   * less than 5s after sending presence unavailable. Otherwise the promise is
   * rejected.
   */


  leave() {
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => onMucLeft(true), 5000);
      const eventEmitter = this.eventEmitter;

      this._removeConnListeners.forEach(remove => remove());

      this._removeConnListeners = [];
      /**
       *
       * @param doReject
       */

      function onMucLeft(doReject = false) {
        eventEmitter.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_LEFT, onMucLeft);
        clearTimeout(timeout);

        if (doReject) {
          // the timeout expired
          reject(new Error('The timeout for the confirmation about ' + 'leaving the room expired.'));
        } else {
          resolve();
        }
      }

      eventEmitter.on(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6___default.a.MUC_LEFT, onMucLeft);
      this.doLeave();
    });
  }

}
/* eslint-enable newline-per-chained-call */
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\ChatRoom.js"))

/***/ }),

/***/ "./modules/xmpp/ConnectionPlugin.js":
/*!******************************************!*\
  !*** ./modules/xmpp/ConnectionPlugin.js ***!
  \******************************************/
/*! exports provided: default, ConnectionPluginListenable */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionPluginListenable", function() { return ConnectionPluginListenable; });
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util/Listenable */ "./modules/util/Listenable.js");

/**
 * Creates ConnectionPlugin class that extends the passed class.
 * @param {Class} base the definition of the class that will be extended by
 * ConnectionPlugin
 */

function getConnectionPluginDefinition(base = class {}) {
  /**
   * Base class for strophe connection plugins.
   */
  return class extends base {
    /**
     *
     */
    constructor(...args) {
      super(...args);
      this.connection = null;
    }
    /**
     *
     * @param connection
     */


    init(connection) {
      this.connection = connection;
    }

  };
}
/**
 * ConnectionPlugin class.
 */


/* harmony default export */ __webpack_exports__["default"] = (getConnectionPluginDefinition());
/**
 * ConnectionPlugin class that extends Listenable.
 */

const ConnectionPluginListenable = getConnectionPluginDefinition(_util_Listenable__WEBPACK_IMPORTED_MODULE_0__["default"]);

/***/ }),

/***/ "./modules/xmpp/JingleSession.js":
/*!***************************************!*\
  !*** ./modules/xmpp/JingleSession.js ***!
  \***************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JingleSession; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JingleSessionState__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./JingleSessionState */ "./modules/xmpp/JingleSessionState.js");
/* global __filename */


const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * JingleSession provides an API to manage a single Jingle session. We will
 * have different implementations depending on the underlying interface used
 * (i.e. WebRTC and ORTC) and here we hold the code common to all of them.
 */

class JingleSession {
  /* eslint-disable max-params */

  /**
   * Creates new <tt>JingleSession</tt>.
   * @param {string} sid the Jingle session identifier
   * @param {string} localJid our JID
   * @param {string} remoteJid the JID of the remote peer
   * @param {Strophe.Connection} connection the XMPP connection
   * @param {Object} mediaConstraints the media constraints object passed to
   * the PeerConnection onCreateAnswer/Offer as defined by the WebRTC.
   * @param {Object} iceConfig the ICE servers config object as defined by
   * the WebRTC. Passed to the PeerConnection's constructor.
   * @param {boolean} isInitiator indicates if it will be the side which
   * initiates the session.
   */
  constructor(sid, localJid, remoteJid, connection, mediaConstraints, iceConfig, isInitiator) {
    this.sid = sid;
    this.localJid = localJid;
    this.remoteJid = remoteJid;
    this.connection = connection;
    this.mediaConstraints = mediaConstraints;
    this.iceConfig = iceConfig;
    /**
     * Indicates whether this instance is an initiator or an answerer of
     * the Jingle session.
     * @type {boolean}
     */

    this.isInitiator = isInitiator;
    /**
     * Whether to use dripping or not. Dripping is sending trickle
     * candidates not one-by-one.
     */

    this.usedrip = true;
    /**
     *  When dripping is used, stores ICE candidates which are to be sent.
     */

    this.dripContainer = [];
    /**
     * The chat room instance associated with the session.
     * @type {ChatRoom}
     */

    this.room = null;
    /**
     * Jingle session state - uninitialized until {@link initialize} is
     * called @type {JingleSessionState}
     */

    this.state = null;
    /**
     * The RTC service instance
     * @type {RTC}
     */

    this.rtc = null;
  }
  /**
   * Returns XMPP address of this session's initiator.
   * @return {string}
   */


  get initiatorJid() {
    return this.isInitiator ? this.localJid : this.remoteJid;
  }
  /**
   * Returns XMPP address of this session's responder.
   * @return {string}
   */


  get responderJid() {
    return this.isInitiator ? this.remoteJid : this.localJid;
  }
  /* eslint-enable max-params */

  /**
   * Prepares this object to initiate a session.
   * @param {ChatRoom} room the chat room for the conference associated with
   * this session
   * @param {RTC} rtc the RTC service instance
   * @param {object} options - the options, see implementing class's
   * {@link #doInitialize} description for more details.
   */


  initialize(room, rtc, options) {
    if (this.state !== null) {
      const errmsg = `attempt to initiate on session ${this.sid}
                   in state ${this.state}`;
      logger.error(errmsg);
      throw new Error(errmsg);
    }

    this.room = room;
    this.rtc = rtc;
    this.state = _JingleSessionState__WEBPACK_IMPORTED_MODULE_1__["PENDING"];
    this.doInitialize(options);
  }
  /**
   * The implementing class finishes initialization here. Called at the end of
   * {@link initialize}.
   * @param {Object} options - The options specific to the implementing class.
   * @protected
   */


  doInitialize(options) {} // eslint-disable-line no-unused-vars, no-empty-function, max-len

  /* eslint-disable no-unused-vars, no-empty-function */

  /**
   * Adds the ICE candidates found in the 'contents' array as remote
   * candidates?
   * Note: currently only used on transport-info
   *
   * @param contents
   */


  addIceCandidates(contents) {}
  /* eslint-enable no-unused-vars, no-empty-function */

  /**
   * Returns current state of this <tt>JingleSession</tt> instance.
   * @returns {JingleSessionState} the current state of this session instance.
   */


  getState() {
    return this.state;
  }
  /* eslint-disable no-unused-vars, no-empty-function */

  /**
   * Handles an 'add-source' event.
   *
   * @param contents an array of Jingle 'content' elements.
   */


  addSources(contents) {}
  /**
   * Handles a 'remove-source' event.
   *
   * @param contents an array of Jingle 'content' elements.
   */


  removeSources(contents) {}
  /**
   * Terminates this Jingle session by sending session-terminate
   * @param success a callback called once the 'session-terminate' packet has
   * been acknowledged with RESULT.
   * @param failure a callback called when either timeout occurs or ERROR
   * response is received.
   * @param {Object} options
   * @param {string} [options.reason] XMPP Jingle error condition
   * @param {string} [options.reasonDescription] some meaningful error message
   * @param {boolean} [options.sendSessionTerminate=true] set to false to skip
   * sending session-terminate. It may not make sense to send it if the XMPP
   * connection has been closed already or if the remote peer has disconnected
   */


  terminate(success, failure, options) {}
  /**
   * Handles an offer from the remote peer (prepares to accept a session).
   * @param jingle the 'jingle' XML element.
   * @param success callback called when we the incoming session has been
   * accepted
   * @param failure callback called when we fail for any reason, will supply
   * error object with details(which is meant more to be printed to the logger
   * than analysed in the code, as the error is unrecoverable anyway)
   */


  acceptOffer(jingle, success, failure) {}
  /**
   * Returns the JID of the initiator of the jingle session.
   */


  _getInitiatorJid() {
    return this.isInitiator ? this.localJid : this.remoteJid;
  }
  /* eslint-enable no-unused-vars, no-empty-function */


}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\JingleSession.js"))

/***/ }),

/***/ "./modules/xmpp/JingleSessionPC.js":
/*!*****************************************!*\
  !*** ./modules/xmpp/JingleSessionPC.js ***!
  \*****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JingleSessionPC; });
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _util_StringUtils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/StringUtils */ "./modules/util/StringUtils.js");
/* harmony import */ var _util_StringUtils__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_util_StringUtils__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./../browser */ "./modules/browser/index.js");
/* harmony import */ var _JingleSession__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./JingleSession */ "./modules/xmpp/JingleSession.js");
/* harmony import */ var _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./JingleSessionState */ "./modules/xmpp/JingleSessionState.js");
/* harmony import */ var _SDP__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./SDP */ "./modules/xmpp/SDP.js");
/* harmony import */ var _SDPDiffer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SDPDiffer */ "./modules/xmpp/SDPDiffer.js");
/* harmony import */ var _SDPUtil__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./SDPUtil */ "./modules/xmpp/SDPUtil.js");
/* harmony import */ var _SignalingLayerImpl__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./SignalingLayerImpl */ "./modules/xmpp/SignalingLayerImpl.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_11___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_11__);
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__);
/* harmony import */ var _util_AsyncQueue__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../util/AsyncQueue */ "./modules/util/AsyncQueue.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_15___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_15__);
/* harmony import */ var _XmppConnection__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./XmppConnection */ "./modules/xmpp/XmppConnection.js");
/* global __filename, $ */

















const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__["getLogger"])(__filename);
/**
 * Constant tells how long we're going to wait for IQ response, before timeout
 * error is  triggered.
 * @type {number}
 */

const IQ_TIMEOUT = 10000;
/*
 * The default number of samples (per stat) to keep when webrtc stats gathering
 * is enabled in TraceablePeerConnection.
 */

const DEFAULT_MAX_STATS = 300;
/**
 * @typedef {Object} JingleSessionPCOptions
 * @property {Object} abTesting - A/B testing related options (ask George).
 * @property {boolean} abTesting.enableSuspendVideoTest - enables the suspend
 * video test ?(ask George).
 * @property {boolean} disableH264 - Described in the config.js[1].
 * @property {boolean} disableRtx - Described in the config.js[1].
 * @property {boolean} disableSimulcast - Described in the config.js[1].
 * @property {boolean} enableLayerSuspension - Described in the config.js[1].
 * @property {boolean} failICE - it's an option used in the tests. Set to
 * <tt>true</tt> to block any real candidates and make the ICE fail.
 * @property {boolean} gatherStats - Described in the config.js[1].
 * @property {object} p2p - Peer to peer related options (FIXME those could be
 * fetched from config.p2p on the upper level).
 * @property {boolean} p2p.disableH264 - Described in the config.js[1].
 * @property {boolean} p2p.preferH264 - Described in the config.js[1].
 * @property {boolean} preferH264 - Described in the config.js[1].
 * @property {Object} testing - Testing and/or experimental options.
 * @property {boolean} webrtcIceUdpDisable - Described in the config.js[1].
 * @property {boolean} webrtcIceTcpDisable - Described in the config.js[1].
 *
 * [1]: https://github.com/jitsi/jitsi-meet/blob/master/config.js
 */

/**
 *
 */

class JingleSessionPC extends _JingleSession__WEBPACK_IMPORTED_MODULE_5__["default"] {
  /**
   * Parses 'senders' attribute of the video content.
   * @param {jQuery} jingleContents
   * @return {string|null} one of the values of content "senders" attribute
   * defined by Jingle. If there is no "senders" attribute or if the value is
   * invalid then <tt>null</tt> will be returned.
   * @private
   */
  static parseVideoSenders(jingleContents) {
    const videoContents = jingleContents.find('>content[name="video"]');

    if (videoContents.length) {
      const senders = videoContents[0].getAttribute('senders');

      if (senders === 'both' || senders === 'initiator' || senders === 'responder' || senders === 'none') {
        return senders;
      }
    }

    return null;
  }
  /* eslint-disable max-params */

  /**
   * Creates new <tt>JingleSessionPC</tt>
   * @param {string} sid the Jingle Session ID - random string which
   * identifies the session
   * @param {string} localJid our JID
   * @param {string} remoteJid remote peer JID
   * @param {XmppConnection} connection - The XMPP connection instance.
   * @param mediaConstraints the media constraints object passed to
   * createOffer/Answer, as defined by the WebRTC standard
   * @param iceConfig the ICE servers config object as defined by the WebRTC
   * standard.
   * @param {boolean} isP2P indicates whether this instance is
   * meant to be used in a direct, peer to peer connection or <tt>false</tt>
   * if it's a JVB connection.
   * @param {boolean} isInitiator indicates if it will be the side which
   * initiates the session.
   * @constructor
   *
   * @implements {SignalingLayer}
   */


  constructor(sid, localJid, remoteJid, connection, mediaConstraints, iceConfig, isP2P, isInitiator) {
    super(sid, localJid, remoteJid, connection, mediaConstraints, iceConfig, isInitiator);
    /**
     * The bridge session's identifier. One Jingle session can during
     * it's lifetime participate in multiple bridge sessions managed by
     * Jicofo. A new bridge session is started whenever Jicofo sends
     * 'session-initiate' or 'transport-replace'.
     *
     * @type {?string}
     * @private
     */

    this._bridgeSessionId = null;
    /**
     * The oldest SDP passed to {@link notifyMySSRCUpdate} while the XMPP connection was offline that will be
     * used to update Jicofo once the XMPP connection goes back online.
     * @type {SDP|undefined}
     * @private
     */

    this._cachedOldLocalSdp = undefined;
    /**
     * The latest SDP passed to {@link notifyMySSRCUpdate} while the XMPP connection was offline that will be
     * used to update Jicofo once the XMPP connection goes back online.
     * @type {SDP|undefined}
     * @private
     */

    this._cachedNewLocalSdp = undefined;
    /**
     * Stores result of {@link window.performance.now()} at the time when
     * ICE enters 'checking' state.
     * @type {number|null} null if no value has been stored yet
     * @private
     */

    this._iceCheckingStartedTimestamp = null;
    /**
     * Stores result of {@link window.performance.now()} at the time when
     * first ICE candidate is spawned by the peerconnection to mark when
     * ICE gathering started. That's, because ICE gathering state changed
     * events are not supported by most of the browsers, so we try something
     * that will work everywhere. It may not be as accurate, but given that
     * 'host' candidate usually comes first, the delay should be minimal.
     * @type {number|null} null if no value has been stored yet
     * @private
     */

    this._gatheringStartedTimestamp = null;
    /**
     * Indicates whether or not this session is willing to send/receive
     * video media. When set to <tt>false</tt> the underlying peer
     * connection will disable local video transfer and the remote peer will
     * be will be asked to stop sending video via 'content-modify' IQ
     * (the senders attribute of video contents will be adjusted
     * accordingly). Note that this notification is sent only in P2P
     * session, because Jicofo does not support it yet. Obviously when
     * the value is changed from <tt>false</tt> to <tt>true</tt> another
     * notification will be sent to resume video transfer on the remote
     * side.
     * @type {boolean}
     * @private
     */

    this._localVideoActive = true;
    /**
     * Indicates whether or not the remote peer has video transfer active.
     * When set to <tt>true</tt> it means that remote peer is neither
     * sending nor willing to receive video. In such case we'll ask
     * our peerconnection to stop sending video by calling
     * {@link TraceablePeerConnection.setVideoTransferActive} with
     * <tt>false</tt>.
     * @type {boolean}
     * @private
     */

    this._remoteVideoActive = true;
    /**
     * Marks that ICE gathering duration has been reported already. That
     * prevents reporting it again, after eventual 'transport-replace' (JVB
     * conference migration/ICE restart).
     * @type {boolean}
     * @private
     */

    this._gatheringReported = false;
    this.lasticecandidate = false;
    this.closed = false;
    /**
     * Indicates whether or not this <tt>JingleSessionPC</tt> is used in
     * a peer to peer type of session.
     * @type {boolean} <tt>true</tt> if it's a peer to peer
     * session or <tt>false</tt> if it's a JVB session
     */

    this.isP2P = isP2P;
    /**
     * The signaling layer implementation.
     * @type {SignalingLayerImpl}
     */

    this.signalingLayer = new _SignalingLayerImpl__WEBPACK_IMPORTED_MODULE_10__["default"]();
    /**
     * The queue used to serialize operations done on the peerconnection.
     *
     * @type {AsyncQueue}
     */

    this.modificationQueue = new _util_AsyncQueue__WEBPACK_IMPORTED_MODULE_14__["default"]();
    /**
     * Flag used to guarantee that the connection established event is
     * triggered just once.
     * @type {boolean}
     */

    this.wasConnected = false;
    /**
     * Keeps track of how long (in ms) it took from ICE start to ICE
     * connect.
     *
     * @type {number}
     */

    this.establishmentDuration = undefined;
    this._xmppListeners = [];

    this._xmppListeners.push(connection.addEventListener(_XmppConnection__WEBPACK_IMPORTED_MODULE_16__["default"].Events.CONN_STATUS_CHANGED, this.onXmppStatusChanged.bind(this)));
  }
  /* eslint-enable max-params */

  /**
   * Checks whether or not this session instance is still operational.
   * @private
   * @returns {boolean} {@code true} if operation or {@code false} otherwise.
   */


  _assertNotEnded() {
    return this.state !== _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__["ENDED"];
  }
  /**
   * @inheritDoc
   * @param {JingleSessionPCOptions} options  - a set of config options.
   */


  doInitialize(options) {
    this.failICE = Boolean(options.failICE);
    this.lasticecandidate = false;
    this.options = options;
    /**
     * {@code true} if reconnect is in progress.
     * @type {boolean}
     */

    this.isReconnect = false;
    /**
     * Set to {@code true} if the connection was ever stable
     * @type {boolean}
     */

    this.wasstable = false;
    this.webrtcIceUdpDisable = Boolean(options.webrtcIceUdpDisable);
    this.webrtcIceTcpDisable = Boolean(options.webrtcIceTcpDisable);
    const pcOptions = {
      disableRtx: options.disableRtx
    };

    if (options.gatherStats) {
      pcOptions.maxstats = DEFAULT_MAX_STATS;
    }

    pcOptions.capScreenshareBitrate = false;

    if (this.isP2P) {
      // simulcast needs to be disabled for P2P (121) calls
      pcOptions.disableSimulcast = true;
      pcOptions.disableH264 = options.p2p && options.p2p.disableH264;
      pcOptions.preferH264 = options.p2p && options.p2p.preferH264;

      const abtestSuspendVideo = this._abtestSuspendVideoEnabled(options);

      if (typeof abtestSuspendVideo !== 'undefined') {
        pcOptions.abtestSuspendVideo = abtestSuspendVideo;
      }
    } else {
      // H264 does not support simulcast, so it needs to be disabled.
      pcOptions.disableSimulcast = options.disableSimulcast || options.preferH264 && !options.disableH264;
      pcOptions.preferH264 = options.preferH264;
      pcOptions.enableLayerSuspension = options.enableLayerSuspension; // disable simulcast for screenshare and set the max bitrate to
      // 500Kbps if the testing flag is present in config.js.

      if (options.testing && options.testing.capScreenshareBitrate && typeof options.testing.capScreenshareBitrate === 'number') {
        pcOptions.capScreenshareBitrate = Math.random() < options.testing.capScreenshareBitrate; // add the capScreenshareBitrate to the permanent properties so
        // that it's included with every event that we send to the
        // analytics backend.

        _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].analytics.addPermanentProperties({
          capScreenshareBitrate: pcOptions.capScreenshareBitrate
        });
      }
    }

    if (options.startSilent) {
      pcOptions.startSilent = true;
    }

    this.peerconnection = this.rtc.createPeerConnection(this.signalingLayer, this.iceConfig, this.isP2P, pcOptions);

    this.peerconnection.onicecandidate = ev => {
      if (!ev) {
        // There was an incomplete check for ev before which left
        // the last line of the function unprotected from a potential
        // throw of an exception. Consequently, it may be argued that
        // the check is unnecessary. Anyway, I'm leaving it and making
        // the check complete.
        return;
      } // XXX this is broken, candidate is not parsed.


      const candidate = ev.candidate;
      const now = window.performance.now();

      if (candidate) {
        if (this._gatheringStartedTimestamp === null) {
          this._gatheringStartedTimestamp = now;
        } // Discard candidates of disabled protocols.


        let protocol = candidate.protocol;

        if (typeof protocol === 'string') {
          protocol = protocol.toLowerCase();

          if (protocol === 'tcp' || protocol === 'ssltcp') {
            if (this.webrtcIceTcpDisable) {
              return;
            }
          } else if (protocol === 'udp') {
            if (this.webrtcIceUdpDisable) {
              return;
            }
          }
        }
      } else if (!this._gatheringReported) {
        // End of gathering
        _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["ICE_DURATION"], {
          phase: 'gathering',
          value: now - this._gatheringStartedTimestamp,
          p2p: this.isP2P,
          initiator: this.isInitiator
        });
        this._gatheringReported = true;
      }

      this.sendIceCandidate(candidate);
    }; // Note there is a change in the spec about closed:
    // This value moved into the RTCPeerConnectionState enum in
    // the May 13, 2016 draft of the specification, as it reflects the state
    // of the RTCPeerConnection, not the signaling connection. You now
    // detect a closed connection by checking for connectionState to be
    // "closed" instead.
    // I suppose at some point this will be moved to onconnectionstatechange


    this.peerconnection.onsignalingstatechange = () => {
      if (this.peerconnection.signalingState === 'stable') {
        this.wasstable = true;
      } else if (this.peerconnection.signalingState === 'closed' || this.peerconnection.connectionState === 'closed') {
        this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.SUSPEND_DETECTED, this);
      }
    };
    /**
     * The oniceconnectionstatechange event handler contains the code to
     * execute when the iceconnectionstatechange event, of type Event,
     * is received by this RTCPeerConnection. Such an event is sent when
     * the value of RTCPeerConnection.iceConnectionState changes.
     */


    this.peerconnection.oniceconnectionstatechange = () => {
      const now = window.performance.now();

      if (!this.isP2P) {
        this.room.connectionTimes[`ice.state.${this.peerconnection.iceConnectionState}`] = now;
      }

      logger.log(`(TIME) ICE ${this.peerconnection.iceConnectionState}` + ` P2P? ${this.isP2P}:\t`, now);
      _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["ICE_STATE_CHANGED"], {
        p2p: this.isP2P,
        state: this.peerconnection.iceConnectionState,
        'signaling_state': this.peerconnection.signalingState,
        reconnect: this.isReconnect,
        value: now
      });
      this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.ICE_CONNECTION_STATE_CHANGED, this, this.peerconnection.iceConnectionState);

      switch (this.peerconnection.iceConnectionState) {
        case 'checking':
          this._iceCheckingStartedTimestamp = now;
          break;

        case 'connected':
          // Informs interested parties that the connection has been
          // restored.
          if (this.peerconnection.signalingState === 'stable') {
            if (this.isReconnect) {
              this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.CONNECTION_RESTORED, this);
            }
          }

          if (!this.wasConnected && this.wasstable) {
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["ICE_DURATION"], {
              phase: 'checking',
              value: now - this._iceCheckingStartedTimestamp,
              p2p: this.isP2P,
              initiator: this.isInitiator
            }); // Switch between ICE gathering and ICE checking whichever
            // started first (scenarios are different for initiator
            // vs responder)

            const iceStarted = Math.min(this._iceCheckingStartedTimestamp, this._gatheringStartedTimestamp);
            this.establishmentDuration = now - iceStarted;
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["ICE_DURATION"], {
              phase: 'establishment',
              value: this.establishmentDuration,
              p2p: this.isP2P,
              initiator: this.isInitiator
            });
            this.wasConnected = true;
            this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.CONNECTION_ESTABLISHED, this);
          }

          this.isReconnect = false;
          break;

        case 'disconnected':
          this.isReconnect = true; // Informs interested parties that the connection has been
          // interrupted.

          if (this.wasstable) {
            this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.CONNECTION_INTERRUPTED, this);
          }

          break;

        case 'failed':
          this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.CONNECTION_ICE_FAILED, this);
          break;
      }
    };
    /**
     * The negotiationneeded event is fired whenever we shake the media on the
     * RTCPeerConnection object.
     */


    this.peerconnection.onnegotiationneeded = () => {
      const state = this.peerconnection.signalingState;
      const remoteDescription = this.peerconnection.remoteDescription;
      this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.PEERCONNECTION_READY, this);

      if (_browser__WEBPACK_IMPORTED_MODULE_4__["default"].usesUnifiedPlan() && state === 'stable' && remoteDescription && typeof remoteDescription.sdp === 'string') {
        logger.debug(`onnegotiationneeded fired on ${this.peerconnection} in state: ${state}`);

        const workFunction = finishedCallback => {
          const oldSdp = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);

          this._renegotiate().then(() => {
            const newSdp = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);
            this.notifyMySSRCUpdate(oldSdp, newSdp);
            finishedCallback();
          }, finishedCallback
          /* will be called with en error */
          );
        };

        this.modificationQueue.push(workFunction, error => {
          if (error) {
            logger.error('onnegotiationneeded error', error);
          } else {
            logger.debug('onnegotiationneeded executed - OK');
          }
        });
      }
    }; // The signaling layer will bind it's listeners at this point


    this.signalingLayer.setChatRoom(this.room);

    if (!this.isP2P && options.enableLayerSuspension) {
      // If this is the bridge session, we'll listen for
      // IS_SELECTED_CHANGED events and notify the peer connection
      this.rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_11___default.a.IS_SELECTED_CHANGED, isSelected => {
        this.peerconnection.setIsSelected(isSelected);
        logger.info('Doing local O/A due to ' + 'IS_SELECTED_CHANGED event');
        this.modificationQueue.push(finishedCallback => {
          this._renegotiate().then(finishedCallback).catch(finishedCallback);
        });
      });
    }
  }
  /**
   * Sends given candidate in Jingle 'transport-info' message.
   * @param {RTCIceCandidate} candidate the WebRTC ICE candidate instance
   * @private
   */


  sendIceCandidate(candidate) {
    const localSDP = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);

    if (candidate && candidate.candidate.length && !this.lasticecandidate) {
      const ice = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].iceparams(localSDP.media[candidate.sdpMLineIndex], localSDP.session);
      const jcand = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].candidateToJingle(candidate.candidate);

      if (!(ice && jcand)) {
        const errorMesssage = 'failed to get ice && jcand';
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_15___default.a.callErrorHandler(new Error(errorMesssage));
        logger.error(errorMesssage);
        return;
      }

      ice.xmlns = 'urn:xmpp:jingle:transports:ice-udp:1';

      if (this.usedrip) {
        if (this.dripContainer.length === 0) {
          // start 20ms callout
          setTimeout(() => {
            if (this.dripContainer.length === 0) {
              return;
            }

            this.sendIceCandidates(this.dripContainer);
            this.dripContainer = [];
          }, 20);
        }

        this.dripContainer.push(candidate);
      } else {
        this.sendIceCandidates([candidate]);
      }
    } else {
      logger.log('sendIceCandidate: last candidate.'); // FIXME: remember to re-think in ICE-restart

      this.lasticecandidate = true;
    }
  }
  /**
   * Sends given candidates in Jingle 'transport-info' message.
   * @param {Array<RTCIceCandidate>} candidates an array of the WebRTC ICE
   * candidate instances
   * @private
   */


  sendIceCandidates(candidates) {
    if (!this._assertNotEnded('sendIceCandidates')) {
      return;
    }

    logger.log('sendIceCandidates', candidates);
    const cand = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      to: this.remoteJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: 'transport-info',
      initiator: this.initiatorJid,
      sid: this.sid
    });
    const localSDP = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);

    for (let mid = 0; mid < localSDP.media.length; mid++) {
      const cands = candidates.filter(el => el.sdpMLineIndex === mid);
      const mline = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].parseMLine(localSDP.media[mid].split('\r\n')[0]);

      if (cands.length > 0) {
        const ice = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].iceparams(localSDP.media[mid], localSDP.session);
        ice.xmlns = 'urn:xmpp:jingle:transports:ice-udp:1';
        cand.c('content', {
          creator: this.initiatorJid === this.localJid ? 'initiator' : 'responder',
          name: cands[0].sdpMid ? cands[0].sdpMid : mline.media
        }).c('transport', ice);

        for (let i = 0; i < cands.length; i++) {
          const candidate = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].candidateToJingle(cands[i].candidate); // Mangle ICE candidate if 'failICE' test option is enabled

          if (this.failICE) {
            candidate.ip = '1.1.1.1';
          }

          cand.c('candidate', candidate).up();
        } // add fingerprint


        const fingerprintLine = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].findLine(localSDP.media[mid], 'a=fingerprint:', localSDP.session);

        if (fingerprintLine) {
          const tmp = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].parseFingerprint(fingerprintLine);
          tmp.required = true;
          cand.c('fingerprint', {
            xmlns: 'urn:xmpp:jingle:apps:dtls:0'
          }).t(tmp.fingerprint);
          delete tmp.fingerprint;
          cand.attrs(tmp);
          cand.up();
        }

        cand.up(); // transport

        cand.up(); // content
      }
    } // might merge last-candidate notification into this, but it is called
    // a lot later. See webrtc issue #2340
    // logger.log('was this the last candidate', this.lasticecandidate);


    this.connection.sendIQ(cand, null, this.newJingleErrorHandler(cand), IQ_TIMEOUT);
  }
  /**
   * Sends Jingle 'session-info' message which includes custom Jitsi Meet
   * 'ice-state' element with the text value 'failed' to let Jicofo know
   * that the ICE connection has entered the failed state. It can then
   * choose to re-create JVB channels and send 'transport-replace' to
   * retry the connection.
   */


  sendIceFailedNotification() {
    const sessionInfo = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      to: this.remoteJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: 'session-info',
      initiator: this.initiatorJid,
      sid: this.sid
    }).c('ice-state', {
      xmlns: 'http://jitsi.org/protocol/focus'
    }).t('failed').up();
    this._bridgeSessionId && sessionInfo.c('bridge-session', {
      xmlns: 'http://jitsi.org/protocol/focus',
      id: this._bridgeSessionId
    });
    this.connection.sendIQ(sessionInfo, null, this.newJingleErrorHandler(sessionInfo),
    /*
     * This message will be often sent when there are connectivity
     * issues, so make it slightly longer than Prosody's default BOSH
     * inactivity timeout of 60 seconds.
     */
    65);
  }
  /**
   * {@inheritDoc}
   */


  addIceCandidates(elem) {
    if (this.peerconnection.signalingState === 'closed') {
      logger.warn('Ignored add ICE candidate when in closed state');
      return;
    }

    const iceCandidates = [];
    elem.find('>content>transport>candidate').each((idx, candidate) => {
      let line = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].candidateFromJingle(candidate);
      line = line.replace('\r\n', '').replace('a=', ''); // FIXME this code does not care to handle
      // non-bundle transport

      const rtcCandidate = new RTCIceCandidate({
        sdpMLineIndex: 0,
        // FF comes up with more complex names like audio-23423,
        // Given that it works on both Chrome and FF without
        // providing it, let's leave it like this for the time
        // being...
        // sdpMid: 'audio',
        sdpMid: '',
        candidate: line
      });
      iceCandidates.push(rtcCandidate);
    });

    if (!iceCandidates.length) {
      logger.error('No ICE candidates to add ?', elem[0] && elem[0].outerHTML);
      return;
    } // We want to have this task queued, so that we know it is executed,
    // after the initial sRD/sLD offer/answer cycle was done (based on
    // the assumption that candidates are spawned after the offer/answer
    // and XMPP preserves order).


    const workFunction = finishedCallback => {
      for (const iceCandidate of iceCandidates) {
        this.peerconnection.addIceCandidate(iceCandidate).then(() => logger.debug('addIceCandidate ok!'), err => logger.error('addIceCandidate failed!', err));
      }

      finishedCallback();
    };

    logger.debug(`Queued add (${iceCandidates.length}) ICE candidates task...`);
    this.modificationQueue.push(workFunction);
  }
  /**
   *
   * @param contents
   */


  readSsrcInfo(contents) {
    const ssrcs = $(contents).find('>description>' + 'source[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]');
    ssrcs.each((i, ssrcElement) => {
      const ssrc = Number(ssrcElement.getAttribute('ssrc'));

      if (this.isP2P) {
        // In P2P all SSRCs are owner by the remote peer
        this.signalingLayer.setSSRCOwner(ssrc, strophe_js__WEBPACK_IMPORTED_MODULE_2__["Strophe"].getResourceFromJid(this.remoteJid));
      } else {
        $(ssrcElement).find('>ssrc-info[xmlns="http://jitsi.org/jitmeet"]').each((i3, ssrcInfoElement) => {
          const owner = ssrcInfoElement.getAttribute('owner');

          if (owner && owner.length) {
            if (isNaN(ssrc) || ssrc < 0) {
              logger.warn(`Invalid SSRC ${ssrc} value received` + ` for ${owner}`);
            } else {
              this.signalingLayer.setSSRCOwner(ssrc, strophe_js__WEBPACK_IMPORTED_MODULE_2__["Strophe"].getResourceFromJid(owner));
            }
          }
        });
      }
    });
  }
  /**
   * Makes the underlying TraceablePeerConnection generate new SSRC for
   * the recvonly video stream.
   * @deprecated
   */


  generateRecvonlySsrc() {
    if (this.peerconnection) {
      this.peerconnection.generateRecvonlySsrc();
    } else {
      logger.error('Unable to generate recvonly SSRC - no peerconnection');
    }
  }
  /* eslint-disable max-params */

  /**
   * Accepts incoming Jingle 'session-initiate' and should send
   * 'session-accept' in result.
   * @param jingleOffer jQuery selector pointing to the jingle element of
   * the offer IQ
   * @param success callback called when we accept incoming session
   * successfully and receive RESULT packet to 'session-accept' sent.
   * @param failure function(error) called if for any reason we fail to accept
   * the incoming offer. 'error' argument can be used to log some details
   * about the error.
   * @param {Array<JitsiLocalTrack>} [localTracks] the optional list of
   * the local tracks that will be added, before the offer/answer cycle
   * executes. We allow the localTracks to optionally be passed in so that
   * the addition of the local tracks and the processing of the initial offer
   * can all be done atomically. We want to make sure that any other
   * operations which originate in the XMPP Jingle messages related with
   * this session to be executed with an assumption that the initial
   * offer/answer cycle has been executed already.
   */


  acceptOffer(jingleOffer, success, failure, localTracks) {
    this.setOfferAnswerCycle(jingleOffer, () => {
      // FIXME we may not care about RESULT packet for session-accept
      // then we should either call 'success' here immediately or
      // modify sendSessionAccept method to do that
      this.sendSessionAccept(success, failure);
    }, failure, localTracks);
  }
  /* eslint-enable max-params */

  /**
   * Creates an offer and sends Jingle 'session-initiate' to the remote peer.
   * @param {Array<JitsiLocalTrack>} localTracks the local tracks that will be
   * added, before the offer/answer cycle executes (for the local track
   * addition to be an atomic operation together with the offer/answer).
   */


  invite(localTracks) {
    if (!this.isInitiator) {
      throw new Error('Trying to invite from the responder session');
    }

    const workFunction = finishedCallback => {
      for (const localTrack of localTracks) {
        this.peerconnection.addTrack(localTrack, true
        /* isInitiator */
        );
      }

      this.peerconnection.createOffer(this.mediaConstraints).then(offerSdp => {
        this.peerconnection.setLocalDescription(offerSdp).then(() => {
          // NOTE that the offer is obtained from
          // the localDescription getter as it needs to go
          // though the transformation chain.
          this.sendSessionInitiate(this.peerconnection.localDescription.sdp);
          finishedCallback();
        }, error => {
          logger.error('Failed to set local SDP', error, offerSdp);
          finishedCallback(error);
        });
      }, error => {
        logger.error('Failed to create an offer', error, this.mediaConstraints);
        finishedCallback(error);
      });
    };

    this.modificationQueue.push(workFunction, error => {
      if (error) {
        logger.error('invite error', error);
      } else {
        logger.debug('invite executed - OK');
      }
    });
  }
  /**
   * Sends 'session-initiate' to the remote peer.
   *
   * NOTE this method is synchronous and we're not waiting for the RESULT
   * response which would delay the startup process.
   *
   * @param {string} offerSdp  - The local session description which will be
   * used to generate an offer.
   * @private
   */


  sendSessionInitiate(offerSdp) {
    let init = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      to: this.remoteJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: 'session-initiate',
      initiator: this.initiatorJid,
      sid: this.sid
    });
    new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](offerSdp).toJingle(init, this.isInitiator ? 'initiator' : 'responder');
    init = init.tree();
    logger.info('Session-initiate: ', init);
    this.connection.sendIQ(init, () => {
      logger.info('Got RESULT for "session-initiate"');
    }, error => {
      logger.error('"session-initiate" error', error);
    }, IQ_TIMEOUT);
  }
  /**
   * Sets the answer received from the remote peer.
   * @param jingleAnswer
   */


  setAnswer(jingleAnswer) {
    if (!this.isInitiator) {
      throw new Error('Trying to set an answer on the responder session');
    }

    this.setOfferAnswerCycle(jingleAnswer, () => {
      logger.info('setAnswer - succeeded');
    }, error => {
      logger.error('setAnswer failed: ', error);
    });
  }
  /* eslint-disable max-params */

  /**
   * This is a setRemoteDescription/setLocalDescription cycle which starts at
   * converting Strophe Jingle IQ into remote offer SDP. Once converted
   * setRemoteDescription, createAnswer and setLocalDescription calls follow.
   * @param jingleOfferAnswerIq jQuery selector pointing to the jingle element
   *        of the offer (or answer) IQ
   * @param success callback called when sRD/sLD cycle finishes successfully.
   * @param failure callback called with an error object as an argument if we
   *        fail at any point during setRD, createAnswer, setLD.
   * @param {Array<JitsiLocalTrack>} [localTracks] the optional list of
   * the local tracks that will be added, before the offer/answer cycle
   * executes (for the local track addition to be an atomic operation together
   * with the offer/answer).
   */


  setOfferAnswerCycle(jingleOfferAnswerIq, success, failure, localTracks) {
    const workFunction = finishedCallback => {
      if (localTracks) {
        for (const track of localTracks) {
          this.peerconnection.addTrack(track);
        }
      }

      const newRemoteSdp = this._processNewJingleOfferIq(jingleOfferAnswerIq);

      const oldLocalSdp = this.peerconnection.localDescription.sdp;
      const bridgeSession = $(jingleOfferAnswerIq).find('>bridge-session[' + 'xmlns="http://jitsi.org/protocol/focus"]');
      const bridgeSessionId = bridgeSession.attr('id');

      if (bridgeSessionId !== this._bridgeSessionId) {
        this._bridgeSessionId = bridgeSessionId;
      }

      this._renegotiate(newRemoteSdp.raw).then(() => {
        if (this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__["PENDING"]) {
          this.state = _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__["ACTIVE"]; // Sync up video transfer active/inactive only after
          // the initial O/A cycle. We want to adjust the video
          // media direction only in the local SDP and the Jingle
          // contents direction included in the initial
          // offer/answer is mapped to the remote SDP. Jingle
          // 'content-modify' IQ is processed in a way that it
          // will only modify local SDP when remote peer is no
          // longer interested in receiving video content.
          // Changing media direction in the remote SDP will mess
          // up our SDP translation chain (simulcast, video mute,
          // RTX etc.)

          if (this.isP2P && !this._localVideoActive) {
            this.sendContentModify(this._localVideoActive);
          }
        } // Old local SDP will be available when we're setting answer
        // for the first time, but not when offer and it's fine
        // since we're generating an answer now it will contain all
        // our SSRCs


        if (oldLocalSdp) {
          const newLocalSdp = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);
          this.notifyMySSRCUpdate(new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](oldLocalSdp), newLocalSdp);
        }

        finishedCallback();
      }, error => {
        logger.error(`Error renegotiating after setting new remote ${this.isInitiator ? 'answer: ' : 'offer: '}${error}`, newRemoteSdp);
        finishedCallback(error);
      });
    };

    this.modificationQueue.push(workFunction, error => {
      error ? failure(error) : success();
    });
  }
  /* eslint-enable max-params */

  /**
   * Although it states "replace transport" it does accept full Jingle offer
   * which should contain new ICE transport details.
   * @param jingleOfferElem an element Jingle IQ that contains new offer and
   *        transport info.
   * @param success callback called when we succeed to accept new offer.
   * @param failure function(error) called when we fail to accept new offer.
   */


  replaceTransport(jingleOfferElem, success, failure) {
    this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.ICE_RESTARTING, this); // We need to first reject the 'data' section to have the SCTP stack
    // cleaned up to signal the known data channel is now invalid. After
    // that the original offer is set to have the SCTP connection
    // established with the new bridge.

    const originalOffer = jingleOfferElem.clone();
    jingleOfferElem.find('>content[name=\'data\']').attr('senders', 'rejected'); // Remove all remote sources in order to reset the client's state
    // for the remote MediaStreams. When a conference is moved to
    // another bridge it will start streaming with a sequence number
    // that is not in sync with the most recently seen by the client.
    // The symptoms include frozen or black video and lots of "failed to
    // unprotect SRTP packets" in Chrome logs.

    jingleOfferElem.find('>content>description>source').remove();
    jingleOfferElem.find('>content>description>ssrc-group').remove(); // On the JVB it's not a real ICE restart and all layers are re-initialized from scratch as Jicofo does
    // the restart by re-allocating new channels. Chrome (or WebRTC stack) needs to have the DTLS transport layer
    // reset to start a new handshake with fresh DTLS transport on the bridge. Make it think that the DTLS
    // fingerprint has changed by setting an all zeros key.

    const newFingerprint = jingleOfferElem.find('>content>transport>fingerprint');
    newFingerprint.attr('hash', 'sha-1');
    newFingerprint.text('00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00'); // First set an offer with a rejected 'data' section

    this.setOfferAnswerCycle(jingleOfferElem, () => {
      // Now set the original offer(with the 'data' section)
      this.setOfferAnswerCycle(originalOffer, () => {
        const localSDP = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);
        this.sendTransportAccept(localSDP, success, failure);
        this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.ICE_RESTART_SUCCESS, this, originalOffer);
      }, failure);
    }, failure);
  }
  /**
   * Sends Jingle 'session-accept' message.
   * @param {function()} success callback called when we receive 'RESULT'
   *        packet for the 'session-accept'
   * @param {function(error)} failure called when we receive an error response
   *        or when the request has timed out.
   * @private
   */


  sendSessionAccept(success, failure) {
    // NOTE: since we're just reading from it, we don't need to be within
    //  the modification queue to access the local description
    const localSDP = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);
    let accept = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      to: this.remoteJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: 'session-accept',
      initiator: this.initiatorJid,
      responder: this.responderJid,
      sid: this.sid
    });

    if (this.webrtcIceTcpDisable) {
      localSDP.removeTcpCandidates = true;
    }

    if (this.webrtcIceUdpDisable) {
      localSDP.removeUdpCandidates = true;
    }

    if (this.failICE) {
      localSDP.failICE = true;
    }

    localSDP.toJingle(accept, this.initiatorJid === this.localJid ? 'initiator' : 'responder', null); // Calling tree() to print something useful

    accept = accept.tree();
    logger.info('Sending session-accept', accept);
    this.connection.sendIQ(accept, success, this.newJingleErrorHandler(accept, error => {
      failure(error); // 'session-accept' is a critical timeout and we'll
      // have to restart

      this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.SESSION_ACCEPT_TIMEOUT, this);
    }), IQ_TIMEOUT); // XXX Videobridge needs WebRTC's answer (ICE ufrag and pwd, DTLS
    // fingerprint and setup) ASAP in order to start the connection
    // establishment.
    //
    // FIXME Flushing the connection at this point triggers an issue with
    // BOSH request handling in Prosody on slow connections.
    //
    // The problem is that this request will be quite large and it may take
    // time before it reaches Prosody. In the meantime Strophe may decide
    // to send the next one. And it was observed that a small request with
    // 'transport-info' usually follows this one. It does reach Prosody
    // before the previous one was completely received. 'rid' on the server
    // is increased and Prosody ignores the request with 'session-accept'.
    // It will never reach Jicofo and everything in the request table is
    // lost. Removing the flush does not guarantee it will never happen, but
    // makes it much less likely('transport-info' is bundled with
    // 'session-accept' and any immediate requests).
    //
    // this.connection.flush();
  }
  /**
   * Will send 'content-modify' IQ in order to ask the remote peer to
   * either stop or resume sending video media.
   * @param {boolean} videoTransferActive <tt>false</tt> to let the other peer
   * know that we're not sending nor interested in receiving video contents.
   * When set to <tt>true</tt> remote peer will be asked to resume video
   * transfer.
   * @private
   */


  sendContentModify(videoTransferActive) {
    const newSendersValue = videoTransferActive ? 'both' : 'none';
    const sessionModify = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      to: this.remoteJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: 'content-modify',
      initiator: this.initiatorJid,
      sid: this.sid
    }).c('content', {
      name: 'video',
      senders: newSendersValue
    });
    logger.info(`Sending content-modify, video senders: ${newSendersValue}`);
    this.connection.sendIQ(sessionModify, null, this.newJingleErrorHandler(sessionModify), IQ_TIMEOUT);
  }
  /**
   * Sends Jingle 'transport-accept' message which is a response to
   * 'transport-replace'.
   * @param localSDP the 'SDP' object with local session description
   * @param success callback called when we receive 'RESULT' packet for
   *        'transport-replace'
   * @param failure function(error) called when we receive an error response
   *        or when the request has timed out.
   * @private
   */


  sendTransportAccept(localSDP, success, failure) {
    let transportAccept = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      to: this.remoteJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: 'transport-accept',
      initiator: this.initiatorJid,
      sid: this.sid
    });
    localSDP.media.forEach((medialines, idx) => {
      const mline = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].parseMLine(medialines.split('\r\n')[0]);
      transportAccept.c('content', {
        creator: this.initiatorJid === this.localJid ? 'initiator' : 'responder',
        name: mline.media
      });
      localSDP.transportToJingle(idx, transportAccept);
      transportAccept.up();
    }); // Calling tree() to print something useful to the logger

    transportAccept = transportAccept.tree();
    logger.info('Sending transport-accept: ', transportAccept);
    this.connection.sendIQ(transportAccept, success, this.newJingleErrorHandler(transportAccept, failure), IQ_TIMEOUT);
  }
  /**
   * Sends Jingle 'transport-reject' message which is a response to
   * 'transport-replace'.
   * @param success callback called when we receive 'RESULT' packet for
   *        'transport-replace'
   * @param failure function(error) called when we receive an error response
   *        or when the request has timed out.
   *
   * FIXME method should be marked as private, but there's some spaghetti that
   *       needs to be fixed prior doing that
   */


  sendTransportReject(success, failure) {
    // Send 'transport-reject', so that the focus will
    // know that we've failed
    let transportReject = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      to: this.remoteJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: 'transport-reject',
      initiator: this.initiatorJid,
      sid: this.sid
    });
    transportReject = transportReject.tree();
    logger.info('Sending \'transport-reject', transportReject);
    this.connection.sendIQ(transportReject, success, this.newJingleErrorHandler(transportReject, failure), IQ_TIMEOUT);
  }
  /**
   * @inheritDoc
   */


  terminate(success, failure, options) {
    if (this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__["ENDED"]) {
      return;
    }

    if (!options || Boolean(options.sendSessionTerminate)) {
      let sessionTerminate = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
        to: this.remoteJid,
        type: 'set'
      }).c('jingle', {
        xmlns: 'urn:xmpp:jingle:1',
        action: 'session-terminate',
        initiator: this.initiatorJid,
        sid: this.sid
      }).c('reason').c(options && options.reason || 'success');

      if (options && options.reasonDescription) {
        sessionTerminate.up().c('text').t(options.reasonDescription);
      } // Calling tree() to print something useful


      sessionTerminate = sessionTerminate.tree();
      logger.info('Sending session-terminate', sessionTerminate);
      this.connection.sendIQ(sessionTerminate, success, this.newJingleErrorHandler(sessionTerminate, failure), IQ_TIMEOUT);
    } else {
      logger.info(`Skipped sending session-terminate for ${this}`);
    } // this should result in 'onTerminated' being called by strope.jingle.js


    this.connection.jingle.terminate(this.sid);
  }
  /**
   *
   * @param reasonCondition
   * @param reasonText
   */


  onTerminated(reasonCondition, reasonText) {
    // Do something with reason and reasonCondition when we start to care
    // this.reasonCondition = reasonCondition;
    // this.reasonText = reasonText;
    logger.info(`Session terminated ${this}`, reasonCondition, reasonText);

    this._xmppListeners.forEach(removeListener => removeListener());

    this._xmppListeners = [];
    this.close();
  }
  /**
   * Handles XMPP connection state changes.
   *
   * @param {XmppConnection.Status} status - The new status.
   */


  onXmppStatusChanged(status) {
    if (status === _XmppConnection__WEBPACK_IMPORTED_MODULE_16__["default"].Status.CONNECTED && this._cachedOldLocalSdp) {
      logger.info('Sending SSRC update on reconnect');
      this.notifyMySSRCUpdate(this._cachedOldLocalSdp, this._cachedNewLocalSdp);
    }
  }
  /**
   * Parse the information from the xml sourceAddElem and translate it
   *  into sdp lines
   * @param {jquery xml element} sourceAddElem the source-add
   *  element from jingle
   * @param {SDP object} currentRemoteSdp the current remote
   *  sdp (as of this new source-add)
   * @returns {list} a list of SDP line strings that should
   *  be added to the remote SDP
   */


  _parseSsrcInfoFromSourceAdd(sourceAddElem, currentRemoteSdp) {
    const addSsrcInfo = [];
    $(sourceAddElem).each((i1, content) => {
      const name = $(content).attr('name');
      let lines = '';
      $(content).find('ssrc-group[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]').each(function () {
        // eslint-disable-next-line no-invalid-this
        const semantics = this.getAttribute('semantics');
        const ssrcs = $(this) // eslint-disable-line no-invalid-this
        .find('>source').map(function () {
          // eslint-disable-next-line no-invalid-this
          return this.getAttribute('ssrc');
        }).get();

        if (ssrcs.length) {
          lines += `a=ssrc-group:${semantics} ${ssrcs.join(' ')}\r\n`;
        }
      }); // handles both >source and >description>source

      const tmp = $(content).find('source[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]');
      /* eslint-disable no-invalid-this */

      tmp.each(function () {
        const ssrc = $(this).attr('ssrc');

        if (currentRemoteSdp.containsSSRC(ssrc)) {
          logger.warn(`Source-add request for existing SSRC: ${ssrc}`);
          return;
        } // eslint-disable-next-line newline-per-chained-call


        $(this).find('>parameter').each(function () {
          lines += `a=ssrc:${ssrc} ${$(this).attr('name')}`;

          if ($(this).attr('value') && $(this).attr('value').length) {
            lines += `:${$(this).attr('value')}`;
          }

          lines += '\r\n';
        });
      });
      /* eslint-enable no-invalid-this */

      currentRemoteSdp.media.forEach((media, i2) => {
        if (!_SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].findLine(media, `a=mid:${name}`)) {
          return;
        }

        if (!addSsrcInfo[i2]) {
          addSsrcInfo[i2] = '';
        }

        addSsrcInfo[i2] += lines;
      });
    });
    return addSsrcInfo;
  }
  /**
   * Handles a Jingle source-add message for this Jingle session.
   * @param elem An array of Jingle "content" elements.
   */


  addRemoteStream(elem) {
    this._addOrRemoveRemoteStream(true
    /* add */
    , elem);
  }
  /**
   * Handles a Jingle source-remove message for this Jingle session.
   * @param elem An array of Jingle "content" elements.
   */


  removeRemoteStream(elem) {
    this._addOrRemoveRemoteStream(false
    /* remove */
    , elem);
  }
  /**
   * Handles either Jingle 'source-add' or 'source-remove' message for this
   * Jingle session.
   * @param {boolean} isAdd <tt>true</tt> for 'source-add' or <tt>false</tt>
   * otherwise.
   * @param {Array<Element>} elem an array of Jingle "content" elements.
   * @private
   */


  _addOrRemoveRemoteStream(isAdd, elem) {
    const logPrefix = isAdd ? 'addRemoteStream' : 'removeRemoteStream';

    if (isAdd) {
      this.readSsrcInfo(elem);
    }

    const workFunction = finishedCallback => {
      if (!this.peerconnection.localDescription || !this.peerconnection.localDescription.sdp) {
        const errMsg = `${logPrefix} - localDescription not ready yet`;
        logger.error(errMsg);
        finishedCallback(errMsg);
        return;
      }

      logger.log(`Processing ${logPrefix}`);
      logger.log('ICE connection state: ', this.peerconnection.iceConnectionState);
      const oldLocalSdp = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);
      const sdp = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.remoteDescription.sdp);
      const addOrRemoveSsrcInfo = isAdd ? this._parseSsrcInfoFromSourceAdd(elem, sdp) : this._parseSsrcInfoFromSourceRemove(elem, sdp);
      const newRemoteSdp = isAdd ? this._processRemoteAddSource(addOrRemoveSsrcInfo) : this._processRemoteRemoveSource(addOrRemoveSsrcInfo);

      this._renegotiate(newRemoteSdp.raw).then(() => {
        const newLocalSdp = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);
        logger.log(`${logPrefix} - OK, SDPs: `, oldLocalSdp, newLocalSdp);
        this.notifyMySSRCUpdate(oldLocalSdp, newLocalSdp);
        finishedCallback();
      }, error => {
        logger.error(`${logPrefix} failed:`, error);
        finishedCallback(error);
      });
    }; // Queue and execute


    this.modificationQueue.push(workFunction);
  }
  /**
   * Takes in a jingle offer iq, returns the new sdp offer
   * @param {jquery xml element} offerIq the incoming offer
   * @returns {SDP object} the jingle offer translated to SDP
   */


  _processNewJingleOfferIq(offerIq) {
    const remoteSdp = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"]('');

    if (this.webrtcIceTcpDisable) {
      remoteSdp.removeTcpCandidates = true;
    }

    if (this.webrtcIceUdpDisable) {
      remoteSdp.removeUdpCandidates = true;
    }

    if (this.failICE) {
      remoteSdp.failICE = true;
    }

    remoteSdp.fromJingle(offerIq);
    this.readSsrcInfo($(offerIq).find('>content'));
    return remoteSdp;
  }
  /**
   * Remove the given ssrc lines from the current remote sdp
   * @param {list} removeSsrcInfo a list of SDP line strings that
   *  should be removed from the remote SDP
   * @returns type {SDP Object} the new remote SDP (after removing the lines
   *  in removeSsrcInfo
   */


  _processRemoteRemoveSource(removeSsrcInfo) {
    const remoteSdp = _browser__WEBPACK_IMPORTED_MODULE_4__["default"].usesPlanB() ? new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.remoteDescription.sdp) : new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.peerconnection.remoteDescription.sdp);
    removeSsrcInfo.forEach((lines, idx) => {
      // eslint-disable-next-line no-param-reassign
      lines = lines.split('\r\n');
      lines.pop(); // remove empty last element;

      if (_browser__WEBPACK_IMPORTED_MODULE_4__["default"].usesPlanB()) {
        lines.forEach(line => {
          remoteSdp.media[idx] = remoteSdp.media[idx].replace(`${line}\r\n`, '');
        });
      } else {
        lines.forEach(line => {
          const mid = remoteSdp.media.findIndex(mLine => mLine.includes(line));

          if (mid > -1) {
            remoteSdp.media[mid] = remoteSdp.media[mid].replace(`${line}\r\n`, ''); // Change the direction to "inactive".

            remoteSdp.media[mid] = remoteSdp.media[mid].replace('a=sendonly', 'a=inactive');
          }
        });
      }
    });
    remoteSdp.raw = remoteSdp.session + remoteSdp.media.join('');
    return remoteSdp;
  }
  /**
   * Add the given ssrc lines to the current remote sdp
   * @param {list} addSsrcInfo a list of SDP line strings that
   *  should be added to the remote SDP
   * @returns type {SDP Object} the new remote SDP (after removing the lines
   *  in removeSsrcInfo
   */


  _processRemoteAddSource(addSsrcInfo) {
    const remoteSdp = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.remoteDescription.sdp);
    addSsrcInfo.forEach((lines, idx) => {
      remoteSdp.media[idx] += lines;
    });
    remoteSdp.raw = remoteSdp.session + remoteSdp.media.join('');
    return remoteSdp;
  }
  /**
   * Do a new o/a flow using the existing remote description
   * @param {string} [optionalRemoteSdp] optional, raw remote sdp
   *  to use.  If not provided, the remote sdp from the
   *  peerconnection will be used
   * @returns {Promise} promise which resolves when the
   *  o/a flow is complete with no arguments or
   *  rejects with an error {string}
   */


  _renegotiate(optionalRemoteSdp) {
    if (this.peerconnection.signalingState === 'closed') {
      const error = new Error('Attempted to renegotiate in state closed');
      this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.RENEGOTIATION_FAILED, error, this);
      return Promise.reject(error);
    }

    const remoteSdp = optionalRemoteSdp || this.peerconnection.remoteDescription.sdp;

    if (!remoteSdp) {
      const error = new Error(`Can not renegotiate without remote description, current state: ${this.state}`);
      this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13___default.a.RENEGOTIATION_FAILED, error, this);
      return Promise.reject(error);
    }

    const remoteDescription = new RTCSessionDescription({
      type: this.isInitiator ? 'answer' : 'offer',
      sdp: remoteSdp
    });

    if (this.isInitiator) {
      return this._initiatorRenegotiate(remoteDescription);
    }

    return this._responderRenegotiate(remoteDescription);
  }
  /**
   * Renegotiate cycle implementation for the responder case.
   * @param {object} remoteDescription the SDP object as defined by the WebRTC
   * which will be used as remote description in the cycle.
   * @private
   */


  _responderRenegotiate(remoteDescription) {
    logger.debug('Renegotiate: setting remote description');
    return this.peerconnection.setRemoteDescription(remoteDescription).then(() => {
      logger.debug('Renegotiate: creating answer');
      return this.peerconnection.createAnswer(this.mediaConstraints).then(answer => {
        logger.debug('Renegotiate: setting local description');
        return this.peerconnection.setLocalDescription(answer);
      });
    });
  }
  /**
   * Renegotiate cycle implementation for the initiator's case.
   * @param {object} remoteDescription the SDP object as defined by the WebRTC
   * which will be used as remote description in the cycle.
   * @private
   */


  _initiatorRenegotiate(remoteDescription) {
    logger.debug('Renegotiate: creating offer');
    return this.peerconnection.createOffer(this.mediaConstraints).then(offer => {
      logger.debug('Renegotiate: setting local description');
      return this.peerconnection.setLocalDescription(offer).then(() => {
        logger.debug('Renegotiate: setting remote description'); // eslint-disable-next-line max-len

        return this.peerconnection.setRemoteDescription(remoteDescription);
      });
    });
  }
  /**
   * Replaces <tt>oldTrack</tt> with <tt>newTrack</tt> and performs a single
   * offer/answer cycle after both operations are done. Either
   * <tt>oldTrack</tt> or <tt>newTrack</tt> can be null; replacing a valid
   * <tt>oldTrack</tt> with a null <tt>newTrack</tt> effectively just removes
   * <tt>oldTrack</tt>
   * @param {JitsiLocalTrack|null} oldTrack the current track in use to be
   * replaced
   * @param {JitsiLocalTrack|null} newTrack the new track to use
   * @returns {Promise} which resolves once the replacement is complete
   *  with no arguments or rejects with an error {string}
   */


  replaceTrack(oldTrack, newTrack) {
    const workFunction = finishedCallback => {
      const oldLocalSdp = this.peerconnection.localDescription.sdp;

      if (_browser__WEBPACK_IMPORTED_MODULE_4__["default"].usesPlanB()) {
        // NOTE the code below assumes that no more than 1 video track
        // can be added to the peer connection.
        // Transition from camera to desktop share
        // or transition from one camera source to another.
        if (this.peerconnection.options.capScreenshareBitrate && oldTrack && newTrack && newTrack.isVideoTrack()) {
          // Clearing current primary SSRC will make
          // the SdpConsistency generate a new one which will result
          // with:
          // 1. source-remove for the old video stream.
          // 2. source-add for the new video stream.
          this.peerconnection.clearRecvonlySsrc();
        } // Transition from no video to video (unmute).


        if (!oldTrack && newTrack && newTrack.isVideoTrack()) {
          // Clearing current primary SSRC will make
          // the SdpConsistency generate a new one which will result
          // with:
          // 1. source-remove for the recvonly
          // 2. source-add for the new video stream
          this.peerconnection.clearRecvonlySsrc(); // Transition from video to no video
        } else if (oldTrack && oldTrack.isVideoTrack() && !newTrack) {
          // Clearing current primary SSRC and generating the recvonly
          // will result in:
          // 1. source-remove for the old video stream
          // 2. source-add for the recvonly stream
          this.peerconnection.clearRecvonlySsrc();
          this.peerconnection.generateRecvonlySsrc();
        }
      }

      this.peerconnection.replaceTrack(oldTrack, newTrack).then(shouldRenegotiate => {
        let promise = Promise.resolve();

        if (shouldRenegotiate && (oldTrack || newTrack) && this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__["ACTIVE"]) {
          promise = this._renegotiate().then(() => {
            const newLocalSDP = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);
            this.notifyMySSRCUpdate(new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](oldLocalSdp), newLocalSDP);
          }, finishedCallback
          /* will be called with en error */
          );
        } // Wait for the renegotation to be done if needed (plan-b) before adjusting
        // the max bitrates on the video sender.


        promise.then(() => {
          // configure max bitrate only when media is routed
          // through JVB. For p2p case, browser takes care of
          // adjusting the uplink based on the feedback it
          // gets from the peer.
          if (newTrack && !this.isP2P) {
            this.peerconnection.setMaxBitRate(newTrack);
          }

          finishedCallback();
        }, finishedCallback
        /* will be called with en error */
        );
      }).catch(err => {
        finishedCallback(err);
      });
    };

    return new Promise((resolve, reject) => {
      this.modificationQueue.push(workFunction, error => {
        if (error) {
          logger.error('Replace track error:', error);
          reject(error);
        } else {
          logger.info('Replace track done!');
          resolve();
        }
      });
    });
  }
  /**
   * Parse the information from the xml sourceRemoveElem and translate it
   *  into sdp lines
   * @param {jquery xml element} sourceRemoveElem the source-remove
   *  element from jingle
   * @param {SDP object} currentRemoteSdp the current remote
   *  sdp (as of this new source-remove)
   * @returns {list} a list of SDP line strings that should
   *  be removed from the remote SDP
   */


  _parseSsrcInfoFromSourceRemove(sourceRemoveElem, currentRemoteSdp) {
    const removeSsrcInfo = [];
    $(sourceRemoveElem).each((i1, content) => {
      const name = $(content).attr('name');
      let lines = '';
      $(content).find('ssrc-group[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]').each(function () {
        /* eslint-disable no-invalid-this */
        const semantics = this.getAttribute('semantics');
        const ssrcs = $(this).find('>source').map(function () {
          return this.getAttribute('ssrc');
        }).get();

        if (ssrcs.length) {
          lines += `a=ssrc-group:${semantics} ${ssrcs.join(' ')}\r\n`;
        }
        /* eslint-enable no-invalid-this */

      });
      const ssrcs = []; // handles both >source and >description>source versions

      const tmp = $(content).find('source[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]');
      tmp.each(function () {
        // eslint-disable-next-line no-invalid-this
        const ssrc = $(this).attr('ssrc');
        ssrcs.push(ssrc);
      });
      currentRemoteSdp.media.forEach((media, i2) => {
        if (!_SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].findLine(media, `a=mid:${name}`)) {
          return;
        }

        if (!removeSsrcInfo[i2]) {
          removeSsrcInfo[i2] = '';
        }

        ssrcs.forEach(ssrc => {
          const ssrcLines = _SDPUtil__WEBPACK_IMPORTED_MODULE_9__["default"].findLines(media, `a=ssrc:${ssrc}`);

          if (ssrcLines.length) {
            removeSsrcInfo[i2] += `${ssrcLines.join('\r\n')}\r\n`;
          }
        });
        removeSsrcInfo[i2] += lines;
      });
    });
    return removeSsrcInfo;
  }
  /**
   * Will print an error if there is any difference, between the SSRCs given
   * in the <tt>oldSDP</tt> and the ones currently described in
   * the peerconnection's local description.
   * @param {string} operationName the operation's name which will be printed
   * in the error message.
   * @param {SDP} oldSDP the old local SDP which will be compared with
   * the current one.
   * @return {boolean} <tt>true</tt> if there was any change or <tt>false</tt>
   * otherwise.
   * @private
   */


  _verifyNoSSRCChanged(operationName, oldSDP) {
    const currentLocalSDP = new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](this.peerconnection.localDescription.sdp);
    let sdpDiff = new _SDPDiffer__WEBPACK_IMPORTED_MODULE_8__["default"](oldSDP, currentLocalSDP);
    const addedMedia = sdpDiff.getNewMedia();

    if (Object.keys(addedMedia).length) {
      logger.error(`${this} - some SSRC were added on ${operationName}`, addedMedia);
      return false;
    }

    sdpDiff = new _SDPDiffer__WEBPACK_IMPORTED_MODULE_8__["default"](currentLocalSDP, oldSDP);
    const removedMedia = sdpDiff.getNewMedia();

    if (Object.keys(removedMedia).length) {
      logger.error(`${this} - some SSRCs were removed on ${operationName}`, removedMedia);
      return false;
    }

    return true;
  }
  /**
   * Adds local track back to this session, as part of the unmute operation.
   * @param {JitsiLocalTrack} track
   * @return {Promise} a promise that will resolve once the local track is
   * added back to this session and renegotiation succeeds. Will be rejected
   * with a <tt>string</tt> that provides some error details in case something
   * goes wrong.
   */


  addTrackAsUnmute(track) {
    return this._addRemoveTrackAsMuteUnmute(false
    /* add as unmute */
    , track);
  }
  /**
   * Remove local track as part of the mute operation.
   * @param {JitsiLocalTrack} track the local track to be removed
   * @return {Promise} a promise which will be resolved once the local track
   * is removed from this session and the renegotiation is performed.
   * The promise will be rejected with a <tt>string</tt> that the describes
   * the error if anything goes wrong.
   */


  removeTrackAsMute(track) {
    return this._addRemoveTrackAsMuteUnmute(true
    /* remove as mute */
    , track);
  }
  /**
   * See {@link addTrackAsUnmute} and {@link removeTrackAsMute}.
   * @param {boolean} isMute <tt>true</tt> for "remove as mute" or
   * <tt>false</tt> for "add as unmute".
   * @param {JitsiLocalTrack} track the track that will be added/removed
   * @private
   */


  _addRemoveTrackAsMuteUnmute(isMute, track) {
    if (!track) {
      return Promise.reject('invalid "track" argument value');
    }

    const operationName = isMute ? 'removeTrackMute' : 'addTrackUnmute';

    const workFunction = finishedCallback => {
      const tpc = this.peerconnection;

      if (!tpc) {
        finishedCallback(`Error:  tried ${operationName} track with no active peer` + 'connection');
        return;
      }

      const oldLocalSDP = tpc.localDescription.sdp;
      const operationPromise = isMute ? tpc.removeTrackMute(track) : tpc.addTrackUnmute(track);
      operationPromise.then(shouldRenegotiate => {
        if (shouldRenegotiate && oldLocalSDP && tpc.remoteDescription.sdp) {
          this._renegotiate().then(() => {
            // The results are ignored, as this check failure is not
            // enough to fail the whole operation. It will log
            // an error inside.
            this._verifyNoSSRCChanged(operationName, new _SDP__WEBPACK_IMPORTED_MODULE_7__["default"](oldLocalSDP));

            finishedCallback();
          });
        } else {
          finishedCallback();
        }
      }, finishedCallback
      /* will be called with an error */
      );
    };

    return new Promise((resolve, reject) => {
      this.modificationQueue.push(workFunction, error => {
        if (error) {
          reject(error);
        } else {
          resolve();
        }
      });
    });
  }
  /**
   * Resumes or suspends media transfer over the underlying peer connection.
   * @param {boolean} audioActive <tt>true</tt> to enable audio media
   * transfer or <tt>false</tt> to suspend audio media transmission.
   * @param {boolean} videoActive <tt>true</tt> to enable video media
   * transfer or <tt>false</tt> to suspend video media transmission.
   * @return {Promise} a <tt>Promise</tt> which will resolve once
   * the operation is done. It will be rejected with an error description as
   * a string in case anything goes wrong.
   */


  setMediaTransferActive(audioActive, videoActive) {
    if (!this.peerconnection) {
      return Promise.reject('Can not modify transfer active state,' + ' before "initialize" is called');
    }

    const logAudioStr = audioActive ? 'audio active' : 'audio inactive';
    const logVideoStr = videoActive ? 'video active' : 'video inactive';
    logger.info(`Queued make ${logVideoStr}, ${logAudioStr} task...`);

    const workFunction = finishedCallback => {
      const isSessionActive = this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__["ACTIVE"]; // Because the value is modified on the queue it's impossible to
      // check it's final value reliably prior to submitting the task.
      // The rule here is that the last submitted state counts.
      // Check the values here to avoid unnecessary renegotiation cycle.

      const audioActiveChanged = this.peerconnection.setAudioTransferActive(audioActive);

      if (this._localVideoActive !== videoActive) {
        this._localVideoActive = videoActive; // Do only for P2P - Jicofo will reply with 'bad-request'
        // We don't want to send 'content-modify', before the initial
        // O/A (state === JingleSessionState.ACTIVE), because that will
        // mess up video media direction in the remote SDP.
        // 'content-modify' when processed only affects the media
        // direction in the local SDP. We're doing that, because setting
        // 'inactive' on video media in remote SDP will mess up our SDP
        // translation chain (simulcast, RTX, video mute etc.).

        if (this.isP2P && isSessionActive) {
          this.sendContentModify(videoActive);
        }
      }

      const pcVideoActiveChanged = this.peerconnection.setVideoTransferActive(this._localVideoActive && this._remoteVideoActive); // Will do the sRD/sLD cycle to update SDPs and adjust the media
      // direction

      if (isSessionActive && (audioActiveChanged || pcVideoActiveChanged)) {
        this._renegotiate().then(finishedCallback, finishedCallback
        /* will be called with an error */
        );
      } else {
        finishedCallback();
      }
    };

    return new Promise((resolve, reject) => {
      this.modificationQueue.push(workFunction, error => {
        if (error) {
          reject(error);
        } else {
          resolve();
        }
      });
    });
  }
  /**
   * Will put and execute on the queue a session modify task. Currently it
   * only checks the senders attribute of the video content in order to figure
   * out if the remote peer has video in the inactive state (stored locally
   * in {@link _remoteVideoActive} - see field description for more info).
   * @param {jQuery} jingleContents jQuery selector pointing to the jingle
   * element of the session modify IQ.
   * @see {@link _remoteVideoActive}
   * @see {@link _localVideoActive}
   */


  modifyContents(jingleContents) {
    const newVideoSenders = JingleSessionPC.parseVideoSenders(jingleContents);

    if (newVideoSenders === null) {
      logger.error(`${this} - failed to parse video "senders" attribute in` + '"content-modify" action');
      return;
    }

    const workFunction = finishedCallback => {
      if (this._assertNotEnded('content-modify') && this._modifyRemoteVideoActive(newVideoSenders)) {
        // Will do the sRD/sLD cycle to update SDPs and adjust
        // the media direction
        this._renegotiate().then(finishedCallback, finishedCallback
        /* (error) */
        );
      } else {
        finishedCallback();
      }
    };

    logger.debug(`${this} queued "content-modify" task` + `(video senders="${newVideoSenders}")`);
    this.modificationQueue.push(workFunction, error => {
      if (error) {
        logger.error('"content-modify" failed', error);
      }
    });
  }
  /**
   * Processes new value of remote video "senders" Jingle attribute and tries
   * to apply it for {@link _remoteVideoActive}.
   * @param {string} remoteVideoSenders the value of "senders" attribute of
   * Jingle video content element advertised by remote peer.
   * @return {boolean} <tt>true</tt> if the change affected state of
   * the underlying peerconnection and renegotiation is required for
   * the changes to take effect.
   * @private
   */


  _modifyRemoteVideoActive(remoteVideoSenders) {
    const isRemoteVideoActive = remoteVideoSenders === 'both' || remoteVideoSenders === 'initiator' && this.isInitiator || remoteVideoSenders === 'responder' && !this.isInitiator;

    if (isRemoteVideoActive !== this._remoteVideoActive) {
      logger.debug(`${this} new remote video active: ${isRemoteVideoActive}`);
      this._remoteVideoActive = isRemoteVideoActive;
    }

    return this.peerconnection.setVideoTransferActive(this._localVideoActive && this._remoteVideoActive);
  }
  /**
   * Figures out added/removed ssrcs and send update IQs.
   * @param oldSDP SDP object for old description.
   * @param newSDP SDP object for new description.
   */


  notifyMySSRCUpdate(oldSDP, newSDP) {
    if (this.state !== _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__["ACTIVE"]) {
      logger.warn(`Skipping SSRC update in '${this.state} ' state.`);
      return;
    }

    if (!this.connection.connected) {
      // The goal is to compare the oldest SDP with the latest one upon reconnect
      if (!this._cachedOldLocalSdp) {
        this._cachedOldLocalSdp = oldSDP;
      }

      this._cachedNewLocalSdp = newSDP;
      logger.warn('Not sending SSRC update while the signaling is disconnected');
      return;
    }

    this._cachedOldLocalSdp = undefined;
    this._cachedNewLocalSdp = undefined; // send source-remove IQ.

    let sdpDiffer = new _SDPDiffer__WEBPACK_IMPORTED_MODULE_8__["default"](newSDP, oldSDP);
    const remove = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      to: this.remoteJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: 'source-remove',
      initiator: this.initiatorJid,
      sid: this.sid
    });
    const removedAnySSRCs = sdpDiffer.toJingle(remove);

    if (removedAnySSRCs) {
      logger.info('Sending source-remove', remove.tree());
      this.connection.sendIQ(remove, null, this.newJingleErrorHandler(remove), IQ_TIMEOUT);
    } else {
      logger.log('removal not necessary');
    } // send source-add IQ.


    sdpDiffer = new _SDPDiffer__WEBPACK_IMPORTED_MODULE_8__["default"](oldSDP, newSDP);
    const add = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      to: this.remoteJid,
      type: 'set'
    }).c('jingle', {
      xmlns: 'urn:xmpp:jingle:1',
      action: 'source-add',
      initiator: this.initiatorJid,
      sid: this.sid
    });
    const containsNewSSRCs = sdpDiffer.toJingle(add);

    if (containsNewSSRCs) {
      logger.info('Sending source-add', add.tree());
      this.connection.sendIQ(add, null, this.newJingleErrorHandler(add), IQ_TIMEOUT);
    } else {
      logger.log('addition not necessary');
    }
  }
  /**
   * Method returns function(errorResponse) which is a callback to be passed
   * to Strophe connection.sendIQ method. An 'error' structure is created that
   * is passed as 1st argument to given <tt>failureCb</tt>. The format of this
   * structure is as follows:
   * {
   *  code: {XMPP error response code}
   *  reason: {the name of XMPP error reason element or 'timeout' if the
    *          request has timed out within <tt>IQ_TIMEOUT</tt> milliseconds}
   *  source: {request.tree() that provides original request}
   *  session: {this JingleSessionPC.toString()}
   * }
   * @param request Strophe IQ instance which is the request to be dumped into
   *        the error structure
   * @param failureCb function(error) called when error response was returned
   *        or when a timeout has occurred.
   * @returns {function(this:JingleSessionPC)}
   */


  newJingleErrorHandler(request, failureCb) {
    return errResponse => {
      const error = {}; // Get XMPP error code and condition(reason)

      const errorElSel = $(errResponse).find('error');

      if (errorElSel.length) {
        error.code = errorElSel.attr('code');
        const errorReasonSel = $(errResponse).find('error :first');

        if (errorReasonSel.length) {
          error.reason = errorReasonSel[0].tagName;
        }

        const errorMsgSel = errorElSel.find('>text');

        if (errorMsgSel.length) {
          error.msg = errorMsgSel.text();
        }
      }

      if (!errResponse) {
        error.reason = 'timeout';
      }

      error.session = this.toString();

      if (failureCb) {
        failureCb(error);
      } else if (this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__["ENDED"] && error.reason === 'item-not-found') {
        // When remote peer decides to terminate the session, but it
        // still have few messages on the queue for processing,
        // it will first send us 'session-terminate' (we enter ENDED)
        // and then follow with 'item-not-found' for the queued requests
        // We don't want to have that logged on error level.
        logger.debug(`Jingle error: ${JSON.stringify(error)}`);
      } else {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_15___default.a.callErrorHandler(new Error(`Jingle error: ${JSON.stringify(error)}`));
      }
    };
  }
  /**
   * Returns the ice connection state for the peer connection.
   * @returns the ice connection state for the peer connection.
   */


  getIceConnectionState() {
    return this.peerconnection.iceConnectionState;
  }
  /**
   * Closes the peerconnection.
   */


  close() {
    this.state = _JingleSessionState__WEBPACK_IMPORTED_MODULE_6__["ENDED"];
    this.establishmentDuration = undefined;

    if (this.peerconnection) {
      this.peerconnection.onicecandidate = null;
      this.peerconnection.oniceconnectionstatechange = null;
      this.peerconnection.onnegotiationneeded = null;
      this.peerconnection.onsignalingstatechange = null;
    } // Remove any pending tasks from the queue


    this.modificationQueue.clear();
    this.modificationQueue.push(finishCallback => {
      // The signaling layer will remove it's listeners
      this.signalingLayer.setChatRoom(null); // do not try to close if already closed.

      this.peerconnection && this.peerconnection.close();
      finishCallback();
    }); // No more tasks can go in after the close task

    this.modificationQueue.shutdown();
  }
  /**
   * Converts to string with minor summary.
   * @return {string}
   */


  toString() {
    return `JingleSessionPC[p2p=${this.isP2P},` + `initiator=${this.isInitiator},sid=${this.sid}]`;
  }
  /**
   * If the A/B test for suspend video is disabled according to the room's
   * configuration, returns undefined. Otherwise returns a boolean which
   * indicates whether the suspend video option should be enabled or disabled.
   * @param {JingleSessionPCOptions} options - The config options.
   */


  _abtestSuspendVideoEnabled({
    abTesting
  }) {
    if (!abTesting || !abTesting.enableSuspendVideoTest) {
      return;
    } // We want the two participants in a P2P call to agree on the value of
    // the "suspend" option. We use the JID of the initiator, because it is
    // both randomly selected and agreed upon by both participants.


    const jid = this._getInitiatorJid();

    return Object(_util_StringUtils__WEBPACK_IMPORTED_MODULE_3__["integerHash"])(jid) % 2 === 0;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\JingleSessionPC.js"))

/***/ }),

/***/ "./modules/xmpp/JingleSessionState.js":
/*!********************************************!*\
  !*** ./modules/xmpp/JingleSessionState.js ***!
  \********************************************/
/*! exports provided: PENDING, ACTIVE, ENDED */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PENDING", function() { return PENDING; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTIVE", function() { return ACTIVE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ENDED", function() { return ENDED; });
/**
 * The pending Jingle session state which means the session as defined in
 * XEP-0166(before 'session-invite/session-accept' took place).
 *
 * @type {string}
 */
const PENDING = 'pending';
/**
 * The active Jingle session state as defined in XEP-0166
 * (after 'session-invite'/'session-accept').
 *
 * @type {string}
 */

const ACTIVE = 'active';
/**
 * The ended Jingle session state as defined in XEP-0166
 * (after 'session-terminate').
 * @type {string}
 */

const ENDED = 'ended';

/***/ }),

/***/ "./modules/xmpp/RtxModifier.js":
/*!*************************************!*\
  !*** ./modules/xmpp/RtxModifier.js ***!
  \*************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return RtxModifier; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./SdpTransformUtil */ "./modules/xmpp/SdpTransformUtil.js");
/* harmony import */ var _SDPUtil__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SDPUtil */ "./modules/xmpp/SDPUtil.js");
/* global __filename */



const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Begin helper functions
 */

/**
 * Updates or inserts the appropriate rtx information for primarySsrc with
 *  the given rtxSsrc.  If no rtx ssrc for primarySsrc currently exists, it will
 *  add the appropriate ssrc and ssrc group lines.  If primarySsrc already has
 *  an rtx ssrc, the appropriate ssrc and group lines will be updated
 * @param {MLineWrap} mLine
 * @param {object} primarySsrcInfo the info (ssrc, msid & cname) for the
 *  primary ssrc
 * @param {number} rtxSsrc the rtx ssrc to associate with the primary ssrc
 */

function updateAssociatedRtxStream(mLine, primarySsrcInfo, rtxSsrc) {
  logger.debug(`Updating mline to associate ${rtxSsrc}` + `rtx ssrc with primary stream, ${primarySsrcInfo.id}`);
  const primarySsrc = primarySsrcInfo.id;
  const primarySsrcMsid = primarySsrcInfo.msid;
  const primarySsrcCname = primarySsrcInfo.cname;
  const previousRtxSSRC = mLine.getRtxSSRC(primarySsrc);

  if (previousRtxSSRC === rtxSsrc) {
    logger.debug(`${rtxSsrc} was already associated with ${primarySsrc}`);
    return;
  }

  if (previousRtxSSRC) {
    logger.debug(`${primarySsrc} was previously associated with rtx` + `${previousRtxSSRC}, removing all references to it`); // Stream already had an rtx ssrc that is different than the one given,
    //  remove all trace of the old one

    mLine.removeSSRC(previousRtxSSRC);
    logger.debug(`groups before filtering for ${previousRtxSSRC}`);
    logger.debug(mLine.dumpSSRCGroups());
    mLine.removeGroupsWithSSRC(previousRtxSSRC);
  }

  mLine.addSSRCAttribute({
    id: rtxSsrc,
    attribute: 'cname',
    value: primarySsrcCname
  });
  mLine.addSSRCAttribute({
    id: rtxSsrc,
    attribute: 'msid',
    value: primarySsrcMsid
  });
  mLine.addSSRCGroup({
    semantics: 'FID',
    ssrcs: `${primarySsrc} ${rtxSsrc}`
  });
}
/**
 * End helper functions
 */

/**
 * Adds any missing RTX streams for video streams
 *  and makes sure that they remain consistent
 */


class RtxModifier {
  /**
   * Constructor
   */
  constructor() {
    /**
     * Map of video ssrc to corresponding RTX
     *  ssrc
     */
    this.correspondingRtxSsrcs = new Map();
  }
  /**
   * Clear the cached map of primary video ssrcs to
   *  their corresponding rtx ssrcs so that they will
   *  not be used for the next call to modifyRtxSsrcs
   */


  clearSsrcCache() {
    this.correspondingRtxSsrcs.clear();
  }
  /**
   * Explicitly set the primary video ssrc -> rtx ssrc
   *  mapping to be used in modifyRtxSsrcs
   * @param {Map} ssrcMapping a mapping of primary video
   *  ssrcs to their corresponding rtx ssrcs
   */


  setSsrcCache(ssrcMapping) {
    logger.debug('Setting ssrc cache to ', ssrcMapping);
    this.correspondingRtxSsrcs = ssrcMapping;
  }
  /**
   * Adds RTX ssrcs for any video ssrcs that don't
   *  already have them.  If the video ssrc has been
   *  seen before, and already had an RTX ssrc generated,
   *  the same RTX ssrc will be used again.
   * @param {string} sdpStr sdp in raw string format
   */


  modifyRtxSsrcs(sdpStr) {
    const sdpTransformer = new _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_1__["SdpTransformWrap"](sdpStr);
    const videoMLine = sdpTransformer.selectMedia('video');

    if (!videoMLine) {
      logger.debug(`No 'video' media found in the sdp: ${sdpStr}`);
      return sdpStr;
    }

    return this.modifyRtxSsrcs2(videoMLine) ? sdpTransformer.toRawSDP() : sdpStr;
  }
  /**
   * Does the same thing as {@link modifyRtxSsrcs}, but takes the
   *  {@link MLineWrap} instance wrapping video media as an argument.
   * @param {MLineWrap} videoMLine
   * @return {boolean} <tt>true</tt> if the SDP wrapped by
   *  {@link SdpTransformWrap} has been modified or <tt>false</tt> otherwise.
   */


  modifyRtxSsrcs2(videoMLine) {
    if (videoMLine.direction === 'recvonly') {
      logger.debug('RtxModifier doing nothing, video m line is recvonly');
      return false;
    }

    if (videoMLine.getSSRCCount() < 1) {
      logger.debug('RtxModifier doing nothing, no video ssrcs present');
      return false;
    }

    logger.debug('Current ssrc mapping: ', this.correspondingRtxSsrcs);
    const primaryVideoSsrcs = videoMLine.getPrimaryVideoSSRCs();
    logger.debug('Parsed primary video ssrcs ', primaryVideoSsrcs, ' making sure all have rtx streams');

    for (const ssrc of primaryVideoSsrcs) {
      const msid = videoMLine.getSSRCAttrValue(ssrc, 'msid');
      const cname = videoMLine.getSSRCAttrValue(ssrc, 'cname');
      let correspondingRtxSsrc = this.correspondingRtxSsrcs.get(ssrc);

      if (correspondingRtxSsrc) {
        logger.debug('Already have an associated rtx ssrc for' + `video ssrc ${ssrc}: ${correspondingRtxSsrc}`);
      } else {
        logger.debug(`No previously associated rtx ssrc for video ssrc ${ssrc}`); // If there's one in the sdp already for it, we'll just set
        //  that as the corresponding one

        const previousAssociatedRtxStream = videoMLine.getRtxSSRC(ssrc);

        if (previousAssociatedRtxStream) {
          logger.debug(`Rtx stream ${previousAssociatedRtxStream} ` + 'already existed in the sdp as an rtx stream for ' + `${ssrc}`);
          correspondingRtxSsrc = previousAssociatedRtxStream;
        } else {
          correspondingRtxSsrc = _SDPUtil__WEBPACK_IMPORTED_MODULE_2__["default"].generateSsrc();
          logger.debug(`Generated rtx ssrc ${correspondingRtxSsrc} ` + `for ssrc ${ssrc}`);
        }

        logger.debug(`Caching rtx ssrc ${correspondingRtxSsrc} ` + `for video ssrc ${ssrc}`);
        this.correspondingRtxSsrcs.set(ssrc, correspondingRtxSsrc);
      }

      updateAssociatedRtxStream(videoMLine, {
        id: ssrc,
        cname,
        msid
      }, correspondingRtxSsrc);
    } // FIXME we're not looking into much details whether the SDP has been
    // modified or not once the precondition requirements are met.


    return true;
  }
  /**
   * Strip all rtx streams from the given sdp
   * @param {string} sdpStr sdp in raw string format
   * @returns {string} sdp string with all rtx streams stripped
   */


  stripRtx(sdpStr) {
    const sdpTransformer = new _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_1__["SdpTransformWrap"](sdpStr);
    const videoMLine = sdpTransformer.selectMedia('video');

    if (!videoMLine) {
      logger.debug(`No 'video' media found in the sdp: ${sdpStr}`);
      return sdpStr;
    }

    if (videoMLine.direction === 'recvonly') {
      logger.debug('RtxModifier doing nothing, video m line is recvonly');
      return sdpStr;
    }

    if (videoMLine.getSSRCCount() < 1) {
      logger.debug('RtxModifier doing nothing, no video ssrcs present');
      return sdpStr;
    }

    if (!videoMLine.containsAnySSRCGroups()) {
      logger.debug('RtxModifier doing nothing, ' + 'no video ssrcGroups present');
      return sdpStr;
    }

    const fidGroups = videoMLine.findGroups('FID'); // Remove the fid groups from the mline

    videoMLine.removeGroupsBySemantics('FID'); // Get the rtx ssrcs and remove them from the mline

    for (const fidGroup of fidGroups) {
      const rtxSsrc = Object(_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_1__["parseSecondarySSRC"])(fidGroup);
      videoMLine.removeSSRC(rtxSsrc);
    }

    return sdpTransformer.toRawSDP();
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\RtxModifier.js"))

/***/ }),

/***/ "./modules/xmpp/SDP.js":
/*!*****************************!*\
  !*** ./modules/xmpp/SDP.js ***!
  \*****************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return SDP; });
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _SDPUtil__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./SDPUtil */ "./modules/xmpp/SDPUtil.js");
/* global $ */


/**
 *
 * @param sdp
 */

function SDP(sdp) {
  const media = sdp.split('\r\nm=');

  for (let i = 1, length = media.length; i < length; i++) {
    let mediaI = `m=${media[i]}`;

    if (i !== length - 1) {
      mediaI += '\r\n';
    }

    media[i] = mediaI;
  }

  const session = `${media.shift()}\r\n`;
  this.media = media;
  this.raw = session + media.join('');
  this.session = session;
}
/**
 * A flag will make {@link transportToJingle} and {@link jingle2media} replace
 * ICE candidates IPs with invalid value of '1.1.1.1' which will cause ICE
 * failure. The flag is used in the automated testing.
 * @type {boolean}
 */

SDP.prototype.failICE = false;
/**
 * Whether or not to remove TCP ice candidates when translating from/to jingle.
 * @type {boolean}
 */

SDP.prototype.removeTcpCandidates = false;
/**
 * Whether or not to remove UDP ice candidates when translating from/to jingle.
 * @type {boolean}
 */

SDP.prototype.removeUdpCandidates = false;
/**
 * Returns map of MediaChannel mapped per channel idx.
 */

SDP.prototype.getMediaSsrcMap = function () {
  const self = this;
  const mediaSSRCs = {};
  let tmp;

  for (let mediaindex = 0; mediaindex < self.media.length; mediaindex++) {
    tmp = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(self.media[mediaindex], 'a=ssrc:');
    const mid = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseMID(_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(self.media[mediaindex], 'a=mid:'));
    const media = {
      mediaindex,
      mid,
      ssrcs: {},
      ssrcGroups: []
    };
    mediaSSRCs[mediaindex] = media;
    tmp.forEach(line => {
      const linessrc = line.substring(7).split(' ')[0]; // allocate new ChannelSsrc

      if (!media.ssrcs[linessrc]) {
        media.ssrcs[linessrc] = {
          ssrc: linessrc,
          lines: []
        };
      }

      media.ssrcs[linessrc].lines.push(line);
    });
    tmp = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(self.media[mediaindex], 'a=ssrc-group:');
    tmp.forEach(line => {
      const idx = line.indexOf(' ');
      const semantics = line.substr(0, idx).substr(13);
      const ssrcs = line.substr(14 + semantics.length).split(' ');

      if (ssrcs.length) {
        media.ssrcGroups.push({
          semantics,
          ssrcs
        });
      }
    });
  }

  return mediaSSRCs;
};
/**
 * Returns <tt>true</tt> if this SDP contains given SSRC.
 * @param ssrc the ssrc to check.
 * @returns {boolean} <tt>true</tt> if this SDP contains given SSRC.
 */


SDP.prototype.containsSSRC = function (ssrc) {
  // FIXME this code is really strange - improve it if you can
  const medias = this.getMediaSsrcMap();
  let result = false;
  Object.keys(medias).forEach(mediaindex => {
    if (result) {
      return;
    }

    if (medias[mediaindex].ssrcs[ssrc]) {
      result = true;
    }
  });
  return result;
}; // remove iSAC and CN from SDP


SDP.prototype.mangle = function () {
  let i, j, lines, mline, newdesc, rtpmap;

  for (i = 0; i < this.media.length; i++) {
    lines = this.media[i].split('\r\n');
    lines.pop(); // remove empty last element

    mline = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseMLine(lines.shift());

    if (mline.media !== 'audio') {
      continue; // eslint-disable-line no-continue
    }

    newdesc = '';
    mline.fmt.length = 0;

    for (j = 0; j < lines.length; j++) {
      if (lines[j].substr(0, 9) === 'a=rtpmap:') {
        rtpmap = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseRTPMap(lines[j]);

        if (rtpmap.name === 'CN' || rtpmap.name === 'ISAC') {
          continue; // eslint-disable-line no-continue
        }

        mline.fmt.push(rtpmap.id);
      }

      newdesc += `${lines[j]}\r\n`;
    }

    this.media[i] = `${_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].buildMLine(mline)}\r\n${newdesc}`;
  }

  this.raw = this.session + this.media.join('');
}; // remove lines matching prefix from session section


SDP.prototype.removeSessionLines = function (prefix) {
  const self = this;
  const lines = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.session, prefix);
  lines.forEach(line => {
    self.session = self.session.replace(`${line}\r\n`, '');
  });
  this.raw = this.session + this.media.join('');
  return lines;
}; // remove lines matching prefix from a media section specified by mediaindex
// TODO: non-numeric mediaindex could match mid


SDP.prototype.removeMediaLines = function (mediaindex, prefix) {
  const self = this;
  const lines = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.media[mediaindex], prefix);
  lines.forEach(line => {
    self.media[mediaindex] = self.media[mediaindex].replace(`${line}\r\n`, '');
  });
  this.raw = this.session + this.media.join('');
  return lines;
}; // add content's to a jingle element


SDP.prototype.toJingle = function (elem, thecreator) {
  let i, j, k, lines, mline, rtpmap, ssrc, tmp; // new bundle plan

  lines = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.session, 'a=group:');

  if (lines.length) {
    for (i = 0; i < lines.length; i++) {
      tmp = lines[i].split(' ');
      const semantics = tmp.shift().substr(8);
      elem.c('group', {
        xmlns: 'urn:xmpp:jingle:apps:grouping:0',
        semantics
      });

      for (j = 0; j < tmp.length; j++) {
        elem.c('content', {
          name: tmp[j]
        }).up();
      }

      elem.up();
    }
  }

  for (i = 0; i < this.media.length; i++) {
    mline = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseMLine(this.media[i].split('\r\n')[0]);

    if (!(mline.media === 'audio' || mline.media === 'video' || mline.media === 'application')) {
      continue; // eslint-disable-line no-continue
    }

    const assrcline = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(this.media[i], 'a=ssrc:');

    if (assrcline) {
      ssrc = assrcline.substring(7).split(' ')[0]; // take the first
    } else {
      ssrc = false;
    }

    elem.c('content', {
      creator: thecreator,
      name: mline.media
    });
    const amidline = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(this.media[i], 'a=mid:');

    if (amidline) {
      // prefer identifier from a=mid if present
      const mid = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseMID(amidline);
      elem.attrs({
        name: mid
      });
    }

    if (_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(this.media[i], 'a=rtpmap:').length) {
      elem.c('description', {
        xmlns: 'urn:xmpp:jingle:apps:rtp:1',
        media: mline.media
      });

      if (ssrc) {
        elem.attrs({
          ssrc
        });
      }

      for (j = 0; j < mline.fmt.length; j++) {
        rtpmap = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(this.media[i], `a=rtpmap:${mline.fmt[j]}`);
        elem.c('payload-type', _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseRTPMap(rtpmap)); // put any 'a=fmtp:' + mline.fmt[j] lines into <param name=foo
        // value=bar/>

        const afmtpline = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(this.media[i], `a=fmtp:${mline.fmt[j]}`);

        if (afmtpline) {
          tmp = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseFmtp(afmtpline); // eslint-disable-next-line max-depth

          for (k = 0; k < tmp.length; k++) {
            elem.c('parameter', tmp[k]).up();
          }
        } // XEP-0293 -- map a=rtcp-fb


        this.rtcpFbToJingle(i, elem, mline.fmt[j]);
        elem.up();
      }

      const crypto = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.media[i], 'a=crypto:', this.session);

      if (crypto.length) {
        elem.c('encryption', {
          required: 1
        });
        crypto.forEach(line => elem.c('crypto', _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseCrypto(line)).up());
        elem.up(); // end of encryption
      }

      if (ssrc) {
        const ssrcMap = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseSSRC(this.media[i]);

        for (const [availableSsrc, ssrcParameters] of ssrcMap) {
          elem.c('source', {
            ssrc: availableSsrc,
            xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
          });
          ssrcParameters.forEach(ssrcSdpLine => {
            // get everything after first space
            const idx = ssrcSdpLine.indexOf(' ');
            const kv = ssrcSdpLine.substr(idx + 1);
            elem.c('parameter');

            if (kv.indexOf(':') === -1) {
              elem.attrs({
                name: kv
              });
            } else {
              const name = kv.split(':', 2)[0];
              elem.attrs({
                name
              });
              let v = kv.split(':', 2)[1];
              v = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].filterSpecialChars(v);
              elem.attrs({
                value: v
              });
            }

            elem.up();
          });
          elem.up();
        } // XEP-0339 handle ssrc-group attributes


        const ssrcGroupLines = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.media[i], 'a=ssrc-group:');
        ssrcGroupLines.forEach(line => {
          const idx = line.indexOf(' ');
          const semantics = line.substr(0, idx).substr(13);
          const ssrcs = line.substr(14 + semantics.length).split(' ');

          if (ssrcs.length) {
            elem.c('ssrc-group', {
              semantics,
              xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
            });
            ssrcs.forEach(s => elem.c('source', {
              ssrc: s
            }).up());
            elem.up();
          }
        });
      }

      const ridLines = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.media[i], 'a=rid');

      if (ridLines.length && _browser__WEBPACK_IMPORTED_MODULE_0__["default"].usesRidsForSimulcast()) {
        // Map a line which looks like "a=rid:2 send" to just
        // the rid ("2")
        const rids = ridLines.map(ridLine => ridLine.split(':')[1]).map(ridInfo => ridInfo.split(' ')[0]);
        rids.forEach(rid => {
          elem.c('source', {
            rid,
            xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
          });
          elem.up();
        });
        const unifiedSimulcast = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(this.media[i], 'a=simulcast');

        if (unifiedSimulcast) {
          elem.c('rid-group', {
            semantics: 'SIM',
            xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
          });
          rids.forEach(rid => {
            elem.c('source', {
              rid
            }).up();
          });
          elem.up();
        }
      }

      if (_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(this.media[i], 'a=rtcp-mux')) {
        elem.c('rtcp-mux').up();
      } // XEP-0293 -- map a=rtcp-fb:*


      this.rtcpFbToJingle(i, elem, '*'); // XEP-0294

      lines = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.media[i], 'a=extmap:');

      if (lines.length) {
        for (j = 0; j < lines.length; j++) {
          tmp = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseExtmap(lines[j]);
          elem.c('rtp-hdrext', {
            xmlns: 'urn:xmpp:jingle:apps:rtp:rtp-hdrext:0',
            uri: tmp.uri,
            id: tmp.value
          }); // eslint-disable-next-line max-depth

          if (tmp.hasOwnProperty('direction')) {
            // eslint-disable-next-line max-depth
            switch (tmp.direction) {
              case 'sendonly':
                elem.attrs({
                  senders: 'responder'
                });
                break;

              case 'recvonly':
                elem.attrs({
                  senders: 'initiator'
                });
                break;

              case 'sendrecv':
                elem.attrs({
                  senders: 'both'
                });
                break;

              case 'inactive':
                elem.attrs({
                  senders: 'none'
                });
                break;
            }
          } // TODO: handle params


          elem.up();
        }
      }

      elem.up(); // end of description
    } // map ice-ufrag/pwd, dtls fingerprint, candidates


    this.transportToJingle(i, elem);
    const m = this.media[i];

    if (_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(m, 'a=sendrecv', this.session)) {
      elem.attrs({
        senders: 'both'
      });
    } else if (_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(m, 'a=sendonly', this.session)) {
      elem.attrs({
        senders: 'initiator'
      });
    } else if (_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(m, 'a=recvonly', this.session)) {
      elem.attrs({
        senders: 'responder'
      });
    } else if (_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(m, 'a=inactive', this.session)) {
      elem.attrs({
        senders: 'none'
      });
    } // Reject an m-line only when port is 0 and a=bundle-only is not present in the section.
    // The port is automatically set to 0 when bundle-only is used.


    if (mline.port === '0' && !_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(m, 'a=bundle-only', this.session)) {
      // estos hack to reject an m-line
      elem.attrs({
        senders: 'rejected'
      });
    }

    elem.up(); // end of content
  }

  elem.up();
  return elem;
};

SDP.prototype.transportToJingle = function (mediaindex, elem) {
  let tmp;
  const self = this;
  elem.c('transport'); // XEP-0343 DTLS/SCTP

  const sctpmap = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(this.media[mediaindex], 'a=sctpmap:', self.session);

  if (sctpmap) {
    const sctpAttrs = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseSCTPMap(sctpmap);
    elem.c('sctpmap', {
      xmlns: 'urn:xmpp:jingle:transports:dtls-sctp:1',
      number: sctpAttrs[0],

      /* SCTP port */
      protocol: sctpAttrs[1]
      /* protocol */

    }); // Optional stream count attribute

    if (sctpAttrs.length > 2) {
      elem.attrs({
        streams: sctpAttrs[2]
      });
    }

    elem.up();
  } // XEP-0320


  const fingerprints = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.media[mediaindex], 'a=fingerprint:', this.session);
  fingerprints.forEach(line => {
    tmp = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseFingerprint(line);
    tmp.xmlns = 'urn:xmpp:jingle:apps:dtls:0';
    elem.c('fingerprint').t(tmp.fingerprint);
    delete tmp.fingerprint; // eslint-disable-next-line no-param-reassign

    line = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLine(self.media[mediaindex], 'a=setup:', self.session);

    if (line) {
      tmp.setup = line.substr(8);
    }

    elem.attrs(tmp);
    elem.up(); // end of fingerprint
  });
  tmp = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].iceparams(this.media[mediaindex], this.session);

  if (tmp) {
    tmp.xmlns = 'urn:xmpp:jingle:transports:ice-udp:1';
    elem.attrs(tmp); // XEP-0176

    const lines = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.media[mediaindex], 'a=candidate:', this.session);

    if (lines.length) {
      // add any a=candidate lines
      lines.forEach(line => {
        const candidate = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].candidateToJingle(line);

        if (self.failICE) {
          candidate.ip = '1.1.1.1';
        }

        const protocol = candidate && typeof candidate.protocol === 'string' ? candidate.protocol.toLowerCase() : '';

        if (self.removeTcpCandidates && (protocol === 'tcp' || protocol === 'ssltcp') || self.removeUdpCandidates && protocol === 'udp') {
          return;
        }

        elem.c('candidate', candidate).up();
      });
    }
  }

  elem.up(); // end of transport
}; // XEP-0293


SDP.prototype.rtcpFbToJingle = function (mediaindex, elem, payloadtype) {
  const lines = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].findLines(this.media[mediaindex], `a=rtcp-fb:${payloadtype}`);
  lines.forEach(line => {
    const tmp = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].parseRTCPFB(line);

    if (tmp.type === 'trr-int') {
      elem.c('rtcp-fb-trr-int', {
        xmlns: 'urn:xmpp:jingle:apps:rtp:rtcp-fb:0',
        value: tmp.params[0]
      });
      elem.up();
    } else {
      elem.c('rtcp-fb', {
        xmlns: 'urn:xmpp:jingle:apps:rtp:rtcp-fb:0',
        type: tmp.type
      });

      if (tmp.params.length > 0) {
        elem.attrs({
          'subtype': tmp.params[0]
        });
      }

      elem.up();
    }
  });
};

SDP.prototype.rtcpFbFromJingle = function (elem, payloadtype) {
  // XEP-0293
  let media = '';
  let tmp = elem.find('>rtcp-fb-trr-int[xmlns="urn:xmpp:jingle:apps:rtp:rtcp-fb:0"]');

  if (tmp.length) {
    media += 'a=rtcp-fb:* trr-int ';

    if (tmp.attr('value')) {
      media += tmp.attr('value');
    } else {
      media += '0';
    }

    media += '\r\n';
  }

  tmp = elem.find('>rtcp-fb[xmlns="urn:xmpp:jingle:apps:rtp:rtcp-fb:0"]');
  tmp.each(function () {
    /* eslint-disable no-invalid-this */
    media += `a=rtcp-fb:${payloadtype} ${$(this).attr('type')}`;

    if ($(this).attr('subtype')) {
      media += ` ${$(this).attr('subtype')}`;
    }

    media += '\r\n';
    /* eslint-enable no-invalid-this */
  });
  return media;
}; // construct an SDP from a jingle stanza


SDP.prototype.fromJingle = function (jingle) {
  const self = this;
  const sessionId = Date.now(); // Use a unique session id for every TPC.

  this.raw = 'v=0\r\n' + `o=- ${sessionId} 2 IN IP4 0.0.0.0\r\n` + 's=-\r\n' + 't=0 0\r\n'; // http://tools.ietf.org/html/draft-ietf-mmusic-sdp-bundle-negotiation-04
  // #section-8

  const groups = $(jingle).find('>group[xmlns="urn:xmpp:jingle:apps:grouping:0"]');

  if (groups.length) {
    groups.each((idx, group) => {
      const contents = $(group).find('>content').map((_, content) => content.getAttribute('name')).get();

      if (contents.length > 0) {
        self.raw += `a=group:${group.getAttribute('semantics') || group.getAttribute('type')} ${contents.join(' ')}\r\n`;
      }
    });
  }

  this.session = this.raw;
  jingle.find('>content').each(function () {
    // eslint-disable-next-line no-invalid-this
    const m = self.jingle2media($(this));
    self.media.push(m);
  }); // reconstruct msid-semantic -- apparently not necessary

  /*
   var msid = SDPUtil.parseSSRC(this.raw);
   if (msid.hasOwnProperty('mslabel')) {
   this.session += "a=msid-semantic: WMS " + msid.mslabel + "\r\n";
   }
   */

  this.raw = this.session + this.media.join('');
}; // translate a jingle content element into an an SDP media part


SDP.prototype.jingle2media = function (content) {
  const desc = content.find('description');
  let media = '';
  const self = this;
  const sctp = content.find('>transport>sctpmap[xmlns="urn:xmpp:jingle:transports:dtls-sctp:1"]');
  let tmp = {
    media: desc.attr('media')
  };
  tmp.port = '1';

  if (content.attr('senders') === 'rejected') {
    // estos hack to reject an m-line.
    tmp.port = '0';
  }

  if (content.find('>transport>fingerprint').length || desc.find('encryption').length) {
    tmp.proto = sctp.length ? 'DTLS/SCTP' : 'RTP/SAVPF';
  } else {
    tmp.proto = 'RTP/AVPF';
  }

  if (sctp.length) {
    media += `m=application ${tmp.port} DTLS/SCTP ${sctp.attr('number')}\r\n`;
    media += `a=sctpmap:${sctp.attr('number')} ${sctp.attr('protocol')}`;
    const streamCount = sctp.attr('streams');

    if (streamCount) {
      media += ` ${streamCount}\r\n`;
    } else {
      media += '\r\n';
    }
  } else {
    tmp.fmt = desc.find('payload-type').map(function () {
      // eslint-disable-next-line no-invalid-this
      return this.getAttribute('id');
    }).get();
    media += `${_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].buildMLine(tmp)}\r\n`;
  }

  media += 'c=IN IP4 0.0.0.0\r\n';

  if (!sctp.length) {
    media += 'a=rtcp:1 IN IP4 0.0.0.0\r\n';
  }

  tmp = content.find('>transport[xmlns="urn:xmpp:jingle:transports:ice-udp:1"]');

  if (tmp.length) {
    if (tmp.attr('ufrag')) {
      media += `${_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].buildICEUfrag(tmp.attr('ufrag'))}\r\n`;
    }

    if (tmp.attr('pwd')) {
      media += `${_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].buildICEPwd(tmp.attr('pwd'))}\r\n`;
    }

    tmp.find('>fingerprint').each(function () {
      /* eslint-disable no-invalid-this */
      // FIXME: check namespace at some point
      media += `a=fingerprint:${this.getAttribute('hash')}`;
      media += ` ${$(this).text()}`;
      media += '\r\n';

      if (this.getAttribute('setup')) {
        media += `a=setup:${this.getAttribute('setup')}\r\n`;
      }
      /* eslint-enable no-invalid-this */

    });
  }

  switch (content.attr('senders')) {
    case 'initiator':
      media += 'a=sendonly\r\n';
      break;

    case 'responder':
      media += 'a=recvonly\r\n';
      break;

    case 'none':
      media += 'a=inactive\r\n';
      break;

    case 'both':
      media += 'a=sendrecv\r\n';
      break;
  }

  media += `a=mid:${content.attr('name')}\r\n`; // <description><rtcp-mux/></description>
  // see http://code.google.com/p/libjingle/issues/detail?id=309 -- no spec
  // though
  // and http://mail.jabber.org/pipermail/jingle/2011-December/001761.html

  if (desc.find('rtcp-mux').length) {
    media += 'a=rtcp-mux\r\n';
  }

  if (desc.find('encryption').length) {
    desc.find('encryption>crypto').each(function () {
      /* eslint-disable no-invalid-this */
      media += `a=crypto:${this.getAttribute('tag')}`;
      media += ` ${this.getAttribute('crypto-suite')}`;
      media += ` ${this.getAttribute('key-params')}`;

      if (this.getAttribute('session-params')) {
        media += ` ${this.getAttribute('session-params')}`;
      }

      media += '\r\n';
      /* eslint-enable no-invalid-this */
    });
  }

  desc.find('payload-type').each(function () {
    /* eslint-disable no-invalid-this */
    media += `${_SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].buildRTPMap(this)}\r\n`;

    if ($(this).find('>parameter').length) {
      media += `a=fmtp:${this.getAttribute('id')} `;
      media += $(this).find('parameter').map(function () {
        const name = this.getAttribute('name');
        return (name ? `${name}=` : '') + this.getAttribute('value');
      }).get().join('; ');
      media += '\r\n';
    } // xep-0293


    media += self.rtcpFbFromJingle($(this), this.getAttribute('id'));
    /* eslint-enable no-invalid-this */
  }); // xep-0293

  media += self.rtcpFbFromJingle(desc, '*'); // xep-0294

  tmp = desc.find('>rtp-hdrext[xmlns="urn:xmpp:jingle:apps:rtp:rtp-hdrext:0"]');
  tmp.each(function () {
    /* eslint-disable no-invalid-this */
    media += `a=extmap:${this.getAttribute('id')} ${this.getAttribute('uri')}\r\n`;
    /* eslint-enable no-invalid-this */
  });
  content.find('>transport[xmlns="urn:xmpp:jingle:transports:ice-udp:1"]' + '>candidate').each(function () {
    /* eslint-disable no-invalid-this */
    let protocol = this.getAttribute('protocol');
    protocol = typeof protocol === 'string' ? protocol.toLowerCase() : '';

    if (self.removeTcpCandidates && (protocol === 'tcp' || protocol === 'ssltcp') || self.removeUdpCandidates && protocol === 'udp') {
      return;
    } else if (self.failICE) {
      this.setAttribute('ip', '1.1.1.1');
    }

    media += _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].candidateFromJingle(this);
    /* eslint-enable no-invalid-this */
  }); // XEP-0339 handle ssrc-group attributes

  content.find('description>ssrc-group[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]').each(function () {
    /* eslint-disable no-invalid-this */
    const semantics = this.getAttribute('semantics');
    const ssrcs = $(this).find('>source').map(function () {
      return this.getAttribute('ssrc');
    }).get();

    if (ssrcs.length) {
      media += `a=ssrc-group:${semantics} ${ssrcs.join(' ')}\r\n`;
    }
    /* eslint-enable no-invalid-this */

  });
  tmp = content.find('description>source[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]');
  tmp.each(function () {
    /* eslint-disable no-invalid-this */
    const ssrc = this.getAttribute('ssrc'); // eslint-disable-next-line newline-per-chained-call

    $(this).find('>parameter').each(function () {
      const name = this.getAttribute('name');
      let value = this.getAttribute('value');
      value = _SDPUtil__WEBPACK_IMPORTED_MODULE_1__["default"].filterSpecialChars(value);
      media += `a=ssrc:${ssrc} ${name}`;

      if (value && value.length) {
        media += `:${value}`;
      }

      media += '\r\n';
    });
    /* eslint-enable no-invalid-this */
  });
  return media;
};

/***/ }),

/***/ "./modules/xmpp/SDPDiffer.js":
/*!***********************************!*\
  !*** ./modules/xmpp/SDPDiffer.js ***!
  \***********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return SDPDiffer; });
/* harmony import */ var _SDPUtil__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SDPUtil */ "./modules/xmpp/SDPUtil.js");
 // this could be useful in Array.prototype.

/**
 *
 * @param array1
 * @param array2
 */

function arrayEquals(array1, array2) {
  // if the other array is a falsy value, return
  if (!array2) {
    return false;
  } // compare lengths - can save a lot of time


  if (array1.length !== array2.length) {
    return false;
  }

  for (let i = 0, l = array1.length; i < l; i++) {
    // Check if we have nested arrays
    if (array1[i] instanceof Array && array2[i] instanceof Array) {
      // recurse into the nested arrays
      if (!array1[i].equals(array2[i])) {
        return false;
      }
    } else if (array1[i] !== array2[i]) {
      // Warning - two different object instances will never be
      // equal: {x:20} != {x:20}
      return false;
    }
  }

  return true;
}
/**
 *
 * @param mySDP
 * @param otherSDP
 */


function SDPDiffer(mySDP, otherSDP) {
  this.mySDP = mySDP;
  this.otherSDP = otherSDP;

  if (!mySDP) {
    throw new Error('"mySDP" is undefined!');
  } else if (!otherSDP) {
    throw new Error('"otherSDP" is undefined!');
  }
}
/**
 * Returns map of MediaChannel that contains media contained in
 * 'mySDP', but not contained in 'otherSdp'. Mapped by channel idx.
 */

SDPDiffer.prototype.getNewMedia = function () {
  const myMedias = this.mySDP.getMediaSsrcMap();
  const othersMedias = this.otherSDP.getMediaSsrcMap();
  const newMedia = {};
  Object.keys(othersMedias).forEach(othersMediaIdx => {
    const myMedia = myMedias[othersMediaIdx];
    const othersMedia = othersMedias[othersMediaIdx];

    if (!myMedia && othersMedia) {
      // Add whole channel
      newMedia[othersMediaIdx] = othersMedia;
      return;
    } // Look for new ssrcs across the channel


    Object.keys(othersMedia.ssrcs).forEach(ssrc => {
      if (Object.keys(myMedia.ssrcs).indexOf(ssrc) === -1) {
        // Allocate channel if we've found ssrc that doesn't exist in
        // our channel
        if (!newMedia[othersMediaIdx]) {
          newMedia[othersMediaIdx] = {
            mediaindex: othersMedia.mediaindex,
            mid: othersMedia.mid,
            ssrcs: {},
            ssrcGroups: []
          };
        }

        newMedia[othersMediaIdx].ssrcs[ssrc] = othersMedia.ssrcs[ssrc];
      } else if (othersMedia.ssrcs[ssrc].lines && myMedia.ssrcs[ssrc].lines) {
        // we want to detect just changes in adding/removing msid
        const myContainMsid = myMedia.ssrcs[ssrc].lines.find(line => line.indexOf('msid') !== -1) !== undefined;
        const newContainMsid = othersMedia.ssrcs[ssrc].lines.find(line => line.indexOf('msid') !== -1) !== undefined;

        if (myContainMsid !== newContainMsid) {
          if (!newMedia[othersMediaIdx]) {
            newMedia[othersMediaIdx] = {
              mediaindex: othersMedia.mediaindex,
              mid: othersMedia.mid,
              ssrcs: {},
              ssrcGroups: []
            };
          }

          newMedia[othersMediaIdx].ssrcs[ssrc] = othersMedia.ssrcs[ssrc];
        }
      }
    }); // Look for new ssrc groups across the channels

    othersMedia.ssrcGroups.forEach(otherSsrcGroup => {
      // try to match the other ssrc-group with an ssrc-group of ours
      let matched = false;

      for (let i = 0; i < myMedia.ssrcGroups.length; i++) {
        const mySsrcGroup = myMedia.ssrcGroups[i];

        if (otherSsrcGroup.semantics === mySsrcGroup.semantics && arrayEquals(otherSsrcGroup.ssrcs, mySsrcGroup.ssrcs)) {
          matched = true;
          break;
        }
      }

      if (!matched) {
        // Allocate channel if we've found an ssrc-group that doesn't
        // exist in our channel
        if (!newMedia[othersMediaIdx]) {
          newMedia[othersMediaIdx] = {
            mediaindex: othersMedia.mediaindex,
            mid: othersMedia.mid,
            ssrcs: {},
            ssrcGroups: []
          };
        }

        newMedia[othersMediaIdx].ssrcGroups.push(otherSsrcGroup);
      }
    });
  });
  return newMedia;
};
/**
 * TODO: document!
 */


SDPDiffer.prototype.toJingle = function (modify) {
  const sdpMediaSsrcs = this.getNewMedia();
  let modified = false;
  Object.keys(sdpMediaSsrcs).forEach(mediaindex => {
    modified = true;
    const media = sdpMediaSsrcs[mediaindex];
    modify.c('content', {
      name: media.mid
    });
    modify.c('description', {
      xmlns: 'urn:xmpp:jingle:apps:rtp:1',
      media: media.mid
    }); // FIXME: not completely sure this operates on blocks and / or handles
    // different ssrcs correctly
    // generate sources from lines

    Object.keys(media.ssrcs).forEach(ssrcNum => {
      const mediaSsrc = media.ssrcs[ssrcNum];
      modify.c('source', {
        xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
      });
      modify.attrs({
        ssrc: mediaSsrc.ssrc
      }); // iterate over ssrc lines

      mediaSsrc.lines.forEach(line => {
        const idx = line.indexOf(' ');
        const kv = line.substr(idx + 1);
        modify.c('parameter');

        if (kv.indexOf(':') === -1) {
          modify.attrs({
            name: kv
          });
        } else {
          const nv = kv.split(':', 2);
          const name = nv[0];
          const value = _SDPUtil__WEBPACK_IMPORTED_MODULE_0__["default"].filterSpecialChars(nv[1]);
          modify.attrs({
            name
          });
          modify.attrs({
            value
          });
        }

        modify.up(); // end of parameter
      });
      modify.up(); // end of source
    }); // generate source groups from lines

    media.ssrcGroups.forEach(ssrcGroup => {
      if (ssrcGroup.ssrcs.length) {
        modify.c('ssrc-group', {
          semantics: ssrcGroup.semantics,
          xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
        });
        ssrcGroup.ssrcs.forEach(ssrc => {
          modify.c('source', {
            ssrc
          }).up(); // end of source
        });
        modify.up(); // end of ssrc-group
      }
    });
    modify.up(); // end of description

    modify.up(); // end of content
  });
  return modified;
};

/***/ }),

/***/ "./modules/xmpp/SDPUtil.js":
/*!*********************************!*\
  !*** ./modules/xmpp/SDPUtil.js ***!
  \*********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/RandomUtil */ "./modules/util/RandomUtil.js");
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_util_RandomUtil__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");

const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);


const SDPUtil = {
  filterSpecialChars(text) {
    // XXX Neither one of the falsy values (e.g. null, undefined, false,
    // "", etc.) "contain" special chars.
    // eslint-disable-next-line no-useless-escape
    return text ? text.replace(/[\\\/\{,\}\+]/g, '') : text;
  },

  iceparams(mediadesc, sessiondesc) {
    let data = null;
    let pwd, ufrag;

    if ((ufrag = SDPUtil.findLine(mediadesc, 'a=ice-ufrag:', sessiondesc)) && (pwd = SDPUtil.findLine(mediadesc, 'a=ice-pwd:', sessiondesc))) {
      data = {
        ufrag: SDPUtil.parseICEUfrag(ufrag),
        pwd: SDPUtil.parseICEPwd(pwd)
      };
    }

    return data;
  },

  parseICEUfrag(line) {
    return line.substring(12);
  },

  buildICEUfrag(frag) {
    return `a=ice-ufrag:${frag}`;
  },

  parseICEPwd(line) {
    return line.substring(10);
  },

  buildICEPwd(pwd) {
    return `a=ice-pwd:${pwd}`;
  },

  parseMID(line) {
    return line.substring(6);
  },

  parseMLine(line) {
    const data = {};
    const parts = line.substring(2).split(' ');
    data.media = parts.shift();
    data.port = parts.shift();
    data.proto = parts.shift();

    if (parts[parts.length - 1] === '') {
      // trailing whitespace
      parts.pop();
    }

    data.fmt = parts;
    return data;
  },

  buildMLine(mline) {
    return `m=${mline.media} ${mline.port} ${mline.proto} ${mline.fmt.join(' ')}`;
  },

  parseRTPMap(line) {
    const data = {};
    let parts = line.substring(9).split(' ');
    data.id = parts.shift();
    parts = parts[0].split('/');
    data.name = parts.shift();
    data.clockrate = parts.shift();
    data.channels = parts.length ? parts.shift() : '1';
    return data;
  },

  /**
   * Parses SDP line "a=sctpmap:..." and extracts SCTP port from it.
   * @param line eg. "a=sctpmap:5000 webrtc-datachannel"
   * @returns [SCTP port number, protocol, streams]
   */
  parseSCTPMap(line) {
    const parts = line.substring(10).split(' ');
    const sctpPort = parts[0];
    const protocol = parts[1]; // Stream count is optional

    const streamCount = parts.length > 2 ? parts[2] : null;
    return [sctpPort, protocol, streamCount]; // SCTP port
  },

  buildRTPMap(el) {
    let line = `a=rtpmap:${el.getAttribute('id')} ${el.getAttribute('name')}/${el.getAttribute('clockrate')}`;

    if (el.getAttribute('channels') && el.getAttribute('channels') !== '1') {
      line += `/${el.getAttribute('channels')}`;
    }

    return line;
  },

  parseCrypto(line) {
    const data = {};
    const parts = line.substring(9).split(' ');
    data.tag = parts.shift();
    data['crypto-suite'] = parts.shift();
    data['key-params'] = parts.shift();

    if (parts.length) {
      data['session-params'] = parts.join(' ');
    }

    return data;
  },

  parseFingerprint(line) {
    // RFC 4572
    const data = {};
    const parts = line.substring(14).split(' ');
    data.hash = parts.shift();
    data.fingerprint = parts.shift(); // TODO assert that fingerprint satisfies 2UHEX *(":" 2UHEX) ?

    return data;
  },

  parseFmtp(line) {
    const data = [];
    let parts = line.split(' ');
    parts.shift();
    parts = parts.join(' ').split(';');

    for (let i = 0; i < parts.length; i++) {
      let key = parts[i].split('=')[0];

      while (key.length && key[0] === ' ') {
        key = key.substring(1);
      }

      const value = parts[i].split('=')[1];

      if (key && value) {
        data.push({
          name: key,
          value
        });
      } else if (key) {
        // rfc 4733 (DTMF) style stuff
        data.push({
          name: '',
          value: key
        });
      }
    }

    return data;
  },

  parseICECandidate(line) {
    const candidate = {};
    const elems = line.split(' ');
    candidate.foundation = elems[0].substring(12);
    candidate.component = elems[1];
    candidate.protocol = elems[2].toLowerCase();
    candidate.priority = elems[3];
    candidate.ip = elems[4];
    candidate.port = elems[5]; // elems[6] => "typ"

    candidate.type = elems[7];
    candidate.generation = 0; // default value, may be overwritten below

    for (let i = 8; i < elems.length; i += 2) {
      switch (elems[i]) {
        case 'raddr':
          candidate['rel-addr'] = elems[i + 1];
          break;

        case 'rport':
          candidate['rel-port'] = elems[i + 1];
          break;

        case 'generation':
          candidate.generation = elems[i + 1];
          break;

        case 'tcptype':
          candidate.tcptype = elems[i + 1];
          break;

        default:
          // TODO
          logger.log(`parseICECandidate not translating "${elems[i]}" = "${elems[i + 1]}"`);
      }
    }

    candidate.network = '1'; // not applicable to SDP -- FIXME: should be unique, not just random
    // eslint-disable-next-line newline-per-chained-call

    candidate.id = Math.random().toString(36).substr(2, 10);
    return candidate;
  },

  buildICECandidate(cand) {
    let line = [`a=candidate:${cand.foundation}`, cand.component, cand.protocol, cand.priority, cand.ip, cand.port, 'typ', cand.type].join(' ');
    line += ' ';

    switch (cand.type) {
      case 'srflx':
      case 'prflx':
      case 'relay':
        if (cand.hasOwnAttribute('rel-addr') && cand.hasOwnAttribute('rel-port')) {
          line += 'raddr';
          line += ' ';
          line += cand['rel-addr'];
          line += ' ';
          line += 'rport';
          line += ' ';
          line += cand['rel-port'];
          line += ' ';
        }

        break;
    }

    if (cand.hasOwnAttribute('tcptype')) {
      line += 'tcptype';
      line += ' ';
      line += cand.tcptype;
      line += ' ';
    }

    line += 'generation';
    line += ' ';
    line += cand.hasOwnAttribute('generation') ? cand.generation : '0';
    return line;
  },

  parseSSRC(desc) {
    // proprietary mapping of a=ssrc lines
    // TODO: see "Jingle RTP Source Description" by Juberti and P. Thatcher
    // on google docs and parse according to that
    const data = new Map();
    const lines = desc.split('\r\n');

    for (let i = 0; i < lines.length; i++) {
      if (lines[i].substring(0, 7) === 'a=ssrc:') {
        // FIXME: Use regex to smartly find the ssrc.
        const ssrc = lines[i].split('a=ssrc:')[1].split(' ')[0];

        if (!data.get(ssrc)) {
          data.set(ssrc, []);
        }

        data.get(ssrc).push(lines[i]);
      }
    }

    return data;
  },

  parseRTCPFB(line) {
    const parts = line.substr(10).split(' ');
    const data = {};
    data.pt = parts.shift();
    data.type = parts.shift();
    data.params = parts;
    return data;
  },

  parseExtmap(line) {
    const parts = line.substr(9).split(' ');
    const data = {};
    data.value = parts.shift();

    if (data.value.indexOf('/') === -1) {
      data.direction = 'both';
    } else {
      data.direction = data.value.substr(data.value.indexOf('/') + 1);
      data.value = data.value.substr(0, data.value.indexOf('/'));
    }

    data.uri = parts.shift();
    data.params = parts;
    return data;
  },

  findLine(haystack, needle, sessionpart) {
    let lines = haystack.split('\r\n');

    for (let i = 0; i < lines.length; i++) {
      if (lines[i].substring(0, needle.length) === needle) {
        return lines[i];
      }
    }

    if (!sessionpart) {
      return false;
    } // search session part


    lines = sessionpart.split('\r\n');

    for (let j = 0; j < lines.length; j++) {
      if (lines[j].substring(0, needle.length) === needle) {
        return lines[j];
      }
    }

    return false;
  },

  findLines(haystack, needle, sessionpart) {
    let lines = haystack.split('\r\n');
    const needles = [];

    for (let i = 0; i < lines.length; i++) {
      if (lines[i].substring(0, needle.length) === needle) {
        needles.push(lines[i]);
      }
    }

    if (needles.length || !sessionpart) {
      return needles;
    } // search session part


    lines = sessionpart.split('\r\n');

    for (let j = 0; j < lines.length; j++) {
      if (lines[j].substring(0, needle.length) === needle) {
        needles.push(lines[j]);
      }
    }

    return needles;
  },

  candidateToJingle(line) {
    // a=candidate:2979166662 1 udp 2113937151 192.168.2.100 57698 typ host
    // generation 0
    //      <candidate component=... foundation=... generation=... id=...
    // ip=... network=... port=... priority=... protocol=... type=.../>
    if (line.indexOf('candidate:') === 0) {
      // eslint-disable-next-line no-param-reassign
      line = `a=${line}`;
    } else if (line.substring(0, 12) !== 'a=candidate:') {
      logger.log('parseCandidate called with a line that is not a candidate' + ' line');
      logger.log(line);
      return null;
    }

    if (line.substring(line.length - 2) === '\r\n') {
      // chomp it
      // eslint-disable-next-line no-param-reassign
      line = line.substring(0, line.length - 2);
    }

    const candidate = {};
    const elems = line.split(' ');

    if (elems[6] !== 'typ') {
      logger.log('did not find typ in the right place');
      logger.log(line);
      return null;
    }

    candidate.foundation = elems[0].substring(12);
    candidate.component = elems[1];
    candidate.protocol = elems[2].toLowerCase();
    candidate.priority = elems[3];
    candidate.ip = elems[4];
    candidate.port = elems[5]; // elems[6] => "typ"

    candidate.type = elems[7];
    candidate.generation = '0'; // default, may be overwritten below

    for (let i = 8; i < elems.length; i += 2) {
      switch (elems[i]) {
        case 'raddr':
          candidate['rel-addr'] = elems[i + 1];
          break;

        case 'rport':
          candidate['rel-port'] = elems[i + 1];
          break;

        case 'generation':
          candidate.generation = elems[i + 1];
          break;

        case 'tcptype':
          candidate.tcptype = elems[i + 1];
          break;

        default:
          // TODO
          logger.log(`not translating "${elems[i]}" = "${elems[i + 1]}"`);
      }
    }

    candidate.network = '1'; // not applicable to SDP -- FIXME: should be unique, not just random
    // eslint-disable-next-line newline-per-chained-call

    candidate.id = Math.random().toString(36).substr(2, 10);
    return candidate;
  },

  candidateFromJingle(cand) {
    let line = 'a=candidate:';
    line += cand.getAttribute('foundation');
    line += ' ';
    line += cand.getAttribute('component');
    line += ' ';
    let protocol = cand.getAttribute('protocol'); // use tcp candidates for FF

    if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isFirefox() && protocol.toLowerCase() === 'ssltcp') {
      protocol = 'tcp';
    }

    line += protocol; // .toUpperCase(); // chrome M23 doesn't like this

    line += ' ';
    line += cand.getAttribute('priority');
    line += ' ';
    line += cand.getAttribute('ip');
    line += ' ';
    line += cand.getAttribute('port');
    line += ' ';
    line += 'typ';
    line += ` ${cand.getAttribute('type')}`;
    line += ' ';

    switch (cand.getAttribute('type')) {
      case 'srflx':
      case 'prflx':
      case 'relay':
        if (cand.getAttribute('rel-addr') && cand.getAttribute('rel-port')) {
          line += 'raddr';
          line += ' ';
          line += cand.getAttribute('rel-addr');
          line += ' ';
          line += 'rport';
          line += ' ';
          line += cand.getAttribute('rel-port');
          line += ' ';
        }

        break;
    }

    if (protocol.toLowerCase() === 'tcp') {
      line += 'tcptype';
      line += ' ';
      line += cand.getAttribute('tcptype');
      line += ' ';
    }

    line += 'generation';
    line += ' ';
    line += cand.getAttribute('generation') || '0';
    return `${line}\r\n`;
  },

  /**
   * Parse the 'most' primary video ssrc from the given m line
   * @param {object} mLine object as parsed from transform.parse
   * @return {number} the primary video ssrc from the given m line
   */
  parsePrimaryVideoSsrc(videoMLine) {
    const numSsrcs = videoMLine.ssrcs.map(ssrcInfo => ssrcInfo.id).filter((ssrc, index, array) => array.indexOf(ssrc) === index).length;
    const numGroups = videoMLine.ssrcGroups && videoMLine.ssrcGroups.length || 0;

    if (numSsrcs > 1 && numGroups === 0) {
      // Ambiguous, can't figure out the primary
      return;
    }

    let primarySsrc = null;

    if (numSsrcs === 1) {
      primarySsrc = videoMLine.ssrcs[0].id;
    } else if (numSsrcs === 2) {
      // Can figure it out if there's an FID group
      const fidGroup = videoMLine.ssrcGroups.find(group => group.semantics === 'FID');

      if (fidGroup) {
        primarySsrc = fidGroup.ssrcs.split(' ')[0];
      }
    } else if (numSsrcs >= 3) {
      // Can figure it out if there's a sim group
      const simGroup = videoMLine.ssrcGroups.find(group => group.semantics === 'SIM');

      if (simGroup) {
        primarySsrc = simGroup.ssrcs.split(' ')[0];
      }
    }

    return primarySsrc;
  },

  /**
   * Generate an ssrc
   * @returns {number} an ssrc
   */
  generateSsrc() {
    return _util_RandomUtil__WEBPACK_IMPORTED_MODULE_1___default.a.randomInt(1, 0xffffffff);
  },

  /**
   * Get an attribute for the given ssrc with the given attributeName
   *  from the given mline
   * @param {object} mLine an mLine object as parsed from transform.parse
   * @param {number} ssrc the ssrc for which an attribute is desired
   * @param {string} attributeName the name of the desired attribute
   * @returns {string} the value corresponding to the given ssrc
   *  and attributeName
   */
  getSsrcAttribute(mLine, ssrc, attributeName) {
    for (let i = 0; i < mLine.ssrcs.length; ++i) {
      const ssrcLine = mLine.ssrcs[i];

      if (ssrcLine.id === ssrc && ssrcLine.attribute === attributeName) {
        return ssrcLine.value;
      }
    }
  },

  /**
   * Parses the ssrcs from the group sdp line and
   *  returns them as a list of numbers
   * @param {object} the ssrcGroup object as parsed from
   *  sdp-transform
   * @returns {list<number>} a list of the ssrcs in the group
   *  parsed as numbers
   */
  parseGroupSsrcs(ssrcGroup) {
    return ssrcGroup.ssrcs.split(' ').map(ssrcStr => parseInt(ssrcStr, 10));
  },

  /**
   * Get the mline of the given type from the given sdp
   * @param {object} sdp sdp as parsed from transform.parse
   * @param {string} type the type of the desired mline (e.g. "video")
   * @returns {object} a media object
   */
  getMedia(sdp, type) {
    return sdp.media.find(m => m.type === type);
  },

  /**
   * Extracts the ICE username fragment from an SDP string.
   * @param {string} sdp the SDP in raw text format
   */
  getUfrag(sdp) {
    const ufragLines = sdp.split('\n').filter(line => line.startsWith('a=ice-ufrag:'));

    if (ufragLines.length > 0) {
      return ufragLines[0].substr('a=ice-ufrag:'.length);
    }
  },

  /**
   * Sets the given codecName as the preferred codec by
   *  moving it to the beginning of the payload types
   *  list (modifies the given mline in place).  If there
   *  are multiple options within the same codec (multiple h264
   *  profiles, for instance), this will prefer the first one
   *  that is found.
   * @param {object} videoMLine the video mline object from
   *  an sdp as parsed by transform.parse
   * @param {string} codecName the name of the preferred codec
   */
  preferVideoCodec(videoMLine, codecName) {
    let payloadType = null;

    if (!videoMLine || !codecName) {
      return;
    }

    for (let i = 0; i < videoMLine.rtp.length; ++i) {
      const rtp = videoMLine.rtp[i];

      if (rtp.codec && rtp.codec.toLowerCase() === codecName.toLowerCase()) {
        payloadType = rtp.payload;
        break;
      }
    }

    if (payloadType) {
      // Call toString() on payloads to get around an issue within
      // SDPTransform that sets payloads as a number, instead of a string,
      // when there is only one payload.
      const payloadTypes = videoMLine.payloads.toString().split(' ').map(p => parseInt(p, 10));
      const payloadIndex = payloadTypes.indexOf(payloadType);
      payloadTypes.splice(payloadIndex, 1);
      payloadTypes.unshift(payloadType);
      videoMLine.payloads = payloadTypes.join(' ');
    }
  },

  /**
   * Strips the given codec from the given mline. All related RTX payload
   * types are also stripped. If the resulting mline would have no codecs,
   * it's disabled.
   *
   * @param {object} videoMLine the video mline object from an sdp as parsed
   * by transform.parse.
   * @param {string} codecName the name of the codec which will be stripped.
   */
  stripVideoCodec(videoMLine, codecName) {
    if (!videoMLine || !codecName) {
      return;
    }

    const removePts = [];

    for (const rtp of videoMLine.rtp) {
      if (rtp.codec && rtp.codec.toLowerCase() === codecName.toLowerCase()) {
        removePts.push(rtp.payload);
      }
    }

    if (removePts.length > 0) {
      // We also need to remove the payload types that are related to RTX
      // for the codecs we want to disable.
      const rtxApts = removePts.map(item => `apt=${item}`);
      const rtxPts = videoMLine.fmtp.filter(item => rtxApts.indexOf(item.config) !== -1);
      removePts.push(...rtxPts.map(item => item.payload)); // Call toString() on payloads to get around an issue within
      // SDPTransform that sets payloads as a number, instead of a string,
      // when there is only one payload.

      const allPts = videoMLine.payloads.toString().split(' ').map(Number);
      const keepPts = allPts.filter(pt => removePts.indexOf(pt) === -1);

      if (keepPts.length === 0) {
        // There are no other video codecs, disable the stream.
        videoMLine.port = 0;
        videoMLine.direction = 'inactive';
        videoMLine.payloads = '*';
      } else {
        videoMLine.payloads = keepPts.join(' ');
      }

      videoMLine.rtp = videoMLine.rtp.filter(item => keepPts.indexOf(item.payload) !== -1);
      videoMLine.fmtp = videoMLine.fmtp.filter(item => keepPts.indexOf(item.payload) !== -1);

      if (videoMLine.rtcpFb) {
        videoMLine.rtcpFb = videoMLine.rtcpFb.filter(item => keepPts.indexOf(item.payload) !== -1);
      }
    }
  }

};
/* harmony default export */ __webpack_exports__["default"] = (SDPUtil);
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\SDPUtil.js"))

/***/ }),

/***/ "./modules/xmpp/SdpConsistency.js":
/*!****************************************!*\
  !*** ./modules/xmpp/SdpConsistency.js ***!
  \****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return SdpConsistency; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./SdpTransformUtil */ "./modules/xmpp/SdpTransformUtil.js");
/* global __filename */


const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Handles the work of keeping video ssrcs consistent across multiple
 * o/a cycles, making it such that all stream operations can be
 * kept local and do not need to be signaled.
 * NOTE: This only keeps the 'primary' video ssrc consistent: meaning
 * the primary video stream
 */

class SdpConsistency {
  /**
   * Constructor
   * @param {string} logPrefix the log prefix appended to every logged
   * message, currently used to distinguish for which
   * <tt>TraceablePeerConnection</tt> the instance works.
   */
  constructor(logPrefix) {
    this.clearVideoSsrcCache();
    this.logPrefix = logPrefix;
  }
  /**
   * Clear the cached video primary and primary rtx ssrcs so that
   *  they will not be used for the next call to
   *  makeVideoPrimarySsrcsConsistent
   */


  clearVideoSsrcCache() {
    this.cachedPrimarySsrc = null;
    this.injectRecvOnly = false;
  }
  /**
   * Explicitly set the primary ssrc to be used in
   *  makeVideoPrimarySsrcsConsistent
   * @param {number} primarySsrc the primarySsrc to be used
   *  in future calls to makeVideoPrimarySsrcsConsistent
   * @throws Error if <tt>primarySsrc</tt> is not a number
   */


  setPrimarySsrc(primarySsrc) {
    if (typeof primarySsrc !== 'number') {
      throw new Error('Primary SSRC must be a number!');
    }

    this.cachedPrimarySsrc = primarySsrc;
  }
  /**
   * Checks whether or not there is a primary video SSRC cached already.
   * @return {boolean}
   */


  hasPrimarySsrcCached() {
    return Boolean(this.cachedPrimarySsrc);
  }
  /**
   * Given an sdp string, either:
   *  1) record the primary video and primary rtx ssrcs to be
   *   used in future calls to makeVideoPrimarySsrcsConsistent or
   *  2) change the primary and primary rtx ssrcs in the given sdp
   *   to match the ones previously cached
   * @param {string} sdpStr the sdp string to (potentially)
   *  change to make the video ssrcs consistent
   * @returns {string} a (potentially) modified sdp string
   *  with ssrcs consistent with this class' cache
   */


  makeVideoPrimarySsrcsConsistent(sdpStr) {
    const sdpTransformer = new _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_1__["SdpTransformWrap"](sdpStr);
    const videoMLine = sdpTransformer.selectMedia('video');

    if (!videoMLine) {
      logger.debug(`${this.logPrefix} no 'video' media found in the sdp: ` + `${sdpStr}`);
      return sdpStr;
    }

    if (videoMLine.direction === 'recvonly') {
      // If the mline is recvonly, we'll add the primary
      //  ssrc as a recvonly ssrc
      if (this.cachedPrimarySsrc && this.injectRecvOnly) {
        videoMLine.addSSRCAttribute({
          id: this.cachedPrimarySsrc,
          attribute: 'cname',
          value: `recvonly-${this.cachedPrimarySsrc}`
        });
      } else {
        logger.info(`${this.logPrefix} no SSRC found for the recvonly video` + 'stream!');
      }
    } else {
      const newPrimarySsrc = videoMLine.getPrimaryVideoSsrc();

      if (!newPrimarySsrc) {
        logger.info(`${this.logPrefix} sdp-consistency couldn't` + ' parse new primary ssrc');
        return sdpStr;
      }

      if (this.cachedPrimarySsrc) {
        logger.info(`${this.logPrefix} sdp-consistency replacing new ssrc` + `${newPrimarySsrc} with cached ` + `${this.cachedPrimarySsrc}`);
        videoMLine.replaceSSRC(newPrimarySsrc, this.cachedPrimarySsrc);

        for (const group of videoMLine.ssrcGroups) {
          if (group.semantics === 'FID') {
            const primarySsrc = Object(_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_1__["parsePrimarySSRC"])(group);
            const rtxSsrc = Object(_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_1__["parseSecondarySSRC"])(group); // eslint-disable-next-line max-depth

            if (primarySsrc === newPrimarySsrc) {
              group.ssrcs = `${this.cachedPrimarySsrc} ${rtxSsrc}`;
            }
          }
        }
      } else {
        this.cachedPrimarySsrc = newPrimarySsrc;
        logger.info(`${this.logPrefix} sdp-consistency caching primary ssrc` + `${this.cachedPrimarySsrc}`);
      }

      this.injectRecvOnly = true;
    }

    return sdpTransformer.toRawSDP();
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\SdpConsistency.js"))

/***/ }),

/***/ "./modules/xmpp/SdpTransformUtil.js":
/*!******************************************!*\
  !*** ./modules/xmpp/SdpTransformUtil.js ***!
  \******************************************/
/*! exports provided: parsePrimarySSRC, parseSecondarySSRC, SdpTransformWrap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parsePrimarySSRC", function() { return parsePrimarySSRC; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseSecondarySSRC", function() { return parseSecondarySSRC; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SdpTransformWrap", function() { return SdpTransformWrap; });
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(sdp_transform__WEBPACK_IMPORTED_MODULE_0__);

/**
 * Parses the primary SSRC of given SSRC group.
 * @param {object} group the SSRC group object as defined by the 'sdp-transform'
 * @return {Number} the primary SSRC number
 */

function parsePrimarySSRC(group) {
  return parseInt(group.ssrcs.split(' ')[0], 10);
}
/**
 * Parses the secondary SSRC of given SSRC group.
 * @param {object} group the SSRC group object as defined by the 'sdp-transform'
 * @return {Number} the secondary SSRC number
 */

function parseSecondarySSRC(group) {
  return parseInt(group.ssrcs.split(' ')[1], 10);
}
/**
 * Tells how many distinct SSRCs are contained in given media line.
 * @param {Object} mLine the media line object as defined by 'sdp-transform' lib
 * @return {number}
 */

function _getSSRCCount(mLine) {
  if (!mLine.ssrcs) {
    return 0;
  }

  return mLine.ssrcs.map(ssrcInfo => ssrcInfo.id).filter((ssrc, index, array) => array.indexOf(ssrc) === index).length;
}
/**
 * A wrapper around 'sdp-transform' media description object which provides
 * utility methods for common SDP/SSRC related operations.
 */


class MLineWrap {
  /**
   * Creates new <tt>MLineWrap</t>>
   * @param {Object} mLine the media line object as defined by 'sdp-transform'
   * lib.
   */
  constructor(mLine) {
    if (!mLine) {
      throw new Error('mLine is undefined');
    }

    this.mLine = mLine;
  }
  /**
   * Getter for the mLine's "ssrcs" array. If the array was undefined an empty
   * one will be preassigned.
   *
   * @return {Array<Object>} an array of 'sdp-transform' SSRC attributes
   * objects.
   */


  get ssrcs() {
    if (!this.mLine.ssrcs) {
      this.mLine.ssrcs = [];
    }

    return this.mLine.ssrcs;
  }
  /**
   * Setter for the mLine's "ssrcs" array.
   *
   * @param {Array<Object>} ssrcs an array of 'sdp-transform' SSRC attributes
   * objects.
   */


  set ssrcs(ssrcs) {
    this.mLine.ssrcs = ssrcs;
  }
  /**
   * Returns the direction of the underlying media description.
   * @return {string} the media direction name as defined in the SDP.
   */


  get direction() {
    return this.mLine.direction;
  }
  /**
   * Modifies the direction of the underlying media description.
   * @param {string} direction the new direction to be set
   */


  set direction(direction) {
    this.mLine.direction = direction;
  }
  /**
   * Exposes the SSRC group array of the underlying media description object.
   * @return {Array.<Object>}
   */


  get ssrcGroups() {
    if (!this.mLine.ssrcGroups) {
      this.mLine.ssrcGroups = [];
    }

    return this.mLine.ssrcGroups;
  }
  /**
   * Modifies the SSRC groups array of the underlying media description
   * object.
   * @param {Array.<Object>} ssrcGroups
   */


  set ssrcGroups(ssrcGroups) {
    this.mLine.ssrcGroups = ssrcGroups;
  }
  /**
   * Obtains value from SSRC attribute.
   * @param {number} ssrcNumber the SSRC number for which attribute is to be
   * found
   * @param {string} attrName the name of the SSRC attribute to be found.
   * @return {string|undefined} the value of SSRC attribute or
   * <tt>undefined</tt> if no such attribute exists.
   */


  getSSRCAttrValue(ssrcNumber, attrName) {
    const attribute = this.ssrcs.find(ssrcObj => ssrcObj.id === ssrcNumber && ssrcObj.attribute === attrName);
    return attribute && attribute.value;
  }
  /**
   * Removes all attributes for given SSRC number.
   * @param {number} ssrcNum the SSRC number for which all attributes will be
   * removed.
   */


  removeSSRC(ssrcNum) {
    if (!this.mLine.ssrcs || !this.mLine.ssrcs.length) {
      return;
    }

    this.mLine.ssrcs = this.mLine.ssrcs.filter(ssrcObj => ssrcObj.id !== ssrcNum);
  }
  /**
   * Adds SSRC attribute
   * @param {object} ssrcObj the SSRC attribute object as defined in
   * the 'sdp-transform' lib.
   */


  addSSRCAttribute(ssrcObj) {
    this.ssrcs.push(ssrcObj);
  }
  /**
   * Finds a SSRC group matching both semantics and SSRCs in order.
   * @param {string} semantics the name of the semantics
   * @param {string} [ssrcs] group SSRCs as a string (like it's defined in
   * SSRC group object of the 'sdp-transform' lib) e.g. "1232546 342344 25434"
   * @return {object|undefined} the SSRC group object or <tt>undefined</tt> if
   * not found.
   */


  findGroup(semantics, ssrcs) {
    return this.ssrcGroups.find(group => group.semantics === semantics && (!ssrcs || ssrcs === group.ssrcs));
  }
  /**
   * Finds all groups matching given semantic's name.
   * @param {string} semantics the name of the semantics
   * @return {Array.<object>} an array of SSRC group objects as defined by
   * the 'sdp-transform' lib.
   */


  findGroups(semantics) {
    return this.ssrcGroups.filter(group => group.semantics === semantics);
  }
  /**
   * Finds all groups matching given semantic's name and group's primary SSRC.
   * @param {string} semantics the name of the semantics
   * @param {number} primarySSRC the primary SSRC number to be matched
   * @return {Object} SSRC group object as defined by the 'sdp-transform' lib.
   */


  findGroupByPrimarySSRC(semantics, primarySSRC) {
    return this.ssrcGroups.find(group => group.semantics === semantics && parsePrimarySSRC(group) === primarySSRC);
  }
  /**
   * @param {string|null} msid the media stream id or <tt>null</tt> to match
   * the first SSRC object with any 'msid' value.
   * @return {Object|undefined} the SSRC object as defined by 'sdp-transform'
   * lib.
   */


  findSSRCByMSID(msid) {
    return this.ssrcs.find(ssrcObj => ssrcObj.attribute === 'msid' && (msid === null || ssrcObj.value === msid));
  }
  /**
   * Gets the SSRC count for the underlying media description.
   * @return {number}
   */


  getSSRCCount() {
    return _getSSRCCount(this.mLine);
  }
  /**
   * Checks whether the underlying media description contains any SSRC groups.
   * @return {boolean} <tt>true</tt> if there are any SSRC groups or
   * <tt>false</tt> otherwise.
   */


  containsAnySSRCGroups() {
    return this.mLine.ssrcGroups !== undefined;
  }
  /**
   * Finds the primary video SSRC.
   * @returns {number|undefined} the primary video ssrc
   * @throws Error if the underlying media description is not a video
   */


  getPrimaryVideoSsrc() {
    const mediaType = this.mLine.type;

    if (mediaType !== 'video') {
      throw new Error(`getPrimarySsrc doesn't work with '${mediaType}'`);
    }

    const numSsrcs = _getSSRCCount(this.mLine);

    if (numSsrcs === 1) {
      // Not using "ssrcs" getter on purpose here
      return this.mLine.ssrcs[0].id;
    } // Look for a SIM, FID, or FEC-FR group


    if (this.mLine.ssrcGroups) {
      const simGroup = this.findGroup('SIM');

      if (simGroup) {
        return parsePrimarySSRC(simGroup);
      }

      const fidGroup = this.findGroup('FID');

      if (fidGroup) {
        return parsePrimarySSRC(fidGroup);
      }

      const fecGroup = this.findGroup('FEC-FR');

      if (fecGroup) {
        return parsePrimarySSRC(fecGroup);
      }
    }
  }
  /**
   * Obtains RTX SSRC from the underlying video description (the
   * secondary SSRC of the first "FID" group found)
   * @param {number} primarySsrc the video ssrc for which to find the
   * corresponding rtx ssrc
   * @returns {number|undefined} the rtx ssrc (or undefined if there isn't
   * one)
   */


  getRtxSSRC(primarySsrc) {
    const fidGroup = this.findGroupByPrimarySSRC('FID', primarySsrc);
    return fidGroup && parseSecondarySSRC(fidGroup);
  }
  /**
   * Obtains all SSRCs contained in the underlying media description.
   * @return {Array.<number>} an array with all SSRC as numbers.
   */


  getSSRCs() {
    return this.ssrcs.map(ssrcInfo => ssrcInfo.id).filter((ssrc, index, array) => array.indexOf(ssrc) === index);
  }
  /**
   * Obtains primary video SSRCs.
   * @return {Array.<number>} an array of all primary video SSRCs as numbers.
   * @throws Error if the wrapped media description is not a video.
   */


  getPrimaryVideoSSRCs() {
    const mediaType = this.mLine.type;

    if (mediaType !== 'video') {
      throw new Error(`getPrimaryVideoSSRCs doesn't work with ${mediaType}`);
    }

    const videoSSRCs = this.getSSRCs();

    for (const ssrcGroupInfo of this.ssrcGroups) {
      // Right now, FID and FEC-FR groups are the only ones we parse to
      // disqualify streams.  If/when others arise we'll
      // need to add support for them here
      if (ssrcGroupInfo.semantics === 'FID' || ssrcGroupInfo.semantics === 'FEC-FR') {
        // secondary streams should be filtered out
        const secondarySsrc = parseSecondarySSRC(ssrcGroupInfo);
        videoSSRCs.splice(videoSSRCs.indexOf(secondarySsrc), 1);
      }
    }

    return videoSSRCs;
  }
  /**
   * Dumps all SSRC groups of this media description to JSON.
   */


  dumpSSRCGroups() {
    return JSON.stringify(this.mLine.ssrcGroups);
  }
  /**
   * Removes all SSRC groups which contain given SSRC number at any position.
   * @param {number} ssrc the SSRC for which all matching groups are to be
   * removed.
   */


  removeGroupsWithSSRC(ssrc) {
    if (!this.mLine.ssrcGroups) {
      return;
    }

    this.mLine.ssrcGroups = this.mLine.ssrcGroups.filter(groupInfo => groupInfo.ssrcs.indexOf(`${ssrc}`) === -1);
  }
  /**
   * Removes groups that match given semantics.
   * @param {string} semantics e.g. "SIM" or "FID"
   */


  removeGroupsBySemantics(semantics) {
    if (!this.mLine.ssrcGroups) {
      return;
    }

    this.mLine.ssrcGroups = this.mLine.ssrcGroups.filter(groupInfo => groupInfo.semantics !== semantics);
  }
  /**
   * Replaces SSRC (does not affect SSRC groups, but only attributes).
   * @param {number} oldSSRC the old SSRC number
   * @param {number} newSSRC the new SSRC number
   */


  replaceSSRC(oldSSRC, newSSRC) {
    if (this.mLine.ssrcs) {
      this.mLine.ssrcs.forEach(ssrcInfo => {
        if (ssrcInfo.id === oldSSRC) {
          ssrcInfo.id = newSSRC;
        }
      });
    }
  }
  /**
   * Adds given SSRC group to this media description.
   * @param {object} group the SSRC group object as defined by
   * the 'sdp-transform' lib.
   */


  addSSRCGroup(group) {
    this.ssrcGroups.push(group);
  }

}
/**
 * Utility class for SDP manipulation using the 'sdp-transform' library.
 *
 * Typical use usage scenario:
 *
 * const transformer = new SdpTransformWrap(rawSdp);
 * const videoMLine = transformer.selectMedia('video);
 * if (videoMLine) {
 *     videoMLiner.addSSRCAttribute({
 *         id: 2342343,
 *         attribute: "cname",
 *         value: "someCname"
 *     });
 *     rawSdp = transformer.toRawSdp();
 * }
 */


class SdpTransformWrap {
  /**
   * Creates new instance and parses the raw SDP into objects using
   * 'sdp-transform' lib.
   * @param {string} rawSDP the SDP in raw text format.
   */
  constructor(rawSDP) {
    this.parsedSDP = sdp_transform__WEBPACK_IMPORTED_MODULE_0__["parse"](rawSDP);
  }
  /**
   * Selects the first media SDP of given name.
   * @param {string} mediaType the name of the media e.g. 'audio', 'video',
   * 'data'.
   * @return {MLineWrap|null} return {@link MLineWrap} instance for the media
   * line or <tt>null</tt> if not found. The object returned references
   * the underlying SDP state held by this <tt>SdpTransformWrap</tt> instance
   * (it's not a copy).
   */


  selectMedia(mediaType) {
    const selectedMLine = this.parsedSDP.media.find(mLine => mLine.type === mediaType);
    return selectedMLine ? new MLineWrap(selectedMLine) : null;
  }
  /**
   * Converts the currently stored SDP state in this instance to raw text SDP
   * format.
   * @return {string}
   */


  toRawSDP() {
    return sdp_transform__WEBPACK_IMPORTED_MODULE_0__["write"](this.parsedSDP);
  }

}

/***/ }),

/***/ "./modules/xmpp/SignalingLayerImpl.js":
/*!********************************************!*\
  !*** ./modules/xmpp/SignalingLayerImpl.js ***!
  \********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return SignalingLayerImpl; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/SignalingEvents */ "./service/RTC/SignalingEvents.js");
/* harmony import */ var _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/SignalingLayer */ "./service/RTC/SignalingLayer.js");
/* global __filename */




const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Default XMPP implementation of the {@link SignalingLayer} interface. Obtains
 * the data from the MUC presence.
 */

class SignalingLayerImpl extends _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_3__["default"] {
  /**
   * Creates new instance.
   */
  constructor() {
    super();
    /**
     * A map that stores SSRCs of remote streams. And is used only locally
     * We store the mapping when jingle is received, and later is used
     * onaddstream webrtc event where we have only the ssrc
     * FIXME: This map got filled and never cleaned and can grow during long
     * conference
     * @type {Map<number, string>} maps SSRC number to jid
     */

    this.ssrcOwners = new Map();
    /**
     *
     * @type {ChatRoom|null}
     */

    this.chatRoom = null;
  }
  /**
   * Sets the <tt>ChatRoom</tt> instance used and binds presence listeners.
   * @param {ChatRoom} room
   */


  setChatRoom(room) {
    const oldChatRoom = this.chatRoom;
    this.chatRoom = room;

    if (oldChatRoom) {
      oldChatRoom.removePresenceListener('audiomuted', this._audioMuteHandler);
      oldChatRoom.removePresenceListener('videomuted', this._videoMuteHandler);
      oldChatRoom.removePresenceListener('videoType', this._videoTypeHandler);
    }

    if (room) {
      // SignalingEvents
      this._audioMuteHandler = (node, from) => {
        this.eventEmitter.emit(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_2__["PEER_MUTED_CHANGED"], from, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__["AUDIO"], node.value === 'true');
      };

      room.addPresenceListener('audiomuted', this._audioMuteHandler);

      this._videoMuteHandler = (node, from) => {
        this.eventEmitter.emit(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_2__["PEER_MUTED_CHANGED"], from, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__["VIDEO"], node.value === 'true');
      };

      room.addPresenceListener('videomuted', this._videoMuteHandler);

      this._videoTypeHandler = (node, from) => {
        this.eventEmitter.emit(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_2__["PEER_VIDEO_TYPE_CHANGED"], from, node.value);
      };

      room.addPresenceListener('videoType', this._videoTypeHandler);
    }
  }
  /**
   * @inheritDoc
   */


  getPeerMediaInfo(owner, mediaType) {
    if (this.chatRoom) {
      return this.chatRoom.getMediaPresenceInfo(owner, mediaType);
    }

    logger.error('Requested peer media info, before room was set');
  }
  /**
   * @inheritDoc
   */


  getSSRCOwner(ssrc) {
    return this.ssrcOwners.get(ssrc);
  }
  /**
   * Set an SSRC owner.
   * @param {number} ssrc an SSRC to be owned
   * @param {string} endpointId owner's ID (MUC nickname)
   * @throws TypeError if <tt>ssrc</tt> is not a number
   */


  setSSRCOwner(ssrc, endpointId) {
    if (typeof ssrc !== 'number') {
      throw new TypeError(`SSRC(${ssrc}) must be a number`);
    }

    this.ssrcOwners.set(ssrc, endpointId);
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\SignalingLayerImpl.js"))

/***/ }),

/***/ "./modules/xmpp/StropheLastSuccess.js":
/*!********************************************!*\
  !*** ./modules/xmpp/StropheLastSuccess.js ***!
  \********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return LastRequestTracker; });
/**
 * Attaches to the {@link Strophe.Connection.rawInput} which is called whenever any data is received from the server.
 */
class LastRequestTracker {
  /**
   * Initializes new instance.
   */
  constructor() {
    this._lastSuccess = null;
  }
  /**
   * Starts tracking requests on the given connection.
   *
   * @param {Object} stropheConnection - Strophe connection instance.
   */


  startTracking(stropheConnection) {
    const originalRawInput = stropheConnection.rawInput;

    stropheConnection.rawInput = function (...args) {
      this._lastSuccess = Date.now();
      originalRawInput.apply(stropheConnection, args);
    };
  }
  /**
   * Returns how many milliseconds have passed since the last successful BOSH request.
   *
   * @returns {number|null}
   */


  getTimeSinceLastSuccess() {
    return this._lastSuccess ? Date.now() - this._lastSuccess : null;
  }

}

/***/ }),

/***/ "./modules/xmpp/XmppConnection.js":
/*!****************************************!*\
  !*** ./modules/xmpp/XmppConnection.js ***!
  \****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return XmppConnection; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophejs_plugin_stream_management__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophejs-plugin-stream-management */ "./node_modules/strophejs-plugin-stream-management/lib/strophe.stream-management.js");
/* harmony import */ var strophejs_plugin_stream_management__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophejs_plugin_stream_management__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Listenable */ "./modules/util/Listenable.js");
/* harmony import */ var _util_Retry__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Retry */ "./modules/util/Retry.js");
/* harmony import */ var _StropheLastSuccess__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./StropheLastSuccess */ "./modules/xmpp/StropheLastSuccess.js");






const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * The lib-jitsi-meet layer for {@link Strophe.Connection}.
 */

class XmppConnection extends _util_Listenable__WEBPACK_IMPORTED_MODULE_3__["default"] {
  /**
   * The list of {@link XmppConnection} events.
   *
   * @returns {Object}
   */
  static get Events() {
    return {
      CONN_STATUS_CHANGED: 'CONN_STATUS_CHANGED'
    };
  }
  /**
   * The list of Xmpp connection statuses.
   *
   * @returns {Strophe.Status}
   */


  static get Status() {
    return strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status;
  }
  /**
   * Initializes new connection instance.
   *
   * @param {Object} options
   * @param {String} options.serviceUrl - The BOSH or WebSocket service URL.
   * @param {String} [options.enableWebsocketResume=true] - True/false to control the stream resumption functionality.
   * It will enable automatically by default if supported by the XMPP server.
   * @param {Number} [options.websocketKeepAlive=240000] - The websocket keep alive interval. It's 4 minutes by
   * default with jitter. Pass -1 to disable. The actual interval equation is:
   * jitterDelay = (interval * 0.2) + (0.8 * interval * Math.random())
   * The keep alive is HTTP GET request to the {@link options.serviceUrl}.
   */


  constructor({
    enableWebsocketResume,
    websocketKeepAlive,
    serviceUrl
  }) {
    super();
    this._options = {
      enableWebsocketResume: typeof enableWebsocketResume === 'undefined' ? true : enableWebsocketResume,
      websocketKeepAlive: typeof websocketKeepAlive === 'undefined' ? 4 * 60 * 1000 : Number(websocketKeepAlive)
    };
    /**
     * The counter increased before each resume retry attempt, used to calculate exponential backoff.
     * @type {number}
     * @private
     */

    this._resumeRetryN = 0;
    this._stropheConn = new strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Connection(serviceUrl);
    this._usesWebsocket = serviceUrl.startsWith('ws:') || serviceUrl.startsWith('wss:'); // The default maxRetries is 5, which is too long.

    this._stropheConn.maxRetries = 3;
    this._lastSuccessTracker = new _StropheLastSuccess__WEBPACK_IMPORTED_MODULE_5__["default"]();

    this._lastSuccessTracker.startTracking(this._stropheConn);
  }
  /**
   * A getter for the connected state.
   *
   * @returns {boolean}
   */


  get connected() {
    return this._status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.CONNECTED || this._status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.ATTACHED;
  }
  /**
   * Retrieves the feature discovery plugin instance.
   *
   * @returns {Strophe.Connection.disco}
   */


  get disco() {
    return this._stropheConn.disco;
  }
  /**
   * A getter for the disconnecting state.
   *
   * @returns {boolean}
   */


  get disconnecting() {
    return this._stropheConn.disconnecting === true;
  }
  /**
   * A getter for the domain.
   *
   * @returns {string|null}
   */


  get domain() {
    return this._stropheConn.domain;
  }
  /**
   * Tells if Websocket is used as the transport for the current XMPP connection. Returns true for Websocket or false
   * for BOSH.
   * @returns {boolean}
   */


  get isUsingWebSocket() {
    return this._usesWebsocket;
  }
  /**
   * A getter for the JID.
   *
   * @returns {string|null}
   */


  get jid() {
    return this._stropheConn.jid;
  }
  /**
   * Returns headers for the last BOSH response received.
   *
   * @returns {string}
   */


  get lastResponseHeaders() {
    return this._stropheConn._proto && this._stropheConn._proto.lastResponseHeaders;
  }
  /**
   * A getter for the logger plugin instance.
   *
   * @returns {*}
   */


  get logger() {
    return this._stropheConn.logger;
  }
  /**
   * A getter for the connection options.
   *
   * @returns {*}
   */


  get options() {
    return this._stropheConn.options;
  }
  /**
   * A getter for the service URL.
   *
   * @returns {string}
   */


  get service() {
    return this._stropheConn.service;
  }
  /**
   * Returns the current connection status.
   *
   * @returns {Strophe.Status}
   */


  get status() {
    return this._status;
  }
  /**
   * Adds a connection plugin to this instance.
   *
   * @param {string} name - The name of the plugin or rather a key under which it will be stored on this connection
   * instance.
   * @param {ConnectionPluginListenable} plugin - The plugin to add.
   */


  addConnectionPlugin(name, plugin) {
    this[name] = plugin;
    plugin.init(this);
  }
  /**
   * See {@link Strophe.Connection.addHandler}
   *
   * @returns {void}
   */


  addHandler(...args) {
    this._stropheConn.addHandler(...args);
  }
  /* eslint-disable max-params */

  /**
   * Wraps {@link Strophe.Connection.attach} method in order to intercept the connection status updates.
   * See {@link Strophe.Connection.attach} for the params description.
   *
   * @returns {void}
   */


  attach(jid, sid, rid, callback, ...args) {
    this._stropheConn.attach(jid, sid, rid, this._stropheConnectionCb.bind(this, callback), ...args);
  }
  /**
   * Wraps Strophe.Connection.connect method in order to intercept the connection status updates.
   * See {@link Strophe.Connection.connect} for the params description.
   *
   * @returns {void}
   */


  connect(jid, pass, callback, ...args) {
    this._stropheConn.connect(jid, pass, this._stropheConnectionCb.bind(this, callback), ...args);
  }
  /* eslint-enable max-params */

  /**
   * Handles {@link Strophe.Status} updates for the current connection.
   *
   * @param {function} targetCallback - The callback passed by the {@link XmppConnection} consumer to one of
   * the connect methods.
   * @param {Strophe.Status} status - The new connection status.
   * @param {*} args - The rest of the arguments passed by Strophe.
   * @private
   */


  _stropheConnectionCb(targetCallback, status, ...args) {
    this._status = status;
    let blockCallback = false;

    if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.CONNECTED) {
      this._maybeEnableStreamResume();

      this._maybeStartWSKeepAlive();

      this._resumeRetryN = 0;
    } else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.DISCONNECTED) {
      // FIXME add RECONNECTING state instead of blocking the DISCONNECTED update
      blockCallback = this._tryResumingConnection();

      if (!blockCallback) {
        clearTimeout(this._wsKeepAlive);
      }
    }

    if (!blockCallback) {
      targetCallback(status, ...args);
      this.eventEmitter.emit(XmppConnection.Events.CONN_STATUS_CHANGED, status);
    }
  }
  /**
   * The method is meant to be used for testing. It's a shortcut for closing the WebSocket.
   *
   * @returns {void}
   */


  closeWebsocket() {
    this._stropheConn._proto && this._stropheConn._proto.socket && this._stropheConn._proto.socket.close();
  }
  /**
   * See {@link Strophe.Connection.disconnect}.
   *
   * @returns {void}
   */


  disconnect(...args) {
    clearTimeout(this._resumeTimeout);
    clearTimeout(this._wsKeepAlive);

    this._stropheConn.disconnect(...args);
  }
  /**
   * See {@link Strophe.Connection.flush}.
   *
   * @returns {void}
   */


  flush(...args) {
    this._stropheConn.flush(...args);
  }
  /**
   * See {@link LastRequestTracker.getTimeSinceLastSuccess}.
   *
   * @returns {number|null}
   */


  getTimeSinceLastSuccess() {
    return this._lastSuccessTracker.getTimeSinceLastSuccess();
  }
  /**
   * Requests a resume token from the server if enabled and all requirements are met.
   *
   * @private
   */


  _maybeEnableStreamResume() {
    if (!this._options.enableWebsocketResume) {
      return;
    }

    const {
      streamManagement
    } = this._stropheConn;

    if (!this.isUsingWebSocket) {
      logger.warn('Stream resume enabled, but WebSockets are not enabled');
    } else if (!streamManagement) {
      logger.warn('Stream resume enabled, but Strophe streamManagement plugin is not installed');
    } else if (!streamManagement.isSupported()) {
      logger.warn('Stream resume enabled, but XEP-0198 is not supported by the server');
    } else if (!streamManagement.getResumeToken()) {
      logger.info('Enabling XEP-0198 stream management');
      streamManagement.enable(
      /* resume */
      true);
    }
  }
  /**
   * Starts the Websocket keep alive if enabled.
   *
   * @private
   * @returns {void}
   */


  _maybeStartWSKeepAlive() {
    const {
      websocketKeepAlive
    } = this._options;

    if (this._usesWebsocket && websocketKeepAlive > 0) {
      this._wsKeepAlive || logger.info(`WebSocket keep alive interval: ${websocketKeepAlive}ms`);
      clearTimeout(this._wsKeepAlive);
      const intervalWithJitter =
      /* base */
      websocketKeepAlive * 0.2 +
      /* jitter */
      Math.random() * 0.8 * websocketKeepAlive;
      logger.debug(`Scheduling next WebSocket keep-alive in ${intervalWithJitter}ms`);
      this._wsKeepAlive = setTimeout(() => {
        const url = this.service.replace('wss://', 'https://').replace('ws://', 'http://');
        fetch(url).catch(error => {
          logger.error(`Websocket Keep alive failed for url: ${url}`, {
            error
          });
        }).then(() => this._maybeStartWSKeepAlive());
      }, intervalWithJitter);
    }
  }
  /**
   * Send a stanza. This function is called to push data onto the send queue to go out over the wire.
   *
   * @param {Element|Strophe.Builder} stanza - The stanza to send.
   * @returns {void}
   */


  send(stanza) {
    if (!this.connected) {
      throw new Error('Not connected');
    }

    this._stropheConn.send(stanza);
  }
  /**
   * Helper function to send IQ stanzas.
   *
   * @param {Element} elem - The stanza to send.
   * @param {Function} callback - The callback function for a successful request.
   * @param {Function} errback - The callback function for a failed or timed out request.  On timeout, the stanza will
   * be null.
   * @param {number} timeout - The time specified in milliseconds for a timeout to occur.
   * @returns {number} - The id used to send the IQ.
   */


  sendIQ(elem, callback, errback, timeout) {
    if (!this.connected) {
      errback('Not connected');
      return;
    }

    return this._stropheConn.sendIQ(elem, callback, errback, timeout);
  }
  /**
   *  Helper function to send presence stanzas. The main benefit is for sending presence stanzas for which you expect
   *  a responding presence stanza with the same id (for example when leaving a chat room).
   *
   * @param {Element} elem - The stanza to send.
   * @param {Function} callback - The callback function for a successful request.
   * @param {Function} errback - The callback function for a failed or timed out request. On timeout, the stanza will
   * be null.
   * @param {number} timeout - The time specified in milliseconds for a timeout to occur.
   * @returns {number} - The id used to send the presence.
   */


  sendPresence(elem, callback, errback, timeout) {
    if (!this.connected) {
      errback('Not connected');
      return;
    }

    this._stropheConn.sendPresence(elem, callback, errback, timeout);
  }
  /**
   * The method gracefully closes the BOSH connection by using 'navigator.sendBeacon'.
   *
   * @returns {boolean} - true if the beacon was sent.
   */


  sendUnavailableBeacon() {
    if (!navigator.sendBeacon || this._stropheConn.disconnecting || !this._stropheConn.connected) {
      return false;
    }

    this._stropheConn._changeConnectStatus(strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.DISCONNECTING);

    this._stropheConn.disconnecting = true;

    const body = this._stropheConn._proto._buildBody().attrs({
      type: 'terminate'
    });

    const pres = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$pres"])({
      xmlns: strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].NS.CLIENT,
      type: 'unavailable'
    });
    body.cnode(pres.tree());
    const res = navigator.sendBeacon(`https:${this.service}`, strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].serialize(body.tree()));
    logger.info(`Successfully send unavailable beacon ${res}`);

    this._stropheConn._proto._abortAllRequests();

    this._stropheConn._doDisconnect();

    return true;
  }
  /**
   * Tries to use stream management plugin to resume dropped XMPP connection. The streamManagement plugin clears
   * the resume token if any connection error occurs which would put it in unrecoverable state, so as long as
   * the token is present it means the connection can be resumed.
   *
   * @private
   * @returns {boolean}
   */


  _tryResumingConnection() {
    const {
      streamManagement
    } = this._stropheConn;
    const resumeToken = streamManagement && streamManagement.getResumeToken();

    if (resumeToken) {
      clearTimeout(this._resumeTimeout); // FIXME detect internet offline
      // The retry delay will be:
      //   1st retry: 1.5s - 3s
      //   2nd retry: 3s - 9s
      //   3rd retry: 3s - 27s

      this._resumeRetryN = Math.min(3, this._resumeRetryN + 1);
      const retryTimeout = Object(_util_Retry__WEBPACK_IMPORTED_MODULE_4__["getJitterDelay"])(this._resumeRetryN, 1500, 3);
      logger.info(`Will try to resume the XMPP connection in ${retryTimeout}ms`);
      this._resumeTimeout = setTimeout(() => {
        logger.info('Trying to resume the XMPP connection');
        const url = new URL(this._stropheConn.service);
        let {
          search
        } = url;
        search += search.indexOf('?') === -1 ? `?previd=${resumeToken}` : `&previd=${resumeToken}`;
        url.search = search;
        this._stropheConn.service = url.toString();
        streamManagement.resume();
      }, retryTimeout);
      return true;
    }

    return false;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\XmppConnection.js"))

/***/ }),

/***/ "./modules/xmpp/moderator.js":
/*!***********************************!*\
  !*** ./modules/xmpp/moderator.js ***!
  \***********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return Moderator; });
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _settings_Settings__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../settings/Settings */ "./modules/settings/Settings.js");
/* global $, Promise */
const logger = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js").getLogger(__filename);



const XMPPEvents = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");

const AuthenticationEvents = __webpack_require__(/*! ../../service/authentication/AuthenticationEvents */ "./service/authentication/AuthenticationEvents.js");

const GlobalOnErrorHandler = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");


/**
 *
 * @param step
 */

function createExpBackoffTimer(step) {
  let count = 1;
  return function (reset) {
    // Reset call
    if (reset) {
      count = 1;
      return;
    } // Calculate next timeout


    const timeout = Math.pow(2, count - 1);
    count += 1;
    return timeout * step;
  };
}
/* eslint-disable max-params */

/**
 *
 * @param roomName
 * @param xmpp
 * @param emitter
 * @param options
 */


function Moderator(roomName, xmpp, emitter, options) {
  this.roomName = roomName;
  this.xmppService = xmpp;
  this.getNextTimeout = createExpBackoffTimer(1000);
  this.getNextErrorTimeout = createExpBackoffTimer(1000); // External authentication stuff

  this.externalAuthEnabled = false;
  this.options = options; // Sip gateway can be enabled by configuring Jigasi host in config.js or
  // it will be enabled automatically if focus detects the component through
  // service discovery.

  this.sipGatewayEnabled = this.options.connection.hosts && this.options.connection.hosts.call_control !== undefined;
  this.eventEmitter = emitter;
  this.connection = this.xmppService.connection; // FIXME: Message listener that talks to POPUP window

  /**
   *
   * @param event
   */

  function listener(event) {
    if (event.data && event.data.sessionId) {
      if (event.origin !== window.location.origin) {
        logger.warn(`Ignoring sessionId from different origin: ${event.origin}`);
        return;
      }

      _settings_Settings__WEBPACK_IMPORTED_MODULE_1__["default"].sessionId = event.data.sessionId; // After popup is closed we will authenticate
    }
  } // Register


  if (window.addEventListener) {
    window.addEventListener('message', listener, false);
  } else {
    window.attachEvent('onmessage', listener);
  }
}
/* eslint-enable max-params */

Moderator.prototype.isExternalAuthEnabled = function () {
  return this.externalAuthEnabled;
};

Moderator.prototype.isSipGatewayEnabled = function () {
  return this.sipGatewayEnabled;
};

Moderator.prototype.onMucMemberLeft = function (jid) {
  logger.info(`Someone left is it focus ? ${jid}`);
  const resource = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getResourceFromJid(jid);

  if (resource === 'focus') {
    logger.info('Focus has left the room - leaving conference');
    this.eventEmitter.emit(XMPPEvents.FOCUS_LEFT);
  }
};

Moderator.prototype.setFocusUserJid = function (focusJid) {
  if (!this.focusUserJid) {
    this.focusUserJid = focusJid;
    logger.info(`Focus jid set to:  ${this.focusUserJid}`);
  }
};

Moderator.prototype.getFocusUserJid = function () {
  return this.focusUserJid;
};

Moderator.prototype.getFocusComponent = function () {
  // Get focus component address
  let focusComponent = this.options.connection.hosts.focus; // If not specified use default:  'focus.domain'

  if (!focusComponent) {
    focusComponent = `focus.${this.options.connection.hosts.domain}`;
  }

  return focusComponent;
};

Moderator.prototype.createConferenceIq = function () {
  // Generate create conference IQ
  const elem = Object(strophe_js__WEBPACK_IMPORTED_MODULE_0__["$iq"])({
    to: this.getFocusComponent(),
    type: 'set'
  }); // Session Id used for authentication

  const {
    sessionId
  } = _settings_Settings__WEBPACK_IMPORTED_MODULE_1__["default"];
  const machineUID = _settings_Settings__WEBPACK_IMPORTED_MODULE_1__["default"].machineId;
  const config = this.options.conference;
  logger.info(`Session ID: ${sessionId} machine UID: ${machineUID}`);
  elem.c('conference', {
    xmlns: 'http://jitsi.org/protocol/focus',
    room: this.roomName,
    'machine-uid': machineUID
  });

  if (sessionId) {
    elem.attrs({
      'session-id': sessionId
    });
  }

  if (this.options.connection.enforcedBridge !== undefined) {
    elem.c('property', {
      name: 'enforcedBridge',
      value: this.options.connection.enforcedBridge
    }).up();
  } // Tell the focus we have Jigasi configured


  if (this.options.connection.hosts !== undefined && this.options.connection.hosts.call_control !== undefined) {
    elem.c('property', {
      name: 'call_control',
      value: this.options.connection.hosts.call_control
    }).up();
  }

  if (config.channelLastN !== undefined) {
    elem.c('property', {
      name: 'channelLastN',
      value: config.channelLastN
    }).up();
  }

  elem.c('property', {
    name: 'disableRtx',
    value: Boolean(config.disableRtx)
  }).up();

  if (config.enableTcc !== undefined) {
    elem.c('property', {
      name: 'enableTcc',
      value: Boolean(config.enableTcc)
    }).up();
  }

  if (config.enableRemb !== undefined) {
    elem.c('property', {
      name: 'enableRemb',
      value: Boolean(config.enableRemb)
    }).up();
  }

  if (config.minParticipants !== undefined) {
    elem.c('property', {
      name: 'minParticipants',
      value: config.minParticipants
    }).up();
  }

  elem.c('property', {
    name: 'enableLipSync',
    value: this.options.connection.enableLipSync === true
  }).up();

  if (config.audioPacketDelay !== undefined) {
    elem.c('property', {
      name: 'audioPacketDelay',
      value: config.audioPacketDelay
    }).up();
  }

  if (config.startBitrate) {
    elem.c('property', {
      name: 'startBitrate',
      value: config.startBitrate
    }).up();
  }

  if (config.minBitrate) {
    elem.c('property', {
      name: 'minBitrate',
      value: config.minBitrate
    }).up();
  }

  if (config.testing && config.testing.octo && typeof config.testing.octo.probability === 'number') {
    if (Math.random() < config.testing.octo.probability) {
      elem.c('property', {
        name: 'octo',
        value: true
      }).up();
    }
  }

  let openSctp;

  switch (this.options.conference.openBridgeChannel) {
    case 'datachannel':
    case true:
    case undefined:
      openSctp = true;
      break;

    case 'websocket':
      openSctp = false;
      break;
  }

  elem.c('property', {
    name: 'openSctp',
    value: openSctp
  }).up();

  if (this.options.conference.startAudioMuted !== undefined) {
    elem.c('property', {
      name: 'startAudioMuted',
      value: this.options.conference.startAudioMuted
    }).up();
  }

  if (this.options.conference.startVideoMuted !== undefined) {
    elem.c('property', {
      name: 'startVideoMuted',
      value: this.options.conference.startVideoMuted
    }).up();
  }

  if (this.options.conference.stereo !== undefined) {
    elem.c('property', {
      name: 'stereo',
      value: this.options.conference.stereo
    }).up();
  }

  if (this.options.conference.useRoomAsSharedDocumentName !== undefined) {
    elem.c('property', {
      name: 'useRoomAsSharedDocumentName',
      value: this.options.conference.useRoomAsSharedDocumentName
    }).up();
  }

  elem.up();
  return elem;
};

Moderator.prototype.parseSessionId = function (resultIq) {
  // eslint-disable-next-line newline-per-chained-call
  const sessionId = $(resultIq).find('conference').attr('session-id');

  if (sessionId) {
    logger.info(`Received sessionId:  ${sessionId}`);
    _settings_Settings__WEBPACK_IMPORTED_MODULE_1__["default"].sessionId = sessionId;
  }
};

Moderator.prototype.parseConfigOptions = function (resultIq) {
  // eslint-disable-next-line newline-per-chained-call
  this.setFocusUserJid($(resultIq).find('conference').attr('focusjid'));
  const authenticationEnabled = $(resultIq).find('>conference>property' + '[name=\'authentication\'][value=\'true\']').length > 0;
  logger.info(`Authentication enabled: ${authenticationEnabled}`);
  this.externalAuthEnabled = $(resultIq).find('>conference>property' + '[name=\'externalAuth\'][value=\'true\']').length > 0;
  logger.info(`External authentication enabled: ${this.externalAuthEnabled}`);

  if (!this.externalAuthEnabled) {
    // We expect to receive sessionId in 'internal' authentication mode
    this.parseSessionId(resultIq);
  } // eslint-disable-next-line newline-per-chained-call


  const authIdentity = $(resultIq).find('>conference').attr('identity');
  this.eventEmitter.emit(AuthenticationEvents.IDENTITY_UPDATED, authenticationEnabled, authIdentity); // Check if focus has auto-detected Jigasi component(this will be also
  // included if we have passed our host from the config)

  if ($(resultIq).find('>conference>property' + '[name=\'sipGatewayEnabled\'][value=\'true\']').length) {
    this.sipGatewayEnabled = true;
  }

  logger.info(`Sip gateway enabled:  ${this.sipGatewayEnabled}`);
}; // FIXME We need to show the fact that we're waiting for the focus to the user
// (or that the focus is not available)

/**
 * Allocates the conference focus.
 *
 * @param {Function} callback - the function to be called back upon the
 * successful allocation of the conference focus
 * @returns {Promise} - Resolved when Jicofo allows to join the room. It's never
 * rejected and it'll keep on pinging Jicofo forever.
 */


Moderator.prototype.allocateConferenceFocus = function () {
  return new Promise(resolve => {
    // Try to use focus user JID from the config
    this.setFocusUserJid(this.options.connection.focusUserJid); // Send create conference IQ

    this.connection.sendIQ(this.createConferenceIq(), result => this._allocateConferenceFocusSuccess(result, resolve), error => this._allocateConferenceFocusError(error, resolve)); // XXX We're pressed for time here because we're beginning a complex
    // and/or lengthy conference-establishment process which supposedly
    // involves multiple RTTs. We don't have the time to wait for Strophe to
    // decide to send our IQ.

    this.connection.flush();
  });
};
/**
 * Invoked by {@link #allocateConferenceFocus} upon its request receiving an
 * error result.
 *
 * @param error - the error result of the request that
 * {@link #allocateConferenceFocus} sent
 * @param {Function} callback - the function to be called back upon the
 * successful allocation of the conference focus
 */


Moderator.prototype._allocateConferenceFocusError = function (error, callback) {
  // If the session is invalid, remove and try again without session ID to get
  // a new one
  const invalidSession = $(error).find('>error>session-invalid').length || $(error).find('>error>not-acceptable').length;

  if (invalidSession) {
    logger.info('Session expired! - removing');
    _settings_Settings__WEBPACK_IMPORTED_MODULE_1__["default"].sessionId = undefined;
  }

  if ($(error).find('>error>graceful-shutdown').length) {
    this.eventEmitter.emit(XMPPEvents.GRACEFUL_SHUTDOWN);
    return;
  } // Check for error returned by the reservation system


  const reservationErr = $(error).find('>error>reservation-error');

  if (reservationErr.length) {
    // Trigger error event
    const errorCode = reservationErr.attr('error-code');
    const errorTextNode = $(error).find('>error>text');
    let errorMsg;

    if (errorTextNode) {
      errorMsg = errorTextNode.text();
    }

    this.eventEmitter.emit(XMPPEvents.RESERVATION_ERROR, errorCode, errorMsg);
    return;
  } // Not authorized to create new room


  if ($(error).find('>error>not-authorized').length) {
    logger.warn('Unauthorized to start the conference', error);
    const toDomain = strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].getDomainFromJid(error.getAttribute('to'));

    if (toDomain !== this.options.connection.hosts.anonymousdomain) {
      // FIXME "is external" should come either from the focus or
      // config.js
      this.externalAuthEnabled = true;
    }

    this.eventEmitter.emit(XMPPEvents.AUTHENTICATION_REQUIRED);
    return;
  }

  const waitMs = this.getNextErrorTimeout();
  const errmsg = `Focus error, retry after ${waitMs}`;
  GlobalOnErrorHandler.callErrorHandler(new Error(errmsg));
  logger.error(errmsg, error); // Show message

  const focusComponent = this.getFocusComponent();
  const retrySec = waitMs / 1000; // FIXME: message is duplicated ? Do not show in case of session invalid
  // which means just a retry

  if (!invalidSession) {
    this.eventEmitter.emit(XMPPEvents.FOCUS_DISCONNECTED, focusComponent, retrySec);
  } // Reset response timeout


  this.getNextTimeout(true);
  window.setTimeout(() => this.allocateConferenceFocus().then(callback), waitMs);
};
/**
 * Invoked by {@link #allocateConferenceFocus} upon its request receiving a
 * success (i.e. non-error) result.
 *
 * @param result - the success (i.e. non-error) result of the request that
 * {@link #allocateConferenceFocus} sent
 * @param {Function} callback - the function to be called back upon the
 * successful allocation of the conference focus
 */


Moderator.prototype._allocateConferenceFocusSuccess = function (result, callback) {
  // Setup config options
  this.parseConfigOptions(result); // Reset the error timeout (because we haven't failed here).

  this.getNextErrorTimeout(true); // eslint-disable-next-line newline-per-chained-call

  if ($(result).find('conference').attr('ready') === 'true') {
    // Reset the non-error timeout (because we've succeeded here).
    this.getNextTimeout(true); // Exec callback

    callback();
  } else {
    const waitMs = this.getNextTimeout();
    logger.info(`Waiting for the focus... ${waitMs}`);
    window.setTimeout(() => this.allocateConferenceFocus().then(callback), waitMs);
  }
};

Moderator.prototype.authenticate = function () {
  return new Promise((resolve, reject) => {
    this.connection.sendIQ(this.createConferenceIq(), result => {
      this.parseSessionId(result);
      resolve();
    }, errorIq => reject({
      error: $(errorIq).find('iq>error :first').prop('tagName'),
      message: $(errorIq).find('iq>error>text').text()
    }));
  });
};

Moderator.prototype.getLoginUrl = function (urlCallback, failureCallback) {
  this._getLoginUrl(
  /* popup */
  false, urlCallback, failureCallback);
};
/**
 *
 * @param {boolean} popup false for {@link Moderator#getLoginUrl} or true for
 * {@link Moderator#getPopupLoginUrl}
 * @param urlCb
 * @param failureCb
 */


Moderator.prototype._getLoginUrl = function (popup, urlCb, failureCb) {
  const iq = Object(strophe_js__WEBPACK_IMPORTED_MODULE_0__["$iq"])({
    to: this.getFocusComponent(),
    type: 'get'
  });
  const attrs = {
    xmlns: 'http://jitsi.org/protocol/focus',
    room: this.roomName,
    'machine-uid': _settings_Settings__WEBPACK_IMPORTED_MODULE_1__["default"].machineId
  };
  let str = 'auth url'; // for logger

  if (popup) {
    attrs.popup = true;
    str = `POPUP ${str}`;
  }

  iq.c('login-url', attrs);
  /**
   * Implements a failure callback which reports an error message and an error
   * through (1) GlobalOnErrorHandler, (2) logger, and (3) failureCb.
   *
   * @param {string} errmsg the error messsage to report
   * @param {*} error the error to report (in addition to errmsg)
   */

  function reportError(errmsg, err) {
    GlobalOnErrorHandler.callErrorHandler(new Error(errmsg));
    logger.error(errmsg, err);
    failureCb(err);
  }

  this.connection.sendIQ(iq, result => {
    // eslint-disable-next-line newline-per-chained-call
    let url = $(result).find('login-url').attr('url');
    url = decodeURIComponent(url);

    if (url) {
      logger.info(`Got ${str}: ${url}`);
      urlCb(url);
    } else {
      reportError(`Failed to get ${str} from the focus`, result);
    }
  }, reportError.bind(undefined, `Get ${str} error`));
};

Moderator.prototype.getPopupLoginUrl = function (urlCallback, failureCallback) {
  this._getLoginUrl(
  /* popup */
  true, urlCallback, failureCallback);
};

Moderator.prototype.logout = function (callback) {
  const iq = Object(strophe_js__WEBPACK_IMPORTED_MODULE_0__["$iq"])({
    to: this.getFocusComponent(),
    type: 'set'
  });
  const {
    sessionId
  } = _settings_Settings__WEBPACK_IMPORTED_MODULE_1__["default"];

  if (!sessionId) {
    callback();
    return;
  }

  iq.c('logout', {
    xmlns: 'http://jitsi.org/protocol/focus',
    'session-id': sessionId
  });
  this.connection.sendIQ(iq, result => {
    // eslint-disable-next-line newline-per-chained-call
    let logoutUrl = $(result).find('logout').attr('logout-url');

    if (logoutUrl) {
      logoutUrl = decodeURIComponent(logoutUrl);
    }

    logger.info(`Log out OK, url: ${logoutUrl}`, result);
    _settings_Settings__WEBPACK_IMPORTED_MODULE_1__["default"].sessionId = undefined;
    callback(logoutUrl);
  }, error => {
    const errmsg = 'Logout error';
    GlobalOnErrorHandler.callErrorHandler(new Error(errmsg));
    logger.error(errmsg, error);
  });
};
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\moderator.js"))

/***/ }),

/***/ "./modules/xmpp/strophe.emuc.js":
/*!**************************************!*\
  !*** ./modules/xmpp/strophe.emuc.js ***!
  \**************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return MucConnectionPlugin; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _ChatRoom__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ChatRoom */ "./modules/xmpp/ChatRoom.js");
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionPlugin */ "./modules/xmpp/ConnectionPlugin.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_4__);
/* global $ */





const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * MUC connection plugin.
 */

class MucConnectionPlugin extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_3__["ConnectionPluginListenable"] {
  /**
   *
   * @param xmpp
   */
  constructor(xmpp) {
    super();
    this.xmpp = xmpp;
    this.rooms = {};
  }
  /**
   *
   * @param connection
   */


  init(connection) {
    super.init(connection); // add handlers (just once)

    this.connection.addHandler(this.onPresence.bind(this), null, 'presence', null, null, null, null);
    this.connection.addHandler(this.onPresenceUnavailable.bind(this), null, 'presence', 'unavailable', null);
    this.connection.addHandler(this.onPresenceError.bind(this), null, 'presence', 'error', null);
    this.connection.addHandler(this.onMessage.bind(this), null, 'message', null, null);
    this.connection.addHandler(this.onMute.bind(this), 'http://jitsi.org/jitmeet/audio', 'iq', 'set', null, null);
  }
  /**
   *
   * @param jid
   * @param password
   * @param options
   */


  createRoom(jid, password, options) {
    const roomJid = strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getBareJidFromJid(jid);

    if (this.rooms[roomJid]) {
      const errmsg = 'You are already in the room!';
      logger.error(errmsg);
      throw new Error(errmsg);
    }

    this.rooms[roomJid] = new _ChatRoom__WEBPACK_IMPORTED_MODULE_2__["default"](this.connection, jid, password, this.xmpp, options);
    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_4___default.a.EMUC_ROOM_ADDED, this.rooms[roomJid]);
    return this.rooms[roomJid];
  }
  /**
   *
   * @param jid
   */


  doLeave(jid) {
    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_4___default.a.EMUC_ROOM_REMOVED, this.rooms[jid]);
    delete this.rooms[jid];
  }
  /**
   *
   * @param pres
   */


  onPresence(pres) {
    const from = pres.getAttribute('from'); // What is this for? A workaround for something?

    if (pres.getAttribute('type')) {
      return true;
    }

    const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getBareJidFromJid(from)];

    if (!room) {
      return true;
    } // Parse status.


    if ($(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]' + '>status[code="201"]').length) {
      room.createNonAnonymousRoom();
    }

    room.onPresence(pres);
    return true;
  }
  /**
   *
   * @param pres
   */


  onPresenceUnavailable(pres) {
    const from = pres.getAttribute('from');
    const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getBareJidFromJid(from)];

    if (!room) {
      return true;
    }

    room.onPresenceUnavailable(pres, from);
    return true;
  }
  /**
   *
   * @param pres
   */


  onPresenceError(pres) {
    const from = pres.getAttribute('from');
    const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getBareJidFromJid(from)];

    if (!room) {
      return true;
    }

    room.onPresenceError(pres, from);
    return true;
  }
  /**
   *
   * @param msg
   */


  onMessage(msg) {
    // FIXME: this is a hack. but jingle on muc makes nickchanges hard
    const from = msg.getAttribute('from');
    const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getBareJidFromJid(from)];

    if (!room) {
      return true;
    }

    room.onMessage(msg, from);
    return true;
  }
  /**
   * TODO: Document
   * @param iq
   */


  onMute(iq) {
    const from = iq.getAttribute('from');
    const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getBareJidFromJid(from)]; // Returning false would result in the listener being deregistered by Strophe

    if (!room) {
      return true;
    }

    room.onMute(iq);
    return true;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\strophe.emuc.js"))

/***/ }),

/***/ "./modules/xmpp/strophe.jingle.js":
/*!****************************************!*\
  !*** ./modules/xmpp/strophe.jingle.js ***!
  \****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return JingleConnectionPlugin; });
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./service/statistics/AnalyticsEvents.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4__);
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/RandomUtil */ "./modules/util/RandomUtil.js");
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(_util_RandomUtil__WEBPACK_IMPORTED_MODULE_5__);
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../statistics/statistics */ "./modules/statistics/statistics.js");
/* harmony import */ var _JingleSessionPC__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./JingleSessionPC */ "./modules/xmpp/JingleSessionPC.js");
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ConnectionPlugin */ "./modules/xmpp/ConnectionPlugin.js");
/* global $, __filename */









const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_1__["getLogger"])(__filename); // XXX Strophe is build around the idea of chaining function calls so allow long
// function call chains.

/* eslint-disable newline-per-chained-call */

/**
 *
 */

class JingleConnectionPlugin extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_8__["default"] {
  /**
   * Creates new <tt>JingleConnectionPlugin</tt>
   * @param {XMPP} xmpp
   * @param {EventEmitter} eventEmitter
   * @param {Object} iceConfig an object that holds the iceConfig to be passed
   * to the p2p and the jvb <tt>PeerConnection</tt>.
   */
  constructor(xmpp, eventEmitter, iceConfig) {
    super();
    this.xmpp = xmpp;
    this.eventEmitter = eventEmitter;
    this.sessions = {};
    this.jvbIceConfig = iceConfig.jvb;
    this.p2pIceConfig = iceConfig.p2p;
    this.mediaConstraints = {
      offerToReceiveAudio: true,
      offerToReceiveVideo: true
    };
  }
  /**
   *
   * @param connection
   */


  init(connection) {
    super.init(connection);
    this.connection.addHandler(this.onJingle.bind(this), 'urn:xmpp:jingle:1', 'iq', 'set', null, null);
  }
  /**
   *
   * @param iq
   */


  onJingle(iq) {
    const sid = $(iq).find('jingle').attr('sid');
    const action = $(iq).find('jingle').attr('action');
    const fromJid = iq.getAttribute('from'); // send ack first

    const ack = Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      type: 'result',
      to: fromJid,
      id: iq.getAttribute('id')
    });
    logger.log(`on jingle ${action} from ${fromJid}`, iq);
    let sess = this.sessions[sid];

    if (action !== 'session-initiate') {
      if (!sess) {
        ack.attrs({
          type: 'error'
        });
        ack.c('error', {
          type: 'cancel'
        }).c('item-not-found', {
          xmlns: 'urn:ietf:params:xml:ns:xmpp-stanzas'
        }).up().c('unknown-session', {
          xmlns: 'urn:xmpp:jingle:errors:1'
        });
        logger.warn('invalid session id', iq);
        this.connection.send(ack);
        return true;
      } // local jid is not checked


      if (fromJid !== sess.remoteJid) {
        logger.warn('jid mismatch for session id', sid, sess.remoteJid, iq);
        ack.attrs({
          type: 'error'
        });
        ack.c('error', {
          type: 'cancel'
        }).c('item-not-found', {
          xmlns: 'urn:ietf:params:xml:ns:xmpp-stanzas'
        }).up().c('unknown-session', {
          xmlns: 'urn:xmpp:jingle:errors:1'
        });
        this.connection.send(ack);
        return true;
      }
    } else if (sess !== undefined) {
      // Existing session with same session id. This might be out-of-order
      // if the sess.remoteJid is the same as from.
      ack.attrs({
        type: 'error'
      });
      ack.c('error', {
        type: 'cancel'
      }).c('service-unavailable', {
        xmlns: 'urn:ietf:params:xml:ns:xmpp-stanzas'
      }).up();
      logger.warn('duplicate session id', sid, iq);
      this.connection.send(ack);
      return true;
    }

    const now = window.performance.now(); // FIXME that should work most of the time, but we'd have to
    // think how secure it is to assume that user with "focus"
    // nickname is Jicofo.

    const isP2P = strophe_js__WEBPACK_IMPORTED_MODULE_2__["Strophe"].getResourceFromJid(fromJid) !== 'focus'; // see http://xmpp.org/extensions/xep-0166.html#concepts-session

    switch (action) {
      case 'session-initiate':
        {
          logger.log('(TIME) received session-initiate:\t', now);
          const startMuted = $(iq).find('jingle>startmuted');

          if (startMuted && startMuted.length > 0) {
            const audioMuted = startMuted.attr('audio');
            const videoMuted = startMuted.attr('video');
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default.a.START_MUTED_FROM_FOCUS, audioMuted === 'true', videoMuted === 'true');
          }

          logger.info(`Marking session from ${fromJid} as ${isP2P ? '' : '*not*'} P2P`);
          const iceConfig = isP2P ? this.p2pIceConfig : this.jvbIceConfig;
          sess = new _JingleSessionPC__WEBPACK_IMPORTED_MODULE_7__["default"]($(iq).find('jingle').attr('sid'), $(iq).attr('to'), fromJid, this.connection, this.mediaConstraints, // Makes a copy in order to prevent exception thrown on RN when either this.p2pIceConfig or
          // this.jvbIceConfig is modified and there's a PeerConnection instance holding a reference
          JSON.parse(JSON.stringify(iceConfig)), isP2P,
          /* initiator */
          false);
          this.sessions[sess.sid] = sess;
          this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default.a.CALL_INCOMING, sess, $(iq).find('>jingle'), now);
          break;
        }

      case 'session-accept':
        {
          this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default.a.CALL_ACCEPTED, sess, $(iq).find('>jingle'));
          break;
        }

      case 'content-modify':
        {
          sess.modifyContents($(iq).find('>jingle'));
          break;
        }

      case 'transport-info':
        {
          this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default.a.TRANSPORT_INFO, sess, $(iq).find('>jingle'));
          break;
        }

      case 'session-terminate':
        {
          logger.log('terminating...', sess.sid);
          let reasonCondition = null;
          let reasonText = null;

          if ($(iq).find('>jingle>reason').length) {
            reasonCondition = $(iq).find('>jingle>reason>:first')[0].tagName;
            reasonText = $(iq).find('>jingle>reason>text').text();
          }

          this.terminate(sess.sid, reasonCondition, reasonText);
          this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3___default.a.CALL_ENDED, sess, reasonCondition, reasonText);
          break;
        }

      case 'transport-replace':
        logger.info('(TIME) Start transport replace:\t', now);
        _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["createJingleEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["ACTION_JINGLE_TR_RECEIVED"], {
          p2p: isP2P,
          value: now
        }));
        sess.replaceTransport($(iq).find('>jingle'), () => {
          const successTime = window.performance.now();
          logger.info('(TIME) Transport replace success:\t', successTime);
          _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics(Object(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["createJingleEvent"])(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_0__["ACTION_JINGLE_TR_SUCCESS"], {
            p2p: isP2P,
            value: successTime
          }));
        }, error => {
          _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4___default.a.callErrorHandler(error);
          logger.error('Transport replace failed', error);
          sess.sendTransportReject();
        });
        break;

      case 'addsource': // FIXME: proprietary, un-jingleish

      case 'source-add':
        // FIXME: proprietary
        sess.addRemoteStream($(iq).find('>jingle>content'));
        break;

      case 'removesource': // FIXME: proprietary, un-jingleish

      case 'source-remove':
        // FIXME: proprietary
        sess.removeRemoteStream($(iq).find('>jingle>content'));
        break;

      default:
        logger.warn('jingle action not implemented', action);
        ack.attrs({
          type: 'error'
        });
        ack.c('error', {
          type: 'cancel'
        }).c('bad-request', {
          xmlns: 'urn:ietf:params:xml:ns:xmpp-stanzas'
        }).up();
        break;
    }

    this.connection.send(ack);
    return true;
  }
  /**
   * Creates new <tt>JingleSessionPC</tt> meant to be used in a direct P2P
   * connection, configured as 'initiator'.
   * @param {string} me our JID
   * @param {string} peer remote participant's JID
   * @return {JingleSessionPC}
   */


  newP2PJingleSession(me, peer) {
    const sess = new _JingleSessionPC__WEBPACK_IMPORTED_MODULE_7__["default"](_util_RandomUtil__WEBPACK_IMPORTED_MODULE_5___default.a.randomHexString(12), me, peer, this.connection, this.mediaConstraints, this.p2pIceConfig,
    /* P2P */
    true,
    /* initiator */
    true);
    this.sessions[sess.sid] = sess;
    return sess;
  }
  /**
   *
   * @param sid
   * @param reasonCondition
   * @param reasonText
   */


  terminate(sid, reasonCondition, reasonText) {
    if (this.sessions.hasOwnProperty(sid)) {
      if (this.sessions[sid].state !== 'ended') {
        this.sessions[sid].onTerminated(reasonCondition, reasonText);
      }

      delete this.sessions[sid];
    }
  }
  /**
   *
   */


  getStunAndTurnCredentials() {
    // get stun and turn configuration from server via xep-0215
    // uses time-limited credentials as described in
    // http://tools.ietf.org/html/draft-uberti-behave-turn-rest-00
    //
    // See https://modules.prosody.im/mod_turncredentials.html
    // for a prosody module which implements this.
    //
    // Currently, this doesn't work with updateIce and therefore credentials
    // with a long validity have to be fetched before creating the
    // peerconnection.
    // TODO: implement refresh via updateIce as described in
    //      https://code.google.com/p/webrtc/issues/detail?id=1650
    this.connection.sendIQ(Object(strophe_js__WEBPACK_IMPORTED_MODULE_2__["$iq"])({
      type: 'get',
      to: this.connection.domain
    }).c('services', {
      xmlns: 'urn:xmpp:extdisco:1'
    }), res => {
      const iceservers = [];
      $(res).find('>services>service').each((idx, el) => {
        // eslint-disable-next-line no-param-reassign
        el = $(el);
        const dict = {};
        const type = el.attr('type');

        switch (type) {
          case 'stun':
            dict.urls = `stun:${el.attr('host')}`;

            if (el.attr('port')) {
              dict.urls += `:${el.attr('port')}`;
            }

            iceservers.push(dict);
            break;

          case 'turn':
          case 'turns':
            {
              dict.urls = `${type}:`;
              const username = el.attr('username'); // https://code.google.com/p/webrtc/issues/detail
              // ?id=1508

              if (username) {
                const match = navigator.userAgent.match(/Chrom(e|ium)\/([0-9]+)\./);

                if (match && parseInt(match[2], 10) < 28) {
                  dict.urls += `${username}@`;
                } else {
                  // only works in M28
                  dict.username = username;
                }
              }

              dict.urls += el.attr('host');
              const port = el.attr('port');

              if (port) {
                dict.urls += `:${el.attr('port')}`;
              }

              const transport = el.attr('transport');

              if (transport && transport !== 'udp') {
                dict.urls += `?transport=${transport}`;
              }

              dict.credential = el.attr('password') || dict.credential;
              iceservers.push(dict);
              break;
            }
        }
      });
      const options = this.xmpp.options;

      if (options.useStunTurn) {
        // we want to filter and leave only tcp/turns candidates
        // which make sense for the jvb connections
        this.jvbIceConfig.iceServers = iceservers.filter(s => s.urls.startsWith('turns'));
      }

      if (options.p2p && options.p2p.useStunTurn) {
        this.p2pIceConfig.iceServers = iceservers;
      }
    }, err => {
      logger.warn('getting turn credentials failed', err);
      logger.warn('is mod_turncredentials or similar installed?');
    }); // implement push?
  }
  /**
   * Returns the data saved in 'updateLog' in a format to be logged.
   */


  getLog() {
    const data = {};
    Object.keys(this.sessions).forEach(sid => {
      const session = this.sessions[sid];
      const pc = session.peerconnection;

      if (pc && pc.updateLog) {
        // FIXME: should probably be a .dump call
        data[`jingle_${sid}`] = {
          updateLog: pc.updateLog,
          stats: pc.stats,
          url: window.location.href
        };
      }
    });
    return data;
  }

}
/* eslint-enable newline-per-chained-call */
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\strophe.jingle.js"))

/***/ }),

/***/ "./modules/xmpp/strophe.logger.js":
/*!****************************************!*\
  !*** ./modules/xmpp/strophe.logger.js ***!
  \****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionPlugin */ "./modules/xmpp/ConnectionPlugin.js");


/**
 *  Logs raw stanzas and makes them available for download as JSON
 */

class StropheLogger extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_1__["default"] {
  /**
   *
   */
  constructor() {
    super();
    this.log = [];
  }
  /**
   *
   * @param connection
   */


  init(connection) {
    super.init(connection);
    this.connection.rawInput = this.logIncoming.bind(this);
    this.connection.rawOutput = this.logOutgoing.bind(this);
  }
  /**
   *
   * @param stanza
   */


  logIncoming(stanza) {
    this.log.push([new Date().getTime(), 'incoming', stanza]);
  }
  /**
   *
   * @param stanza
   */


  logOutgoing(stanza) {
    this.log.push([new Date().getTime(), 'outgoing', stanza]);
  }

}
/**
 *
 */


/* harmony default export */ __webpack_exports__["default"] = (function () {
  strophe_js__WEBPACK_IMPORTED_MODULE_0__["Strophe"].addConnectionPlugin('logger', new StropheLogger());
});

/***/ }),

/***/ "./modules/xmpp/strophe.ping.js":
/*!**************************************!*\
  !*** ./modules/xmpp/strophe.ping.js ***!
  \**************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return PingConnectionPlugin; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionPlugin */ "./modules/xmpp/ConnectionPlugin.js");




const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Ping every 10 sec
 */

const PING_INTERVAL = 10000;
/**
 * Ping timeout error after 15 sec of waiting.
 */

const PING_TIMEOUT = 15000;
/**
 * Will close the connection after 3 consecutive ping errors.
 */

const PING_THRESHOLD = 3;
/**
 * The number of timestamps of send pings to keep.
 * The current value is 2 minutes.
 * @type {number} number of timestamps.
 */

const PING_TIMESTAMPS_TO_KEEP = 120000 / PING_INTERVAL;
/**
 * XEP-0199 ping plugin.
 *
 * Registers "urn:xmpp:ping" namespace under Strophe.NS.PING.
 */

class PingConnectionPlugin extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_3__["default"] {
  /**
   * Contructs new object
   * @param {XMPP} xmpp the xmpp module.
   * @constructor
   */
  constructor(xmpp) {
    super();
    this.failedPings = 0;
    this.xmpp = xmpp;
    this.pingExecIntervals = new Array(PING_TIMESTAMPS_TO_KEEP);
  }
  /**
   * Initializes the plugin. Method called by Strophe.
   * @param connection Strophe connection instance.
   */


  init(connection) {
    super.init(connection);
    strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].addNamespace('PING', 'urn:xmpp:ping');
  }
  /* eslint-disable max-params */

  /**
   * Sends "ping" to given <tt>jid</tt>
   * @param jid the JID to which ping request will be sent.
   * @param success callback called on success.
   * @param error callback called on error.
   * @param timeout ms how long are we going to wait for the response. On
   * timeout <tt>error<//t> callback is called with undefined error argument.
   */


  ping(jid, success, error, timeout) {
    this._addPingExecutionTimestamp();

    const iq = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
      type: 'get',
      to: jid
    });
    iq.c('ping', {
      xmlns: strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].NS.PING
    });
    this.connection.sendIQ(iq, success, error, timeout);
  }
  /* eslint-enable max-params */

  /**
   * Starts to send ping in given interval to specified remote JID.
   * This plugin supports only one such task and <tt>stopInterval</tt>
   * must be called before starting a new one.
   * @param remoteJid remote JID to which ping requests will be sent to.
   * @param interval task interval in ms.
   */


  startInterval(remoteJid, interval = PING_INTERVAL) {
    clearInterval(this.intervalId);
    this.intervalId = window.setInterval(() => {
      this.ping(remoteJid, () => {
        this.failedPings = 0;
      }, error => {
        this.failedPings += 1;
        const errmsg = `Ping ${error ? 'error' : 'timeout'}`;

        if (this.failedPings >= PING_THRESHOLD) {
          _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default.a.callErrorHandler(new Error(errmsg));
          logger.error(errmsg, error); // FIXME it doesn't help to disconnect when 3rd PING
          // times out, it only stops Strophe from retrying.
          // Not really sure what's the right thing to do in that
          // situation, but just closing the connection makes no
          // sense.
          // self.connection.disconnect();
        } else {
          logger.warn(errmsg, error);
        }
      }, PING_TIMEOUT);
    }, interval);
    logger.info(`XMPP pings will be sent every ${interval} ms`);
  }
  /**
   * Stops current "ping"  interval task.
   */


  stopInterval() {
    if (this.intervalId) {
      window.clearInterval(this.intervalId);
      this.intervalId = null;
      this.failedPings = 0;
      logger.info('Ping interval cleared');
    }
  }
  /**
   * Adds the current time to the array of send ping timestamps.
   * @private
   */


  _addPingExecutionTimestamp() {
    this.pingExecIntervals.push(new Date().getTime()); // keep array length to PING_TIMESTAMPS_TO_KEEP

    if (this.pingExecIntervals.length > PING_TIMESTAMPS_TO_KEEP) {
      this.pingExecIntervals.shift();
    }
  }
  /**
   * Returns the maximum time between the recent sent pings, if there is a
   * big value it means the computer was inactive for some time(suspended).
   * Checks the maximum gap between sending pings, considering and the
   * current time. Trying to detect computer inactivity (sleep).
   *
   * @returns {int} the time ping was suspended, if it was not 0 is returned.
   */


  getPingSuspendTime() {
    const pingIntervals = this.pingExecIntervals.slice(); // we need current time, as if ping was sent now
    // if computer sleeps we will get correct interval after next
    // scheduled ping, bet we sometimes need that interval before waiting
    // for the next ping, on closing the connection on error.

    pingIntervals.push(new Date().getTime());
    let maxInterval = 0;
    let previousTS = pingIntervals[0];
    pingIntervals.forEach(e => {
      const currentInterval = e - previousTS;

      if (currentInterval > maxInterval) {
        maxInterval = currentInterval;
      }

      previousTS = e;
    }); // remove the interval between the ping sent
    // this way in normal execution there is no suspend and the return
    // will be 0 or close to 0.

    maxInterval -= PING_INTERVAL; // make sure we do not return less than 0

    return Math.max(maxInterval, 0);
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\strophe.ping.js"))

/***/ }),

/***/ "./modules/xmpp/strophe.rayo.js":
/*!**************************************!*\
  !*** ./modules/xmpp/strophe.rayo.js ***!
  \**************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return RayoConnectionPlugin; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionPlugin */ "./modules/xmpp/ConnectionPlugin.js");
/* global $ */



const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
const RAYO_XMLNS = 'urn:xmpp:rayo:1';
/**
 *
 */

class RayoConnectionPlugin extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_2__["default"] {
  /**
   *
   * @param connection
   */
  init(connection) {
    super.init(connection);
    this.connection.addHandler(this.onRayo.bind(this), RAYO_XMLNS, 'iq', 'set', null, null);
  }
  /**
   *
   * @param iq
   */


  onRayo(iq) {
    logger.info('Rayo IQ', iq);
  }
  /* eslint-disable max-params */

  /**
   *
   * @param to
   * @param from
   * @param roomName
   * @param roomPass
   * @param focusMucJid
   */


  dial(to, from, roomName, roomPass, focusMucJid) {
    return new Promise((resolve, reject) => {
      if (!focusMucJid) {
        reject(new Error('Internal error!'));
        return;
      }

      const req = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
        type: 'set',
        to: focusMucJid
      });
      req.c('dial', {
        xmlns: RAYO_XMLNS,
        to,
        from
      });
      req.c('header', {
        name: 'JvbRoomName',
        value: roomName
      }).up();

      if (roomPass && roomPass.length) {
        req.c('header', {
          name: 'JvbRoomPassword',
          value: roomPass
        }).up();
      }

      this.connection.sendIQ(req, result => {
        logger.info('Dial result ', result); // eslint-disable-next-line newline-per-chained-call

        const resource = $(result).find('ref').attr('uri');
        this.callResource = resource.substr('xmpp:'.length);
        logger.info(`Received call resource: ${this.callResource}`);
        resolve();
      }, error => {
        logger.info('Dial error ', error);
        reject(error);
      });
    });
  }
  /* eslint-enable max-params */

  /**
   *
   */


  hangup() {
    return new Promise((resolve, reject) => {
      if (!this.callResource) {
        reject(new Error('No call in progress'));
        logger.warn('No call in progress');
        return;
      }

      const req = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$iq"])({
        type: 'set',
        to: this.callResource
      });
      req.c('hangup', {
        xmlns: RAYO_XMLNS
      });
      this.connection.sendIQ(req, result => {
        logger.info('Hangup result ', result);
        this.callResource = null;
        resolve();
      }, error => {
        logger.info('Hangup error ', error);
        this.callResource = null;
        reject(new Error('Hangup error '));
      });
    });
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\strophe.rayo.js"))

/***/ }),

/***/ "./modules/xmpp/strophe.util.js":
/*!**************************************!*\
  !*** ./modules/xmpp/strophe.util.js ***!
  \**************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__);
/* global __filename */

/**
 * Strophe logger implementation. Logs from level WARN and above.
 */



const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * This is the last HTTP error status captured from Strophe debug logs.
 * The purpose of storing it is to distinguish between the network and
 * infrastructure reason for connection being dropped (see connectionHandler in
 * xmpp.js). The value will be cleared (-1) if the subsequent request succeeds
 * which means that the failure could be transient.
 *
 * FIXME in the latest Strophe (not released on npm) there is API to handle
 * particular HTTP errors, but there is no way to learn if the subsequent
 * request succeeded in order to tell if the error was one time incident or if
 * it was the reason for dropping the connection by Strophe (the connection is
 * dropped after 5 subsequent failures). Ideally Strophe should provide more
 * details about the reason on why the connection stopped.
 *
 * @type {number}
 */

let lastErrorStatus = -1;
/**
 * A regular expression used to catch Strophe's log message indicating that the
 * last BOSH request was successful. When there is such message seen the
 * {@link lastErrorStatus} will be set back to '-1'.
 * @type {RegExp}
 */

const resetLastErrorStatusRegExpr = /request id \d+.\d+ got 200/;
/**
 * A regular expression used to capture the current value of the BOSH request
 * error status (HTTP error code or '0' or something else).
 * @type {RegExp}
 */

const lastErrorStatusRegExpr = /request errored, status: (\d+), number of errors: \d+/;
/**
 *
 */

/* harmony default export */ __webpack_exports__["default"] = (function () {
  strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].log = function (level, msg) {
    // Our global handler reports uncaught errors to the stats which may
    // interpret those as partial call failure.
    // Strophe log entry about secondary request timeout does not mean that
    // it's a final failure(the request will be restarted), so we lower it's
    // level here to a warning.
    logger.trace('Strophe', level, msg);

    if (typeof msg === 'string' && msg.indexOf('Request ') !== -1 && msg.indexOf('timed out (secondary), restarting') !== -1) {
      // eslint-disable-next-line no-param-reassign
      level = strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].LogLevel.WARN;
    }
    /* eslint-disable no-case-declarations */


    switch (level) {
      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].LogLevel.DEBUG:
        // The log message which reports successful status is logged on
        // Strophe's DEBUG level.
        if (lastErrorStatus !== -1 && resetLastErrorStatusRegExpr.test(msg)) {
          logger.debug('Reset lastErrorStatus');
          lastErrorStatus = -1;
        }

        break;

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].LogLevel.WARN:
        logger.warn(`Strophe: ${msg}`);
        const errStatusCapture = lastErrorStatusRegExpr.exec(msg);

        if (errStatusCapture && errStatusCapture.length === 2) {
          lastErrorStatus = parseInt(errStatusCapture[1], 10);
          logger.debug(`lastErrorStatus set to: ${lastErrorStatus}`);
        }

        break;

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].LogLevel.ERROR:
      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].LogLevel.FATAL:
        // eslint-disable-next-line no-param-reassign
        msg = `Strophe: ${msg}`;
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default.a.callErrorHandler(new Error(msg));
        logger.error(msg);
        break;
    }
    /* eslint-enable no-case-declarations */

  };
  /**
   * Returns error status (HTTP error code) of the last BOSH request.
   *
   * @return {number} HTTP error code, '0' for unknown or "god knows what"
   * (this is a hack).
   */


  strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getLastErrorStatus = function () {
    return lastErrorStatus;
  };

  strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getStatusString = function (status) {
    switch (status) {
      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.BINDREQUIRED:
        return 'BINDREQUIRED';

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.ERROR:
        return 'ERROR';

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.CONNECTING:
        return 'CONNECTING';

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.CONNFAIL:
        return 'CONNFAIL';

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.AUTHENTICATING:
        return 'AUTHENTICATING';

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.AUTHFAIL:
        return 'AUTHFAIL';

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.CONNECTED:
        return 'CONNECTED';

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.DISCONNECTED:
        return 'DISCONNECTED';

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.DISCONNECTING:
        return 'DISCONNECTING';

      case strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.ATTACHED:
        return 'ATTACHED';

      default:
        return 'unknown';
    }
  };
});
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\strophe.util.js"))

/***/ }),

/***/ "./modules/xmpp/xmpp.js":
/*!******************************!*\
  !*** ./modules/xmpp/xmpp.js ***!
  \******************************/
/*! exports provided: DEFAULT_STUN_SERVERS, JITSI_MEET_MUC_TYPE, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(__filename) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DEFAULT_STUN_SERVERS", function() { return DEFAULT_STUN_SERVERS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "JITSI_MEET_MUC_TYPE", function() { return JITSI_MEET_MUC_TYPE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return XMPP; });
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jitsi-meet-logger */ "./node_modules/jitsi-meet-logger/lib/index.js");
/* harmony import */ var jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophejs_plugin_disco__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophejs-plugin-disco */ "./node_modules/strophejs-plugin-disco/lib/strophe.disco.js");
/* harmony import */ var strophejs_plugin_disco__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophejs_plugin_disco__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/RandomUtil */ "./modules/util/RandomUtil.js");
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_util_RandomUtil__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../JitsiConnectionErrors */ "./JitsiConnectionErrors.js");
/* harmony import */ var _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../JitsiConnectionEvents */ "./JitsiConnectionEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../browser */ "./modules/browser/index.js");
/* harmony import */ var _strophe_emuc__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./strophe.emuc */ "./modules/xmpp/strophe.emuc.js");
/* harmony import */ var _strophe_jingle__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./strophe.jingle */ "./modules/xmpp/strophe.jingle.js");
/* harmony import */ var _strophe_util__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./strophe.util */ "./modules/xmpp/strophe.util.js");
/* harmony import */ var _strophe_ping__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./strophe.ping */ "./modules/xmpp/strophe.ping.js");
/* harmony import */ var _strophe_rayo__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./strophe.rayo */ "./modules/xmpp/strophe.rayo.js");
/* harmony import */ var _strophe_logger__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./strophe.logger */ "./modules/xmpp/strophe.logger.js");
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../util/Listenable */ "./modules/util/Listenable.js");
/* harmony import */ var _Caps__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./Caps */ "./modules/xmpp/Caps.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_15___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_15__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./service/xmpp/XMPPEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_16___default = /*#__PURE__*/__webpack_require__.n(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_16__);
/* harmony import */ var _XmppConnection__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./XmppConnection */ "./modules/xmpp/XmppConnection.js");
/* global $ */


















const logger = Object(jitsi_meet_logger__WEBPACK_IMPORTED_MODULE_0__["getLogger"])(__filename);
/**
 * Creates XMPP connection.
 *
 * @param {Object} options
 * @param {string} [options.token] - JWT token used for authentication(JWT authentication module must be enabled in
 * Prosody).
 * @param {string} options.serviceUrl - The service URL for XMPP connection.
 * @param {string} options.enableWebsocketResume - True to enable stream resumption.
 * @param {number} [options.websocketKeepAlive] - See {@link XmppConnection} constructor.
 * @returns {XmppConnection}
 */

function createConnection({
  enableWebsocketResume,
  serviceUrl = '/http-bind',
  token,
  websocketKeepAlive
}) {
  // Append token as URL param
  if (token) {
    // eslint-disable-next-line no-param-reassign
    serviceUrl += `${serviceUrl.indexOf('?') === -1 ? '?' : '&'}token=${token}`;
  }

  return new _XmppConnection__WEBPACK_IMPORTED_MODULE_17__["default"]({
    enableWebsocketResume,
    serviceUrl,
    websocketKeepAlive
  });
}
/**
 * Initializes Strophe plugins that need to work with Strophe.Connection directly rather than the lib-jitsi-meet's
 * {@link XmppConnection} wrapper.
 *
 * @returns {void}
 */


function initStropheNativePlugins() {
  Object(_strophe_util__WEBPACK_IMPORTED_MODULE_9__["default"])();
  Object(_strophe_logger__WEBPACK_IMPORTED_MODULE_12__["default"])();
} // FIXME: remove once we have a default config template. -saghul

/**
 * A list of ice servers to use by default for P2P.
 */


const DEFAULT_STUN_SERVERS = [{
  urls: 'stun:stun.l.google.com:19302'
}, {
  urls: 'stun:stun1.l.google.com:19302'
}, {
  urls: 'stun:stun2.l.google.com:19302'
}];
/**
 * The name of the field used to recognize a chat message as carrying a JSON
 * payload from another endpoint.
 * If the json-message of a chat message contains a valid JSON object, and
 * the JSON has this key, then it is a valid json-message to be sent.
 */

const JITSI_MEET_MUC_TYPE = 'type';
/**
 *
 */

class XMPP extends _util_Listenable__WEBPACK_IMPORTED_MODULE_13__["default"] {
  /**
   * FIXME describe all options
   * @param {Object} options
   * @param {String} options.serviceUrl - URL passed to the XMPP client which will be used to establish XMPP
   * connection with the server.
   * @param {String} options.bosh - Deprecated, use {@code serviceUrl}.
   * @param {boolean} options.enableWebsocketResume - Enables XEP-0198 stream management which will make the XMPP
   * module try to resume the session in case the Websocket connection breaks.
   * @param {number} [options.websocketKeepAlive] - The websocket keep alive interval. See {@link XmppConnection}
   * constructor for more details.
   * @param {Array<Object>} options.p2pStunServers see {@link JingleConnectionPlugin} for more details.
   * @param token
   */
  constructor(options, token) {
    super();
    this.connection = null;
    this.disconnectInProgress = false;
    this.connectionTimes = {};
    this.options = options;
    this.token = token;
    this.authenticatedUser = false;
    initStropheNativePlugins();
    this.connection = createConnection({
      enableWebsocketResume: options.enableWebsocketResume,
      // FIXME remove deprecated bosh option at some point
      serviceUrl: options.serviceUrl || options.bosh,
      token,
      websocketKeepAlive: options.websocketKeepAlive
    });

    this._initStrophePlugins();

    this.caps = new _Caps__WEBPACK_IMPORTED_MODULE_14__["default"](this.connection, this.options.clientNode); // Initialize features advertised in disco-info

    this.initFeaturesList(); // Setup a disconnect on unload as a way to facilitate API consumers. It
    // sounds like they would want that. A problem for them though may be if
    // they wanted to utilize the connected connection in an unload handler
    // of their own. However, it should be fairly easy for them to do that
    // by registering their unload handler before us.

    $(window).on('beforeunload unload', ev => {
      this.disconnect(ev).catch(() => {// ignore errors in order to not brake the unload.
      });
    });
  }
  /**
   * Initializes the list of feature advertised through the disco-info
   * mechanism.
   */


  initFeaturesList() {
    // http://xmpp.org/extensions/xep-0167.html#support
    // http://xmpp.org/extensions/xep-0176.html#support
    this.caps.addFeature('urn:xmpp:jingle:1');
    this.caps.addFeature('urn:xmpp:jingle:apps:rtp:1');
    this.caps.addFeature('urn:xmpp:jingle:transports:ice-udp:1');
    this.caps.addFeature('urn:xmpp:jingle:apps:dtls:0');
    this.caps.addFeature('urn:xmpp:jingle:transports:dtls-sctp:1');
    this.caps.addFeature('urn:xmpp:jingle:apps:rtp:audio');
    this.caps.addFeature('urn:xmpp:jingle:apps:rtp:video');

    if (!this.options.disableRtx && _browser__WEBPACK_IMPORTED_MODULE_6__["default"].supportsRtx()) {
      this.caps.addFeature('urn:ietf:rfc:4588');
    } // this is dealt with by SDP O/A so we don't need to announce this
    // XEP-0293
    // this.caps.addFeature('urn:xmpp:jingle:apps:rtp:rtcp-fb:0');
    // XEP-0294
    // this.caps.addFeature('urn:xmpp:jingle:apps:rtp:rtp-hdrext:0');


    this.caps.addFeature('urn:ietf:rfc:5761'); // rtcp-mux

    this.caps.addFeature('urn:ietf:rfc:5888'); // a=group, e.g. bundle
    // this.caps.addFeature('urn:ietf:rfc:5576'); // a=ssrc
    // Enable Lipsync ?

    if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isChrome() && this.options.enableLipSync === true) {
      logger.info('Lip-sync enabled !');
      this.caps.addFeature('http://jitsi.org/meet/lipsync');
    }

    if (this.connection.rayo) {
      this.caps.addFeature('urn:xmpp:rayo:client:1');
    }

    if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].supportsInsertableStreams()) {
      this.caps.addFeature('https://jitsi.org/meet/e2ee');
    }
  }
  /**
   * Returns {@code true} if the PING functionality is supported by the server
   * or {@code false} otherwise.
   * @returns {boolean}
   */


  isPingSupported() {
    return this._pingSupported !== false;
  }
  /**
   *
   */


  getConnection() {
    return this.connection;
  }
  /**
   * Receive connection status changes and handles them.
   *
   * @param {Object} credentials
   * @param {string} credentials.jid - The user's XMPP ID passed to the
   * connect method. For example, 'user@xmpp.com'.
   * @param {string} credentials.password - The password passed to the connect
   * method.
   * @param {string} status - One of Strophe's connection status strings.
   * @param {string} [msg] - The connection error message provided by Strophe.
   */


  connectionHandler(credentials = {}, status, msg) {
    const now = window.performance.now();
    const statusStr = strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getStatusString(status).toLowerCase();
    this.connectionTimes[statusStr] = now;
    logger.log(`(TIME) Strophe ${statusStr}${msg ? `[${msg}]` : ''}:\t`, now);
    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_16___default.a.CONNECTION_STATUS_CHANGED, credentials, status, msg);

    if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.CONNECTED || status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.ATTACHED) {
      if (this.options.useStunTurn || this.options.p2p && this.options.p2p.useStunTurn) {
        this.connection.jingle.getStunAndTurnCredentials();
      }

      logger.info(`My Jabber ID: ${this.connection.jid}`); // XmppConnection emits CONNECTED again on reconnect - a good opportunity to clear any "last error" flags

      this._resetState(); // Schedule ping ?


      const pingJid = this.connection.domain; // FIXME no need to do it again on stream resume

      this.caps.getFeaturesAndIdentities(pingJid).then(({
        features,
        identities
      }) => {
        if (features.has(strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].NS.PING)) {
          this._pingSupported = true;
          this.connection.ping.startInterval(pingJid);
        } else {
          logger.warn(`Ping NOT supported by ${pingJid}`);
        } // check for speakerstats


        identities.forEach(identity => {
          if (identity.type === 'speakerstats') {
            this.speakerStatsComponentAddress = identity.name;
          }

          if (identity.type === 'conference_duration') {
            this.conferenceDurationComponentAddress = identity.name;
          }
        });

        if (this.speakerStatsComponentAddress || this.conferenceDurationComponentAddress) {
          this.connection.addHandler(this._onPrivateMessage.bind(this), null, 'message', null, null);
        }
      }).catch(error => {
        const errmsg = 'Feature discovery error';
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_15___default.a.callErrorHandler(new Error(`${errmsg}: ${error}`));
        logger.error(errmsg, error);
      });

      if (credentials.password) {
        this.authenticatedUser = true;
      }

      if (this.connection && this.connection.connected && strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getResourceFromJid(this.connection.jid)) {
        // .connected is true while connecting?
        // this.connection.send($pres());
        this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_ESTABLISHED"], strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getResourceFromJid(this.connection.jid));
      }
    } else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.CONNFAIL) {
      if (msg === 'x-strophe-bad-non-anon-jid') {
        this.anonymousConnectionFailed = true;
      } else {
        this.connectionFailed = true;
      }

      this.lastErrorMsg = msg;

      if (msg === 'giving-up') {
        this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_FAILED"], _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__["OTHER_ERROR"], msg);
      }
    } else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.ERROR) {
      this.lastErrorMsg = msg;
    } else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.DISCONNECTED) {
      // Stop ping interval
      this.connection.ping.stopInterval();
      const wasIntentionalDisconnect = Boolean(this.disconnectInProgress);
      const errMsg = msg || this.lastErrorMsg;

      if (this.anonymousConnectionFailed) {
        // prompt user for username and password
        this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_FAILED"], _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__["PASSWORD_REQUIRED"]);
      } else if (this.connectionFailed) {
        this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_FAILED"], _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__["OTHER_ERROR"], errMsg, undefined,
        /* credentials */
        this._getConnectionFailedReasonDetails());
      } else if (wasIntentionalDisconnect) {
        this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_DISCONNECTED"], errMsg);
      } else {
        // XXX if Strophe drops the connection while not being asked to,
        // it means that most likely some serious error has occurred.
        // One currently known case is when a BOSH request fails for
        // more than 4 times. The connection is dropped without
        // supplying a reason(error message/event) through the API.
        logger.error('XMPP connection dropped!'); // XXX if the last request error is within 5xx range it means it
        // was a server failure

        const lastErrorStatus = strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].getLastErrorStatus();

        if (lastErrorStatus >= 500 && lastErrorStatus < 600) {
          this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_FAILED"], _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__["SERVER_ERROR"], errMsg || 'server-error',
          /* credentials */
          undefined, this._getConnectionFailedReasonDetails());
        } else {
          this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_FAILED"], _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__["CONNECTION_DROPPED_ERROR"], errMsg || 'connection-dropped-error',
          /* credentials */
          undefined, this._getConnectionFailedReasonDetails());
        }
      }
    } else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.AUTHFAIL) {
      // wrong password or username, prompt user
      this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__["CONNECTION_FAILED"], _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__["PASSWORD_REQUIRED"], msg, credentials);
    }
  }
  /**
   *
   * @param jid
   * @param password
   */


  _connect(jid, password) {
    // connection.connect() starts the connection process.
    //
    // As the connection process proceeds, the user supplied callback will
    // be triggered multiple times with status updates. The callback should
    // take two arguments - the status code and the error condition.
    //
    // The status code will be one of the values in the Strophe.Status
    // constants. The error condition will be one of the conditions defined
    // in RFC 3920 or the condition ‘strophe-parsererror’.
    //
    // The Parameters wait, hold and route are optional and only relevant
    // for BOSH connections. Please see XEP 124 for a more detailed
    // explanation of the optional parameters.
    //
    // Connection status constants for use by the connection handler
    // callback.
    //
    //  Status.ERROR - An error has occurred (websockets specific)
    //  Status.CONNECTING - The connection is currently being made
    //  Status.CONNFAIL - The connection attempt failed
    //  Status.AUTHENTICATING - The connection is authenticating
    //  Status.AUTHFAIL - The authentication attempt failed
    //  Status.CONNECTED - The connection has succeeded
    //  Status.DISCONNECTED - The connection has been terminated
    //  Status.DISCONNECTING - The connection is currently being terminated
    //  Status.ATTACHED - The connection has been attached
    this._resetState();

    this.connection.connect(jid, password, this.connectionHandler.bind(this, {
      jid,
      password
    }));
  }
  /**
   * Attach to existing connection. Can be used for optimizations. For
   * example: if the connection is created on the server we can attach to it
   * and start using it.
   *
   * @param options {object} connecting options - rid, sid, jid and password.
   */


  attach(options) {
    this._resetState();

    const now = this.connectionTimes.attaching = window.performance.now();
    logger.log('(TIME) Strophe Attaching:\t', now);
    this.connection.attach(options.jid, options.sid, parseInt(options.rid, 10) + 1, this.connectionHandler.bind(this, {
      jid: options.jid,
      password: options.password
    }));
  }
  /**
   * Resets any state/flag before starting a new connection.
   * @private
   */


  _resetState() {
    this.anonymousConnectionFailed = false;
    this.connectionFailed = false;
    this.lastErrorMsg = undefined;
    this.disconnectInProgress = undefined;
  }
  /**
   *
   * @param jid
   * @param password
   */


  connect(jid, password) {
    if (!jid) {
      const {
        anonymousdomain,
        domain
      } = this.options.hosts;
      let configDomain = anonymousdomain || domain; // Force authenticated domain if room is appended with '?login=true'
      // or if we're joining with the token
      // FIXME Do not rely on window.location because (1) React Native
      // does not have a window.location by default and (2) here we cannot
      // know for sure that query/search has not be stripped from
      // window.location by the time the following executes.

      const {
        location
      } = window;

      if (anonymousdomain) {
        const search = location && location.search;

        if (search && search.indexOf('login=true') !== -1 || this.token) {
          configDomain = domain;
        }
      } // eslint-disable-next-line no-param-reassign


      jid = configDomain || location && location.hostname;
    }

    return this._connect(jid, password);
  }
  /**
   * Joins or creates a muc with the provided jid, created from the passed
   * in room name and muc host and onCreateResource result.
   *
   * @param {string} roomName - The name of the muc to join.
   * @param {Object} options - Configuration for how to join the muc.
   * @param {Function} [onCreateResource] - Callback to invoke when a resource
   * is to be added to the jid.
   * @returns {Promise} Resolves with an instance of a strophe muc.
   */


  createRoom(roomName, options, onCreateResource) {
    let roomjid = `${roomName}@${this.options.hosts.muc}/`;
    const mucNickname = onCreateResource ? onCreateResource(this.connection.jid, this.authenticatedUser) : _util_RandomUtil__WEBPACK_IMPORTED_MODULE_3___default.a.randomHexString(8).toLowerCase();
    logger.info(`JID ${this.connection.jid} using MUC nickname ${mucNickname}`);
    roomjid += mucNickname;
    return this.connection.emuc.createRoom(roomjid, null, options);
  }
  /**
   * Returns the jid of the participant associated with the Strophe connection.
   *
   * @returns {string} The jid of the participant.
   */


  getJid() {
    return this.connection.jid;
  }
  /**
   * Returns the logs from strophe.jingle.
   * @returns {Object}
   */


  getJingleLog() {
    const jingle = this.connection.jingle;
    return jingle ? jingle.getLog() : {};
  }
  /**
   * Returns the logs from strophe.
   */


  getXmppLog() {
    return (this.connection.logger || {}).log || null;
  }
  /**
   *
   */


  dial(...args) {
    this.connection.rayo.dial(...args);
  }
  /**
   * Pings the server. Remember to check {@link isPingSupported} before using
   * this method.
   * @param timeout how many ms before a timeout should occur.
   * @returns {Promise} resolved on ping success and reject on an error or
   * a timeout.
   */


  ping(timeout) {
    return new Promise((resolve, reject) => {
      if (this.isPingSupported()) {
        this.connection.ping.ping(this.connection.domain, resolve, reject, timeout);
      } else {
        reject('PING operation is not supported by the server');
      }
    });
  }
  /**
   *
   */


  getSessions() {
    return this.connection.jingle.sessions;
  }
  /**
   * Disconnects this from the XMPP server (if this is connected).
   *
   * @param {Object} ev - Optionally, the event which triggered the necessity to
   * disconnect from the XMPP server (e.g. beforeunload, unload).
   * @returns {Promise} - Resolves when the disconnect process is finished or rejects with an error.
   */


  disconnect(ev) {
    if (this.disconnectInProgress) {
      return this.disconnectInProgress;
    } else if (!this.connection) {
      return Promise.resolve();
    }

    this.disconnectInProgress = new Promise(resolve => {
      const disconnectListener = (credentials, status) => {
        if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__["Strophe"].Status.DISCONNECTED) {
          resolve();
          this.eventEmitter.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_16___default.a.CONNECTION_STATUS_CHANGED, disconnectListener);
        }
      };

      this.eventEmitter.on(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_16___default.a.CONNECTION_STATUS_CHANGED, disconnectListener);
    });

    this._cleanupXmppConnection(ev);

    return this.disconnectInProgress;
  }
  /**
   * The method is supposed to gracefully close the XMPP connection and the main goal is to make sure that the current
   * participant will be removed from the conference XMPP MUC, so that it doesn't leave a "ghost" participant behind.
   *
   * @param {Object} ev - Optionally, the event which triggered the necessity to disconnect from the XMPP server
   * (e.g. beforeunload, unload).
   * @private
   * @returns {void}
   */


  _cleanupXmppConnection(ev) {
    // XXX Strophe is asynchronously sending by default. Unfortunately, that means that there may not be enough time
    // to send an unavailable presence or disconnect at all. Switching Strophe to synchronous sending is not much of
    // an option because it may lead to a noticeable delay in navigating away from the current location. As
    // a compromise, we will try to increase the chances of sending an unavailable presence and/or disconnecting
    // within the short time span that we have upon unloading by invoking flush() on the connection. We flush() once
    // before disconnect() in order to attempt to have its unavailable presence at the top of the send queue. We
    // flush() once more after disconnect() in order to attempt to have its unavailable presence sent as soon as
    // possible.
    !this.connection.isUsingWebSocket && this.connection.flush();

    if (!this.connection.isUsingWebSocket && ev !== null && typeof ev !== 'undefined') {
      const evType = ev.type;

      if (evType === 'beforeunload' || evType === 'unload') {
        // XXX Whatever we said above, synchronous sending is the best (known) way to properly disconnect from
        // the XMPP server. Consequently, it may be fine to have the source code and comment it in or out
        // depending on whether we want to run with it for some time.
        this.connection.options.sync = true; // This is needed in some browsers where sync xhr sending is disabled by default on unload.

        if (this.connection.sendUnavailableBeacon()) {
          return;
        }
      }
    }

    this.connection.disconnect();

    if (this.connection.options.sync !== true) {
      this.connection.flush();
    }
  }
  /**
   *
   */


  _initStrophePlugins() {
    const iceConfig = {
      jvb: {
        iceServers: []
      },
      p2p: {
        iceServers: []
      }
    };
    const p2pStunServers = this.options.p2p && this.options.p2p.stunServers || DEFAULT_STUN_SERVERS;

    if (Array.isArray(p2pStunServers)) {
      logger.info('P2P STUN servers: ', p2pStunServers);
      iceConfig.p2p.iceServers = p2pStunServers;
    }

    if (this.options.p2p && this.options.p2p.iceTransportPolicy) {
      logger.info('P2P ICE transport policy: ', this.options.p2p.iceTransportPolicy);
      iceConfig.p2p.iceTransportPolicy = this.options.p2p.iceTransportPolicy;
    }

    this.connection.addConnectionPlugin('emuc', new _strophe_emuc__WEBPACK_IMPORTED_MODULE_7__["default"](this));
    this.connection.addConnectionPlugin('jingle', new _strophe_jingle__WEBPACK_IMPORTED_MODULE_8__["default"](this, this.eventEmitter, iceConfig));
    this.connection.addConnectionPlugin('ping', new _strophe_ping__WEBPACK_IMPORTED_MODULE_10__["default"](this));
    this.connection.addConnectionPlugin('rayo', new _strophe_rayo__WEBPACK_IMPORTED_MODULE_11__["default"]());
  }
  /**
   * Returns details about connection failure. Shard change or is it after
   * suspend.
   * @returns {object} contains details about a connection failure.
   * @private
   */


  _getConnectionFailedReasonDetails() {
    const details = {}; // check for moving between shard if information is available

    if (this.options.deploymentInfo && this.options.deploymentInfo.shard && this.connection.lastResponseHeaders) {
      // split headers by line
      const headersArr = this.connection.lastResponseHeaders.trim().split(/[\r\n]+/);
      const headers = {};
      headersArr.forEach(line => {
        const parts = line.split(': ');
        const header = parts.shift();
        const value = parts.join(': ');
        headers[header] = value;
      });
      /* eslint-disable camelcase */

      details.shard_changed = this.options.deploymentInfo.shard !== headers['x-jitsi-shard'];
      /* eslint-enable camelcase */
    }
    /* eslint-disable camelcase */
    // check for possible suspend


    details.suspend_time = this.connection.ping.getPingSuspendTime();
    details.time_since_last_success = this.connection.getTimeSinceLastSuccess();
    /* eslint-enable camelcase */

    return details;
  }
  /**
   * Notifies speaker stats component if available that we are the new
   * dominant speaker in the conference.
   * @param {String} roomJid - The room jid where the speaker event occurred.
   */


  sendDominantSpeakerEvent(roomJid) {
    // no speaker stats component advertised
    if (!this.speakerStatsComponentAddress || !roomJid) {
      return;
    }

    const msg = Object(strophe_js__WEBPACK_IMPORTED_MODULE_1__["$msg"])({
      to: this.speakerStatsComponentAddress
    });
    msg.c('speakerstats', {
      xmlns: 'http://jitsi.org/jitmeet',
      room: roomJid
    }).up();
    this.connection.send(msg);
  }
  /**
   * Check if the given argument is a valid JSON ENDPOINT_MESSAGE string by
   * parsing it and checking if it has a field called 'type'.
   *
   * @param {string} jsonString check if this string is a valid json string
   * and contains the special structure.
   * @returns {boolean, object} if given object is a valid JSON string, return
   * the json object. Otherwise, returns false.
   */


  tryParseJSONAndVerify(jsonString) {
    try {
      const json = JSON.parse(jsonString); // Handle non-exception-throwing cases:
      // Neither JSON.parse(false) or JSON.parse(1234) throw errors,
      // hence the type-checking,
      // but... JSON.parse(null) returns null, and
      // typeof null === "object",
      // so we must check for that, too.
      // Thankfully, null is falsey, so this suffices:

      if (json && typeof json === 'object') {
        const type = json[JITSI_MEET_MUC_TYPE];

        if (typeof type !== 'undefined') {
          return json;
        }

        logger.debug('parsing valid json but does not have correct ' + 'structure', 'topic: ', type);
      }
    } catch (e) {
      return false;
    }

    return false;
  }
  /**
   * A private message is received, message that is not addressed to the muc.
   * We expect private message coming from plugins component if it is
   * enabled and running.
   *
   * @param {string} msg - The message.
   */


  _onPrivateMessage(msg) {
    const from = msg.getAttribute('from');

    if (!(from === this.speakerStatsComponentAddress || from === this.conferenceDurationComponentAddress)) {
      return;
    }

    const jsonMessage = $(msg).find('>json-message').text();
    const parsedJson = this.tryParseJSONAndVerify(jsonMessage);

    if (parsedJson && parsedJson[JITSI_MEET_MUC_TYPE] === 'speakerstats' && parsedJson.users) {
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_16___default.a.SPEAKER_STATS_RECEIVED, parsedJson.users);
    }

    if (parsedJson && parsedJson[JITSI_MEET_MUC_TYPE] === 'conference_duration' && parsedJson.created_timestamp) {
      this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_16___default.a.CONFERENCE_TIMESTAMP_RECEIVED, parsedJson.created_timestamp);
    }

    return true;
  }

}
/* WEBPACK VAR INJECTION */}.call(this, "modules\\xmpp\\xmpp.js"))

/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/lib/index.js":
/*!******************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/lib/index.js ***!
  \******************************************************/
/*! exports provided: Interop */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _interop__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./interop */ "./node_modules/@jitsi/sdp-interop/lib/interop.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Interop", function() { return _interop__WEBPACK_IMPORTED_MODULE_0__["Interop"]; });

/* Copyright @ 2015 - Present, 8x8 Inc
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/lib/interop.js":
/*!********************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/lib/interop.js ***!
  \********************************************************/
/*! exports provided: Interop */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Interop", function() { return Interop; });
/* harmony import */ var lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! lodash.clonedeep */ "./node_modules/lodash.clonedeep/index.js");
/* harmony import */ var lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _transform_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./transform.js */ "./node_modules/@jitsi/sdp-interop/lib/transform.js");
/* Copyright @ 2015 - Present, 8x8 Inc
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


const PLAN_B_MIDS = ['audio', 'video', 'data'];

const findSimGroup = ssrcGroup => ssrcGroup.find(grp => grp.semantics === 'SIM');

const findFidGroup = ssrcGroup => ssrcGroup.find(grp => grp.semantics === 'FID');
/**
 * Add the ssrcs of the SIM group and their corresponding FID group ssrcs
 * to the m-line.
 * @param {Object} mLine - The m-line to which ssrcs have to be added.
 * @param {Object} simGroup - The SIM group whose ssrcs have to be added to
 * the m-line.
 * @param {Object} sourceGroups - inverted source-group map.
 * @param {Array<Object>} sourceList - array containing all the sources.
 */


function addSimGroupSources(mLine, simGroup, sourceGroups, sourceList) {
  if (!mLine || !simGroup) {
    return;
  }

  const findSourcebyId = src => sourceList.find(source => source.id.toString() === src);

  simGroup.ssrcs.forEach(src => {
    mLine.sources.push(findSourcebyId(src)); // find the related FID group member for this ssrc.

    const relatedFidGroup = sourceGroups[parseInt(src, 10)].find(grp => grp.semantics === 'FID');

    if (relatedFidGroup) {
      const relatedSsrc = relatedFidGroup.ssrcs.find(s => s !== src);
      mLine.sources.push(findSourcebyId(relatedSsrc));
      mLine.ssrcGroups.push(relatedFidGroup);
    }
  }); // Add the SIM group last.

  mLine.ssrcGroups.push(simGroup);
}
/**
 * Add ssrcs and ssrc-groups to the m-line. When a primary ssrc, i.e., the
 * first ssrc in a SIM group is passed, all the other ssrcs from the SIM
 * group and the other ssrcs from the related FID groups are added to the same
 * m-line since they all belong to the same remote source. Since the ssrcs are
 * not guaranteed to be in the correct order, try to find if a SIM group exists,
 * if not, just add the FID group.
 * @param {Object} mLine - The m-line to which ssrcs have to be added.
 * @param {Object} ssrc - the primary ssrc.
 * @param {Object} sourceGroups - inverted source-group map.
 * @param {Array<Object>} sourceList - array containing all the sources.
 * @returns {void}
 */


function addSourcesToMline(mLine, ssrc, sourceGroups, sourceList) {
  if (!mLine || !ssrc) {
    return;
  }

  mLine.sources = [];
  mLine.ssrcGroups = []; // If there are no associated ssrc-groups, just add the ssrc and msid.

  if (!sourceGroups[ssrc.id]) {
    mLine.sources.push(ssrc);
    mLine.msid = ssrc.msid;
    return;
  }

  const findSourcebyId = src => sourceList.find(source => source.id.toString() === src); // Find the SIM and FID groups that this ssrc belongs to.


  const simGroup = findSimGroup(sourceGroups[ssrc.id]);
  const fidGroup = findFidGroup(sourceGroups[ssrc.id]); // Add the ssrcs for the SIM group and their corresponding FID groups.

  if (simGroup) {
    addSimGroupSources(mLine, simGroup, sourceGroups, sourceList);
  } else if (fidGroup) {
    // check if the other ssrc from this FID group is part of a SIM group
    const otherSsrc = fidGroup.ssrcs.find(s => s !== ssrc);
    const simGroup2 = findSimGroup(sourceGroups[otherSsrc]);

    if (simGroup2) {
      addSimGroupSources(mLine, simGroup2, sourceGroups, sourceList);
    } else {
      // Add the FID group ssrcs.
      fidGroup.ssrcs.forEach(src => {
        mLine.sources.push(findSourcebyId(src));
      });
      mLine.ssrcGroups.push(fidGroup);
    }
  } // Set the msid for the media description using the msid attribute of the ssrcs.


  mLine.msid = mLine.sources[0].msid;
}
/**
 * Checks if there is a mline for the given ssrc or its related primary ssrc.
 * We always implode the SIM group to the first ssrc in the SIM group before sRD,
 * so we also check if mline for that ssrc exists.
 * For example:
 * If the following ssrcs are in a SIM group,
 * <ssrc-group xmlns=\"urn:xmpp:jingle:apps:rtp:ssma:0\" semantics=\"SIM\">
 *        <source ssrc=\"1806330949\"/>
 *        <source ssrc=\"4173145196\"/>
 *        <source ssrc=\"2002632207\"/>
 * </ssrc-group>
 * This method returns true for any one of the 3 ssrcs if there is a mline for 1806330949.
 * @param {Object} ssrc - ssrc to check.
 * @param {Object} sourceGroups - inverted source-group map.
 * @param {Array<Object>} mlines - mlines in the description

 * @returns {Boolean} - Returns true if mline for the given ssrc or the related primary ssrc
 * exists, returns false otherwise.
 */


function checkIfMlineForSsrcExists(ssrc, sourceGroups, mlines) {
  const findMatchingMline = mline => {
    if (mline.sources) {
      return mline.sources.some(source => source.id === ssrc.id);
    }

    return false;
  };

  if (!mlines.find(findMatchingMline)) {
    // check if this ssrc is member of a SIM group. If so, check if there
    // is a matching m-line for the primary ssrc of the SIM group.
    if (!sourceGroups[ssrc.id]) {
      return false;
    }

    const simGroup = findSimGroup(sourceGroups[ssrc.id]);
    const fidGroup = findFidGroup(sourceGroups[ssrc.id]);

    if (simGroup) {
      return mlines.some(mline => mline.sources && mline.sources.some(src => src.id.toString() === simGroup.ssrcs[0]));
    } else if (fidGroup && ssrc.id.toString() !== fidGroup.ssrcs[0]) {
      const otherSsrc = {
        id: fidGroup.ssrcs[0]
      };
      return checkIfMlineForSsrcExists(otherSsrc, sourceGroups, mlines);
    }

    return false;
  }

  return true;
}
/**
 * Create an inverted sourceGroup map to put all the grouped ssrcs
 * in the same m-line.
 * @param {Array<Object>} sourceGroups
 * @returns {Object} - An inverted sourceGroup map.
 */


function createSourceGroupMap(sourceGroups) {
  const ssrc2group = {};

  if (!sourceGroups || !Array.isArray(sourceGroups)) {
    return ssrc2group;
  }

  sourceGroups.forEach(group => {
    if (group.ssrcs && Array.isArray(group.ssrcs)) {
      group.ssrcs.forEach(ssrc => {
        if (typeof ssrc2group[ssrc] === 'undefined') {
          ssrc2group[ssrc] = [];
        }

        ssrc2group[ssrc].push(group);
      });
    }
  });
  return ssrc2group;
}
/**
 * Interop provides an API for tranforming a Plan B SDP to a Unified Plan SDP and
 * vice versa.
 */


class Interop {
  /**
   * This method transforms a Unified Plan SDP to an equivalent Plan B SDP.
   * @param {RTCSessionDescription} description - The description in Unified plan format.
   * @returns RTCSessionDescription - The transformed session description.
   */
  toPlanB(description) {
    if (!description || typeof description.sdp !== 'string') {
      console.warn('An empty description was passed as an argument.');
      return description;
    } // Objectify the SDP for easier manipulation.


    const session = _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].parse(description.sdp); // If the SDP contains no media, there's nothing to transform.

    if (!session.media || !session.media.length) {
      console.warn('The description has no media.');
      return description;
    } // Make sure this is a unified plan sdp


    if (session.media.every(m => PLAN_B_MIDS.indexOf(m.mid) !== -1)) {
      console.warn('The description does not look like unified plan sdp');
      return description;
    }

    const media = {};
    const sessionMedia = session.media;
    session.media = [];
    sessionMedia.forEach(mLine => {
      const type = mLine.type;

      if (type === 'application') {
        mLine.mid = 'data';
        media[mLine.mid] = mLine;
        return;
      }

      if (typeof media[type] === 'undefined') {
        const bLine = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0___default()(mLine); // Copy the msid attribute to all the ssrcs if they belong to the same source group

        if (bLine.sources && Array.isArray(bLine.sources)) {
          bLine.sources.forEach(source => {
            mLine.msid ? source.msid = mLine.msid : delete source.msid;
          });
        }

        if (!bLine.ssrcGroups) {
          bLine.ssrcGroups = [];
        }

        delete bLine.msid;
        bLine.mid = type;
        media[type] = bLine;
      } else if (mLine.msid) {
        // Add sources and source-groups to the existing m-line of the same media type.
        if (mLine.sources && Array.isArray(mLine.sources)) {
          media[type].sources = media[type].sources.concat(mLine.sources);
        }

        if (typeof mLine.ssrcGroups !== 'undefined' && Array.isArray(mLine.ssrcGroups)) {
          media[type].ssrcGroups = media[type].ssrcGroups.concat(mLine.ssrcGroups);
        }
      }
    });
    session.media = Object.values(media); // Bundle the media only if it is active.

    const bundle = [];
    Object.values(media).forEach(mline => {
      if (mline.direction !== 'inactive') {
        bundle.push(mline.mid);
      }
    }); // We regenerate the BUNDLE group with the new mids.

    session.groups.forEach(group => {
      if (group.type === 'BUNDLE') {
        group.mids = bundle.join(' ');
      }
    }); // msid semantic

    session.msidSemantic = {
      semantic: 'WMS',
      token: '*'
    };
    const resStr = _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].write(session);
    return new RTCSessionDescription({
      type: description.type,
      sdp: resStr
    });
  }
  /**
   * This method transforms a Plan B SDP to an equivalent Unified Plan SDP.
   * @param {RTCSessionDescription} description - The description in plan-b format.
   * @param {RTCSessionDescription} current - The current description set on
   * the peerconnection in Unified-plan format, i.e., the readonly attribute
   * remoteDescription on the RTCPeerConnection object.
   * @returns RTCSessionDescription - The transformed session description.
   */


  toUnifiedPlan(description, current = null) {
    if (!description || typeof description.sdp !== 'string') {
      console.warn('An empty description was passed as an argument.');
      return description;
    } // Objectify the SDP for easier manipulation.


    const session = _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].parse(description.sdp); // If the SDP contains no media, there's nothing to transform.

    if (!session.media || !session.media.length) {
      console.warn('The description has no media.');
      return description;
    } // Make sure this is a plan-b sdp.


    if (session.media.length > 3 || session.media.every(m => PLAN_B_MIDS.indexOf(m.mid) === -1)) {
      console.warn('The description does not look like plan-b');
      return description;
    }

    const currentDesc = current ? _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].parse(current.sdp) : null;
    const media = {};
    session.media.forEach(mLine => {
      const type = mLine.type;

      if (type === 'application') {
        if (!currentDesc || !currentDesc.media) {
          const newMline = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0___default()(mLine);
          newMline.mid = Object.keys(media).length.toString();
          media[mLine.mid] = newMline;
          return;
        }

        const mLineForData = currentDesc.media.findIndex(m => m.type === type);

        if (mLineForData) {
          currentDesc.media[mLineForData] = mLine;
          currentDesc.media[mLineForData].mid = mLineForData;
        }

        return;
      } // Create an inverted sourceGroup map here to put all the grouped SSRCs in the same m-line.


      const ssrc2group = createSourceGroupMap(mLine.ssrcGroups);

      if (!mLine.sources) {
        return;
      }

      mLine.sources.forEach((ssrc, idx) => {
        // Do not add the receive-only ssrcs that Jicofo sends in the source-add.
        // These ssrcs do not have the "msid" attribute set.
        if (!ssrc.msid) {
          return;
        } // If there is no description set on the peerconnection, create new m-lines.


        if (!currentDesc || !currentDesc.media) {
          if (checkIfMlineForSsrcExists(ssrc, ssrc2group, Object.values(media))) {
            return;
          }

          const newMline = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0___default()(mLine);
          newMline.mid = Object.keys(media).length.toString();
          newMline.direction = idx ? 'sendonly' : mLine.direction === 'sendonly' ? 'sendonly' : 'sendrecv';
          newMline.bundleOnly = undefined;
          addSourcesToMline(newMline, ssrc, ssrc2group, mLine.sources);
          media[newMline.mid] = newMline;
          return;
        } // Create and append the m-lines to the existing description.


        if (checkIfMlineForSsrcExists(ssrc, ssrc2group, currentDesc.media)) {
          return;
        } // check if there is a m-line that is inactive and is of the same media type


        const inactiveMid = currentDesc.media.findIndex(cmLine => cmLine.direction && cmLine.direction === 'inactive' && cmLine.type === type);

        if (inactiveMid > -1) {
          currentDesc.media[inactiveMid].direction = 'sendonly';
          addSourcesToMline(currentDesc.media[inactiveMid], ssrc, ssrc2group, mLine.sources);
        } else {
          const newMline = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0___default()(mLine);
          newMline.mid = currentDesc.media.length.toString();
          newMline.direction = 'sendonly';
          addSourcesToMline(newMline, ssrc, ssrc2group, mLine.sources);
          currentDesc.media.push(newMline);
        }
      });
    });
    session.media = currentDesc ? currentDesc.media : Object.values(media);
    const mids = [];
    session.media.forEach(mLine => {
      mids.push(mLine.mid);
    }); // We regenerate the BUNDLE group (since we regenerated the mids)

    session.groups.forEach(group => {
      if (group.type === 'BUNDLE') {
        group.mids = mids.join(' ');
      }
    }); // msid semantic

    session.msidSemantic = {
      semantic: 'WMS',
      token: '*'
    }; // Increment the session version every time.

    session.origin.sessionVersion++;
    const resultSdp = _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].write(session);
    return new RTCSessionDescription({
      type: description.type,
      sdp: resultSdp
    });
  }

}

/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/lib/transform.js":
/*!**********************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/lib/transform.js ***!
  \**********************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(sdp_transform__WEBPACK_IMPORTED_MODULE_0__);
/* Copyright @ 2015 - Present, 8x8 Inc
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * Rewrites the source information in the way sdp-transform expects.
 * Source information is split into multiple ssrc objects each containing
 * an id, attribute and value.
 * @param {Object} media - media description to be modified.
 * @returns {void}
 */

const write = function (session, opts) {
  if (typeof session !== 'undefined' && typeof session.media !== 'undefined' && Array.isArray(session.media)) {
    session.media.forEach(mLine => {
      if (mLine.sources && mLine.sources.length) {
        mLine.ssrcs = [];
        mLine.sources.forEach(source => {
          Object.keys(source).forEach(attribute => {
            if (attribute === 'id') {
              return;
            }

            mLine.ssrcs.push({
              id: source.id,
              attribute,
              value: source[attribute]
            });
          });
        });
        delete mLine.sources;
      } // join ssrcs in ssrc groups


      if (mLine.ssrcGroups && mLine.ssrcGroups.length) {
        mLine.ssrcGroups.forEach(ssrcGroup => {
          if (typeof ssrcGroup.ssrcs !== 'undefined' && Array.isArray(ssrcGroup.ssrcs)) {
            ssrcGroup.ssrcs = ssrcGroup.ssrcs.join(' ');
          }
        });
      }
    });
  }

  return sdp_transform__WEBPACK_IMPORTED_MODULE_0___default.a.write(session, opts);
};
/**
 * Rewrites the source information that we get from sdp-transform.
 * All the ssrc lines with different attributes that belong to the
 * same ssrc are grouped into a single soure object with multiple key value pairs.
 * @param {Object} media - media description to be modified.
 * @returns {void}
 */


const parse = function (sdp) {
  const session = sdp_transform__WEBPACK_IMPORTED_MODULE_0___default.a.parse(sdp);

  if (typeof session !== 'undefined' && typeof session.media !== 'undefined' && Array.isArray(session.media)) {
    session.media.forEach(mLine => {
      // group sources attributes by ssrc
      if (typeof mLine.ssrcs !== 'undefined' && Array.isArray(mLine.ssrcs)) {
        mLine.sources = [];
        mLine.ssrcs.forEach(ssrc => {
          const found = mLine.sources.findIndex(source => source.id === ssrc.id);

          if (found > -1) {
            mLine.sources[found][ssrc.attribute] = ssrc.value;
          } else {
            const src = {
              id: ssrc.id
            };
            src[ssrc.attribute] = ssrc.value;
            mLine.sources.push(src);
          }
        });
        delete mLine.ssrcs;
      } // split ssrcs in ssrc groups


      if (typeof mLine.ssrcGroups !== 'undefined' && Array.isArray(mLine.ssrcGroups)) {
        mLine.ssrcGroups.forEach(ssrcGroup => {
          if (typeof ssrcGroup.ssrcs === 'string') {
            ssrcGroup.ssrcs = ssrcGroup.ssrcs.split(' ');
          }
        });
      }
    });
  }

  return session;
};

/* harmony default export */ __webpack_exports__["default"] = ({
  write,
  parse
});

/***/ }),

/***/ "./node_modules/@jitsi/sdp-simulcast/lib/index.js":
/*!********************************************************!*\
  !*** ./node_modules/@jitsi/sdp-simulcast/lib/index.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* Copyright @ 2016 Atlassian Pty Ltd
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
var transform = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");

var transformUtils = __webpack_require__(/*! ./transform-utils */ "./node_modules/@jitsi/sdp-simulcast/lib/transform-utils.js");

var parseSsrcs = transformUtils.parseSsrcs;
var writeSsrcs = transformUtils.writeSsrcs; //region Constants

var DEFAULT_NUM_OF_LAYERS = 3; //endregion

function getSsrcAttribute(mLine, ssrc, attributeName) {
  return mLine.ssrcs.filter(function (ssrcInfo) {
    return ssrcInfo.id === ssrc;
  }).filter(function (ssrcInfo) {
    return ssrcInfo.attribute === attributeName;
  }).map(function (ssrcInfo) {
    return ssrcInfo.value;
  })[0];
} //region Ctor


function Simulcast(options) {
  this.options = options ? options : {};

  if (!this.options.numOfLayers) {
    this.options.numOfLayers = DEFAULT_NUM_OF_LAYERS;
  }

  console.log("SdpSimulcast: using " + this.options.numOfLayers + " layers");
  /**
   * An IN-ORDER list of the simulcast ssrcs
   * @type {list<number>}
   */

  this.ssrcCache = [];
} //endregion
//region Stateless private utility functions

/**
 * Returns a random integer between min (included) and max (excluded)
 * Using Math.round() gives a non-uniform distribution!
 * @returns {number}
 */


function generateSSRC() {
  var min = 0,
      max = 0xffffffff;
  return Math.floor(Math.random() * (max - min)) + min;
}

;

function processVideo(session, action) {
  if (session == null || !Array.isArray(session.media)) {
    return;
  }

  session.media.forEach(function (mLine) {
    if (mLine.type === 'video') {
      action(mLine);
    }
  });
}

;

function validateDescription(desc) {
  return desc && desc != null && desc.type && desc.type != '' && desc.sdp && desc.sdp != '';
}

function explodeRemoteSimulcast(mLine) {
  if (!mLine || !Array.isArray(mLine.ssrcGroups)) {
    return;
  }

  var sources = parseSsrcs(mLine);
  var order = []; // Find the SIM group and explode its sources.

  var j = mLine.ssrcGroups.length;

  while (j--) {
    if (mLine.ssrcGroups[j].semantics !== 'SIM') {
      continue;
    }

    var simulcastSsrcs = mLine.ssrcGroups[j].ssrcs.split(' ');

    for (var i = 0; i < simulcastSsrcs.length; i++) {
      var ssrc = simulcastSsrcs[i];
      order.push(ssrc);
      var parts = sources[ssrc].msid.split(' ');
      sources[ssrc].msid = [parts[0], '/', i, ' ', parts[1], '/', i].join('');
      sources[ssrc].cname = [sources[ssrc].cname, '/', i].join(''); // Remove all the groups that this SSRC participates in.

      mLine.ssrcGroups.forEach(function (relatedGroup) {
        if (relatedGroup.semantics === 'SIM') {
          return;
        }

        var relatedSsrcs = relatedGroup.ssrcs.split(' ');

        if (relatedSsrcs.indexOf(ssrc) === -1) {
          return;
        } // Nuke all the related SSRCs.


        relatedSsrcs.forEach(function (relatedSSRC) {
          sources[relatedSSRC].msid = sources[ssrc].msid;
          sources[relatedSSRC].cname = sources[ssrc].cname;

          if (relatedSSRC !== ssrc) {
            order.push(relatedSSRC);
          }
        }); // Schedule the related group for nuking.
      });
    }

    mLine.ssrcs = writeSsrcs(sources, order);
    mLine.ssrcGroups.splice(j, 1);
  }

  ;
}

function implodeRemoteSimulcast(mLine) {
  if (!mLine || !Array.isArray(mLine.ssrcGroups)) {
    console.info('Halt: There are no SSRC groups in the remote ' + 'description.');
    return;
  }

  var sources = parseSsrcs(mLine); // Find the SIM group and nuke it.

  mLine.ssrcGroups.forEach(function (simulcastGroup) {
    if (simulcastGroup.semantics !== 'SIM') {
      return;
    }

    console.info("Imploding SIM group: " + simulcastGroup.ssrcs); // Schedule the SIM group for nuking.

    simulcastGroup.nuke = true;
    var simulcastSsrcs = simulcastGroup.ssrcs.split(' '); // Nuke all the higher layer SSRCs.

    for (var i = 1; i < simulcastSsrcs.length; i++) {
      var ssrc = simulcastSsrcs[i];
      delete sources[ssrc]; // Remove all the groups that this SSRC participates in.

      mLine.ssrcGroups.forEach(function (relatedGroup) {
        if (relatedGroup.semantics === 'SIM') {
          return;
        }

        var relatedSsrcs = relatedGroup.ssrcs.split(' ');

        if (relatedSsrcs.indexOf(ssrc) === -1) {
          return;
        } // Nuke all the related SSRCs.


        relatedSsrcs.forEach(function (relatedSSRC) {
          delete sources[relatedSSRC];
        }); // Schedule the related group for nuking.

        relatedGroup.nuke = true;
      });
    }

    return;
  });
  mLine.ssrcs = writeSsrcs(sources); // Nuke all the scheduled groups.

  var i = mLine.ssrcGroups.length;

  while (i--) {
    if (mLine.ssrcGroups[i].nuke) {
      mLine.ssrcGroups.splice(i, 1);
    }
  }
}

function removeGoogConference(mLine) {
  if (!mLine || !Array.isArray(mLine.invalid)) {
    return;
  }

  var i = mLine.invalid.length;

  while (i--) {
    if (mLine.invalid[i].value == 'x-google-flag:conference') {
      mLine.invalid.splice(i, 1);
    }
  }
}

function assertGoogConference(mLine) {
  if (!mLine) {
    return;
  }

  if (!Array.isArray(mLine.invalid)) {
    mLine.invalid = [];
  }

  if (!mLine.invalid.some(function (i) {
    return i.value === 'x-google-flag:conference';
  })) {
    mLine.invalid.push({
      'value': 'x-google-flag:conference'
    });
  }
}

Simulcast.prototype.clearSsrcCache = function () {
  this.ssrcCache = [];
};
/**
 * When we start as video muted, all of the video
 *  ssrcs get generated so we can include them as part
 *  of the original session-accept.  That means we
 *  need this library to restore to those same ssrcs
 *  the first time we unmute, so we need the ability to
 *  force its cache
 */


Simulcast.prototype.setSsrcCache = function (ssrcs) {
  this.ssrcCache = ssrcs;
}; //endregion
//region "Private" functions

/**
 * Given a video mLine, return a list of the video ssrcs
 *  in simulcast layer order (returns a list of just
 *  the primary ssrc if there are no simulcast layers)
 */


Simulcast.prototype._parseSimLayers = function (mLine) {
  var simGroup = mLine.ssrcGroups && mLine.ssrcGroups.find(function (group) {
    return group.semantics === "SIM";
  });

  if (simGroup) {
    return simGroup.ssrcs.split(" ").map(function (ssrcStr) {
      return parseInt(ssrcStr);
    });
  } else {
    return [mLine.ssrcs[0].id];
  }
};

Simulcast.prototype._buildNewToOldSsrcMap = function (newSsrcList, oldSsrcList) {
  var ssrcMap = {};

  for (var i = 0; i < newSsrcList.length; ++i) {
    var newSsrc = newSsrcList[i];
    var oldSsrc = oldSsrcList[i] || null;
    ssrcMap[newSsrc] = oldSsrc;
  }

  return ssrcMap;
};

Simulcast.prototype._fillInSourceDataFromCache = function (mLine) {
  console.log("SdpSimulcast restoring from cache: ", this.ssrcCache);

  var newSimSsrcs = this._parseSimLayers(mLine);

  console.log("SdpSimulcast Parsed new sim ssrcs: ", newSimSsrcs);
  var newMsid = getSsrcAttribute(mLine, newSimSsrcs[0], "msid");
  var newCname = getSsrcAttribute(mLine, newSimSsrcs[0], "cname");

  var ssrcsToReplace = this._buildNewToOldSsrcMap(newSimSsrcs, this.ssrcCache);

  console.log("SdpSimulcast built replacement map: ", ssrcsToReplace); // New sdp might only have 1 layer, so not every cached ssrc will have a new one
  //  to replace directly

  var ssrcsToAdd = this.ssrcCache.filter(function (ssrc) {
    return Object.values(ssrcsToReplace).indexOf(ssrc) === -1;
  });
  console.log("SdpSimulcast built ssrcs to add: ", ssrcsToAdd); // First do the replacements

  mLine.ssrcs.forEach(function (ssrc) {
    if (ssrcsToReplace[ssrc.id]) {
      ssrc.id = ssrcsToReplace[ssrc.id];
    }
  }); // Now the adds

  ssrcsToAdd.forEach(function (ssrc) {
    mLine.ssrcs.push({
      id: ssrc,
      attribute: "msid",
      value: newMsid
    });
    mLine.ssrcs.push({
      id: ssrc,
      attribute: "cname",
      value: newCname
    });
  });
  mLine.ssrcGroups = mLine.ssrcGroups || [];
  mLine.ssrcGroups.push({
    semantics: "SIM",
    ssrcs: this.ssrcCache.join(" ")
  });
  return mLine;
};

Simulcast.prototype._generateSourceData = function (mLine, primarySsrc) {
  var addAssociatedStream = function (mLine, ssrc) {
    mLine.ssrcs.push({
      id: ssrc,
      attribute: "cname",
      value: primarySsrcCname
    });
    mLine.ssrcs.push({
      id: ssrc,
      attribute: "msid",
      value: primarySsrcMsid
    });
  };

  var primarySsrcMsid = getSsrcAttribute(mLine, primarySsrc, "msid");
  var primarySsrcCname = getSsrcAttribute(mLine, primarySsrc, "cname"); // In Unified-plan mode, the a=ssrc lines with the msid attribute are not present
  // in the answers that Chrome and Safari generate for an offer received from Jicofo.
  // Generate these a=ssrc lines using the msid values from the a=msid line.

  if (this.options.usesUnifiedPlan && !primarySsrcMsid) {
    primarySsrcMsid = mLine.msid;
    var primarySsrcs = mLine.ssrcs;
    primarySsrcs.forEach(ssrc => {
      mLine.ssrcs.push({
        id: ssrc.id,
        attribute: "msid",
        value: primarySsrcMsid
      });
    });
  } // Generate sim layers


  var simSsrcs = [];

  for (var i = 0; i < this.options.numOfLayers - 1; ++i) {
    var simSsrc = generateSSRC();
    addAssociatedStream(mLine, simSsrc);
    simSsrcs.push(simSsrc);
  }

  mLine.ssrcGroups = mLine.ssrcGroups || [];
  mLine.ssrcGroups.push({
    semantics: "SIM",
    ssrcs: primarySsrc + " " + simSsrcs.join(" ")
  });
  return mLine;
}; // Assumptions:
//  1) 'mLine' contains only a single primary video source
//   (i.e. it will not already have simulcast streams inserted)
//  2) 'mLine' MAY already contain an RTX stream for its video source
//  3) 'mLine' is in sendrecv or sendonly state
// Guarantees:
//  1) return mLine will contain 2 additional simulcast layers
//   generated
//  2) if the base video ssrc in mLine has been seen before,
//   then the same generated simulcast streams from before will
//   be used again
//  3) if rtx is enabled for the mLine, all generated simulcast
//   streams will have rtx streams generated as well
//  4) if rtx has been generated for a src before, we will generate
//   the same rtx stream again


Simulcast.prototype._restoreSimulcast = function (mLine) {
  // First, find the primary video source in the given
  // mLine and see if we've seen it before.
  var primarySsrc;
  var numSsrcs = mLine.ssrcs && mLine.ssrcs.map(function (ssrcInfo) {
    return ssrcInfo.id;
  }).filter(function (ssrc, index, array) {
    return array.indexOf(ssrc) === index;
  }).length || 0;
  var numGroups = mLine.ssrcGroups && mLine.ssrcGroups.length || 0;

  if (numSsrcs === 0 || numSsrcs > 2) {
    // Unsupported scenario
    return mLine;
  }

  if (numSsrcs == 2 && numGroups === 0) {
    // Unsupported scenario
    return mLine;
  }

  if (numSsrcs === 1) {
    primarySsrc = mLine.ssrcs[0].id;
  } else {
    // There must be an FID group, so parse
    //  that and pull the primary ssrc from there
    var fidGroup = mLine.ssrcGroups.filter(function (group) {
      return group.semantics === "FID";
    })[0];

    if (fidGroup) {
      primarySsrc = parseInt(fidGroup.ssrcs.split(" ")[0]);
    } else {
      // Unsupported scenario
      return mLine;
    }
  }

  console.log("SdpSimulcast: current ssrc cache: ", this.ssrcCache);
  console.log("SdpSimulcast: parsed primary ssrc " + primarySsrc);
  var seenPrimarySsrc = this.ssrcCache.indexOf(primarySsrc) !== -1;

  if (seenPrimarySsrc) {
    console.log("SdpSimulcast: Have seen primary ssrc before, " + "filling in data from cache");
    mLine = this._fillInSourceDataFromCache(mLine);
  } else {
    console.log("SdpSimulcast: Have not seen primary ssrc before, " + "generating source data");
    mLine = this._generateSourceData(mLine, primarySsrc);
  } // Now update the cache to match whatever we've just put into this sdp


  this.ssrcCache = this._parseSimLayers(mLine);
  return mLine;
}; //endregion
//region "Public" functions

/**
 *
 * @param desc
 * @returns {RTCSessionDescription}
 */


Simulcast.prototype.mungeRemoteDescription = function (desc) {
  if (!validateDescription(desc)) {
    return desc;
  }

  var session = transform.parse(desc.sdp);
  var self = this;
  processVideo(session, function (mLine) {
    // Handle simulcast reception.
    if (self.options.explodeRemoteSimulcast) {
      explodeRemoteSimulcast(mLine);
    } else {
      implodeRemoteSimulcast(mLine);
    } // Make sure that we ALWAYS add the conference flag to the remote
    // description: That flag is deprecated but, as of this writing
    // (09/2019), it's still used in jitsi-meet to enable legacy simulcast
    // when screen-sharing (https://cs.chromium.org/chromium/src/third_party/webrtc/media/base/media_channel.h?rcl=f2773b54647633d5725fa25dea883f99dd1b400c&l=838).
    //
    // We've observed the following chain of events that almost always
    // results in connectivity issues at the receiver:
    //
    // 1. The user joins a call with startVideoMuted=true, so there's no
    //    jitsi track created.
    // 2. The user enables screen-sharing. At this point we do a
    //    renegotiation (which starts with an sRD); the ssrcCache is empty,
    //    so the conference flag is not added to the remote description SDP.
    // 3. The next step of the re-negotiation is to set the answer, so
    //    mungeLocalDescription is called, and because now we have a track
    //    due to the user enabling screen-sharing, it enables simulcast.
    // 4. sLD is called with simulcast ssrcs, but the sRD call of step 2
    //    didn't add the conference flag in the SDP, so the screen-sharing
    //    is without simulcast.
    // 5. Any subsequent re-negotiation (for example, due to a participant
    //    joining/leaving the call) will enable simulcast and this switch
    //    almost always results in a broken stream at the receiver.


    if (!self.options.usesUnifiedPlan) {
      assertGoogConference(mLine);
    }
  });
  return new RTCSessionDescription({
    type: desc.type,
    sdp: transform.write(session)
  });
};
/**
 *
 * NOTE this method should be called only if simulcast is supported by
 * the current browser, otherwise local SDP should not be munged.
 * @param desc
 * @returns {RTCSessionDescription}
 */


Simulcast.prototype.mungeLocalDescription = function (desc) {
  if (!validateDescription(desc)) {
    return desc;
  }

  var session = transform.parse(desc.sdp);
  var self = this;
  processVideo(session, function (mLine) {
    if (mLine.direction == 'recvonly' || mLine.direction == 'inactive') {
      return;
    }

    self._restoreSimulcast(mLine);
  });
  return new RTCSessionDescription({
    type: desc.type,
    sdp: transform.write(session)
  });
}; //endregion


module.exports = Simulcast;

/***/ }),

/***/ "./node_modules/@jitsi/sdp-simulcast/lib/transform-utils.js":
/*!******************************************************************!*\
  !*** ./node_modules/@jitsi/sdp-simulcast/lib/transform-utils.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/* Copyright @ 2015 Atlassian Pty Ltd
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * FIXME
 * @param sources FIXME
 * @param order An array of SSRCs which will be used to order the entries in
 * the returned array. Sources whose SSRC appears in 'order' will be added first,
 * in the specified order, and all other sources will be added afterwards (in
 * no specific order).
 * @returns {Array} FIXME
 */
exports.writeSsrcs = function (sources, order) {
  var ssrcs = []; // expand sources to ssrcs

  if (typeof sources !== 'undefined' && Object.keys(sources).length !== 0) {
    if (!Array.isArray(order)) {
      order = [];
    } // Add the sources that appear in 'order' first.


    for (var i = 0; i < order.length; i++) {
      var ssrc = order[i];
      var source = sources[ssrc];
      Object.keys(source).forEach(function (attribute) {
        ssrcs.push({
          id: ssrc,
          attribute: attribute,
          value: source[attribute]
        });
      });
    } // Now add the rest of the sources.


    Object.keys(sources).forEach(function (ssrc) {
      ssrc = parseInt(ssrc); // Object.keys() returns string

      if (order.indexOf(ssrc) >= 0) {
        // Already added.
        return;
      }

      var source = sources[ssrc];
      Object.keys(source).forEach(function (attribute) {
        ssrcs.push({
          id: ssrc,
          attribute: attribute,
          value: source[attribute]
        });
      });
    });
  }

  return ssrcs;
};

exports.parseSsrcs = function (mLine) {
  var sources = {}; // group sources attributes by ssrc.

  if (typeof mLine.ssrcs !== 'undefined' && Array.isArray(mLine.ssrcs)) {
    mLine.ssrcs.forEach(function (ssrc) {
      if (!sources[ssrc.id]) sources[ssrc.id] = {};
      sources[ssrc.id][ssrc.attribute] = ssrc.value;
    });
  }

  return sources;
};

/***/ }),

/***/ "./node_modules/async/lib/async.js":
/*!*****************************************!*\
  !*** ./node_modules/async/lib/async.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(process, setImmediate) {var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/*!
 * async
 * https://github.com/caolan/async
 *
 * Copyright 2010-2014 Caolan McMahon
 * Released under the MIT license
 */

/*jshint onevar: false, indent:4 */

/*global setImmediate: false, setTimeout: false, console: false */
(function () {
  var async = {}; // global on the server, window in the browser

  var root, previous_async;
  root = this;

  if (root != null) {
    previous_async = root.async;
  }

  async.noConflict = function () {
    root.async = previous_async;
    return async;
  };

  function only_once(fn) {
    var called = false;
    return function () {
      if (called) throw new Error("Callback was already called.");
      called = true;
      fn.apply(root, arguments);
    };
  } //// cross-browser compatiblity functions ////


  var _toString = Object.prototype.toString;

  var _isArray = Array.isArray || function (obj) {
    return _toString.call(obj) === '[object Array]';
  };

  var _each = function (arr, iterator) {
    if (arr.forEach) {
      return arr.forEach(iterator);
    }

    for (var i = 0; i < arr.length; i += 1) {
      iterator(arr[i], i, arr);
    }
  };

  var _map = function (arr, iterator) {
    if (arr.map) {
      return arr.map(iterator);
    }

    var results = [];

    _each(arr, function (x, i, a) {
      results.push(iterator(x, i, a));
    });

    return results;
  };

  var _reduce = function (arr, iterator, memo) {
    if (arr.reduce) {
      return arr.reduce(iterator, memo);
    }

    _each(arr, function (x, i, a) {
      memo = iterator(memo, x, i, a);
    });

    return memo;
  };

  var _keys = function (obj) {
    if (Object.keys) {
      return Object.keys(obj);
    }

    var keys = [];

    for (var k in obj) {
      if (obj.hasOwnProperty(k)) {
        keys.push(k);
      }
    }

    return keys;
  }; //// exported async module functions ////
  //// nextTick implementation with browser-compatible fallback ////


  if (typeof process === 'undefined' || !process.nextTick) {
    if (typeof setImmediate === 'function') {
      async.nextTick = function (fn) {
        // not a direct alias for IE10 compatibility
        setImmediate(fn);
      };

      async.setImmediate = async.nextTick;
    } else {
      async.nextTick = function (fn) {
        setTimeout(fn, 0);
      };

      async.setImmediate = async.nextTick;
    }
  } else {
    async.nextTick = process.nextTick;

    if (typeof setImmediate !== 'undefined') {
      async.setImmediate = function (fn) {
        // not a direct alias for IE10 compatibility
        setImmediate(fn);
      };
    } else {
      async.setImmediate = async.nextTick;
    }
  }

  async.each = function (arr, iterator, callback) {
    callback = callback || function () {};

    if (!arr.length) {
      return callback();
    }

    var completed = 0;

    _each(arr, function (x) {
      iterator(x, only_once(done));
    });

    function done(err) {
      if (err) {
        callback(err);

        callback = function () {};
      } else {
        completed += 1;

        if (completed >= arr.length) {
          callback();
        }
      }
    }
  };

  async.forEach = async.each;

  async.eachSeries = function (arr, iterator, callback) {
    callback = callback || function () {};

    if (!arr.length) {
      return callback();
    }

    var completed = 0;

    var iterate = function () {
      iterator(arr[completed], function (err) {
        if (err) {
          callback(err);

          callback = function () {};
        } else {
          completed += 1;

          if (completed >= arr.length) {
            callback();
          } else {
            iterate();
          }
        }
      });
    };

    iterate();
  };

  async.forEachSeries = async.eachSeries;

  async.eachLimit = function (arr, limit, iterator, callback) {
    var fn = _eachLimit(limit);

    fn.apply(null, [arr, iterator, callback]);
  };

  async.forEachLimit = async.eachLimit;

  var _eachLimit = function (limit) {
    return function (arr, iterator, callback) {
      callback = callback || function () {};

      if (!arr.length || limit <= 0) {
        return callback();
      }

      var completed = 0;
      var started = 0;
      var running = 0;

      (function replenish() {
        if (completed >= arr.length) {
          return callback();
        }

        while (running < limit && started < arr.length) {
          started += 1;
          running += 1;
          iterator(arr[started - 1], function (err) {
            if (err) {
              callback(err);

              callback = function () {};
            } else {
              completed += 1;
              running -= 1;

              if (completed >= arr.length) {
                callback();
              } else {
                replenish();
              }
            }
          });
        }
      })();
    };
  };

  var doParallel = function (fn) {
    return function () {
      var args = Array.prototype.slice.call(arguments);
      return fn.apply(null, [async.each].concat(args));
    };
  };

  var doParallelLimit = function (limit, fn) {
    return function () {
      var args = Array.prototype.slice.call(arguments);
      return fn.apply(null, [_eachLimit(limit)].concat(args));
    };
  };

  var doSeries = function (fn) {
    return function () {
      var args = Array.prototype.slice.call(arguments);
      return fn.apply(null, [async.eachSeries].concat(args));
    };
  };

  var _asyncMap = function (eachfn, arr, iterator, callback) {
    arr = _map(arr, function (x, i) {
      return {
        index: i,
        value: x
      };
    });

    if (!callback) {
      eachfn(arr, function (x, callback) {
        iterator(x.value, function (err) {
          callback(err);
        });
      });
    } else {
      var results = [];
      eachfn(arr, function (x, callback) {
        iterator(x.value, function (err, v) {
          results[x.index] = v;
          callback(err);
        });
      }, function (err) {
        callback(err, results);
      });
    }
  };

  async.map = doParallel(_asyncMap);
  async.mapSeries = doSeries(_asyncMap);

  async.mapLimit = function (arr, limit, iterator, callback) {
    return _mapLimit(limit)(arr, iterator, callback);
  };

  var _mapLimit = function (limit) {
    return doParallelLimit(limit, _asyncMap);
  }; // reduce only has a series version, as doing reduce in parallel won't
  // work in many situations.


  async.reduce = function (arr, memo, iterator, callback) {
    async.eachSeries(arr, function (x, callback) {
      iterator(memo, x, function (err, v) {
        memo = v;
        callback(err);
      });
    }, function (err) {
      callback(err, memo);
    });
  }; // inject alias


  async.inject = async.reduce; // foldl alias

  async.foldl = async.reduce;

  async.reduceRight = function (arr, memo, iterator, callback) {
    var reversed = _map(arr, function (x) {
      return x;
    }).reverse();

    async.reduce(reversed, memo, iterator, callback);
  }; // foldr alias


  async.foldr = async.reduceRight;

  var _filter = function (eachfn, arr, iterator, callback) {
    var results = [];
    arr = _map(arr, function (x, i) {
      return {
        index: i,
        value: x
      };
    });
    eachfn(arr, function (x, callback) {
      iterator(x.value, function (v) {
        if (v) {
          results.push(x);
        }

        callback();
      });
    }, function (err) {
      callback(_map(results.sort(function (a, b) {
        return a.index - b.index;
      }), function (x) {
        return x.value;
      }));
    });
  };

  async.filter = doParallel(_filter);
  async.filterSeries = doSeries(_filter); // select alias

  async.select = async.filter;
  async.selectSeries = async.filterSeries;

  var _reject = function (eachfn, arr, iterator, callback) {
    var results = [];
    arr = _map(arr, function (x, i) {
      return {
        index: i,
        value: x
      };
    });
    eachfn(arr, function (x, callback) {
      iterator(x.value, function (v) {
        if (!v) {
          results.push(x);
        }

        callback();
      });
    }, function (err) {
      callback(_map(results.sort(function (a, b) {
        return a.index - b.index;
      }), function (x) {
        return x.value;
      }));
    });
  };

  async.reject = doParallel(_reject);
  async.rejectSeries = doSeries(_reject);

  var _detect = function (eachfn, arr, iterator, main_callback) {
    eachfn(arr, function (x, callback) {
      iterator(x, function (result) {
        if (result) {
          main_callback(x);

          main_callback = function () {};
        } else {
          callback();
        }
      });
    }, function (err) {
      main_callback();
    });
  };

  async.detect = doParallel(_detect);
  async.detectSeries = doSeries(_detect);

  async.some = function (arr, iterator, main_callback) {
    async.each(arr, function (x, callback) {
      iterator(x, function (v) {
        if (v) {
          main_callback(true);

          main_callback = function () {};
        }

        callback();
      });
    }, function (err) {
      main_callback(false);
    });
  }; // any alias


  async.any = async.some;

  async.every = function (arr, iterator, main_callback) {
    async.each(arr, function (x, callback) {
      iterator(x, function (v) {
        if (!v) {
          main_callback(false);

          main_callback = function () {};
        }

        callback();
      });
    }, function (err) {
      main_callback(true);
    });
  }; // all alias


  async.all = async.every;

  async.sortBy = function (arr, iterator, callback) {
    async.map(arr, function (x, callback) {
      iterator(x, function (err, criteria) {
        if (err) {
          callback(err);
        } else {
          callback(null, {
            value: x,
            criteria: criteria
          });
        }
      });
    }, function (err, results) {
      if (err) {
        return callback(err);
      } else {
        var fn = function (left, right) {
          var a = left.criteria,
              b = right.criteria;
          return a < b ? -1 : a > b ? 1 : 0;
        };

        callback(null, _map(results.sort(fn), function (x) {
          return x.value;
        }));
      }
    });
  };

  async.auto = function (tasks, callback) {
    callback = callback || function () {};

    var keys = _keys(tasks);

    var remainingTasks = keys.length;

    if (!remainingTasks) {
      return callback();
    }

    var results = {};
    var listeners = [];

    var addListener = function (fn) {
      listeners.unshift(fn);
    };

    var removeListener = function (fn) {
      for (var i = 0; i < listeners.length; i += 1) {
        if (listeners[i] === fn) {
          listeners.splice(i, 1);
          return;
        }
      }
    };

    var taskComplete = function () {
      remainingTasks--;

      _each(listeners.slice(0), function (fn) {
        fn();
      });
    };

    addListener(function () {
      if (!remainingTasks) {
        var theCallback = callback; // prevent final callback from calling itself if it errors

        callback = function () {};

        theCallback(null, results);
      }
    });

    _each(keys, function (k) {
      var task = _isArray(tasks[k]) ? tasks[k] : [tasks[k]];

      var taskCallback = function (err) {
        var args = Array.prototype.slice.call(arguments, 1);

        if (args.length <= 1) {
          args = args[0];
        }

        if (err) {
          var safeResults = {};

          _each(_keys(results), function (rkey) {
            safeResults[rkey] = results[rkey];
          });

          safeResults[k] = args;
          callback(err, safeResults); // stop subsequent errors hitting callback multiple times

          callback = function () {};
        } else {
          results[k] = args;
          async.setImmediate(taskComplete);
        }
      };

      var requires = task.slice(0, Math.abs(task.length - 1)) || [];

      var ready = function () {
        return _reduce(requires, function (a, x) {
          return a && results.hasOwnProperty(x);
        }, true) && !results.hasOwnProperty(k);
      };

      if (ready()) {
        task[task.length - 1](taskCallback, results);
      } else {
        var listener = function () {
          if (ready()) {
            removeListener(listener);
            task[task.length - 1](taskCallback, results);
          }
        };

        addListener(listener);
      }
    });
  };

  async.retry = function (times, task, callback) {
    var DEFAULT_TIMES = 5;
    var attempts = []; // Use defaults if times not passed

    if (typeof times === 'function') {
      callback = task;
      task = times;
      times = DEFAULT_TIMES;
    } // Make sure times is a number


    times = parseInt(times, 10) || DEFAULT_TIMES;

    var wrappedTask = function (wrappedCallback, wrappedResults) {
      var retryAttempt = function (task, finalAttempt) {
        return function (seriesCallback) {
          task(function (err, result) {
            seriesCallback(!err || finalAttempt, {
              err: err,
              result: result
            });
          }, wrappedResults);
        };
      };

      while (times) {
        attempts.push(retryAttempt(task, !(times -= 1)));
      }

      async.series(attempts, function (done, data) {
        data = data[data.length - 1];
        (wrappedCallback || callback)(data.err, data.result);
      });
    }; // If a callback is passed, run this as a controll flow


    return callback ? wrappedTask() : wrappedTask;
  };

  async.waterfall = function (tasks, callback) {
    callback = callback || function () {};

    if (!_isArray(tasks)) {
      var err = new Error('First argument to waterfall must be an array of functions');
      return callback(err);
    }

    if (!tasks.length) {
      return callback();
    }

    var wrapIterator = function (iterator) {
      return function (err) {
        if (err) {
          callback.apply(null, arguments);

          callback = function () {};
        } else {
          var args = Array.prototype.slice.call(arguments, 1);
          var next = iterator.next();

          if (next) {
            args.push(wrapIterator(next));
          } else {
            args.push(callback);
          }

          async.setImmediate(function () {
            iterator.apply(null, args);
          });
        }
      };
    };

    wrapIterator(async.iterator(tasks))();
  };

  var _parallel = function (eachfn, tasks, callback) {
    callback = callback || function () {};

    if (_isArray(tasks)) {
      eachfn.map(tasks, function (fn, callback) {
        if (fn) {
          fn(function (err) {
            var args = Array.prototype.slice.call(arguments, 1);

            if (args.length <= 1) {
              args = args[0];
            }

            callback.call(null, err, args);
          });
        }
      }, callback);
    } else {
      var results = {};
      eachfn.each(_keys(tasks), function (k, callback) {
        tasks[k](function (err) {
          var args = Array.prototype.slice.call(arguments, 1);

          if (args.length <= 1) {
            args = args[0];
          }

          results[k] = args;
          callback(err);
        });
      }, function (err) {
        callback(err, results);
      });
    }
  };

  async.parallel = function (tasks, callback) {
    _parallel({
      map: async.map,
      each: async.each
    }, tasks, callback);
  };

  async.parallelLimit = function (tasks, limit, callback) {
    _parallel({
      map: _mapLimit(limit),
      each: _eachLimit(limit)
    }, tasks, callback);
  };

  async.series = function (tasks, callback) {
    callback = callback || function () {};

    if (_isArray(tasks)) {
      async.mapSeries(tasks, function (fn, callback) {
        if (fn) {
          fn(function (err) {
            var args = Array.prototype.slice.call(arguments, 1);

            if (args.length <= 1) {
              args = args[0];
            }

            callback.call(null, err, args);
          });
        }
      }, callback);
    } else {
      var results = {};
      async.eachSeries(_keys(tasks), function (k, callback) {
        tasks[k](function (err) {
          var args = Array.prototype.slice.call(arguments, 1);

          if (args.length <= 1) {
            args = args[0];
          }

          results[k] = args;
          callback(err);
        });
      }, function (err) {
        callback(err, results);
      });
    }
  };

  async.iterator = function (tasks) {
    var makeCallback = function (index) {
      var fn = function () {
        if (tasks.length) {
          tasks[index].apply(null, arguments);
        }

        return fn.next();
      };

      fn.next = function () {
        return index < tasks.length - 1 ? makeCallback(index + 1) : null;
      };

      return fn;
    };

    return makeCallback(0);
  };

  async.apply = function (fn) {
    var args = Array.prototype.slice.call(arguments, 1);
    return function () {
      return fn.apply(null, args.concat(Array.prototype.slice.call(arguments)));
    };
  };

  var _concat = function (eachfn, arr, fn, callback) {
    var r = [];
    eachfn(arr, function (x, cb) {
      fn(x, function (err, y) {
        r = r.concat(y || []);
        cb(err);
      });
    }, function (err) {
      callback(err, r);
    });
  };

  async.concat = doParallel(_concat);
  async.concatSeries = doSeries(_concat);

  async.whilst = function (test, iterator, callback) {
    if (test()) {
      iterator(function (err) {
        if (err) {
          return callback(err);
        }

        async.whilst(test, iterator, callback);
      });
    } else {
      callback();
    }
  };

  async.doWhilst = function (iterator, test, callback) {
    iterator(function (err) {
      if (err) {
        return callback(err);
      }

      var args = Array.prototype.slice.call(arguments, 1);

      if (test.apply(null, args)) {
        async.doWhilst(iterator, test, callback);
      } else {
        callback();
      }
    });
  };

  async.until = function (test, iterator, callback) {
    if (!test()) {
      iterator(function (err) {
        if (err) {
          return callback(err);
        }

        async.until(test, iterator, callback);
      });
    } else {
      callback();
    }
  };

  async.doUntil = function (iterator, test, callback) {
    iterator(function (err) {
      if (err) {
        return callback(err);
      }

      var args = Array.prototype.slice.call(arguments, 1);

      if (!test.apply(null, args)) {
        async.doUntil(iterator, test, callback);
      } else {
        callback();
      }
    });
  };

  async.queue = function (worker, concurrency) {
    if (concurrency === undefined) {
      concurrency = 1;
    }

    function _insert(q, data, pos, callback) {
      if (!q.started) {
        q.started = true;
      }

      if (!_isArray(data)) {
        data = [data];
      }

      if (data.length == 0) {
        // call drain immediately if there are no tasks
        return async.setImmediate(function () {
          if (q.drain) {
            q.drain();
          }
        });
      }

      _each(data, function (task) {
        var item = {
          data: task,
          callback: typeof callback === 'function' ? callback : null
        };

        if (pos) {
          q.tasks.unshift(item);
        } else {
          q.tasks.push(item);
        }

        if (q.saturated && q.tasks.length === q.concurrency) {
          q.saturated();
        }

        async.setImmediate(q.process);
      });
    }

    var workers = 0;
    var q = {
      tasks: [],
      concurrency: concurrency,
      saturated: null,
      empty: null,
      drain: null,
      started: false,
      paused: false,
      push: function (data, callback) {
        _insert(q, data, false, callback);
      },
      kill: function () {
        q.drain = null;
        q.tasks = [];
      },
      unshift: function (data, callback) {
        _insert(q, data, true, callback);
      },
      process: function () {
        if (!q.paused && workers < q.concurrency && q.tasks.length) {
          var task = q.tasks.shift();

          if (q.empty && q.tasks.length === 0) {
            q.empty();
          }

          workers += 1;

          var next = function () {
            workers -= 1;

            if (task.callback) {
              task.callback.apply(task, arguments);
            }

            if (q.drain && q.tasks.length + workers === 0) {
              q.drain();
            }

            q.process();
          };

          var cb = only_once(next);
          worker(task.data, cb);
        }
      },
      length: function () {
        return q.tasks.length;
      },
      running: function () {
        return workers;
      },
      idle: function () {
        return q.tasks.length + workers === 0;
      },
      pause: function () {
        if (q.paused === true) {
          return;
        }

        q.paused = true;
        q.process();
      },
      resume: function () {
        if (q.paused === false) {
          return;
        }

        q.paused = false;
        q.process();
      }
    };
    return q;
  };

  async.priorityQueue = function (worker, concurrency) {
    function _compareTasks(a, b) {
      return a.priority - b.priority;
    }

    ;

    function _binarySearch(sequence, item, compare) {
      var beg = -1,
          end = sequence.length - 1;

      while (beg < end) {
        var mid = beg + (end - beg + 1 >>> 1);

        if (compare(item, sequence[mid]) >= 0) {
          beg = mid;
        } else {
          end = mid - 1;
        }
      }

      return beg;
    }

    function _insert(q, data, priority, callback) {
      if (!q.started) {
        q.started = true;
      }

      if (!_isArray(data)) {
        data = [data];
      }

      if (data.length == 0) {
        // call drain immediately if there are no tasks
        return async.setImmediate(function () {
          if (q.drain) {
            q.drain();
          }
        });
      }

      _each(data, function (task) {
        var item = {
          data: task,
          priority: priority,
          callback: typeof callback === 'function' ? callback : null
        };
        q.tasks.splice(_binarySearch(q.tasks, item, _compareTasks) + 1, 0, item);

        if (q.saturated && q.tasks.length === q.concurrency) {
          q.saturated();
        }

        async.setImmediate(q.process);
      });
    } // Start with a normal queue


    var q = async.queue(worker, concurrency); // Override push to accept second parameter representing priority

    q.push = function (data, priority, callback) {
      _insert(q, data, priority, callback);
    }; // Remove unshift function


    delete q.unshift;
    return q;
  };

  async.cargo = function (worker, payload) {
    var working = false,
        tasks = [];
    var cargo = {
      tasks: tasks,
      payload: payload,
      saturated: null,
      empty: null,
      drain: null,
      drained: true,
      push: function (data, callback) {
        if (!_isArray(data)) {
          data = [data];
        }

        _each(data, function (task) {
          tasks.push({
            data: task,
            callback: typeof callback === 'function' ? callback : null
          });
          cargo.drained = false;

          if (cargo.saturated && tasks.length === payload) {
            cargo.saturated();
          }
        });

        async.setImmediate(cargo.process);
      },
      process: function process() {
        if (working) return;

        if (tasks.length === 0) {
          if (cargo.drain && !cargo.drained) cargo.drain();
          cargo.drained = true;
          return;
        }

        var ts = typeof payload === 'number' ? tasks.splice(0, payload) : tasks.splice(0, tasks.length);

        var ds = _map(ts, function (task) {
          return task.data;
        });

        if (cargo.empty) cargo.empty();
        working = true;
        worker(ds, function () {
          working = false;
          var args = arguments;

          _each(ts, function (data) {
            if (data.callback) {
              data.callback.apply(null, args);
            }
          });

          process();
        });
      },
      length: function () {
        return tasks.length;
      },
      running: function () {
        return working;
      }
    };
    return cargo;
  };

  var _console_fn = function (name) {
    return function (fn) {
      var args = Array.prototype.slice.call(arguments, 1);
      fn.apply(null, args.concat([function (err) {
        var args = Array.prototype.slice.call(arguments, 1);

        if (typeof console !== 'undefined') {
          if (err) {
            if (console.error) {
              console.error(err);
            }
          } else if (console[name]) {
            _each(args, function (x) {
              console[name](x);
            });
          }
        }
      }]));
    };
  };

  async.log = _console_fn('log');
  async.dir = _console_fn('dir');
  /*async.info = _console_fn('info');
  async.warn = _console_fn('warn');
  async.error = _console_fn('error');*/

  async.memoize = function (fn, hasher) {
    var memo = {};
    var queues = {};

    hasher = hasher || function (x) {
      return x;
    };

    var memoized = function () {
      var args = Array.prototype.slice.call(arguments);
      var callback = args.pop();
      var key = hasher.apply(null, args);

      if (key in memo) {
        async.nextTick(function () {
          callback.apply(null, memo[key]);
        });
      } else if (key in queues) {
        queues[key].push(callback);
      } else {
        queues[key] = [callback];
        fn.apply(null, args.concat([function () {
          memo[key] = arguments;
          var q = queues[key];
          delete queues[key];

          for (var i = 0, l = q.length; i < l; i++) {
            q[i].apply(null, arguments);
          }
        }]));
      }
    };

    memoized.memo = memo;
    memoized.unmemoized = fn;
    return memoized;
  };

  async.unmemoize = function (fn) {
    return function () {
      return (fn.unmemoized || fn).apply(null, arguments);
    };
  };

  async.times = function (count, iterator, callback) {
    var counter = [];

    for (var i = 0; i < count; i++) {
      counter.push(i);
    }

    return async.map(counter, iterator, callback);
  };

  async.timesSeries = function (count, iterator, callback) {
    var counter = [];

    for (var i = 0; i < count; i++) {
      counter.push(i);
    }

    return async.mapSeries(counter, iterator, callback);
  };

  async.seq = function ()
  /* functions... */
  {
    var fns = arguments;
    return function () {
      var that = this;
      var args = Array.prototype.slice.call(arguments);
      var callback = args.pop();
      async.reduce(fns, args, function (newargs, fn, cb) {
        fn.apply(that, newargs.concat([function () {
          var err = arguments[0];
          var nextargs = Array.prototype.slice.call(arguments, 1);
          cb(err, nextargs);
        }]));
      }, function (err, results) {
        callback.apply(that, [err].concat(results));
      });
    };
  };

  async.compose = function ()
  /* functions... */
  {
    return async.seq.apply(null, Array.prototype.reverse.call(arguments));
  };

  var _applyEach = function (eachfn, fns
  /*args...*/
  ) {
    var go = function () {
      var that = this;
      var args = Array.prototype.slice.call(arguments);
      var callback = args.pop();
      return eachfn(fns, function (fn, cb) {
        fn.apply(that, args.concat([cb]));
      }, callback);
    };

    if (arguments.length > 2) {
      var args = Array.prototype.slice.call(arguments, 2);
      return go.apply(this, args);
    } else {
      return go;
    }
  };

  async.applyEach = doParallel(_applyEach);
  async.applyEachSeries = doSeries(_applyEach);

  async.forever = function (fn, callback) {
    function next(err) {
      if (err) {
        if (callback) {
          return callback(err);
        }

        throw err;
      }

      fn(next);
    }

    next();
  }; // Node.js


  if ( true && module.exports) {
    module.exports = async;
  } // AMD / RequireJS
  else if (true) {
      !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function () {
        return async;
      }).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),
				__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));
    } // included directly via <script> tag
    else {}
})();
/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ "./node_modules/process/browser.js"), __webpack_require__(/*! ./../../timers-browserify/main.js */ "./node_modules/timers-browserify/main.js").setImmediate))

/***/ }),

/***/ "./node_modules/bowser/es5.js":
/*!************************************!*\
  !*** ./node_modules/bowser/es5.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

!function (e, t) {
   true ? module.exports = t() : undefined;
}(this, function () {
  return function (e) {
    var t = {};

    function r(i) {
      if (t[i]) return t[i].exports;
      var n = t[i] = {
        i: i,
        l: !1,
        exports: {}
      };
      return e[i].call(n.exports, n, n.exports, r), n.l = !0, n.exports;
    }

    return r.m = e, r.c = t, r.d = function (e, t, i) {
      r.o(e, t) || Object.defineProperty(e, t, {
        enumerable: !0,
        get: i
      });
    }, r.r = function (e) {
      "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(e, Symbol.toStringTag, {
        value: "Module"
      }), Object.defineProperty(e, "__esModule", {
        value: !0
      });
    }, r.t = function (e, t) {
      if (1 & t && (e = r(e)), 8 & t) return e;
      if (4 & t && "object" == typeof e && e && e.__esModule) return e;
      var i = Object.create(null);
      if (r.r(i), Object.defineProperty(i, "default", {
        enumerable: !0,
        value: e
      }), 2 & t && "string" != typeof e) for (var n in e) r.d(i, n, function (t) {
        return e[t];
      }.bind(null, n));
      return i;
    }, r.n = function (e) {
      var t = e && e.__esModule ? function () {
        return e.default;
      } : function () {
        return e;
      };
      return r.d(t, "a", t), t;
    }, r.o = function (e, t) {
      return Object.prototype.hasOwnProperty.call(e, t);
    }, r.p = "", r(r.s = 90);
  }({
    17: function (e, t, r) {
      "use strict";

      t.__esModule = !0, t.default = void 0;

      var i = r(18),
          n = function () {
        function e() {}

        return e.getFirstMatch = function (e, t) {
          var r = t.match(e);
          return r && r.length > 0 && r[1] || "";
        }, e.getSecondMatch = function (e, t) {
          var r = t.match(e);
          return r && r.length > 1 && r[2] || "";
        }, e.matchAndReturnConst = function (e, t, r) {
          if (e.test(t)) return r;
        }, e.getWindowsVersionName = function (e) {
          switch (e) {
            case "NT":
              return "NT";

            case "XP":
              return "XP";

            case "NT 5.0":
              return "2000";

            case "NT 5.1":
              return "XP";

            case "NT 5.2":
              return "2003";

            case "NT 6.0":
              return "Vista";

            case "NT 6.1":
              return "7";

            case "NT 6.2":
              return "8";

            case "NT 6.3":
              return "8.1";

            case "NT 10.0":
              return "10";

            default:
              return;
          }
        }, e.getMacOSVersionName = function (e) {
          var t = e.split(".").splice(0, 2).map(function (e) {
            return parseInt(e, 10) || 0;
          });
          if (t.push(0), 10 === t[0]) switch (t[1]) {
            case 5:
              return "Leopard";

            case 6:
              return "Snow Leopard";

            case 7:
              return "Lion";

            case 8:
              return "Mountain Lion";

            case 9:
              return "Mavericks";

            case 10:
              return "Yosemite";

            case 11:
              return "El Capitan";

            case 12:
              return "Sierra";

            case 13:
              return "High Sierra";

            case 14:
              return "Mojave";

            case 15:
              return "Catalina";

            default:
              return;
          }
        }, e.getAndroidVersionName = function (e) {
          var t = e.split(".").splice(0, 2).map(function (e) {
            return parseInt(e, 10) || 0;
          });
          if (t.push(0), !(1 === t[0] && t[1] < 5)) return 1 === t[0] && t[1] < 6 ? "Cupcake" : 1 === t[0] && t[1] >= 6 ? "Donut" : 2 === t[0] && t[1] < 2 ? "Eclair" : 2 === t[0] && 2 === t[1] ? "Froyo" : 2 === t[0] && t[1] > 2 ? "Gingerbread" : 3 === t[0] ? "Honeycomb" : 4 === t[0] && t[1] < 1 ? "Ice Cream Sandwich" : 4 === t[0] && t[1] < 4 ? "Jelly Bean" : 4 === t[0] && t[1] >= 4 ? "KitKat" : 5 === t[0] ? "Lollipop" : 6 === t[0] ? "Marshmallow" : 7 === t[0] ? "Nougat" : 8 === t[0] ? "Oreo" : 9 === t[0] ? "Pie" : void 0;
        }, e.getVersionPrecision = function (e) {
          return e.split(".").length;
        }, e.compareVersions = function (t, r, i) {
          void 0 === i && (i = !1);
          var n = e.getVersionPrecision(t),
              s = e.getVersionPrecision(r),
              o = Math.max(n, s),
              a = 0,
              u = e.map([t, r], function (t) {
            var r = o - e.getVersionPrecision(t),
                i = t + new Array(r + 1).join(".0");
            return e.map(i.split("."), function (e) {
              return new Array(20 - e.length).join("0") + e;
            }).reverse();
          });

          for (i && (a = o - Math.min(n, s)), o -= 1; o >= a;) {
            if (u[0][o] > u[1][o]) return 1;

            if (u[0][o] === u[1][o]) {
              if (o === a) return 0;
              o -= 1;
            } else if (u[0][o] < u[1][o]) return -1;
          }
        }, e.map = function (e, t) {
          var r,
              i = [];
          if (Array.prototype.map) return Array.prototype.map.call(e, t);

          for (r = 0; r < e.length; r += 1) i.push(t(e[r]));

          return i;
        }, e.getBrowserAlias = function (e) {
          return i.BROWSER_ALIASES_MAP[e];
        }, e.getBrowserTypeByAlias = function (e) {
          return i.BROWSER_MAP[e] || "";
        }, e;
      }();

      t.default = n, e.exports = t.default;
    },
    18: function (e, t, r) {
      "use strict";

      t.__esModule = !0, t.ENGINE_MAP = t.OS_MAP = t.PLATFORMS_MAP = t.BROWSER_MAP = t.BROWSER_ALIASES_MAP = void 0;
      t.BROWSER_ALIASES_MAP = {
        "Amazon Silk": "amazon_silk",
        "Android Browser": "android",
        Bada: "bada",
        BlackBerry: "blackberry",
        Chrome: "chrome",
        Chromium: "chromium",
        Epiphany: "epiphany",
        Firefox: "firefox",
        Focus: "focus",
        Generic: "generic",
        "Google Search": "google_search",
        Googlebot: "googlebot",
        "Internet Explorer": "ie",
        "K-Meleon": "k_meleon",
        Maxthon: "maxthon",
        "Microsoft Edge": "edge",
        "MZ Browser": "mz",
        "NAVER Whale Browser": "naver",
        Opera: "opera",
        "Opera Coast": "opera_coast",
        PhantomJS: "phantomjs",
        Puffin: "puffin",
        QupZilla: "qupzilla",
        QQ: "qq",
        QQLite: "qqlite",
        Safari: "safari",
        Sailfish: "sailfish",
        "Samsung Internet for Android": "samsung_internet",
        SeaMonkey: "seamonkey",
        Sleipnir: "sleipnir",
        Swing: "swing",
        Tizen: "tizen",
        "UC Browser": "uc",
        Vivaldi: "vivaldi",
        "WebOS Browser": "webos",
        WeChat: "wechat",
        "Yandex Browser": "yandex",
        Roku: "roku"
      };
      t.BROWSER_MAP = {
        amazon_silk: "Amazon Silk",
        android: "Android Browser",
        bada: "Bada",
        blackberry: "BlackBerry",
        chrome: "Chrome",
        chromium: "Chromium",
        epiphany: "Epiphany",
        firefox: "Firefox",
        focus: "Focus",
        generic: "Generic",
        googlebot: "Googlebot",
        google_search: "Google Search",
        ie: "Internet Explorer",
        k_meleon: "K-Meleon",
        maxthon: "Maxthon",
        edge: "Microsoft Edge",
        mz: "MZ Browser",
        naver: "NAVER Whale Browser",
        opera: "Opera",
        opera_coast: "Opera Coast",
        phantomjs: "PhantomJS",
        puffin: "Puffin",
        qupzilla: "QupZilla",
        qq: "QQ Browser",
        qqlite: "QQ Browser Lite",
        safari: "Safari",
        sailfish: "Sailfish",
        samsung_internet: "Samsung Internet for Android",
        seamonkey: "SeaMonkey",
        sleipnir: "Sleipnir",
        swing: "Swing",
        tizen: "Tizen",
        uc: "UC Browser",
        vivaldi: "Vivaldi",
        webos: "WebOS Browser",
        wechat: "WeChat",
        yandex: "Yandex Browser"
      };
      t.PLATFORMS_MAP = {
        tablet: "tablet",
        mobile: "mobile",
        desktop: "desktop",
        tv: "tv"
      };
      t.OS_MAP = {
        WindowsPhone: "Windows Phone",
        Windows: "Windows",
        MacOS: "macOS",
        iOS: "iOS",
        Android: "Android",
        WebOS: "WebOS",
        BlackBerry: "BlackBerry",
        Bada: "Bada",
        Tizen: "Tizen",
        Linux: "Linux",
        ChromeOS: "Chrome OS",
        PlayStation4: "PlayStation 4",
        Roku: "Roku"
      };
      t.ENGINE_MAP = {
        EdgeHTML: "EdgeHTML",
        Blink: "Blink",
        Trident: "Trident",
        Presto: "Presto",
        Gecko: "Gecko",
        WebKit: "WebKit"
      };
    },
    90: function (e, t, r) {
      "use strict";

      t.__esModule = !0, t.default = void 0;
      var i,
          n = (i = r(91)) && i.__esModule ? i : {
        default: i
      },
          s = r(18);

      function o(e, t) {
        for (var r = 0; r < t.length; r++) {
          var i = t[r];
          i.enumerable = i.enumerable || !1, i.configurable = !0, "value" in i && (i.writable = !0), Object.defineProperty(e, i.key, i);
        }
      }

      var a = function () {
        function e() {}

        var t, r, i;
        return e.getParser = function (e, t) {
          if (void 0 === t && (t = !1), "string" != typeof e) throw new Error("UserAgent should be a string");
          return new n.default(e, t);
        }, e.parse = function (e) {
          return new n.default(e).getResult();
        }, t = e, i = [{
          key: "BROWSER_MAP",
          get: function () {
            return s.BROWSER_MAP;
          }
        }, {
          key: "ENGINE_MAP",
          get: function () {
            return s.ENGINE_MAP;
          }
        }, {
          key: "OS_MAP",
          get: function () {
            return s.OS_MAP;
          }
        }, {
          key: "PLATFORMS_MAP",
          get: function () {
            return s.PLATFORMS_MAP;
          }
        }], (r = null) && o(t.prototype, r), i && o(t, i), e;
      }();

      t.default = a, e.exports = t.default;
    },
    91: function (e, t, r) {
      "use strict";

      t.__esModule = !0, t.default = void 0;
      var i = u(r(92)),
          n = u(r(93)),
          s = u(r(94)),
          o = u(r(95)),
          a = u(r(17));

      function u(e) {
        return e && e.__esModule ? e : {
          default: e
        };
      }

      var d = function () {
        function e(e, t) {
          if (void 0 === t && (t = !1), null == e || "" === e) throw new Error("UserAgent parameter can't be empty");
          this._ua = e, this.parsedResult = {}, !0 !== t && this.parse();
        }

        var t = e.prototype;
        return t.getUA = function () {
          return this._ua;
        }, t.test = function (e) {
          return e.test(this._ua);
        }, t.parseBrowser = function () {
          var e = this;
          this.parsedResult.browser = {};
          var t = i.default.find(function (t) {
            if ("function" == typeof t.test) return t.test(e);
            if (t.test instanceof Array) return t.test.some(function (t) {
              return e.test(t);
            });
            throw new Error("Browser's test function is not valid");
          });
          return t && (this.parsedResult.browser = t.describe(this.getUA())), this.parsedResult.browser;
        }, t.getBrowser = function () {
          return this.parsedResult.browser ? this.parsedResult.browser : this.parseBrowser();
        }, t.getBrowserName = function (e) {
          return e ? String(this.getBrowser().name).toLowerCase() || "" : this.getBrowser().name || "";
        }, t.getBrowserVersion = function () {
          return this.getBrowser().version;
        }, t.getOS = function () {
          return this.parsedResult.os ? this.parsedResult.os : this.parseOS();
        }, t.parseOS = function () {
          var e = this;
          this.parsedResult.os = {};
          var t = n.default.find(function (t) {
            if ("function" == typeof t.test) return t.test(e);
            if (t.test instanceof Array) return t.test.some(function (t) {
              return e.test(t);
            });
            throw new Error("Browser's test function is not valid");
          });
          return t && (this.parsedResult.os = t.describe(this.getUA())), this.parsedResult.os;
        }, t.getOSName = function (e) {
          var t = this.getOS().name;
          return e ? String(t).toLowerCase() || "" : t || "";
        }, t.getOSVersion = function () {
          return this.getOS().version;
        }, t.getPlatform = function () {
          return this.parsedResult.platform ? this.parsedResult.platform : this.parsePlatform();
        }, t.getPlatformType = function (e) {
          void 0 === e && (e = !1);
          var t = this.getPlatform().type;
          return e ? String(t).toLowerCase() || "" : t || "";
        }, t.parsePlatform = function () {
          var e = this;
          this.parsedResult.platform = {};
          var t = s.default.find(function (t) {
            if ("function" == typeof t.test) return t.test(e);
            if (t.test instanceof Array) return t.test.some(function (t) {
              return e.test(t);
            });
            throw new Error("Browser's test function is not valid");
          });
          return t && (this.parsedResult.platform = t.describe(this.getUA())), this.parsedResult.platform;
        }, t.getEngine = function () {
          return this.parsedResult.engine ? this.parsedResult.engine : this.parseEngine();
        }, t.getEngineName = function (e) {
          return e ? String(this.getEngine().name).toLowerCase() || "" : this.getEngine().name || "";
        }, t.parseEngine = function () {
          var e = this;
          this.parsedResult.engine = {};
          var t = o.default.find(function (t) {
            if ("function" == typeof t.test) return t.test(e);
            if (t.test instanceof Array) return t.test.some(function (t) {
              return e.test(t);
            });
            throw new Error("Browser's test function is not valid");
          });
          return t && (this.parsedResult.engine = t.describe(this.getUA())), this.parsedResult.engine;
        }, t.parse = function () {
          return this.parseBrowser(), this.parseOS(), this.parsePlatform(), this.parseEngine(), this;
        }, t.getResult = function () {
          return Object.assign({}, this.parsedResult);
        }, t.satisfies = function (e) {
          var t = this,
              r = {},
              i = 0,
              n = {},
              s = 0;

          if (Object.keys(e).forEach(function (t) {
            var o = e[t];
            "string" == typeof o ? (n[t] = o, s += 1) : "object" == typeof o && (r[t] = o, i += 1);
          }), i > 0) {
            var o = Object.keys(r),
                a = o.find(function (e) {
              return t.isOS(e);
            });

            if (a) {
              var u = this.satisfies(r[a]);
              if (void 0 !== u) return u;
            }

            var d = o.find(function (e) {
              return t.isPlatform(e);
            });

            if (d) {
              var c = this.satisfies(r[d]);
              if (void 0 !== c) return c;
            }
          }

          if (s > 0) {
            var f = Object.keys(n).find(function (e) {
              return t.isBrowser(e, !0);
            });
            if (void 0 !== f) return this.compareVersion(n[f]);
          }
        }, t.isBrowser = function (e, t) {
          void 0 === t && (t = !1);
          var r = this.getBrowserName().toLowerCase(),
              i = e.toLowerCase(),
              n = a.default.getBrowserTypeByAlias(i);
          return t && n && (i = n.toLowerCase()), i === r;
        }, t.compareVersion = function (e) {
          var t = [0],
              r = e,
              i = !1,
              n = this.getBrowserVersion();
          if ("string" == typeof n) return ">" === e[0] || "<" === e[0] ? (r = e.substr(1), "=" === e[1] ? (i = !0, r = e.substr(2)) : t = [], ">" === e[0] ? t.push(1) : t.push(-1)) : "=" === e[0] ? r = e.substr(1) : "~" === e[0] && (i = !0, r = e.substr(1)), t.indexOf(a.default.compareVersions(n, r, i)) > -1;
        }, t.isOS = function (e) {
          return this.getOSName(!0) === String(e).toLowerCase();
        }, t.isPlatform = function (e) {
          return this.getPlatformType(!0) === String(e).toLowerCase();
        }, t.isEngine = function (e) {
          return this.getEngineName(!0) === String(e).toLowerCase();
        }, t.is = function (e) {
          return this.isBrowser(e) || this.isOS(e) || this.isPlatform(e);
        }, t.some = function (e) {
          var t = this;
          return void 0 === e && (e = []), e.some(function (e) {
            return t.is(e);
          });
        }, e;
      }();

      t.default = d, e.exports = t.default;
    },
    92: function (e, t, r) {
      "use strict";

      t.__esModule = !0, t.default = void 0;
      var i,
          n = (i = r(17)) && i.__esModule ? i : {
        default: i
      };
      var s = /version\/(\d+(\.?_?\d+)+)/i,
          o = [{
        test: [/googlebot/i],
        describe: function (e) {
          var t = {
            name: "Googlebot"
          },
              r = n.default.getFirstMatch(/googlebot\/(\d+(\.\d+))/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/opera/i],
        describe: function (e) {
          var t = {
            name: "Opera"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:opera)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/opr\/|opios/i],
        describe: function (e) {
          var t = {
            name: "Opera"
          },
              r = n.default.getFirstMatch(/(?:opr|opios)[\s/](\S+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/SamsungBrowser/i],
        describe: function (e) {
          var t = {
            name: "Samsung Internet for Android"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:SamsungBrowser)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/Whale/i],
        describe: function (e) {
          var t = {
            name: "NAVER Whale Browser"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:whale)[\s/](\d+(?:\.\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/MZBrowser/i],
        describe: function (e) {
          var t = {
            name: "MZ Browser"
          },
              r = n.default.getFirstMatch(/(?:MZBrowser)[\s/](\d+(?:\.\d+)+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/focus/i],
        describe: function (e) {
          var t = {
            name: "Focus"
          },
              r = n.default.getFirstMatch(/(?:focus)[\s/](\d+(?:\.\d+)+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/swing/i],
        describe: function (e) {
          var t = {
            name: "Swing"
          },
              r = n.default.getFirstMatch(/(?:swing)[\s/](\d+(?:\.\d+)+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/coast/i],
        describe: function (e) {
          var t = {
            name: "Opera Coast"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:coast)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/yabrowser/i],
        describe: function (e) {
          var t = {
            name: "Yandex Browser"
          },
              r = n.default.getFirstMatch(/(?:yabrowser)[\s/](\d+(\.?_?\d+)+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/ucbrowser/i],
        describe: function (e) {
          var t = {
            name: "UC Browser"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:ucbrowser)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/Maxthon|mxios/i],
        describe: function (e) {
          var t = {
            name: "Maxthon"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:Maxthon|mxios)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/epiphany/i],
        describe: function (e) {
          var t = {
            name: "Epiphany"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:epiphany)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/puffin/i],
        describe: function (e) {
          var t = {
            name: "Puffin"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:puffin)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/sleipnir/i],
        describe: function (e) {
          var t = {
            name: "Sleipnir"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:sleipnir)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/k-meleon/i],
        describe: function (e) {
          var t = {
            name: "K-Meleon"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/(?:k-meleon)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/micromessenger/i],
        describe: function (e) {
          var t = {
            name: "WeChat"
          },
              r = n.default.getFirstMatch(/(?:micromessenger)[\s/](\d+(\.?_?\d+)+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/qqbrowser/i],
        describe: function (e) {
          var t = {
            name: /qqbrowserlite/i.test(e) ? "QQ Browser Lite" : "QQ Browser"
          },
              r = n.default.getFirstMatch(/(?:qqbrowserlite|qqbrowser)[/](\d+(\.?_?\d+)+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/msie|trident/i],
        describe: function (e) {
          var t = {
            name: "Internet Explorer"
          },
              r = n.default.getFirstMatch(/(?:msie |rv:)(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/\sedg\//i],
        describe: function (e) {
          var t = {
            name: "Microsoft Edge"
          },
              r = n.default.getFirstMatch(/\sedg\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/edg([ea]|ios)/i],
        describe: function (e) {
          var t = {
            name: "Microsoft Edge"
          },
              r = n.default.getSecondMatch(/edg([ea]|ios)\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/vivaldi/i],
        describe: function (e) {
          var t = {
            name: "Vivaldi"
          },
              r = n.default.getFirstMatch(/vivaldi\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/seamonkey/i],
        describe: function (e) {
          var t = {
            name: "SeaMonkey"
          },
              r = n.default.getFirstMatch(/seamonkey\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/sailfish/i],
        describe: function (e) {
          var t = {
            name: "Sailfish"
          },
              r = n.default.getFirstMatch(/sailfish\s?browser\/(\d+(\.\d+)?)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/silk/i],
        describe: function (e) {
          var t = {
            name: "Amazon Silk"
          },
              r = n.default.getFirstMatch(/silk\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/phantom/i],
        describe: function (e) {
          var t = {
            name: "PhantomJS"
          },
              r = n.default.getFirstMatch(/phantomjs\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/slimerjs/i],
        describe: function (e) {
          var t = {
            name: "SlimerJS"
          },
              r = n.default.getFirstMatch(/slimerjs\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/blackberry|\bbb\d+/i, /rim\stablet/i],
        describe: function (e) {
          var t = {
            name: "BlackBerry"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/blackberry[\d]+\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/(web|hpw)[o0]s/i],
        describe: function (e) {
          var t = {
            name: "WebOS Browser"
          },
              r = n.default.getFirstMatch(s, e) || n.default.getFirstMatch(/w(?:eb)?[o0]sbrowser\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/bada/i],
        describe: function (e) {
          var t = {
            name: "Bada"
          },
              r = n.default.getFirstMatch(/dolfin\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/tizen/i],
        describe: function (e) {
          var t = {
            name: "Tizen"
          },
              r = n.default.getFirstMatch(/(?:tizen\s?)?browser\/(\d+(\.?_?\d+)+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/qupzilla/i],
        describe: function (e) {
          var t = {
            name: "QupZilla"
          },
              r = n.default.getFirstMatch(/(?:qupzilla)[\s/](\d+(\.?_?\d+)+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/firefox|iceweasel|fxios/i],
        describe: function (e) {
          var t = {
            name: "Firefox"
          },
              r = n.default.getFirstMatch(/(?:firefox|iceweasel|fxios)[\s/](\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/chromium/i],
        describe: function (e) {
          var t = {
            name: "Chromium"
          },
              r = n.default.getFirstMatch(/(?:chromium)[\s/](\d+(\.?_?\d+)+)/i, e) || n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/chrome|crios|crmo/i],
        describe: function (e) {
          var t = {
            name: "Chrome"
          },
              r = n.default.getFirstMatch(/(?:chrome|crios|crmo)\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/GSA/i],
        describe: function (e) {
          var t = {
            name: "Google Search"
          },
              r = n.default.getFirstMatch(/(?:GSA)\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: function (e) {
          var t = !e.test(/like android/i),
              r = e.test(/android/i);
          return t && r;
        },
        describe: function (e) {
          var t = {
            name: "Android Browser"
          },
              r = n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/playstation 4/i],
        describe: function (e) {
          var t = {
            name: "PlayStation 4"
          },
              r = n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/safari|applewebkit/i],
        describe: function (e) {
          var t = {
            name: "Safari"
          },
              r = n.default.getFirstMatch(s, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/.*/i],
        describe: function (e) {
          var t = -1 !== e.search("\\(") ? /^(.*)\/(.*)[ \t]\((.*)/ : /^(.*)\/(.*) /;
          return {
            name: n.default.getFirstMatch(t, e),
            version: n.default.getSecondMatch(t, e)
          };
        }
      }];
      t.default = o, e.exports = t.default;
    },
    93: function (e, t, r) {
      "use strict";

      t.__esModule = !0, t.default = void 0;
      var i,
          n = (i = r(17)) && i.__esModule ? i : {
        default: i
      },
          s = r(18);
      var o = [{
        test: [/Roku\/DVP/],
        describe: function (e) {
          var t = n.default.getFirstMatch(/Roku\/DVP-(\d+\.\d+)/i, e);
          return {
            name: s.OS_MAP.Roku,
            version: t
          };
        }
      }, {
        test: [/windows phone/i],
        describe: function (e) {
          var t = n.default.getFirstMatch(/windows phone (?:os)?\s?(\d+(\.\d+)*)/i, e);
          return {
            name: s.OS_MAP.WindowsPhone,
            version: t
          };
        }
      }, {
        test: [/windows/i],
        describe: function (e) {
          var t = n.default.getFirstMatch(/Windows ((NT|XP)( \d\d?.\d)?)/i, e),
              r = n.default.getWindowsVersionName(t);
          return {
            name: s.OS_MAP.Windows,
            version: t,
            versionName: r
          };
        }
      }, {
        test: [/macintosh/i],
        describe: function (e) {
          var t = n.default.getFirstMatch(/mac os x (\d+(\.?_?\d+)+)/i, e).replace(/[_\s]/g, "."),
              r = n.default.getMacOSVersionName(t),
              i = {
            name: s.OS_MAP.MacOS,
            version: t
          };
          return r && (i.versionName = r), i;
        }
      }, {
        test: [/(ipod|iphone|ipad)/i],
        describe: function (e) {
          var t = n.default.getFirstMatch(/os (\d+([_\s]\d+)*) like mac os x/i, e).replace(/[_\s]/g, ".");
          return {
            name: s.OS_MAP.iOS,
            version: t
          };
        }
      }, {
        test: function (e) {
          var t = !e.test(/like android/i),
              r = e.test(/android/i);
          return t && r;
        },
        describe: function (e) {
          var t = n.default.getFirstMatch(/android[\s/-](\d+(\.\d+)*)/i, e),
              r = n.default.getAndroidVersionName(t),
              i = {
            name: s.OS_MAP.Android,
            version: t
          };
          return r && (i.versionName = r), i;
        }
      }, {
        test: [/(web|hpw)[o0]s/i],
        describe: function (e) {
          var t = n.default.getFirstMatch(/(?:web|hpw)[o0]s\/(\d+(\.\d+)*)/i, e),
              r = {
            name: s.OS_MAP.WebOS
          };
          return t && t.length && (r.version = t), r;
        }
      }, {
        test: [/blackberry|\bbb\d+/i, /rim\stablet/i],
        describe: function (e) {
          var t = n.default.getFirstMatch(/rim\stablet\sos\s(\d+(\.\d+)*)/i, e) || n.default.getFirstMatch(/blackberry\d+\/(\d+([_\s]\d+)*)/i, e) || n.default.getFirstMatch(/\bbb(\d+)/i, e);
          return {
            name: s.OS_MAP.BlackBerry,
            version: t
          };
        }
      }, {
        test: [/bada/i],
        describe: function (e) {
          var t = n.default.getFirstMatch(/bada\/(\d+(\.\d+)*)/i, e);
          return {
            name: s.OS_MAP.Bada,
            version: t
          };
        }
      }, {
        test: [/tizen/i],
        describe: function (e) {
          var t = n.default.getFirstMatch(/tizen[/\s](\d+(\.\d+)*)/i, e);
          return {
            name: s.OS_MAP.Tizen,
            version: t
          };
        }
      }, {
        test: [/linux/i],
        describe: function () {
          return {
            name: s.OS_MAP.Linux
          };
        }
      }, {
        test: [/CrOS/],
        describe: function () {
          return {
            name: s.OS_MAP.ChromeOS
          };
        }
      }, {
        test: [/PlayStation 4/],
        describe: function (e) {
          var t = n.default.getFirstMatch(/PlayStation 4[/\s](\d+(\.\d+)*)/i, e);
          return {
            name: s.OS_MAP.PlayStation4,
            version: t
          };
        }
      }];
      t.default = o, e.exports = t.default;
    },
    94: function (e, t, r) {
      "use strict";

      t.__esModule = !0, t.default = void 0;
      var i,
          n = (i = r(17)) && i.__esModule ? i : {
        default: i
      },
          s = r(18);
      var o = [{
        test: [/googlebot/i],
        describe: function () {
          return {
            type: "bot",
            vendor: "Google"
          };
        }
      }, {
        test: [/huawei/i],
        describe: function (e) {
          var t = n.default.getFirstMatch(/(can-l01)/i, e) && "Nova",
              r = {
            type: s.PLATFORMS_MAP.mobile,
            vendor: "Huawei"
          };
          return t && (r.model = t), r;
        }
      }, {
        test: [/nexus\s*(?:7|8|9|10).*/i],
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.tablet,
            vendor: "Nexus"
          };
        }
      }, {
        test: [/ipad/i],
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.tablet,
            vendor: "Apple",
            model: "iPad"
          };
        }
      }, {
        test: [/kftt build/i],
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.tablet,
            vendor: "Amazon",
            model: "Kindle Fire HD 7"
          };
        }
      }, {
        test: [/silk/i],
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.tablet,
            vendor: "Amazon"
          };
        }
      }, {
        test: [/tablet(?! pc)/i],
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.tablet
          };
        }
      }, {
        test: function (e) {
          var t = e.test(/ipod|iphone/i),
              r = e.test(/like (ipod|iphone)/i);
          return t && !r;
        },
        describe: function (e) {
          var t = n.default.getFirstMatch(/(ipod|iphone)/i, e);
          return {
            type: s.PLATFORMS_MAP.mobile,
            vendor: "Apple",
            model: t
          };
        }
      }, {
        test: [/nexus\s*[0-6].*/i, /galaxy nexus/i],
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.mobile,
            vendor: "Nexus"
          };
        }
      }, {
        test: [/[^-]mobi/i],
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.mobile
          };
        }
      }, {
        test: function (e) {
          return "blackberry" === e.getBrowserName(!0);
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.mobile,
            vendor: "BlackBerry"
          };
        }
      }, {
        test: function (e) {
          return "bada" === e.getBrowserName(!0);
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.mobile
          };
        }
      }, {
        test: function (e) {
          return "windows phone" === e.getBrowserName();
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.mobile,
            vendor: "Microsoft"
          };
        }
      }, {
        test: function (e) {
          var t = Number(String(e.getOSVersion()).split(".")[0]);
          return "android" === e.getOSName(!0) && t >= 3;
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.tablet
          };
        }
      }, {
        test: function (e) {
          return "android" === e.getOSName(!0);
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.mobile
          };
        }
      }, {
        test: function (e) {
          return "macos" === e.getOSName(!0);
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.desktop,
            vendor: "Apple"
          };
        }
      }, {
        test: function (e) {
          return "windows" === e.getOSName(!0);
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.desktop
          };
        }
      }, {
        test: function (e) {
          return "linux" === e.getOSName(!0);
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.desktop
          };
        }
      }, {
        test: function (e) {
          return "playstation 4" === e.getOSName(!0);
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.tv
          };
        }
      }, {
        test: function (e) {
          return "roku" === e.getOSName(!0);
        },
        describe: function () {
          return {
            type: s.PLATFORMS_MAP.tv
          };
        }
      }];
      t.default = o, e.exports = t.default;
    },
    95: function (e, t, r) {
      "use strict";

      t.__esModule = !0, t.default = void 0;
      var i,
          n = (i = r(17)) && i.__esModule ? i : {
        default: i
      },
          s = r(18);
      var o = [{
        test: function (e) {
          return "microsoft edge" === e.getBrowserName(!0);
        },
        describe: function (e) {
          if (/\sedg\//i.test(e)) return {
            name: s.ENGINE_MAP.Blink
          };
          var t = n.default.getFirstMatch(/edge\/(\d+(\.?_?\d+)+)/i, e);
          return {
            name: s.ENGINE_MAP.EdgeHTML,
            version: t
          };
        }
      }, {
        test: [/trident/i],
        describe: function (e) {
          var t = {
            name: s.ENGINE_MAP.Trident
          },
              r = n.default.getFirstMatch(/trident\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: function (e) {
          return e.test(/presto/i);
        },
        describe: function (e) {
          var t = {
            name: s.ENGINE_MAP.Presto
          },
              r = n.default.getFirstMatch(/presto\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: function (e) {
          var t = e.test(/gecko/i),
              r = e.test(/like gecko/i);
          return t && !r;
        },
        describe: function (e) {
          var t = {
            name: s.ENGINE_MAP.Gecko
          },
              r = n.default.getFirstMatch(/gecko\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }, {
        test: [/(apple)?webkit\/537\.36/i],
        describe: function () {
          return {
            name: s.ENGINE_MAP.Blink
          };
        }
      }, {
        test: [/(apple)?webkit/i],
        describe: function (e) {
          var t = {
            name: s.ENGINE_MAP.WebKit
          },
              r = n.default.getFirstMatch(/webkit\/(\d+(\.?_?\d+)+)/i, e);
          return r && (t.version = r), t;
        }
      }];
      t.default = o, e.exports = t.default;
    }
  });
});

/***/ }),

/***/ "./node_modules/current-executing-script/dist/currentExecutingScript.js":
/*!******************************************************************************!*\
  !*** ./node_modules/current-executing-script/dist/currentExecutingScript.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/*!
 * currentExecutingScript
 * Get the currently executing script, regardless of its source/trigger/synchronicity. Similar to HTML5's `document.currentScript` but arguably much more useful!
 * Copyright (c) 2015 James M. Greene
 * Licensed MIT
 * https://github.com/JamesMGreene/currentExecutingScript
 * v0.1.3
 */
(function (root, factory) {
  if (true) {
    // AMD. Register as an anonymous module.
    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_FACTORY__ = (factory),
				__WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ?
				(__WEBPACK_AMD_DEFINE_FACTORY__.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__)) : __WEBPACK_AMD_DEFINE_FACTORY__),
				__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));
  } else {}
})( // Current context/scope
this || window, // Factory function to return the export
function () {
  var scriptReadyRegex = /^(interactive|loaded|complete)$/; // This page's URL (minus query string and fragment identifer hash, if any)

  var fullPageUrl = !!window.location ? window.location.href : null;
  var pageUrl = fullPageUrl ? fullPageUrl.replace(/#.*$/, "").replace(/\?.*$/, "") || null : null; // Live NodeList collection

  var scripts = document.getElementsByTagName("script"); // Check if the browser supports the `readyState` property on `script` elements

  var supportsScriptReadyState = "readyState" in (scripts[0] || document.createElement("script")); // Lousy browser detection for [not] Opera

  var isNotOpera = !window.opera || window.opera.toString() !== "[object Opera]"; // Detect if `document.currentScript` is supported

  var hasNativeCurrentScriptAccessor = "currentScript" in document;
  var originalStackDepthConfig; // Detect if the V8 Error Stack Trace API is supported

  if ("stackTraceLimit" in Error && Error.stackTraceLimit !== Infinity) {
    originalStackDepthConfig = Error.stackTraceLimit;
    Error.stackTraceLimit = Infinity;
  } // In some browsers (e.g. Chrome), you can get the current stack from an Error
  // object instance without needing to throw it. Avoiding an unnecessary
  // use of `throw` saves time and performance.


  var hasStackBeforeThrowing = false,
      hasStackAfterThrowing = false;

  (function () {
    try {
      var err = new Error();
      hasStackBeforeThrowing = typeof err.stack === "string" && !!err.stack;
      throw err;
    } catch (thrownErr) {
      hasStackAfterThrowing = typeof thrownErr.stack === "string" && !!thrownErr.stack;
    }
  })(); // Normalize whitespace within a string


  function normalizeWhitespace(str) {
    return str ? str.replace(/^\s+$|\s+$/g, "").replace(/\s\s+/g, " ") : "";
  } // Get script object based on the `src` URL


  function getScriptFromUrl(url, eligibleScripts) {
    var i,
        script = null;
    eligibleScripts = eligibleScripts || scripts;

    if (typeof url === "string" && url) {
      for (i = eligibleScripts.length; i--;) {
        if (eligibleScripts[i].src === url) {
          // NOTE: Could check if the same script URL is used by more than one `script` element
          // here... but let's not. That would yield less useful results in "loose" detection. ;)
          script = eligibleScripts[i];
          break;
        }
      }
    }

    return script;
  } // Get script object based on the caller function's source code body (text)


  function getInlineScriptFromCallerSource(callerFnSource, eligibleScripts) {
    var i,
        inlineScriptText,
        script = null,
        callerSourceText = normalizeWhitespace(callerFnSource);
    eligibleScripts = eligibleScripts || scripts;

    if (callerFnSource && callerSourceText) {
      for (i = eligibleScripts.length; i--;) {
        // Only look at inline scripts
        if (!eligibleScripts[i].hasAttribute("src")) {
          inlineScriptText = normalizeWhitespace(eligibleScripts[i].text);

          if (inlineScriptText.indexOf(callerSourceText) !== -1) {
            // If more than one match is found, don't return any
            if (script) {
              script = null;
              break;
            }

            script = eligibleScripts[i];
          }
        }
      }
    }

    return script;
  } // If there is only a single inline script on the page, return it; otherwise `null`


  function getSoleInlineScript(eligibleScripts) {
    var i,
        len,
        script = null;
    eligibleScripts = eligibleScripts || scripts;

    for (i = 0, len = eligibleScripts.length; i < len; i++) {
      if (!eligibleScripts[i].hasAttribute("src")) {
        if (script) {
          script = null;
          break;
        }

        script = eligibleScripts[i];
      }
    }

    return script;
  } // Get the currently executing script URL from an Error stack trace


  function getScriptUrlFromStack(stack, skipStackDepth) {
    var matches,
        remainingStack,
        url = null,
        ignoreMessage = typeof skipStackDepth === "number";
    skipStackDepth = ignoreMessage ? Math.round(skipStackDepth) : 0;

    if (typeof stack === "string" && stack) {
      if (ignoreMessage) {
        matches = stack.match(/(data:text\/javascript(?:;[^,]+)?,.+?|(?:|blob:)(?:http[s]?|file):\/\/[\/]?.+?\/[^:\)]*?)(?::\d+)(?::\d+)?/);
      } else {
        matches = stack.match(/^(?:|[^:@]*@|.+\)@(?=data:text\/javascript|blob|http[s]?|file)|.+?\s+(?: at |@)(?:[^:\(]+ )*[\(]?)(data:text\/javascript(?:;[^,]+)?,.+?|(?:|blob:)(?:http[s]?|file):\/\/[\/]?.+?\/[^:\)]*?)(?::\d+)(?::\d+)?/);

        if (!(matches && matches[1])) {
          matches = stack.match(/\)@(data:text\/javascript(?:;[^,]+)?,.+?|(?:|blob:)(?:http[s]?|file):\/\/[\/]?.+?\/[^:\)]*?)(?::\d+)(?::\d+)?/);
        }
      }

      if (matches && matches[1]) {
        if (skipStackDepth > 0) {
          remainingStack = stack.slice(stack.indexOf(matches[0]) + matches[0].length);
          url = getScriptUrlFromStack(remainingStack, skipStackDepth - 1);
        } else {
          url = matches[1];
        }
      } // TODO: Handle more edge cases!
      // Fixes #1
      // See https://github.com/JamesMGreene/currentExecutingScript/issues/1
      // ???

    }

    return url;
  } // Get the farthest currently executing (i.e. yes, EXECUTING) `script` DOM
  // element for the caller function, regardless of whether it is that `script`
  // DOM element is currently being evaluated for the first time. The farthest
  // currently executing `script` DOM element would typically be considered the
  // originator of the current execution stack.


  function _farthestExecutingScript() {
    /*jshint noarg:false */
    // TODO: Implement!
    // Fixes #3
    // See https://github.com/JamesMGreene/currentExecutingScript/issues/3
    return null;
    /*
      // Yes, this IS possible, i.e. if a script removes other scripts (or itself)
      if (scripts.length === 0) {
        return null;
      }
    
      // Guaranteed accurate in IE 6-10.
      // Not accurate/supported in any other browsers.
      if (isNotOpera && supportsScriptReadyState) {
        for (var i = scripts.length; i--; ) {
          if (scripts[i].readyState === "interactive") {
            return scripts[i];
          }
        }
      }
    
      var stack,
          e = new Error();
      if (hasStackBeforeThrowing) {
        stack = e.stack;
      }
      if (!stack && hasStackAfterThrowing) {
        try {
          throw e;
        }
        catch (err) {
          // NOTE: Cannot use `err.sourceURL` or `err.fileName` as they will always be THIS script
          stack = err.stack;
        }
      }
      if (stack) {
        var url = getScriptUrlFromStack(stack, skipStackDepth);
        var script = getScriptFromUrl(url, scripts );
        if (!script && pageUrl && url === pageUrl) {
          // Try to find the correct inline script by searching through
          // inline scripts' text content for the caller function's source
          // code to be present. If the caller function's source code is
          // not available, see if there is only one inline script element
          // in the DOM and return that (even though it may be wrong)
    
          // TODO: Implement!
          // Fixes #4 in part
          // See https://github.com/JamesMGreene/currentExecutingScript/issues/4
    
          var callerFn = _farthestExecutingScript.caller || null,
              callerFnStack = [],
              callerFnSource = null;
    
          while (callerFn) {
            callerFnStack.push(callerFn);
            callerFn = callerFn.caller || null;
          }
          callerFn = callerFnStack.slice(-1)[0];
          callerFnSource = callerFn ? ("" + callerFn) : null;
    
    
          if (callerFnSource) {
            script = getInlineScriptFromCallerSource(callerFnSource);
          }
          else {
            // NOTE: This is a loose assumption that could be inaccurate!
            //
            // Inaccuracies:
            //  - If the inline script that initiated the call was also removed from the DOM.
            //  - If the call was initiated by an element's inline event handler,
            //    e.g. `<a onclick="(function() { alert(currentExecutingScript()); }()">click</a>`
            script = getSoleInlineScript();
          }
        }
        return script;
      }
    
      // NOTE: This is a loose assumption that could be inaccurate!
      //
      // Inaccuracies:
      //  - If a script is created dynamically and appended to some position
      //    other than the very end of the document.
      //  - If multiple scripts are created dynamically and all appended to the
      //    same position within the document (and do not have their `async` attributes
      //    set to `false`, at least in browsers that support async script evaluation.
      //    other than the very end of the document.
      //  - If any scripts are added with the `async` attribute set to `true` in a browser
      //    that supports it.
      //  - May get confused by `script` elements within `svg` elements
      return scripts[scripts.length - 1] || null;
    */
  } // Get the originating currently executing (i.e. yes, EXECUTING) `script` DOM
  // element or attribute node (e.g. `onclick`) for the caller function,
  // regardless of whether it is that `script` DOM element is currently being
  // evaluated for the first time. The originating currently executing `script`
  // DOM element [or attribute node] is the originator of the current execution stack.


  function _originatingExecutingScript() {
    // TODO: Implement!
    // Fixes #2
    // See https://github.com/JamesMGreene/currentExecutingScript/issues/2
    return null;
  } // Get the nearest currently executing (i.e. yes, EXECUTING) `script` DOM
  // element for the caller function, regardless of whether it is that `script`
  // DOM element is currently being evaluated for the first time.


  function _nearestExecutingScript() {
    /*jshint noarg:false */
    // Yes, this IS possible, i.e. if a script removes other scripts (or itself)
    if (scripts.length === 0) {
      return null;
    }

    var i,
        e,
        stack,
        url,
        script,
        eligibleScripts = [],
        skipStackDepth = _nearestExecutingScript.skipStackDepth || 1,
        // TODO: Implement!
    // Fixes #4 in part
    // See https://github.com/JamesMGreene/currentExecutingScript/issues/4
    callerFnSource = null; //("" + (_nearestExecutingScript.caller || "")) || null;
    // This part will only help in IE 6-10.

    for (i = 0; i < scripts.length; i++) {
      if (isNotOpera && supportsScriptReadyState) {
        if (scriptReadyRegex.test(scripts[i].readyState)) {
          eligibleScripts.push(scripts[i]);
        }
      } else {
        eligibleScripts.push(scripts[i]);
      }
    }

    e = new Error();

    if (hasStackBeforeThrowing) {
      stack = e.stack;
    }

    if (!stack && hasStackAfterThrowing) {
      try {
        throw e;
      } catch (err) {
        // NOTE: Cannot use `err.sourceURL` or `err.fileName` as they will always be THIS script
        stack = err.stack;
      }
    }

    if (stack) {
      url = getScriptUrlFromStack(stack, skipStackDepth);
      script = getScriptFromUrl(url, eligibleScripts);

      if (!script && pageUrl && url === pageUrl) {
        // Try to find the correct inline script by searching through
        // inline scripts' text content for the caller function's source
        // code to be present.
        if (callerFnSource) {
          script = getInlineScriptFromCallerSource(callerFnSource, eligibleScripts);
        } // If the caller function's source code is not available, see if
        // there is only one inline script element in the DOM and return
        // that (even though it may be wrong)...
        else {
            // NOTE: This is a loose assumption that could be inaccurate!
            //
            // Inaccuracies:
            //  - If the inline script that initiated the call was also removed from the DOM.
            //  - If the call was initiated by an element's inline event handler,
            //    e.g. `<a onclick="(function() { alert(currentExecutingScript()); }()">click</a>`
            script = getSoleInlineScript(eligibleScripts);
          }
      }
    } //
    // Welcome to the Island of Inaccurate Assumptions!
    // NOTE: ALL of the following are loose assumptions that could be inaccurate!
    //


    if (!script) {
      // Inaccuracies:
      //  - If the inline script that initiated the call was also removed from the DOM.
      //  - If the call was initiated by an element's inline event handler,
      //    e.g. `<a onclick="(function() { alert(currentExecutingScript()); }()">click</a>`
      if (eligibleScripts.length === 1) {
        script = eligibleScripts[0];
      }
    }

    if (!script) {
      // Inaccuracies:
      //  - If script currently being synchronously evaluated by the parser is the
      //    originator of this call stack but NOT the source script of the caller/invocation
      //    e.g.
      //    ```html
      //    <script id="a">
      //    function getCurrentScriptCallerFn() {
      //      return currentExecutingScript.near();
      //    }
      //    </script>
      //    <script id="b">
      //    // Should get `script[id="a"]` but will get `script[id="b"]` instead
      //    getCurrentScriptCallerFn();
      //    </script>
      if (hasNativeCurrentScriptAccessor) {
        script = document.currentScript;
      }
    }

    if (!script) {
      // Inaccuracies:
      //  - If script currently being synchronously evaluated by the parser is the
      //    originator of this call stack but NOT the source script of the caller/invocation
      //    e.g.
      //    ```html
      //    <script id="a">
      //    function getCurrentScriptCallerFn() {
      //      return currentExecutingScript.near();
      //    }
      //    </script>
      //    <script id="b">
      //    // Should get `script[id="a"]` but will get `script[id="b"]` instead
      //    getCurrentScriptCallerFn();
      //    </script>
      if (isNotOpera && supportsScriptReadyState) {
        for (i = eligibleScripts.length; i--;) {
          if (eligibleScripts[i].readyState === "interactive") {
            script = eligibleScripts[i];
            break;
          }
        }
      }
    }

    if (!script) {
      // Inaccuracies:
      //  - If a script is created dynamically and appended to some position
      //    other than the very end of the document.
      //  - If multiple scripts are created dynamically and all appended to the
      //    same position within the document (and do not have their `async` attributes
      //    set to `false`, at least in browsers that support async script evaluation.
      //    other than the very end of the document.
      //  - If any scripts are added with the `async` attribute set to `true` in a browser
      //    that supports it.
      //  - May get confused by `script` elements within `svg` elements
      //  - If script currently being synchronously evaluated by the parser is the
      //    originator of this call stack but NOT the source script of the caller/invocation
      //    e.g.
      //    ```html
      //    <script id="a">
      //    function getCurrentScriptCallerFn() {
      //      return currentExecutingScript.near();
      //    }
      //    </script>
      //    <script id="b">
      //    // Should get `script[id="a"]` but will get `script[id="b"]` instead
      //    getCurrentScriptCallerFn();
      //    </script>
      //    ```
      script = eligibleScripts[eligibleScripts.length - 1] || null;
    }

    return script;
  } // Default stack depth to skip over when analyzing call stack frames


  _nearestExecutingScript.skipStackDepth = 1; //
  // Export the API
  //

  var currentExecutingScript = _nearestExecutingScript; // default

  currentExecutingScript.near = _nearestExecutingScript;
  currentExecutingScript.far = _farthestExecutingScript;
  currentExecutingScript.origin = _originatingExecutingScript; // Just return a value to define the module export.
  // This example returns an object, but the module
  // can return a function as the exported value.

  return currentExecutingScript;
});

/***/ }),

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
function EventEmitter() {
  this._events = this._events || {};
  this._maxListeners = this._maxListeners || undefined;
}

module.exports = EventEmitter; // Backwards-compat with node 0.10.x

EventEmitter.EventEmitter = EventEmitter;
EventEmitter.prototype._events = undefined;
EventEmitter.prototype._maxListeners = undefined; // By default EventEmitters will print a warning if more than 10 listeners are
// added to it. This is a useful default which helps finding memory leaks.

EventEmitter.defaultMaxListeners = 10; // Obviously not all Emitters should be limited to 10. This function allows
// that to be increased. Set to zero for unlimited.

EventEmitter.prototype.setMaxListeners = function (n) {
  if (!isNumber(n) || n < 0 || isNaN(n)) throw TypeError('n must be a positive number');
  this._maxListeners = n;
  return this;
};

EventEmitter.prototype.emit = function (type) {
  var er, handler, len, args, i, listeners;
  if (!this._events) this._events = {}; // If there is no 'error' event listener then throw.

  if (type === 'error') {
    if (!this._events.error || isObject(this._events.error) && !this._events.error.length) {
      er = arguments[1];

      if (er instanceof Error) {
        throw er; // Unhandled 'error' event
      } else {
        // At least give some kind of context to the user
        var err = new Error('Uncaught, unspecified "error" event. (' + er + ')');
        err.context = er;
        throw err;
      }
    }
  }

  handler = this._events[type];
  if (isUndefined(handler)) return false;

  if (isFunction(handler)) {
    switch (arguments.length) {
      // fast cases
      case 1:
        handler.call(this);
        break;

      case 2:
        handler.call(this, arguments[1]);
        break;

      case 3:
        handler.call(this, arguments[1], arguments[2]);
        break;
      // slower

      default:
        args = Array.prototype.slice.call(arguments, 1);
        handler.apply(this, args);
    }
  } else if (isObject(handler)) {
    args = Array.prototype.slice.call(arguments, 1);
    listeners = handler.slice();
    len = listeners.length;

    for (i = 0; i < len; i++) listeners[i].apply(this, args);
  }

  return true;
};

EventEmitter.prototype.addListener = function (type, listener) {
  var m;
  if (!isFunction(listener)) throw TypeError('listener must be a function');
  if (!this._events) this._events = {}; // To avoid recursion in the case that type === "newListener"! Before
  // adding it to the listeners, first emit "newListener".

  if (this._events.newListener) this.emit('newListener', type, isFunction(listener.listener) ? listener.listener : listener);
  if (!this._events[type]) // Optimize the case of one listener. Don't need the extra array object.
    this._events[type] = listener;else if (isObject(this._events[type])) // If we've already got an array, just append.
    this._events[type].push(listener);else // Adding the second element, need to change to array.
    this._events[type] = [this._events[type], listener]; // Check for listener leak

  if (isObject(this._events[type]) && !this._events[type].warned) {
    if (!isUndefined(this._maxListeners)) {
      m = this._maxListeners;
    } else {
      m = EventEmitter.defaultMaxListeners;
    }

    if (m && m > 0 && this._events[type].length > m) {
      this._events[type].warned = true;
      console.error('(node) warning: possible EventEmitter memory ' + 'leak detected. %d listeners added. ' + 'Use emitter.setMaxListeners() to increase limit.', this._events[type].length);

      if (typeof console.trace === 'function') {
        // not supported in IE 10
        console.trace();
      }
    }
  }

  return this;
};

EventEmitter.prototype.on = EventEmitter.prototype.addListener;

EventEmitter.prototype.once = function (type, listener) {
  if (!isFunction(listener)) throw TypeError('listener must be a function');
  var fired = false;

  function g() {
    this.removeListener(type, g);

    if (!fired) {
      fired = true;
      listener.apply(this, arguments);
    }
  }

  g.listener = listener;
  this.on(type, g);
  return this;
}; // emits a 'removeListener' event iff the listener was removed


EventEmitter.prototype.removeListener = function (type, listener) {
  var list, position, length, i;
  if (!isFunction(listener)) throw TypeError('listener must be a function');
  if (!this._events || !this._events[type]) return this;
  list = this._events[type];
  length = list.length;
  position = -1;

  if (list === listener || isFunction(list.listener) && list.listener === listener) {
    delete this._events[type];
    if (this._events.removeListener) this.emit('removeListener', type, listener);
  } else if (isObject(list)) {
    for (i = length; i-- > 0;) {
      if (list[i] === listener || list[i].listener && list[i].listener === listener) {
        position = i;
        break;
      }
    }

    if (position < 0) return this;

    if (list.length === 1) {
      list.length = 0;
      delete this._events[type];
    } else {
      list.splice(position, 1);
    }

    if (this._events.removeListener) this.emit('removeListener', type, listener);
  }

  return this;
};

EventEmitter.prototype.removeAllListeners = function (type) {
  var key, listeners;
  if (!this._events) return this; // not listening for removeListener, no need to emit

  if (!this._events.removeListener) {
    if (arguments.length === 0) this._events = {};else if (this._events[type]) delete this._events[type];
    return this;
  } // emit removeListener for all listeners on all events


  if (arguments.length === 0) {
    for (key in this._events) {
      if (key === 'removeListener') continue;
      this.removeAllListeners(key);
    }

    this.removeAllListeners('removeListener');
    this._events = {};
    return this;
  }

  listeners = this._events[type];

  if (isFunction(listeners)) {
    this.removeListener(type, listeners);
  } else if (listeners) {
    // LIFO order
    while (listeners.length) this.removeListener(type, listeners[listeners.length - 1]);
  }

  delete this._events[type];
  return this;
};

EventEmitter.prototype.listeners = function (type) {
  var ret;
  if (!this._events || !this._events[type]) ret = [];else if (isFunction(this._events[type])) ret = [this._events[type]];else ret = this._events[type].slice();
  return ret;
};

EventEmitter.prototype.listenerCount = function (type) {
  if (this._events) {
    var evlistener = this._events[type];
    if (isFunction(evlistener)) return 1;else if (evlistener) return evlistener.length;
  }

  return 0;
};

EventEmitter.listenerCount = function (emitter, type) {
  return emitter.listenerCount(type);
};

function isFunction(arg) {
  return typeof arg === 'function';
}

function isNumber(arg) {
  return typeof arg === 'number';
}

function isObject(arg) {
  return typeof arg === 'object' && arg !== null;
}

function isUndefined(arg) {
  return arg === void 0;
}

/***/ }),

/***/ "./node_modules/jitsi-meet-logger/lib/LogCollector.js":
/*!************************************************************!*\
  !*** ./node_modules/jitsi-meet-logger/lib/LogCollector.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* Copyright @ 2016-present 8x8, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
var Logger = __webpack_require__(/*! ./Logger.js */ "./node_modules/jitsi-meet-logger/lib/Logger.js");
/**
 * Creates new <tt>LogCollector</tt>. Class implements <tt>LoggerTransport</tt>
 * and thus can be added as global transport in order to capture all the logs.
 *
 * It captures subsequent log lines created whenever <tt>Logger</tt> logs
 * a message and stores them in a queue in order to batch log entries. There are
 * time and size limit constraints which determine how often batch entries are
 * stored. Whenever one of these limits is exceeded the <tt>LogCollector</tt>
 * will use the <tt>logStorage</tt> object given as an argument to save
 * the batch log entry.
 *
 * @param {Object} logStorage an object which allows to store the logs collected
 * @param {function(string|object[])} logStorage.storeLogs a method called when
 * this <tt>LogCollector</tt> requests log entry storage. The method's argument
 * is an array which can contain <tt>string</tt>s and <tt>object</tt>s. If given
 * item is an object it means that it's an aggregated message. That is a message
 * which is the same as the previous one and it's representation has
 * the following format:
 * {
 *   {string} text: 'the text of some duplicated message'
 *   {number} count: 3 // how many times the message appeared in a row
 * }
 * If a message "B" after an aggregated message "A" is different, then it breaks
 * the sequence of "A". Which means that even if the next message "C" is
 * the same as "A" it will start a new aggregated message "C".
 * @param {function()} logStorage.isReady a method which should return
 * a <tt>boolean</tt> to tell the collector that it's ready to store. During the
 * time storage is not ready log batches will be cached and stored on the next
 * occasion (flush or interval timeout).
 *
 * @param {Object} options the <tt>LogCollector</tt> configuration options.
 * @param {number} options.maxEntryLength the size limit for a single log entry
 * to be stored. The <tt>LogCollector</tt> will push the entry as soon as it
 * reaches or exceeds this limit given that <tt>logStorage.isReady</tt>
 * returns <tt>true</tt>. Otherwise the log entry will be cached until the log
 * storage becomes ready. Note that the "is ready" condition is checked every
 * <tt>options.storeInterval</tt> milliseconds.
 * @param {number} options.storeInterval how often the logs should be stored in
 * case <tt>maxEntryLength</tt> was not exceeded.
 * @param {boolean} options.stringifyObjects indicates whether or not object
 * arguments should be "stringified" with <tt>JSON.stringify</tt> when a log
 * message is composed. Note that objects logged on the error log level are
 * always stringified.
 *
 * @constructor
 */


function LogCollector(logStorage, options) {
  this.logStorage = logStorage;
  this.stringifyObjects = options && options.stringifyObjects ? options.stringifyObjects : false;
  this.storeInterval = options && options.storeInterval ? options.storeInterval : 30000;
  this.maxEntryLength = options && options.maxEntryLength ? options.maxEntryLength : 10000; // Bind the log method for each level to the corresponding method name
  // in order to implement "global log transport" object.

  Object.keys(Logger.levels).forEach(function (logLevel) {
    var methodName = Logger.levels[logLevel];

    this[methodName] = function () {
      this._log.apply(this, arguments);
    }.bind(this, logLevel);
  }.bind(this));
  /**
   * The ID of store logs interval if one is currently scheduled or
   * <tt>null</tt> otherwise.
   * @type {number|null}
   */

  this.storeLogsIntervalID = null;
  /**
   * The log messages that are to be batched into log entry when
   * {@link LogCollector._flush} method is called.
   * @type {string[]}
   */

  this.queue = [];
  /**
   * The total length of all messages currently stored in the {@link queue}.
   * @type {number}
   */

  this.totalLen = 0;
  /**
   * An array used to temporarily store log batches, before the storage gets
   * ready.
   * @type {string[]}
   */

  this.outputCache = [];
}
/**
 * Method called inside of {@link formatLogMessage} in order to covert an
 * <tt>Object</tt> argument to string. The conversion will happen when either
 * 'stringifyObjects' option is enabled or on the {@link Logger.levels.ERROR}
 * log level. The default implementation uses <tt>JSON.stringify</tt> and
 * returns "[object with circular refs?]" instead of an object if it fails.
 *
 * @param {object} someObject the <tt>object</tt> to be stringified.
 *
 * @return {string} the result of <tt>JSON.stringify</tt> or
 * "[object with circular refs?]" if any error occurs during "stringification".
 *
 * @protected
 */


LogCollector.prototype.stringify = function (someObject) {
  try {
    return JSON.stringify(someObject);
  } catch (error) {
    return '[object with circular refs?]';
  }
};
/**
 * Formats log entry for the given logging level and arguments passed to the
 * <tt>Logger</tt>'s log method. The first argument is log level and the next
 * arguments have to be captured using JS built-in 'arguments' variable.
 *
 * @param {Logger.levels} logLevel provides the logging level of the message to
 * be logged.
 * @param {Date} timestamp - The {@code Date} when a message has been logged.
 *
 * @return {string|null} a non-empty string representation of the log entry
 * crafted from the log arguments. If the return value is <tt>null</tt> then
 * the message wil be discarded by this <tt>LogCollector</tt>.
 *
 * @protected
 */


LogCollector.prototype.formatLogMessage = function (logLevel
/* timestamp, arg2, arg3, arg4... */
) {
  var msg = '';

  for (var i = 1, len = arguments.length; i < len; i++) {
    var arg = arguments[i]; // objects logged on error level are always converted to JSON

    if ((this.stringifyObjects || logLevel === Logger.levels.ERROR) && typeof arg === 'object') {
      arg = this.stringify(arg);
    }

    msg += arg;

    if (i !== len - 1) {
      msg += ' ';
    }
  }

  return msg.length ? msg : null;
};
/**
 * The log method bound to each of the logging levels in order to implement
 * "global log transport" object.
 *
 * @private
 */


LogCollector.prototype._log = function () {
  // var logLevel = arguments[0]; first argument is the log level
  var timestamp = arguments[1];
  var msg = this.formatLogMessage.apply(this, arguments);

  if (msg) {
    // The same as the previous message aggregation logic
    var prevMessage = this.queue[this.queue.length - 1];
    var prevMessageText = prevMessage && prevMessage.text;

    if (prevMessageText === msg) {
      prevMessage.count += 1;
    } else {
      this.queue.push({
        text: msg,
        timestamp: timestamp,
        count: 1
      });
      this.totalLen += msg.length;
    }
  }

  if (this.totalLen >= this.maxEntryLength) {
    this._flush(true
    /* force */
    , true
    /* reschedule */
    );
  }
};
/**
 * Starts periodical "store logs" task which will be triggered at the interval
 * specified in the constructor options.
 */


LogCollector.prototype.start = function () {
  this._reschedulePublishInterval();
};
/**
 * Reschedules the periodical "store logs" task which will store the next batch
 * log entry in the storage.
 * @private
 */


LogCollector.prototype._reschedulePublishInterval = function () {
  if (this.storeLogsIntervalID) {
    window.clearTimeout(this.storeLogsIntervalID);
    this.storeLogsIntervalID = null;
  } // It's actually a timeout, because it is rescheduled on every flush


  this.storeLogsIntervalID = window.setTimeout(this._flush.bind(this, false
  /* do not force */
  , true
  /* reschedule */
  ), this.storeInterval);
};
/**
 * Call this method to flush the log entry buffer and store it in the log
 * storage immediately (given that the storage is ready).
 */


LogCollector.prototype.flush = function () {
  this._flush(false
  /* do not force, as it will not be stored anyway */
  , true
  /* reschedule next update */
  );
};
/**
 * Stores the next batch log entry in the log storage.
 * @param {boolean} force enforce current logs batch to be stored or cached if
 * there is anything to be logged, but the storage is not ready yet. One of
 * legitimate reasons to force is when the logs length exceeds size limit which
 * could result in truncation.
 * @param {boolean} reschedule <tt>true</tt> if the next periodic task should be
 * scheduled after the log entry is stored. <tt>false</tt> will end the periodic
 * task cycle.
 * @private
 */


LogCollector.prototype._flush = function (force, reschedule) {
  // Publish only if there's anything to be logged
  if (this.totalLen > 0 && (this.logStorage.isReady() || force)) {
    //FIXME avoid truncating
    // right now we don't care if the message size is "slightly" exceeded
    if (this.logStorage.isReady()) {
      // Sends all cached logs
      if (this.outputCache.length) {
        this.outputCache.forEach(function (cachedQueue) {
          this.logStorage.storeLogs(cachedQueue);
        }.bind(this)); // Clear the cache

        this.outputCache = [];
      } // Send current batch


      this.logStorage.storeLogs(this.queue);
    } else {
      this.outputCache.push(this.queue);
    }

    this.queue = [];
    this.totalLen = 0;
  }

  if (reschedule) {
    this._reschedulePublishInterval();
  }
};
/**
 * Stops the periodical "store logs" task and immediately stores any pending
 * log entries as a batch.
 */


LogCollector.prototype.stop = function () {
  // Flush and stop publishing logs
  this._flush(false
  /* do not force */
  , false
  /* do not reschedule */
  );
};

module.exports = LogCollector;

/***/ }),

/***/ "./node_modules/jitsi-meet-logger/lib/Logger.js":
/*!******************************************************!*\
  !*** ./node_modules/jitsi-meet-logger/lib/Logger.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/* Copyright @ 2015-present 8x8, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*jslint latedef:false*/

/**
 * Ordered log levels.
 */
var levels = {
  "trace": 0,
  "debug": 1,
  "info": 2,
  "log": 3,
  "warn": 4,
  "error": 5
};
/**
 * The default transport - console
 * @type LoggerTransport
 */

Logger.consoleTransport = console;
/**
 * The array which stores currently registered global transports.
 * @type {[LoggerTransport]}
 */

var globalTransports = [Logger.consoleTransport];
/**
 * Adds given {@link LoggerTransport} instance to the list of global
 * transports which means that it'll be used by all {@link Logger}s
 * @param {LoggerTransport} transport
 */

Logger.addGlobalTransport = function (transport) {
  if (globalTransports.indexOf(transport) === -1) {
    globalTransports.push(transport);
  }
};
/**
 * Removes given {@link LoggerTransport} instance from the list of global
 * transports
 * @param {LoggerTransport} transport
 */


Logger.removeGlobalTransport = function (transport) {
  var transportIdx = globalTransports.indexOf(transport);

  if (transportIdx !== -1) {
    globalTransports.splice(transportIdx, 1);
  }
};
/**
 * The global configuration options.
 */


var globalOptions = {};
/**
 * Sets global options which will be used by all loggers. Changing these works
 * even after other loggers are created.
 */

Logger.setGlobalOptions = function (options) {
  globalOptions = options || {};
};
/**
 * Parses Error's object stack trace and extracts information about the last
 * caller before the log method was called.
 * @returns JS object with info about the caller - method name, file location,
 * line and column.
 */


function getCallerInfo() {
  var callerInfo = {
    methodName: "",
    fileLocation: "",
    line: null,
    column: null
  }; //gets the part of the stack without the logger wrappers

  var error = new Error();
  var stack = error.stack ? error.stack.split("\n") : [];

  if (!stack || stack.length < 1) {
    return callerInfo;
  }

  var m = null;

  if (stack[3]) {
    m = stack[3].match(/\s*at\s*(.+?)\s*\((\S*)\s*:(\d*)\s*:(\d*)\)/);
  }

  if (!m || m.length <= 4) {
    //Firefox && Safari
    if (stack[2].indexOf("log@") === 0) {
      //Safari
      callerInfo.methodName = stack[3].substr(0, stack[3].indexOf("@"));
    } else {
      //Firefox
      callerInfo.methodName = stack[2].substr(0, stack[2].indexOf("@"));
    }

    return callerInfo;
  }

  callerInfo.methodName = m[1];
  callerInfo.fileLocation = m[2];
  callerInfo.line = m[3];
  callerInfo.column = m[4];
  return callerInfo;
}
/**
 * Logs messages using the transports and level from the logger.
 * @param logger a logger instance.
 * @param level the log level of the message. See the levels variable.
 * @param arguments array with arguments that will be logged.
 */


function log() {
  var logger = arguments[0],
      level = arguments[1],
      args = Array.prototype.slice.call(arguments, 2);

  if (levels[level] < logger.level) {
    return;
  }

  var callerInfo = !(logger.options.disableCallerInfo || globalOptions.disableCallerInfo) && getCallerInfo();
  var transports = globalTransports.concat(logger.transports);

  for (var i = 0; i < transports.length; i++) {
    var t = transports[i];
    var l = t[level];

    if (l && typeof l === "function") {
      var logPrefixes = [];
      logPrefixes.push(new Date().toISOString());

      if (logger.id) {
        logPrefixes.push("[" + logger.id + "]");
      }

      if (callerInfo && callerInfo.methodName.length > 1) {
        logPrefixes.push("<" + callerInfo.methodName + ">: ");
      }

      var fullLogParts = logPrefixes.concat(args);
      l.bind(t).apply(t, fullLogParts);
    }
  }
}
/**
 *
 * Constructs new logger object.
 * @param level the logging level for the new logger
 * @param id optional identifier for the logger instance.
 * @param {LoggerTransport} transports optional list of handlers(objects) for
 * the logs. The handlers must support - log, warn, error, debug, info, trace.
 * @param options optional configuration file for how the logger should behave.
 * @param {boolean} options.disableCallerInfo Whether the call site of a logger
 * method invocation should be included in the log. Defaults to false, so the
 * call site will be included.
 */


function Logger(level, id, transports, options) {
  this.id = id;
  this.options = options || {};
  this.transports = transports;

  if (!this.transports) {
    this.transports = [];
  }

  this.level = levels[level];
  var methods = Object.keys(levels);

  for (var i = 0; i < methods.length; i++) {
    this[methods[i]] = log.bind(null, this, methods[i]);
  }
}
/**
 * Sets the log level for the logger.
 * @param level the new log level.
 */


Logger.prototype.setLevel = function (level) {
  this.level = levels[level];
};

module.exports = Logger;
/**
 * Enum for the supported log levels.
 */

Logger.levels = {
  TRACE: "trace",
  DEBUG: "debug",
  INFO: "info",
  LOG: "log",
  WARN: "warn",
  ERROR: "error"
};

/***/ }),

/***/ "./node_modules/jitsi-meet-logger/lib/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/jitsi-meet-logger/lib/index.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* Copyright @ 2015-present 8x8, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
var Logger = __webpack_require__(/*! ./Logger */ "./node_modules/jitsi-meet-logger/lib/Logger.js");

var LogCollector = __webpack_require__(/*! ./LogCollector */ "./node_modules/jitsi-meet-logger/lib/LogCollector.js");
/**
 * Definition of the log method
 * @name log_method
 * @function
 * @param {...*} log_args the arguments to be logged
 */

/**
 * The logger's transport type definition.
 *
 * @typedef {object} LoggerTransport
 *
 * @property {log_method} trace method called to log on {@link Logger.levels.TRACE} logging level
 * @property {log_method} debug method called to log on {@link Logger.levels.DEBUG} logging level
 * @property {log_method} info method called to log on {@link Logger.levels.INFO} logging level
 * @property {log_method} log method called to log on {@link Logger.levels.LOG} logging level
 * @property {log_method} warn method called to log on {@link Logger.levels.WARN} logging level
 * @property {log_method} error method called to log on {@link Logger.levels.ERROR} logging level
 */

/**
 * Map with the created loggers with ID.
 */


var idLoggers = {};
/**
 * Array with the loggers without id.
 */

var loggers = [];
/**
 * Log level for the lbrary.
 */

var curLevel = Logger.levels.TRACE;
module.exports = {
  /**
   * Adds given {@link LoggerTransport} instance to the list of global
   * transports which means that it'll be used by all {@link Logger}s
   * @param {LoggerTransport} transport
   */
  addGlobalTransport: function (transport) {
    Logger.addGlobalTransport(transport);
  },

  /**
   * Removes given {@link LoggerTransport} instance from the list of global
   * transports
   * @param {LoggerTransport} transport
   */
  removeGlobalTransport: function (transport) {
    Logger.removeGlobalTransport(transport);
  },

  /**
  * Sets global options which will be used by all loggers. Changing these
  * works even after other loggers are created.
  */
  setGlobalOptions: function (options) {
    Logger.setGlobalOptions(options);
  },

  /**
   * Creates new logger.
   * @arguments the same as Logger constructor
   */
  getLogger: function (id, transports, options) {
    var logger = new Logger(curLevel, id, transports, options);

    if (id) {
      idLoggers[id] = idLoggers[id] || [];
      idLoggers[id].push(logger);
    } else {
      loggers.push(logger);
    }

    return logger;
  },

  /**
   * Changes the log level for the existing loggers by id.
   * @param level the new log level.
   * @param id if specified the level will be changed only for loggers with the
   * same id. Otherwise the operation will affect all loggers that don't
   * have id.
   */
  setLogLevelById: function (level, id) {
    var l = id ? idLoggers[id] || [] : loggers;

    for (var i = 0; i < l.length; i++) {
      l[i].setLevel(level);
    }
  },

  /**
   * Changes the log level for all existing loggers.
   * @param level the new log level.
   */
  setLogLevel: function (level) {
    curLevel = level;
    var i = 0;

    for (; i < loggers.length; i++) {
      loggers[i].setLevel(level);
    }

    for (var id in idLoggers) {
      var l = idLoggers[id] || [];

      for (i = 0; i < l.length; i++) {
        l[i].setLevel(level);
      }
    }
  },

  /**
   * The supported log levels.
   */
  levels: Logger.levels,

  /**
   * Exports the <tt>LogCollector</tt>.
   */
  LogCollector: LogCollector
};

/***/ }),

/***/ "./node_modules/js-md5/src/md5.js":
/*!****************************************!*\
  !*** ./node_modules/js-md5/src/md5.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(process, global) {var __WEBPACK_AMD_DEFINE_RESULT__;/**
 * [js-md5]{@link https://github.com/emn178/js-md5}
 *
 * @namespace md5
 * @version 0.7.3
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2014-2017
 * @license MIT
 */
(function () {
  'use strict';

  var ERROR = 'input is invalid type';
  var WINDOW = typeof window === 'object';
  var root = WINDOW ? window : {};

  if (root.JS_MD5_NO_WINDOW) {
    WINDOW = false;
  }

  var WEB_WORKER = !WINDOW && typeof self === 'object';
  var NODE_JS = !root.JS_MD5_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;

  if (NODE_JS) {
    root = global;
  } else if (WEB_WORKER) {
    root = self;
  }

  var COMMON_JS = !root.JS_MD5_NO_COMMON_JS && typeof module === 'object' && module.exports;
  var AMD =  true && __webpack_require__(/*! !webpack amd options */ "./node_modules/webpack/buildin/amd-options.js");
  var ARRAY_BUFFER = !root.JS_MD5_NO_ARRAY_BUFFER && typeof ArrayBuffer !== 'undefined';
  var HEX_CHARS = '0123456789abcdef'.split('');
  var EXTRA = [128, 32768, 8388608, -2147483648];
  var SHIFT = [0, 8, 16, 24];
  var OUTPUT_TYPES = ['hex', 'array', 'digest', 'buffer', 'arrayBuffer', 'base64'];
  var BASE64_ENCODE_CHAR = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'.split('');
  var blocks = [],
      buffer8;

  if (ARRAY_BUFFER) {
    var buffer = new ArrayBuffer(68);
    buffer8 = new Uint8Array(buffer);
    blocks = new Uint32Array(buffer);
  }

  if (root.JS_MD5_NO_NODE_JS || !Array.isArray) {
    Array.isArray = function (obj) {
      return Object.prototype.toString.call(obj) === '[object Array]';
    };
  }

  if (ARRAY_BUFFER && (root.JS_MD5_NO_ARRAY_BUFFER_IS_VIEW || !ArrayBuffer.isView)) {
    ArrayBuffer.isView = function (obj) {
      return typeof obj === 'object' && obj.buffer && obj.buffer.constructor === ArrayBuffer;
    };
  }
  /**
   * @method hex
   * @memberof md5
   * @description Output hash as hex string
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {String} Hex string
   * @example
   * md5.hex('The quick brown fox jumps over the lazy dog');
   * // equal to
   * md5('The quick brown fox jumps over the lazy dog');
   */

  /**
   * @method digest
   * @memberof md5
   * @description Output hash as bytes array
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {Array} Bytes array
   * @example
   * md5.digest('The quick brown fox jumps over the lazy dog');
   */

  /**
   * @method array
   * @memberof md5
   * @description Output hash as bytes array
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {Array} Bytes array
   * @example
   * md5.array('The quick brown fox jumps over the lazy dog');
   */

  /**
   * @method arrayBuffer
   * @memberof md5
   * @description Output hash as ArrayBuffer
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {ArrayBuffer} ArrayBuffer
   * @example
   * md5.arrayBuffer('The quick brown fox jumps over the lazy dog');
   */

  /**
   * @method buffer
   * @deprecated This maybe confuse with Buffer in node.js. Please use arrayBuffer instead.
   * @memberof md5
   * @description Output hash as ArrayBuffer
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {ArrayBuffer} ArrayBuffer
   * @example
   * md5.buffer('The quick brown fox jumps over the lazy dog');
   */

  /**
   * @method base64
   * @memberof md5
   * @description Output hash as base64 string
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {String} base64 string
   * @example
   * md5.base64('The quick brown fox jumps over the lazy dog');
   */


  var createOutputMethod = function (outputType) {
    return function (message) {
      return new Md5(true).update(message)[outputType]();
    };
  };
  /**
   * @method create
   * @memberof md5
   * @description Create Md5 object
   * @returns {Md5} Md5 object.
   * @example
   * var hash = md5.create();
   */

  /**
   * @method update
   * @memberof md5
   * @description Create and update Md5 object
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {Md5} Md5 object.
   * @example
   * var hash = md5.update('The quick brown fox jumps over the lazy dog');
   * // equal to
   * var hash = md5.create();
   * hash.update('The quick brown fox jumps over the lazy dog');
   */


  var createMethod = function () {
    var method = createOutputMethod('hex');

    if (NODE_JS) {
      method = nodeWrap(method);
    }

    method.create = function () {
      return new Md5();
    };

    method.update = function (message) {
      return method.create().update(message);
    };

    for (var i = 0; i < OUTPUT_TYPES.length; ++i) {
      var type = OUTPUT_TYPES[i];
      method[type] = createOutputMethod(type);
    }

    return method;
  };

  var nodeWrap = function (method) {
    var crypto = eval("require('crypto')");
    var Buffer = eval("require('buffer').Buffer");

    var nodeMethod = function (message) {
      if (typeof message === 'string') {
        return crypto.createHash('md5').update(message, 'utf8').digest('hex');
      } else {
        if (message === null || message === undefined) {
          throw ERROR;
        } else if (message.constructor === ArrayBuffer) {
          message = new Uint8Array(message);
        }
      }

      if (Array.isArray(message) || ArrayBuffer.isView(message) || message.constructor === Buffer) {
        return crypto.createHash('md5').update(new Buffer(message)).digest('hex');
      } else {
        return method(message);
      }
    };

    return nodeMethod;
  };
  /**
   * Md5 class
   * @class Md5
   * @description This is internal class.
   * @see {@link md5.create}
   */


  function Md5(sharedMemory) {
    if (sharedMemory) {
      blocks[0] = blocks[16] = blocks[1] = blocks[2] = blocks[3] = blocks[4] = blocks[5] = blocks[6] = blocks[7] = blocks[8] = blocks[9] = blocks[10] = blocks[11] = blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
      this.blocks = blocks;
      this.buffer8 = buffer8;
    } else {
      if (ARRAY_BUFFER) {
        var buffer = new ArrayBuffer(68);
        this.buffer8 = new Uint8Array(buffer);
        this.blocks = new Uint32Array(buffer);
      } else {
        this.blocks = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
      }
    }

    this.h0 = this.h1 = this.h2 = this.h3 = this.start = this.bytes = this.hBytes = 0;
    this.finalized = this.hashed = false;
    this.first = true;
  }
  /**
   * @method update
   * @memberof Md5
   * @instance
   * @description Update hash
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {Md5} Md5 object.
   * @see {@link md5.update}
   */


  Md5.prototype.update = function (message) {
    if (this.finalized) {
      return;
    }

    var notString,
        type = typeof message;

    if (type !== 'string') {
      if (type === 'object') {
        if (message === null) {
          throw ERROR;
        } else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) {
          message = new Uint8Array(message);
        } else if (!Array.isArray(message)) {
          if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) {
            throw ERROR;
          }
        }
      } else {
        throw ERROR;
      }

      notString = true;
    }

    var code,
        index = 0,
        i,
        length = message.length,
        blocks = this.blocks;
    var buffer8 = this.buffer8;

    while (index < length) {
      if (this.hashed) {
        this.hashed = false;
        blocks[0] = blocks[16];
        blocks[16] = blocks[1] = blocks[2] = blocks[3] = blocks[4] = blocks[5] = blocks[6] = blocks[7] = blocks[8] = blocks[9] = blocks[10] = blocks[11] = blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
      }

      if (notString) {
        if (ARRAY_BUFFER) {
          for (i = this.start; index < length && i < 64; ++index) {
            buffer8[i++] = message[index];
          }
        } else {
          for (i = this.start; index < length && i < 64; ++index) {
            blocks[i >> 2] |= message[index] << SHIFT[i++ & 3];
          }
        }
      } else {
        if (ARRAY_BUFFER) {
          for (i = this.start; index < length && i < 64; ++index) {
            code = message.charCodeAt(index);

            if (code < 0x80) {
              buffer8[i++] = code;
            } else if (code < 0x800) {
              buffer8[i++] = 0xc0 | code >> 6;
              buffer8[i++] = 0x80 | code & 0x3f;
            } else if (code < 0xd800 || code >= 0xe000) {
              buffer8[i++] = 0xe0 | code >> 12;
              buffer8[i++] = 0x80 | code >> 6 & 0x3f;
              buffer8[i++] = 0x80 | code & 0x3f;
            } else {
              code = 0x10000 + ((code & 0x3ff) << 10 | message.charCodeAt(++index) & 0x3ff);
              buffer8[i++] = 0xf0 | code >> 18;
              buffer8[i++] = 0x80 | code >> 12 & 0x3f;
              buffer8[i++] = 0x80 | code >> 6 & 0x3f;
              buffer8[i++] = 0x80 | code & 0x3f;
            }
          }
        } else {
          for (i = this.start; index < length && i < 64; ++index) {
            code = message.charCodeAt(index);

            if (code < 0x80) {
              blocks[i >> 2] |= code << SHIFT[i++ & 3];
            } else if (code < 0x800) {
              blocks[i >> 2] |= (0xc0 | code >> 6) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | code & 0x3f) << SHIFT[i++ & 3];
            } else if (code < 0xd800 || code >= 0xe000) {
              blocks[i >> 2] |= (0xe0 | code >> 12) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | code >> 6 & 0x3f) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | code & 0x3f) << SHIFT[i++ & 3];
            } else {
              code = 0x10000 + ((code & 0x3ff) << 10 | message.charCodeAt(++index) & 0x3ff);
              blocks[i >> 2] |= (0xf0 | code >> 18) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | code >> 12 & 0x3f) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | code >> 6 & 0x3f) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | code & 0x3f) << SHIFT[i++ & 3];
            }
          }
        }
      }

      this.lastByteIndex = i;
      this.bytes += i - this.start;

      if (i >= 64) {
        this.start = i - 64;
        this.hash();
        this.hashed = true;
      } else {
        this.start = i;
      }
    }

    if (this.bytes > 4294967295) {
      this.hBytes += this.bytes / 4294967296 << 0;
      this.bytes = this.bytes % 4294967296;
    }

    return this;
  };

  Md5.prototype.finalize = function () {
    if (this.finalized) {
      return;
    }

    this.finalized = true;
    var blocks = this.blocks,
        i = this.lastByteIndex;
    blocks[i >> 2] |= EXTRA[i & 3];

    if (i >= 56) {
      if (!this.hashed) {
        this.hash();
      }

      blocks[0] = blocks[16];
      blocks[16] = blocks[1] = blocks[2] = blocks[3] = blocks[4] = blocks[5] = blocks[6] = blocks[7] = blocks[8] = blocks[9] = blocks[10] = blocks[11] = blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
    }

    blocks[14] = this.bytes << 3;
    blocks[15] = this.hBytes << 3 | this.bytes >>> 29;
    this.hash();
  };

  Md5.prototype.hash = function () {
    var a,
        b,
        c,
        d,
        bc,
        da,
        blocks = this.blocks;

    if (this.first) {
      a = blocks[0] - 680876937;
      a = (a << 7 | a >>> 25) - 271733879 << 0;
      d = (-1732584194 ^ a & 2004318071) + blocks[1] - 117830708;
      d = (d << 12 | d >>> 20) + a << 0;
      c = (-271733879 ^ d & (a ^ -271733879)) + blocks[2] - 1126478375;
      c = (c << 17 | c >>> 15) + d << 0;
      b = (a ^ c & (d ^ a)) + blocks[3] - 1316259209;
      b = (b << 22 | b >>> 10) + c << 0;
    } else {
      a = this.h0;
      b = this.h1;
      c = this.h2;
      d = this.h3;
      a += (d ^ b & (c ^ d)) + blocks[0] - 680876936;
      a = (a << 7 | a >>> 25) + b << 0;
      d += (c ^ a & (b ^ c)) + blocks[1] - 389564586;
      d = (d << 12 | d >>> 20) + a << 0;
      c += (b ^ d & (a ^ b)) + blocks[2] + 606105819;
      c = (c << 17 | c >>> 15) + d << 0;
      b += (a ^ c & (d ^ a)) + blocks[3] - 1044525330;
      b = (b << 22 | b >>> 10) + c << 0;
    }

    a += (d ^ b & (c ^ d)) + blocks[4] - 176418897;
    a = (a << 7 | a >>> 25) + b << 0;
    d += (c ^ a & (b ^ c)) + blocks[5] + 1200080426;
    d = (d << 12 | d >>> 20) + a << 0;
    c += (b ^ d & (a ^ b)) + blocks[6] - 1473231341;
    c = (c << 17 | c >>> 15) + d << 0;
    b += (a ^ c & (d ^ a)) + blocks[7] - 45705983;
    b = (b << 22 | b >>> 10) + c << 0;
    a += (d ^ b & (c ^ d)) + blocks[8] + 1770035416;
    a = (a << 7 | a >>> 25) + b << 0;
    d += (c ^ a & (b ^ c)) + blocks[9] - 1958414417;
    d = (d << 12 | d >>> 20) + a << 0;
    c += (b ^ d & (a ^ b)) + blocks[10] - 42063;
    c = (c << 17 | c >>> 15) + d << 0;
    b += (a ^ c & (d ^ a)) + blocks[11] - 1990404162;
    b = (b << 22 | b >>> 10) + c << 0;
    a += (d ^ b & (c ^ d)) + blocks[12] + 1804603682;
    a = (a << 7 | a >>> 25) + b << 0;
    d += (c ^ a & (b ^ c)) + blocks[13] - 40341101;
    d = (d << 12 | d >>> 20) + a << 0;
    c += (b ^ d & (a ^ b)) + blocks[14] - 1502002290;
    c = (c << 17 | c >>> 15) + d << 0;
    b += (a ^ c & (d ^ a)) + blocks[15] + 1236535329;
    b = (b << 22 | b >>> 10) + c << 0;
    a += (c ^ d & (b ^ c)) + blocks[1] - 165796510;
    a = (a << 5 | a >>> 27) + b << 0;
    d += (b ^ c & (a ^ b)) + blocks[6] - 1069501632;
    d = (d << 9 | d >>> 23) + a << 0;
    c += (a ^ b & (d ^ a)) + blocks[11] + 643717713;
    c = (c << 14 | c >>> 18) + d << 0;
    b += (d ^ a & (c ^ d)) + blocks[0] - 373897302;
    b = (b << 20 | b >>> 12) + c << 0;
    a += (c ^ d & (b ^ c)) + blocks[5] - 701558691;
    a = (a << 5 | a >>> 27) + b << 0;
    d += (b ^ c & (a ^ b)) + blocks[10] + 38016083;
    d = (d << 9 | d >>> 23) + a << 0;
    c += (a ^ b & (d ^ a)) + blocks[15] - 660478335;
    c = (c << 14 | c >>> 18) + d << 0;
    b += (d ^ a & (c ^ d)) + blocks[4] - 405537848;
    b = (b << 20 | b >>> 12) + c << 0;
    a += (c ^ d & (b ^ c)) + blocks[9] + 568446438;
    a = (a << 5 | a >>> 27) + b << 0;
    d += (b ^ c & (a ^ b)) + blocks[14] - 1019803690;
    d = (d << 9 | d >>> 23) + a << 0;
    c += (a ^ b & (d ^ a)) + blocks[3] - 187363961;
    c = (c << 14 | c >>> 18) + d << 0;
    b += (d ^ a & (c ^ d)) + blocks[8] + 1163531501;
    b = (b << 20 | b >>> 12) + c << 0;
    a += (c ^ d & (b ^ c)) + blocks[13] - 1444681467;
    a = (a << 5 | a >>> 27) + b << 0;
    d += (b ^ c & (a ^ b)) + blocks[2] - 51403784;
    d = (d << 9 | d >>> 23) + a << 0;
    c += (a ^ b & (d ^ a)) + blocks[7] + 1735328473;
    c = (c << 14 | c >>> 18) + d << 0;
    b += (d ^ a & (c ^ d)) + blocks[12] - 1926607734;
    b = (b << 20 | b >>> 12) + c << 0;
    bc = b ^ c;
    a += (bc ^ d) + blocks[5] - 378558;
    a = (a << 4 | a >>> 28) + b << 0;
    d += (bc ^ a) + blocks[8] - 2022574463;
    d = (d << 11 | d >>> 21) + a << 0;
    da = d ^ a;
    c += (da ^ b) + blocks[11] + 1839030562;
    c = (c << 16 | c >>> 16) + d << 0;
    b += (da ^ c) + blocks[14] - 35309556;
    b = (b << 23 | b >>> 9) + c << 0;
    bc = b ^ c;
    a += (bc ^ d) + blocks[1] - 1530992060;
    a = (a << 4 | a >>> 28) + b << 0;
    d += (bc ^ a) + blocks[4] + 1272893353;
    d = (d << 11 | d >>> 21) + a << 0;
    da = d ^ a;
    c += (da ^ b) + blocks[7] - 155497632;
    c = (c << 16 | c >>> 16) + d << 0;
    b += (da ^ c) + blocks[10] - 1094730640;
    b = (b << 23 | b >>> 9) + c << 0;
    bc = b ^ c;
    a += (bc ^ d) + blocks[13] + 681279174;
    a = (a << 4 | a >>> 28) + b << 0;
    d += (bc ^ a) + blocks[0] - 358537222;
    d = (d << 11 | d >>> 21) + a << 0;
    da = d ^ a;
    c += (da ^ b) + blocks[3] - 722521979;
    c = (c << 16 | c >>> 16) + d << 0;
    b += (da ^ c) + blocks[6] + 76029189;
    b = (b << 23 | b >>> 9) + c << 0;
    bc = b ^ c;
    a += (bc ^ d) + blocks[9] - 640364487;
    a = (a << 4 | a >>> 28) + b << 0;
    d += (bc ^ a) + blocks[12] - 421815835;
    d = (d << 11 | d >>> 21) + a << 0;
    da = d ^ a;
    c += (da ^ b) + blocks[15] + 530742520;
    c = (c << 16 | c >>> 16) + d << 0;
    b += (da ^ c) + blocks[2] - 995338651;
    b = (b << 23 | b >>> 9) + c << 0;
    a += (c ^ (b | ~d)) + blocks[0] - 198630844;
    a = (a << 6 | a >>> 26) + b << 0;
    d += (b ^ (a | ~c)) + blocks[7] + 1126891415;
    d = (d << 10 | d >>> 22) + a << 0;
    c += (a ^ (d | ~b)) + blocks[14] - 1416354905;
    c = (c << 15 | c >>> 17) + d << 0;
    b += (d ^ (c | ~a)) + blocks[5] - 57434055;
    b = (b << 21 | b >>> 11) + c << 0;
    a += (c ^ (b | ~d)) + blocks[12] + 1700485571;
    a = (a << 6 | a >>> 26) + b << 0;
    d += (b ^ (a | ~c)) + blocks[3] - 1894986606;
    d = (d << 10 | d >>> 22) + a << 0;
    c += (a ^ (d | ~b)) + blocks[10] - 1051523;
    c = (c << 15 | c >>> 17) + d << 0;
    b += (d ^ (c | ~a)) + blocks[1] - 2054922799;
    b = (b << 21 | b >>> 11) + c << 0;
    a += (c ^ (b | ~d)) + blocks[8] + 1873313359;
    a = (a << 6 | a >>> 26) + b << 0;
    d += (b ^ (a | ~c)) + blocks[15] - 30611744;
    d = (d << 10 | d >>> 22) + a << 0;
    c += (a ^ (d | ~b)) + blocks[6] - 1560198380;
    c = (c << 15 | c >>> 17) + d << 0;
    b += (d ^ (c | ~a)) + blocks[13] + 1309151649;
    b = (b << 21 | b >>> 11) + c << 0;
    a += (c ^ (b | ~d)) + blocks[4] - 145523070;
    a = (a << 6 | a >>> 26) + b << 0;
    d += (b ^ (a | ~c)) + blocks[11] - 1120210379;
    d = (d << 10 | d >>> 22) + a << 0;
    c += (a ^ (d | ~b)) + blocks[2] + 718787259;
    c = (c << 15 | c >>> 17) + d << 0;
    b += (d ^ (c | ~a)) + blocks[9] - 343485551;
    b = (b << 21 | b >>> 11) + c << 0;

    if (this.first) {
      this.h0 = a + 1732584193 << 0;
      this.h1 = b - 271733879 << 0;
      this.h2 = c - 1732584194 << 0;
      this.h3 = d + 271733878 << 0;
      this.first = false;
    } else {
      this.h0 = this.h0 + a << 0;
      this.h1 = this.h1 + b << 0;
      this.h2 = this.h2 + c << 0;
      this.h3 = this.h3 + d << 0;
    }
  };
  /**
   * @method hex
   * @memberof Md5
   * @instance
   * @description Output hash as hex string
   * @returns {String} Hex string
   * @see {@link md5.hex}
   * @example
   * hash.hex();
   */


  Md5.prototype.hex = function () {
    this.finalize();
    var h0 = this.h0,
        h1 = this.h1,
        h2 = this.h2,
        h3 = this.h3;
    return HEX_CHARS[h0 >> 4 & 0x0F] + HEX_CHARS[h0 & 0x0F] + HEX_CHARS[h0 >> 12 & 0x0F] + HEX_CHARS[h0 >> 8 & 0x0F] + HEX_CHARS[h0 >> 20 & 0x0F] + HEX_CHARS[h0 >> 16 & 0x0F] + HEX_CHARS[h0 >> 28 & 0x0F] + HEX_CHARS[h0 >> 24 & 0x0F] + HEX_CHARS[h1 >> 4 & 0x0F] + HEX_CHARS[h1 & 0x0F] + HEX_CHARS[h1 >> 12 & 0x0F] + HEX_CHARS[h1 >> 8 & 0x0F] + HEX_CHARS[h1 >> 20 & 0x0F] + HEX_CHARS[h1 >> 16 & 0x0F] + HEX_CHARS[h1 >> 28 & 0x0F] + HEX_CHARS[h1 >> 24 & 0x0F] + HEX_CHARS[h2 >> 4 & 0x0F] + HEX_CHARS[h2 & 0x0F] + HEX_CHARS[h2 >> 12 & 0x0F] + HEX_CHARS[h2 >> 8 & 0x0F] + HEX_CHARS[h2 >> 20 & 0x0F] + HEX_CHARS[h2 >> 16 & 0x0F] + HEX_CHARS[h2 >> 28 & 0x0F] + HEX_CHARS[h2 >> 24 & 0x0F] + HEX_CHARS[h3 >> 4 & 0x0F] + HEX_CHARS[h3 & 0x0F] + HEX_CHARS[h3 >> 12 & 0x0F] + HEX_CHARS[h3 >> 8 & 0x0F] + HEX_CHARS[h3 >> 20 & 0x0F] + HEX_CHARS[h3 >> 16 & 0x0F] + HEX_CHARS[h3 >> 28 & 0x0F] + HEX_CHARS[h3 >> 24 & 0x0F];
  };
  /**
   * @method toString
   * @memberof Md5
   * @instance
   * @description Output hash as hex string
   * @returns {String} Hex string
   * @see {@link md5.hex}
   * @example
   * hash.toString();
   */


  Md5.prototype.toString = Md5.prototype.hex;
  /**
   * @method digest
   * @memberof Md5
   * @instance
   * @description Output hash as bytes array
   * @returns {Array} Bytes array
   * @see {@link md5.digest}
   * @example
   * hash.digest();
   */

  Md5.prototype.digest = function () {
    this.finalize();
    var h0 = this.h0,
        h1 = this.h1,
        h2 = this.h2,
        h3 = this.h3;
    return [h0 & 0xFF, h0 >> 8 & 0xFF, h0 >> 16 & 0xFF, h0 >> 24 & 0xFF, h1 & 0xFF, h1 >> 8 & 0xFF, h1 >> 16 & 0xFF, h1 >> 24 & 0xFF, h2 & 0xFF, h2 >> 8 & 0xFF, h2 >> 16 & 0xFF, h2 >> 24 & 0xFF, h3 & 0xFF, h3 >> 8 & 0xFF, h3 >> 16 & 0xFF, h3 >> 24 & 0xFF];
  };
  /**
   * @method array
   * @memberof Md5
   * @instance
   * @description Output hash as bytes array
   * @returns {Array} Bytes array
   * @see {@link md5.array}
   * @example
   * hash.array();
   */


  Md5.prototype.array = Md5.prototype.digest;
  /**
   * @method arrayBuffer
   * @memberof Md5
   * @instance
   * @description Output hash as ArrayBuffer
   * @returns {ArrayBuffer} ArrayBuffer
   * @see {@link md5.arrayBuffer}
   * @example
   * hash.arrayBuffer();
   */

  Md5.prototype.arrayBuffer = function () {
    this.finalize();
    var buffer = new ArrayBuffer(16);
    var blocks = new Uint32Array(buffer);
    blocks[0] = this.h0;
    blocks[1] = this.h1;
    blocks[2] = this.h2;
    blocks[3] = this.h3;
    return buffer;
  };
  /**
   * @method buffer
   * @deprecated This maybe confuse with Buffer in node.js. Please use arrayBuffer instead.
   * @memberof Md5
   * @instance
   * @description Output hash as ArrayBuffer
   * @returns {ArrayBuffer} ArrayBuffer
   * @see {@link md5.buffer}
   * @example
   * hash.buffer();
   */


  Md5.prototype.buffer = Md5.prototype.arrayBuffer;
  /**
   * @method base64
   * @memberof Md5
   * @instance
   * @description Output hash as base64 string
   * @returns {String} base64 string
   * @see {@link md5.base64}
   * @example
   * hash.base64();
   */

  Md5.prototype.base64 = function () {
    var v1,
        v2,
        v3,
        base64Str = '',
        bytes = this.array();

    for (var i = 0; i < 15;) {
      v1 = bytes[i++];
      v2 = bytes[i++];
      v3 = bytes[i++];
      base64Str += BASE64_ENCODE_CHAR[v1 >>> 2] + BASE64_ENCODE_CHAR[(v1 << 4 | v2 >>> 4) & 63] + BASE64_ENCODE_CHAR[(v2 << 2 | v3 >>> 6) & 63] + BASE64_ENCODE_CHAR[v3 & 63];
    }

    v1 = bytes[i];
    base64Str += BASE64_ENCODE_CHAR[v1 >>> 2] + BASE64_ENCODE_CHAR[v1 << 4 & 63] + '==';
    return base64Str;
  };

  var exports = createMethod();

  if (COMMON_JS) {
    module.exports = exports;
  } else {
    /**
     * @method md5
     * @description Md5 hash function, export to global in browsers.
     * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
     * @returns {String} md5 hashes
     * @example
     * md5(''); // d41d8cd98f00b204e9800998ecf8427e
     * md5('The quick brown fox jumps over the lazy dog'); // 9e107d9d372bb6826bd81d3542a419d6
     * md5('The quick brown fox jumps over the lazy dog.'); // e4d909c290d0fb1ca068ffaddf22cbd0
     *
     * // It also supports UTF-8 encoding
     * md5('中文'); // a7bac2239fcdcb3a067903d8077c4a07
     *
     * // It also supports byte `Array`, `Uint8Array`, `ArrayBuffer`
     * md5([]); // d41d8cd98f00b204e9800998ecf8427e
     * md5(new Uint8Array([])); // d41d8cd98f00b204e9800998ecf8427e
     */
    root.md5 = exports;

    if (AMD) {
      !(__WEBPACK_AMD_DEFINE_RESULT__ = (function () {
        return exports;
      }).call(exports, __webpack_require__, exports, module),
				__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));
    }
  }
})();
/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ "./node_modules/process/browser.js"), __webpack_require__(/*! ./../../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js")))

/***/ }),

/***/ "./node_modules/js-utils/avatar/index.js":
/*!***********************************************!*\
  !*** ./node_modules/js-utils/avatar/index.js ***!
  \***********************************************/
/*! exports provided: getAvatarURL, getGravatarURL */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getAvatarURL", function() { return getAvatarURL; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getGravatarURL", function() { return getGravatarURL; });
/* harmony import */ var js_md5__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! js-md5 */ "./node_modules/js-md5/src/md5.js");
/* harmony import */ var js_md5__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(js_md5__WEBPACK_IMPORTED_MODULE_0__);

/**
 * Returns the Avatar URL to be used for the participant.
 *
 * @param {string} [participant.avatarID] - Participant's avatar ID.
 * @param {string} [participant.email] - Participant's e-mail address.
 * @param {string} [participant.id] - Participant's ID.
 * @param {string} [avatarService.urlPrefix] - URL Prefix of the avatar service.
 * @param {string} [avatarService.urlSuffix] - URL Suffix of the avatar service.
 * @returns {string} - Avatar URL.
 */

function getAvatarURL({
  avatarID,
  email,
  id
}, {
  urlPrefix,
  urlSuffix
} = {
  urlPrefix: 'https://abotars.jitsi.net/meeple/',
  urlSuffix: ''
}) {
  return getGravatarURL(email) || generateAvatarURL(avatarID || id, urlPrefix, urlSuffix);
}
/**
 * Returns the Avatar URL generated from the given avatar service.
 *
 * @param {string} key - Key using which avatar has to be generated.
 * @param {string} urlPrefix - URL Prefix of the avatar service to be used.
 * @param {string} urlSuffix - URL Suffix of the avatar service to be used.
 * @returns {string}
 */

function generateAvatarURL(key, urlPrefix, urlSuffix) {
  return urlPrefix + js_md5__WEBPACK_IMPORTED_MODULE_0___default.a.hex(key.trim().toLowerCase()) + urlSuffix;
}
/**
 * Returns the Gravatar URL of a given email id.
 *
 * @param {string} key - Email or id for which we need gravatar url.
 * @returns {string} - Gravatar URL.
 */


function getGravatarURL(key) {
  const urlPrefix = 'https://www.gravatar.com/avatar/';
  const urlSuffix = '?d=404&size=200'; // If the key is a valid email, we hash it. If it's not, we assume it's already a hashed format

  const avatarKey = isValidEmail(key) ? js_md5__WEBPACK_IMPORTED_MODULE_0___default.a.hex(key.trim().toLowerCase()) : key;
  return `${urlPrefix}${avatarKey}${urlSuffix}`;
}
/**
 * Returns if the email id is valid.
 *
 * @param {string} email - Email id to be checked.
 * @returns {boolean}
 */

function isValidEmail(email) {
  return email && email.indexOf('@') > 0;
}

/***/ }),

/***/ "./node_modules/js-utils/browser-capabilities/BrowserCapabilities.js":
/*!***************************************************************************!*\
  !*** ./node_modules/js-utils/browser-capabilities/BrowserCapabilities.js ***!
  \***************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return BrowserCapabilities; });
/* harmony import */ var _browser_detection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../browser-detection */ "./node_modules/js-utils/browser-detection/index.js");
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

 // TODO: Move BrowserCapabilities from lib-jitsi-meet here and use the JSON
// format for them.

/**
 * Implements browser capabilities for lib-jitsi-meet.
 */

class BrowserCapabilities {
  /**
   * Creates new BrowserCapabilities instance.
   *
   * @param {Object} capabilitiesDB - The JSON database with capabilities.
   * @param {boolean} [isUsingIFrame] - True if Jitsi Meet is loaded in iframe
   * and false otherwise.
   * @param {Object} [browserInfo] - Information about the browser.
   * @param {string} browserInfo.name - The name of the browser.
   * @param {string} browserInfo.version - The version of the browser.
   */
  constructor(capabilitiesDB = {}, isUsingIFrame = false, browserInfo) {
    const browser = new _browser_detection__WEBPACK_IMPORTED_MODULE_0__["BrowserDetection"](browserInfo);
    let capabilitiesByVersion; // If the capabilitiesDB is not in the correct format or the type of the
    // version of the browser is undefined(the version is unknown) or the
    // version type is not compatible (not a string) we'll consider the
    // browser as not supported.

    if (typeof capabilitiesDB === 'object' && typeof browser.getVersion() === 'string') {
      const browserCapabilities = capabilitiesDB[browser.getName()] || [];

      for (let i = 0; i < browserCapabilities.length; i++) {
        const capabilities = browserCapabilities[i];

        if (typeof capabilities !== 'object') {
          // eslint-disable-next-line no-continue
          continue;
        }

        const version = capabilities.version;

        if (!version || !browser.isVersionGreaterThan(version)) {
          capabilitiesByVersion = capabilities;
          break;
        }
      }
    }

    if (!capabilitiesByVersion || !capabilitiesByVersion.capabilities) {
      this._capabilities = {
        isSupported: false
      };
    } else if (isUsingIFrame) {
      this._capabilities = _objectSpread({}, capabilitiesByVersion.capabilities, capabilitiesByVersion.iframeCapabilities);
    } else {
      this._capabilities = capabilitiesByVersion.capabilities;
    }

    if (typeof this._capabilities.isSupported === 'undefined') {
      // we have some capabilities but isSupported property is not filled.
      this._capabilities.isSupported = true;
    } else if (this._capabilities.isSupported === false) {
      // Clean the other capabilities.
      this._capabilities = {
        isSupported: false
      };
    }
  }
  /**
   * Checks whether the browser is supported by Jitsi Meet.
   *
   * @returns {boolean}
   */


  isSupported() {
    return this._capabilities.isSupported;
  }
  /**
   * Checks whether the browser supports incoming audio.
   *
   * @returns {boolean}
   */


  supportsAudioIn() {
    return this._capabilities.audioIn || false;
  }
  /**
   * Checks whether the browser supports outgoing audio.
   *
   * @returns {boolean}
   */


  supportsAudioOut() {
    return this._capabilities.audioOut || false;
  }
  /**
   * Checks whether the browser supports screen sharing.
   *
   * @returns {boolean}
   */


  supportsScreenSharing() {
    return this._capabilities.screenSharing || false;
  }
  /**
   * Checks whether the browser supports incomming video.
   *
   * @returns {boolean}
   */


  supportsVideoIn() {
    return this._capabilities.videoIn || false;
  }
  /**
   * Checks whether the browser supports incomming video.
   *
   * @returns {boolean}
   */


  supportsVideoOut() {
    return this._capabilities.videoOut || false;
  }

}

/***/ }),

/***/ "./node_modules/js-utils/browser-capabilities/index.js":
/*!*************************************************************!*\
  !*** ./node_modules/js-utils/browser-capabilities/index.js ***!
  \*************************************************************/
/*! exports provided: BrowserCapabilities */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _BrowserCapabilities__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BrowserCapabilities */ "./node_modules/js-utils/browser-capabilities/BrowserCapabilities.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "BrowserCapabilities", function() { return _BrowserCapabilities__WEBPACK_IMPORTED_MODULE_0__["default"]; });



/***/ }),

/***/ "./node_modules/js-utils/browser-detection/BrowserDetection.js":
/*!*********************************************************************!*\
  !*** ./node_modules/js-utils/browser-detection/BrowserDetection.js ***!
  \*********************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return BrowserDetection; });
/* harmony import */ var bowser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! bowser */ "./node_modules/bowser/es5.js");
/* harmony import */ var bowser__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(bowser__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _browsers__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./browsers */ "./node_modules/js-utils/browser-detection/browsers.js");


/**
 * Maps the names of the browsers from bowser to the internal names defined in
 * ./browsers.js
 */

const bowserNameToJitsiName = {
  'Chrome': _browsers__WEBPACK_IMPORTED_MODULE_1__["CHROME"],
  'Chromium': _browsers__WEBPACK_IMPORTED_MODULE_1__["CHROME"],
  'Opera': _browsers__WEBPACK_IMPORTED_MODULE_1__["OPERA"],
  'Firefox': _browsers__WEBPACK_IMPORTED_MODULE_1__["FIREFOX"],
  'Internet Explorer': _browsers__WEBPACK_IMPORTED_MODULE_1__["INTERNET_EXPLORER"],
  'Safari': _browsers__WEBPACK_IMPORTED_MODULE_1__["SAFARI"]
};
/**
 * Detects a Chromium based environent.
 *
 * NOTE: Here we cannot check solely for "Chrome" in the UA, because Edge has
 * it too. We need to check explicitly for chromium based Edge first and then
 * detect other chromium based browsers.
 *
 * @returns {Object|undefined} - The name (CHROME) and version.
 */

function _detectChromiumBased() {
  const userAgent = navigator.userAgent;
  const browserInfo = {
    name: _browsers__WEBPACK_IMPORTED_MODULE_1__["UNKNOWN"],
    version: undefined
  };

  if (userAgent.match(/Chrome/) && !userAgent.match(/Edge/)) {
    // Edge is currenly supported only on desktop and android.
    if (userAgent.match(/Edg(A?)/)) {
      // Compare the underlying chromium version.
      const version = userAgent.match(/Chrome\/([\d.]+)/)[1];

      if (Number.parseInt(version, 10) > 72) {
        browserInfo.name = _browsers__WEBPACK_IMPORTED_MODULE_1__["CHROME"];
        browserInfo.version = version;
      }
    } else {
      browserInfo.name = _browsers__WEBPACK_IMPORTED_MODULE_1__["CHROME"];
      browserInfo.version = userAgent.match(/Chrome\/([\d.]+)/)[1];
    }
  }

  return browserInfo;
}
/**
 * Detects Electron environment.
 *
 * @returns {Object|undefined} - The name (ELECTRON) and version.
 */


function _detectElectron() {
  const userAgent = navigator.userAgent;

  if (userAgent.match(/Electron/)) {
    const version = userAgent.match(/Electron\/([\d.]+)/)[1];
    return {
      name: _browsers__WEBPACK_IMPORTED_MODULE_1__["ELECTRON"],
      version
    };
  }
}
/**
 * Detects NWJS environment.
 *
 * @returns {Object|undefined} - The name (NWJS) and version.
 */


function _detectNWJS() {
  const userAgent = navigator.userAgent;

  if (userAgent.match(/JitsiMeetNW/)) {
    const version = userAgent.match(/JitsiMeetNW\/([\d.]+)/)[1];
    return {
      name: _browsers__WEBPACK_IMPORTED_MODULE_1__["NWJS"],
      version
    };
  }
}
/**
 * Detects React Native environment.
 * @returns {Object|undefined} - The name (REACT_NATIVE) and version.
 */


function _detectReactNative() {
  const match = navigator.userAgent.match(/\b(react[ \t_-]*native)(?:\/(\S+))?/i);
  let version; // If we're remote debugging a React Native app, it may be treated as
  // Chrome. Check navigator.product as well and always return some version
  // even if we can't get the real one.

  if (match || navigator.product === 'ReactNative') {
    let name;

    if (match && match.length > 2) {
      name = match[1];
      version = match[2];
    }

    name || (name = 'react-native');
    version || (version = 'unknown');
    return {
      name: _browsers__WEBPACK_IMPORTED_MODULE_1__["REACT_NATIVE"],
      version
    };
  }
}
/**
 * Returns information about the current browser.
 * @param {Object} - The bowser instance.
 * @returns {Object} - The name and version of the browser.
 */


function _detect(bowser) {
  let browserInfo;
  const detectors = [_detectReactNative, _detectElectron, _detectNWJS]; // Try all browser detectors

  for (let i = 0; i < detectors.length; i++) {
    browserInfo = detectors[i]();

    if (browserInfo) {
      return browserInfo;
    }
  }

  const name = bowser.getBrowserName();

  if (name in bowserNameToJitsiName) {
    return {
      name: bowserNameToJitsiName[name],
      version: bowser.getBrowserVersion()
    };
  } // Detect other browsers with the Chrome engine, such as Vivaldi and Brave.


  browserInfo = _detectChromiumBased();

  if (browserInfo) {
    return browserInfo;
  }

  return {
    name: _browsers__WEBPACK_IMPORTED_MODULE_1__["UNKNOWN"],
    version: undefined
  };
}
/**
 * Implements browser detection.
 */


class BrowserDetection {
  /**
   * Creates new BrowserDetection instance.
   *
   * @param {Object} [browserInfo] - Information about the browser.
   * @param {string} browserInfo.name - The name of the browser.
   * @param {string} browserInfo.version - The version of the browser.
   */
  constructor(browserInfo) {
    let name, version;
    this._bowser = bowser__WEBPACK_IMPORTED_MODULE_0___default.a.getParser(navigator.userAgent);

    if (typeof browserInfo === 'undefined') {
      const detectedBrowserInfo = _detect(this._bowser);

      name = detectedBrowserInfo.name;
      version = detectedBrowserInfo.version;
    } else if (browserInfo.name in bowserNameToJitsiName) {
      name = bowserNameToJitsiName[browserInfo.name];
      version = browserInfo.version;
    } else {
      name = _browsers__WEBPACK_IMPORTED_MODULE_1__["UNKNOWN"];
      version = undefined;
    }

    this._name = name;
    this._version = version;
  }
  /**
   * Gets current browser name.
   * @returns {string}
   */


  getName() {
    return this._name;
  }
  /**
   * Checks if current browser is Chrome.
   * @returns {boolean}
   */


  isChrome() {
    return this._name === _browsers__WEBPACK_IMPORTED_MODULE_1__["CHROME"];
  }
  /**
   * Checks if current browser is Opera.
   * @returns {boolean}
   */


  isOpera() {
    return this._name === _browsers__WEBPACK_IMPORTED_MODULE_1__["OPERA"];
  }
  /**
   * Checks if current browser is Firefox.
   * @returns {boolean}
   */


  isFirefox() {
    return this._name === _browsers__WEBPACK_IMPORTED_MODULE_1__["FIREFOX"];
  }
  /**
   * Checks if current browser is Internet Explorer.
   * @returns {boolean}
   */


  isIExplorer() {
    return this._name === _browsers__WEBPACK_IMPORTED_MODULE_1__["INTERNET_EXPLORER"];
  }
  /**
   * Checks if current browser is Safari.
   * @returns {boolean}
   */


  isSafari() {
    return this._name === _browsers__WEBPACK_IMPORTED_MODULE_1__["SAFARI"];
  }
  /**
   * Checks if current environment is NWJS.
   * @returns {boolean}
   */


  isNWJS() {
    return this._name === _browsers__WEBPACK_IMPORTED_MODULE_1__["NWJS"];
  }
  /**
   * Checks if current environment is Electron.
   * @returns {boolean}
   */


  isElectron() {
    return this._name === _browsers__WEBPACK_IMPORTED_MODULE_1__["ELECTRON"];
  }
  /**
   * Checks if current environment is React Native.
   * @returns {boolean}
   */


  isReactNative() {
    return this._name === _browsers__WEBPACK_IMPORTED_MODULE_1__["REACT_NATIVE"];
  }
  /**
   * Returns the version of the current browser.
   * @returns {string}
   */


  getVersion() {
    return this._version;
  }
  /**
   * Check if the parsed browser matches the passed condition.
   *
   * @param {Object} checkTree - It's one or two layered object, which can include a
   * platform or an OS on the first layer and should have browsers specs on the
   * bottom layer.
   * Eg. { chrome: '>71.1.0' }
   *     { windows: { chrome: '<70.2' } }
   * @returns {boolean | undefined} - Returns true if the browser satisfies the set
   * conditions, false if not and undefined when the browser is not defined in the
   * checktree object or when the current browser's version is unknown.
   * @private
   */


  _checkCondition(checkTree) {
    if (this._version) {
      return this._bowser.satisfies(checkTree);
    }
  }
  /**
   * Compares the passed version with the current browser version.
   *
   * @param {*} version - The version to compare with. Anything different
   * than string will be converted to string.
   * @returns {boolean|undefined} - Returns true if the current version is
   * greater than the passed version and false otherwise. Returns undefined if
   * the current browser version is unknown.
   */


  isVersionGreaterThan(version) {
    return this._checkCondition({
      [this._name]: `>${version}`
    });
  }
  /**
   * Compares the passed version with the current browser version.
   *
   * @param {*} version - The version to compare with. Anything different
   * than string will be converted to string.
   * @returns {boolean|undefined} - Returns true if the current version is
   * lower than the passed version and false otherwise. Returns undefined if
   * the current browser version is unknown.
   */


  isVersionLessThan(version) {
    return this._checkCondition({
      [this._name]: `<${version}`
    });
  }
  /**
   * Compares the passed version with the current browser version.
   *
   * @param {*} version - The version to compare with. Anything different
   * than string will be converted to string.
   * @returns {boolean|undefined} - Returns true if the current version is
   * equal to the passed version and false otherwise. Returns undefined if
   * the current browser version is unknown.
   * A loose-equality operator is used here so that it matches the sub-versions as well.
   */


  isVersionEqualTo(version) {
    return this._checkCondition({
      [this._name]: `~${version}`
    });
  }

}

/***/ }),

/***/ "./node_modules/js-utils/browser-detection/browsers.js":
/*!*************************************************************!*\
  !*** ./node_modules/js-utils/browser-detection/browsers.js ***!
  \*************************************************************/
/*! exports provided: CHROME, OPERA, FIREFOX, INTERNET_EXPLORER, SAFARI, NWJS, ELECTRON, REACT_NATIVE, UNKNOWN */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CHROME", function() { return CHROME; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OPERA", function() { return OPERA; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "FIREFOX", function() { return FIREFOX; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "INTERNET_EXPLORER", function() { return INTERNET_EXPLORER; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SAFARI", function() { return SAFARI; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NWJS", function() { return NWJS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ELECTRON", function() { return ELECTRON; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "REACT_NATIVE", function() { return REACT_NATIVE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "UNKNOWN", function() { return UNKNOWN; });
// TODO: Maybe fix the values to 'Chrome', 'Internet Explorer', etc. Currently
// this values needs to be as they are becuse they are going to analytics,
// callstats, etc.
const CHROME = 'chrome';
const OPERA = 'opera';
const FIREFOX = 'firefox';
const INTERNET_EXPLORER = 'iexplorer';
const SAFARI = 'safari';
const NWJS = 'nwjs';
const ELECTRON = 'electron';
const REACT_NATIVE = 'react-native';
const UNKNOWN = 'unknown';

/***/ }),

/***/ "./node_modules/js-utils/browser-detection/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/js-utils/browser-detection/index.js ***!
  \**********************************************************/
/*! exports provided: BrowserDetection, browsers */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _BrowserDetection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BrowserDetection */ "./node_modules/js-utils/browser-detection/BrowserDetection.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "BrowserDetection", function() { return _BrowserDetection__WEBPACK_IMPORTED_MODULE_0__["default"]; });

/* harmony import */ var _browsers__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./browsers */ "./node_modules/js-utils/browser-detection/browsers.js");
/* harmony reexport (module object) */ __webpack_require__.d(__webpack_exports__, "browsers", function() { return _browsers__WEBPACK_IMPORTED_MODULE_1__; });




/***/ }),

/***/ "./node_modules/js-utils/index.js":
/*!****************************************!*\
  !*** ./node_modules/js-utils/index.js ***!
  \****************************************/
/*! exports provided: BrowserCapabilities, BrowserDetection, browsers, getAvatarURL, getGravatarURL */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _browser_capabilities__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./browser-capabilities */ "./node_modules/js-utils/browser-capabilities/index.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "BrowserCapabilities", function() { return _browser_capabilities__WEBPACK_IMPORTED_MODULE_0__["BrowserCapabilities"]; });

/* harmony import */ var _browser_detection__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./browser-detection */ "./node_modules/js-utils/browser-detection/index.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "BrowserDetection", function() { return _browser_detection__WEBPACK_IMPORTED_MODULE_1__["BrowserDetection"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "browsers", function() { return _browser_detection__WEBPACK_IMPORTED_MODULE_1__["browsers"]; });

/* harmony import */ var _avatar__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./avatar */ "./node_modules/js-utils/avatar/index.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "getAvatarURL", function() { return _avatar__WEBPACK_IMPORTED_MODULE_2__["getAvatarURL"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "getGravatarURL", function() { return _avatar__WEBPACK_IMPORTED_MODULE_2__["getGravatarURL"]; });





/***/ }),

/***/ "./node_modules/lodash.clonedeep/index.js":
/*!************************************************!*\
  !*** ./node_modules/lodash.clonedeep/index.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(global, module) {/**
 * lodash (Custom Build) <https://lodash.com/>
 * Build: `lodash modularize exports="npm" -o ./`
 * Copyright jQuery Foundation and other contributors <https://jquery.org/>
 * Released under MIT license <https://lodash.com/license>
 * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>
 * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors
 */

/** Used as the size to enable large array optimizations. */
var LARGE_ARRAY_SIZE = 200;
/** Used to stand-in for `undefined` hash values. */

var HASH_UNDEFINED = '__lodash_hash_undefined__';
/** Used as references for various `Number` constants. */

var MAX_SAFE_INTEGER = 9007199254740991;
/** `Object#toString` result references. */

var argsTag = '[object Arguments]',
    arrayTag = '[object Array]',
    boolTag = '[object Boolean]',
    dateTag = '[object Date]',
    errorTag = '[object Error]',
    funcTag = '[object Function]',
    genTag = '[object GeneratorFunction]',
    mapTag = '[object Map]',
    numberTag = '[object Number]',
    objectTag = '[object Object]',
    promiseTag = '[object Promise]',
    regexpTag = '[object RegExp]',
    setTag = '[object Set]',
    stringTag = '[object String]',
    symbolTag = '[object Symbol]',
    weakMapTag = '[object WeakMap]';
var arrayBufferTag = '[object ArrayBuffer]',
    dataViewTag = '[object DataView]',
    float32Tag = '[object Float32Array]',
    float64Tag = '[object Float64Array]',
    int8Tag = '[object Int8Array]',
    int16Tag = '[object Int16Array]',
    int32Tag = '[object Int32Array]',
    uint8Tag = '[object Uint8Array]',
    uint8ClampedTag = '[object Uint8ClampedArray]',
    uint16Tag = '[object Uint16Array]',
    uint32Tag = '[object Uint32Array]';
/**
 * Used to match `RegExp`
 * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).
 */

var reRegExpChar = /[\\^$.*+?()[\]{}|]/g;
/** Used to match `RegExp` flags from their coerced string values. */

var reFlags = /\w*$/;
/** Used to detect host constructors (Safari). */

var reIsHostCtor = /^\[object .+?Constructor\]$/;
/** Used to detect unsigned integer values. */

var reIsUint = /^(?:0|[1-9]\d*)$/;
/** Used to identify `toStringTag` values supported by `_.clone`. */

var cloneableTags = {};
cloneableTags[argsTag] = cloneableTags[arrayTag] = cloneableTags[arrayBufferTag] = cloneableTags[dataViewTag] = cloneableTags[boolTag] = cloneableTags[dateTag] = cloneableTags[float32Tag] = cloneableTags[float64Tag] = cloneableTags[int8Tag] = cloneableTags[int16Tag] = cloneableTags[int32Tag] = cloneableTags[mapTag] = cloneableTags[numberTag] = cloneableTags[objectTag] = cloneableTags[regexpTag] = cloneableTags[setTag] = cloneableTags[stringTag] = cloneableTags[symbolTag] = cloneableTags[uint8Tag] = cloneableTags[uint8ClampedTag] = cloneableTags[uint16Tag] = cloneableTags[uint32Tag] = true;
cloneableTags[errorTag] = cloneableTags[funcTag] = cloneableTags[weakMapTag] = false;
/** Detect free variable `global` from Node.js. */

var freeGlobal = typeof global == 'object' && global && global.Object === Object && global;
/** Detect free variable `self`. */

var freeSelf = typeof self == 'object' && self && self.Object === Object && self;
/** Used as a reference to the global object. */

var root = freeGlobal || freeSelf || Function('return this')();
/** Detect free variable `exports`. */

var freeExports =  true && exports && !exports.nodeType && exports;
/** Detect free variable `module`. */

var freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;
/** Detect the popular CommonJS extension `module.exports`. */

var moduleExports = freeModule && freeModule.exports === freeExports;
/**
 * Adds the key-value `pair` to `map`.
 *
 * @private
 * @param {Object} map The map to modify.
 * @param {Array} pair The key-value pair to add.
 * @returns {Object} Returns `map`.
 */

function addMapEntry(map, pair) {
  // Don't return `map.set` because it's not chainable in IE 11.
  map.set(pair[0], pair[1]);
  return map;
}
/**
 * Adds `value` to `set`.
 *
 * @private
 * @param {Object} set The set to modify.
 * @param {*} value The value to add.
 * @returns {Object} Returns `set`.
 */


function addSetEntry(set, value) {
  // Don't return `set.add` because it's not chainable in IE 11.
  set.add(value);
  return set;
}
/**
 * A specialized version of `_.forEach` for arrays without support for
 * iteratee shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} iteratee The function invoked per iteration.
 * @returns {Array} Returns `array`.
 */


function arrayEach(array, iteratee) {
  var index = -1,
      length = array ? array.length : 0;

  while (++index < length) {
    if (iteratee(array[index], index, array) === false) {
      break;
    }
  }

  return array;
}
/**
 * Appends the elements of `values` to `array`.
 *
 * @private
 * @param {Array} array The array to modify.
 * @param {Array} values The values to append.
 * @returns {Array} Returns `array`.
 */


function arrayPush(array, values) {
  var index = -1,
      length = values.length,
      offset = array.length;

  while (++index < length) {
    array[offset + index] = values[index];
  }

  return array;
}
/**
 * A specialized version of `_.reduce` for arrays without support for
 * iteratee shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} iteratee The function invoked per iteration.
 * @param {*} [accumulator] The initial value.
 * @param {boolean} [initAccum] Specify using the first element of `array` as
 *  the initial value.
 * @returns {*} Returns the accumulated value.
 */


function arrayReduce(array, iteratee, accumulator, initAccum) {
  var index = -1,
      length = array ? array.length : 0;

  if (initAccum && length) {
    accumulator = array[++index];
  }

  while (++index < length) {
    accumulator = iteratee(accumulator, array[index], index, array);
  }

  return accumulator;
}
/**
 * The base implementation of `_.times` without support for iteratee shorthands
 * or max array length checks.
 *
 * @private
 * @param {number} n The number of times to invoke `iteratee`.
 * @param {Function} iteratee The function invoked per iteration.
 * @returns {Array} Returns the array of results.
 */


function baseTimes(n, iteratee) {
  var index = -1,
      result = Array(n);

  while (++index < n) {
    result[index] = iteratee(index);
  }

  return result;
}
/**
 * Gets the value at `key` of `object`.
 *
 * @private
 * @param {Object} [object] The object to query.
 * @param {string} key The key of the property to get.
 * @returns {*} Returns the property value.
 */


function getValue(object, key) {
  return object == null ? undefined : object[key];
}
/**
 * Checks if `value` is a host object in IE < 9.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a host object, else `false`.
 */


function isHostObject(value) {
  // Many host objects are `Object` objects that can coerce to strings
  // despite having improperly defined `toString` methods.
  var result = false;

  if (value != null && typeof value.toString != 'function') {
    try {
      result = !!(value + '');
    } catch (e) {}
  }

  return result;
}
/**
 * Converts `map` to its key-value pairs.
 *
 * @private
 * @param {Object} map The map to convert.
 * @returns {Array} Returns the key-value pairs.
 */


function mapToArray(map) {
  var index = -1,
      result = Array(map.size);
  map.forEach(function (value, key) {
    result[++index] = [key, value];
  });
  return result;
}
/**
 * Creates a unary function that invokes `func` with its argument transformed.
 *
 * @private
 * @param {Function} func The function to wrap.
 * @param {Function} transform The argument transform.
 * @returns {Function} Returns the new function.
 */


function overArg(func, transform) {
  return function (arg) {
    return func(transform(arg));
  };
}
/**
 * Converts `set` to an array of its values.
 *
 * @private
 * @param {Object} set The set to convert.
 * @returns {Array} Returns the values.
 */


function setToArray(set) {
  var index = -1,
      result = Array(set.size);
  set.forEach(function (value) {
    result[++index] = value;
  });
  return result;
}
/** Used for built-in method references. */


var arrayProto = Array.prototype,
    funcProto = Function.prototype,
    objectProto = Object.prototype;
/** Used to detect overreaching core-js shims. */

var coreJsData = root['__core-js_shared__'];
/** Used to detect methods masquerading as native. */

var maskSrcKey = function () {
  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');
  return uid ? 'Symbol(src)_1.' + uid : '';
}();
/** Used to resolve the decompiled source of functions. */


var funcToString = funcProto.toString;
/** Used to check objects for own properties. */

var hasOwnProperty = objectProto.hasOwnProperty;
/**
 * Used to resolve the
 * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)
 * of values.
 */

var objectToString = objectProto.toString;
/** Used to detect if a method is native. */

var reIsNative = RegExp('^' + funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\$&').replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g, '$1.*?') + '$');
/** Built-in value references. */

var Buffer = moduleExports ? root.Buffer : undefined,
    Symbol = root.Symbol,
    Uint8Array = root.Uint8Array,
    getPrototype = overArg(Object.getPrototypeOf, Object),
    objectCreate = Object.create,
    propertyIsEnumerable = objectProto.propertyIsEnumerable,
    splice = arrayProto.splice;
/* Built-in method references for those with the same name as other `lodash` methods. */

var nativeGetSymbols = Object.getOwnPropertySymbols,
    nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined,
    nativeKeys = overArg(Object.keys, Object);
/* Built-in method references that are verified to be native. */

var DataView = getNative(root, 'DataView'),
    Map = getNative(root, 'Map'),
    Promise = getNative(root, 'Promise'),
    Set = getNative(root, 'Set'),
    WeakMap = getNative(root, 'WeakMap'),
    nativeCreate = getNative(Object, 'create');
/** Used to detect maps, sets, and weakmaps. */

var dataViewCtorString = toSource(DataView),
    mapCtorString = toSource(Map),
    promiseCtorString = toSource(Promise),
    setCtorString = toSource(Set),
    weakMapCtorString = toSource(WeakMap);
/** Used to convert symbols to primitives and strings. */

var symbolProto = Symbol ? Symbol.prototype : undefined,
    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;
/**
 * Creates a hash object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */

function Hash(entries) {
  var index = -1,
      length = entries ? entries.length : 0;
  this.clear();

  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}
/**
 * Removes all key-value entries from the hash.
 *
 * @private
 * @name clear
 * @memberOf Hash
 */


function hashClear() {
  this.__data__ = nativeCreate ? nativeCreate(null) : {};
}
/**
 * Removes `key` and its value from the hash.
 *
 * @private
 * @name delete
 * @memberOf Hash
 * @param {Object} hash The hash to modify.
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */


function hashDelete(key) {
  return this.has(key) && delete this.__data__[key];
}
/**
 * Gets the hash value for `key`.
 *
 * @private
 * @name get
 * @memberOf Hash
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */


function hashGet(key) {
  var data = this.__data__;

  if (nativeCreate) {
    var result = data[key];
    return result === HASH_UNDEFINED ? undefined : result;
  }

  return hasOwnProperty.call(data, key) ? data[key] : undefined;
}
/**
 * Checks if a hash value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Hash
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */


function hashHas(key) {
  var data = this.__data__;
  return nativeCreate ? data[key] !== undefined : hasOwnProperty.call(data, key);
}
/**
 * Sets the hash `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Hash
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the hash instance.
 */


function hashSet(key, value) {
  var data = this.__data__;
  data[key] = nativeCreate && value === undefined ? HASH_UNDEFINED : value;
  return this;
} // Add methods to `Hash`.


Hash.prototype.clear = hashClear;
Hash.prototype['delete'] = hashDelete;
Hash.prototype.get = hashGet;
Hash.prototype.has = hashHas;
Hash.prototype.set = hashSet;
/**
 * Creates an list cache object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */

function ListCache(entries) {
  var index = -1,
      length = entries ? entries.length : 0;
  this.clear();

  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}
/**
 * Removes all key-value entries from the list cache.
 *
 * @private
 * @name clear
 * @memberOf ListCache
 */


function listCacheClear() {
  this.__data__ = [];
}
/**
 * Removes `key` and its value from the list cache.
 *
 * @private
 * @name delete
 * @memberOf ListCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */


function listCacheDelete(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    return false;
  }

  var lastIndex = data.length - 1;

  if (index == lastIndex) {
    data.pop();
  } else {
    splice.call(data, index, 1);
  }

  return true;
}
/**
 * Gets the list cache value for `key`.
 *
 * @private
 * @name get
 * @memberOf ListCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */


function listCacheGet(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);
  return index < 0 ? undefined : data[index][1];
}
/**
 * Checks if a list cache value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf ListCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */


function listCacheHas(key) {
  return assocIndexOf(this.__data__, key) > -1;
}
/**
 * Sets the list cache `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf ListCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the list cache instance.
 */


function listCacheSet(key, value) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    data.push([key, value]);
  } else {
    data[index][1] = value;
  }

  return this;
} // Add methods to `ListCache`.


ListCache.prototype.clear = listCacheClear;
ListCache.prototype['delete'] = listCacheDelete;
ListCache.prototype.get = listCacheGet;
ListCache.prototype.has = listCacheHas;
ListCache.prototype.set = listCacheSet;
/**
 * Creates a map cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */

function MapCache(entries) {
  var index = -1,
      length = entries ? entries.length : 0;
  this.clear();

  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}
/**
 * Removes all key-value entries from the map.
 *
 * @private
 * @name clear
 * @memberOf MapCache
 */


function mapCacheClear() {
  this.__data__ = {
    'hash': new Hash(),
    'map': new (Map || ListCache)(),
    'string': new Hash()
  };
}
/**
 * Removes `key` and its value from the map.
 *
 * @private
 * @name delete
 * @memberOf MapCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */


function mapCacheDelete(key) {
  return getMapData(this, key)['delete'](key);
}
/**
 * Gets the map value for `key`.
 *
 * @private
 * @name get
 * @memberOf MapCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */


function mapCacheGet(key) {
  return getMapData(this, key).get(key);
}
/**
 * Checks if a map value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf MapCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */


function mapCacheHas(key) {
  return getMapData(this, key).has(key);
}
/**
 * Sets the map `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf MapCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the map cache instance.
 */


function mapCacheSet(key, value) {
  getMapData(this, key).set(key, value);
  return this;
} // Add methods to `MapCache`.


MapCache.prototype.clear = mapCacheClear;
MapCache.prototype['delete'] = mapCacheDelete;
MapCache.prototype.get = mapCacheGet;
MapCache.prototype.has = mapCacheHas;
MapCache.prototype.set = mapCacheSet;
/**
 * Creates a stack cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */

function Stack(entries) {
  this.__data__ = new ListCache(entries);
}
/**
 * Removes all key-value entries from the stack.
 *
 * @private
 * @name clear
 * @memberOf Stack
 */


function stackClear() {
  this.__data__ = new ListCache();
}
/**
 * Removes `key` and its value from the stack.
 *
 * @private
 * @name delete
 * @memberOf Stack
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */


function stackDelete(key) {
  return this.__data__['delete'](key);
}
/**
 * Gets the stack value for `key`.
 *
 * @private
 * @name get
 * @memberOf Stack
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */


function stackGet(key) {
  return this.__data__.get(key);
}
/**
 * Checks if a stack value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Stack
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */


function stackHas(key) {
  return this.__data__.has(key);
}
/**
 * Sets the stack `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Stack
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the stack cache instance.
 */


function stackSet(key, value) {
  var cache = this.__data__;

  if (cache instanceof ListCache) {
    var pairs = cache.__data__;

    if (!Map || pairs.length < LARGE_ARRAY_SIZE - 1) {
      pairs.push([key, value]);
      return this;
    }

    cache = this.__data__ = new MapCache(pairs);
  }

  cache.set(key, value);
  return this;
} // Add methods to `Stack`.


Stack.prototype.clear = stackClear;
Stack.prototype['delete'] = stackDelete;
Stack.prototype.get = stackGet;
Stack.prototype.has = stackHas;
Stack.prototype.set = stackSet;
/**
 * Creates an array of the enumerable property names of the array-like `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @param {boolean} inherited Specify returning inherited property names.
 * @returns {Array} Returns the array of property names.
 */

function arrayLikeKeys(value, inherited) {
  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.
  // Safari 9 makes `arguments.length` enumerable in strict mode.
  var result = isArray(value) || isArguments(value) ? baseTimes(value.length, String) : [];
  var length = result.length,
      skipIndexes = !!length;

  for (var key in value) {
    if ((inherited || hasOwnProperty.call(value, key)) && !(skipIndexes && (key == 'length' || isIndex(key, length)))) {
      result.push(key);
    }
  }

  return result;
}
/**
 * Assigns `value` to `key` of `object` if the existing value is not equivalent
 * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)
 * for equality comparisons.
 *
 * @private
 * @param {Object} object The object to modify.
 * @param {string} key The key of the property to assign.
 * @param {*} value The value to assign.
 */


function assignValue(object, key, value) {
  var objValue = object[key];

  if (!(hasOwnProperty.call(object, key) && eq(objValue, value)) || value === undefined && !(key in object)) {
    object[key] = value;
  }
}
/**
 * Gets the index at which the `key` is found in `array` of key-value pairs.
 *
 * @private
 * @param {Array} array The array to inspect.
 * @param {*} key The key to search for.
 * @returns {number} Returns the index of the matched value, else `-1`.
 */


function assocIndexOf(array, key) {
  var length = array.length;

  while (length--) {
    if (eq(array[length][0], key)) {
      return length;
    }
  }

  return -1;
}
/**
 * The base implementation of `_.assign` without support for multiple sources
 * or `customizer` functions.
 *
 * @private
 * @param {Object} object The destination object.
 * @param {Object} source The source object.
 * @returns {Object} Returns `object`.
 */


function baseAssign(object, source) {
  return object && copyObject(source, keys(source), object);
}
/**
 * The base implementation of `_.clone` and `_.cloneDeep` which tracks
 * traversed objects.
 *
 * @private
 * @param {*} value The value to clone.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @param {boolean} [isFull] Specify a clone including symbols.
 * @param {Function} [customizer] The function to customize cloning.
 * @param {string} [key] The key of `value`.
 * @param {Object} [object] The parent object of `value`.
 * @param {Object} [stack] Tracks traversed objects and their clone counterparts.
 * @returns {*} Returns the cloned value.
 */


function baseClone(value, isDeep, isFull, customizer, key, object, stack) {
  var result;

  if (customizer) {
    result = object ? customizer(value, key, object, stack) : customizer(value);
  }

  if (result !== undefined) {
    return result;
  }

  if (!isObject(value)) {
    return value;
  }

  var isArr = isArray(value);

  if (isArr) {
    result = initCloneArray(value);

    if (!isDeep) {
      return copyArray(value, result);
    }
  } else {
    var tag = getTag(value),
        isFunc = tag == funcTag || tag == genTag;

    if (isBuffer(value)) {
      return cloneBuffer(value, isDeep);
    }

    if (tag == objectTag || tag == argsTag || isFunc && !object) {
      if (isHostObject(value)) {
        return object ? value : {};
      }

      result = initCloneObject(isFunc ? {} : value);

      if (!isDeep) {
        return copySymbols(value, baseAssign(result, value));
      }
    } else {
      if (!cloneableTags[tag]) {
        return object ? value : {};
      }

      result = initCloneByTag(value, tag, baseClone, isDeep);
    }
  } // Check for circular references and return its corresponding clone.


  stack || (stack = new Stack());
  var stacked = stack.get(value);

  if (stacked) {
    return stacked;
  }

  stack.set(value, result);

  if (!isArr) {
    var props = isFull ? getAllKeys(value) : keys(value);
  }

  arrayEach(props || value, function (subValue, key) {
    if (props) {
      key = subValue;
      subValue = value[key];
    } // Recursively populate clone (susceptible to call stack limits).


    assignValue(result, key, baseClone(subValue, isDeep, isFull, customizer, key, value, stack));
  });
  return result;
}
/**
 * The base implementation of `_.create` without support for assigning
 * properties to the created object.
 *
 * @private
 * @param {Object} prototype The object to inherit from.
 * @returns {Object} Returns the new object.
 */


function baseCreate(proto) {
  return isObject(proto) ? objectCreate(proto) : {};
}
/**
 * The base implementation of `getAllKeys` and `getAllKeysIn` which uses
 * `keysFunc` and `symbolsFunc` to get the enumerable property names and
 * symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {Function} keysFunc The function to get the keys of `object`.
 * @param {Function} symbolsFunc The function to get the symbols of `object`.
 * @returns {Array} Returns the array of property names and symbols.
 */


function baseGetAllKeys(object, keysFunc, symbolsFunc) {
  var result = keysFunc(object);
  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));
}
/**
 * The base implementation of `getTag`.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */


function baseGetTag(value) {
  return objectToString.call(value);
}
/**
 * The base implementation of `_.isNative` without bad shim checks.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a native function,
 *  else `false`.
 */


function baseIsNative(value) {
  if (!isObject(value) || isMasked(value)) {
    return false;
  }

  var pattern = isFunction(value) || isHostObject(value) ? reIsNative : reIsHostCtor;
  return pattern.test(toSource(value));
}
/**
 * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 */


function baseKeys(object) {
  if (!isPrototype(object)) {
    return nativeKeys(object);
  }

  var result = [];

  for (var key in Object(object)) {
    if (hasOwnProperty.call(object, key) && key != 'constructor') {
      result.push(key);
    }
  }

  return result;
}
/**
 * Creates a clone of  `buffer`.
 *
 * @private
 * @param {Buffer} buffer The buffer to clone.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Buffer} Returns the cloned buffer.
 */


function cloneBuffer(buffer, isDeep) {
  if (isDeep) {
    return buffer.slice();
  }

  var result = new buffer.constructor(buffer.length);
  buffer.copy(result);
  return result;
}
/**
 * Creates a clone of `arrayBuffer`.
 *
 * @private
 * @param {ArrayBuffer} arrayBuffer The array buffer to clone.
 * @returns {ArrayBuffer} Returns the cloned array buffer.
 */


function cloneArrayBuffer(arrayBuffer) {
  var result = new arrayBuffer.constructor(arrayBuffer.byteLength);
  new Uint8Array(result).set(new Uint8Array(arrayBuffer));
  return result;
}
/**
 * Creates a clone of `dataView`.
 *
 * @private
 * @param {Object} dataView The data view to clone.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the cloned data view.
 */


function cloneDataView(dataView, isDeep) {
  var buffer = isDeep ? cloneArrayBuffer(dataView.buffer) : dataView.buffer;
  return new dataView.constructor(buffer, dataView.byteOffset, dataView.byteLength);
}
/**
 * Creates a clone of `map`.
 *
 * @private
 * @param {Object} map The map to clone.
 * @param {Function} cloneFunc The function to clone values.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the cloned map.
 */


function cloneMap(map, isDeep, cloneFunc) {
  var array = isDeep ? cloneFunc(mapToArray(map), true) : mapToArray(map);
  return arrayReduce(array, addMapEntry, new map.constructor());
}
/**
 * Creates a clone of `regexp`.
 *
 * @private
 * @param {Object} regexp The regexp to clone.
 * @returns {Object} Returns the cloned regexp.
 */


function cloneRegExp(regexp) {
  var result = new regexp.constructor(regexp.source, reFlags.exec(regexp));
  result.lastIndex = regexp.lastIndex;
  return result;
}
/**
 * Creates a clone of `set`.
 *
 * @private
 * @param {Object} set The set to clone.
 * @param {Function} cloneFunc The function to clone values.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the cloned set.
 */


function cloneSet(set, isDeep, cloneFunc) {
  var array = isDeep ? cloneFunc(setToArray(set), true) : setToArray(set);
  return arrayReduce(array, addSetEntry, new set.constructor());
}
/**
 * Creates a clone of the `symbol` object.
 *
 * @private
 * @param {Object} symbol The symbol object to clone.
 * @returns {Object} Returns the cloned symbol object.
 */


function cloneSymbol(symbol) {
  return symbolValueOf ? Object(symbolValueOf.call(symbol)) : {};
}
/**
 * Creates a clone of `typedArray`.
 *
 * @private
 * @param {Object} typedArray The typed array to clone.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the cloned typed array.
 */


function cloneTypedArray(typedArray, isDeep) {
  var buffer = isDeep ? cloneArrayBuffer(typedArray.buffer) : typedArray.buffer;
  return new typedArray.constructor(buffer, typedArray.byteOffset, typedArray.length);
}
/**
 * Copies the values of `source` to `array`.
 *
 * @private
 * @param {Array} source The array to copy values from.
 * @param {Array} [array=[]] The array to copy values to.
 * @returns {Array} Returns `array`.
 */


function copyArray(source, array) {
  var index = -1,
      length = source.length;
  array || (array = Array(length));

  while (++index < length) {
    array[index] = source[index];
  }

  return array;
}
/**
 * Copies properties of `source` to `object`.
 *
 * @private
 * @param {Object} source The object to copy properties from.
 * @param {Array} props The property identifiers to copy.
 * @param {Object} [object={}] The object to copy properties to.
 * @param {Function} [customizer] The function to customize copied values.
 * @returns {Object} Returns `object`.
 */


function copyObject(source, props, object, customizer) {
  object || (object = {});
  var index = -1,
      length = props.length;

  while (++index < length) {
    var key = props[index];
    var newValue = customizer ? customizer(object[key], source[key], key, object, source) : undefined;
    assignValue(object, key, newValue === undefined ? source[key] : newValue);
  }

  return object;
}
/**
 * Copies own symbol properties of `source` to `object`.
 *
 * @private
 * @param {Object} source The object to copy symbols from.
 * @param {Object} [object={}] The object to copy symbols to.
 * @returns {Object} Returns `object`.
 */


function copySymbols(source, object) {
  return copyObject(source, getSymbols(source), object);
}
/**
 * Creates an array of own enumerable property names and symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names and symbols.
 */


function getAllKeys(object) {
  return baseGetAllKeys(object, keys, getSymbols);
}
/**
 * Gets the data for `map`.
 *
 * @private
 * @param {Object} map The map to query.
 * @param {string} key The reference key.
 * @returns {*} Returns the map data.
 */


function getMapData(map, key) {
  var data = map.__data__;
  return isKeyable(key) ? data[typeof key == 'string' ? 'string' : 'hash'] : data.map;
}
/**
 * Gets the native function at `key` of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {string} key The key of the method to get.
 * @returns {*} Returns the function if it's native, else `undefined`.
 */


function getNative(object, key) {
  var value = getValue(object, key);
  return baseIsNative(value) ? value : undefined;
}
/**
 * Creates an array of the own enumerable symbol properties of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of symbols.
 */


var getSymbols = nativeGetSymbols ? overArg(nativeGetSymbols, Object) : stubArray;
/**
 * Gets the `toStringTag` of `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */

var getTag = baseGetTag; // Fallback for data views, maps, sets, and weak maps in IE 11,
// for data views in Edge < 14, and promises in Node.js.

if (DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag || Map && getTag(new Map()) != mapTag || Promise && getTag(Promise.resolve()) != promiseTag || Set && getTag(new Set()) != setTag || WeakMap && getTag(new WeakMap()) != weakMapTag) {
  getTag = function (value) {
    var result = objectToString.call(value),
        Ctor = result == objectTag ? value.constructor : undefined,
        ctorString = Ctor ? toSource(Ctor) : undefined;

    if (ctorString) {
      switch (ctorString) {
        case dataViewCtorString:
          return dataViewTag;

        case mapCtorString:
          return mapTag;

        case promiseCtorString:
          return promiseTag;

        case setCtorString:
          return setTag;

        case weakMapCtorString:
          return weakMapTag;
      }
    }

    return result;
  };
}
/**
 * Initializes an array clone.
 *
 * @private
 * @param {Array} array The array to clone.
 * @returns {Array} Returns the initialized clone.
 */


function initCloneArray(array) {
  var length = array.length,
      result = array.constructor(length); // Add properties assigned by `RegExp#exec`.

  if (length && typeof array[0] == 'string' && hasOwnProperty.call(array, 'index')) {
    result.index = array.index;
    result.input = array.input;
  }

  return result;
}
/**
 * Initializes an object clone.
 *
 * @private
 * @param {Object} object The object to clone.
 * @returns {Object} Returns the initialized clone.
 */


function initCloneObject(object) {
  return typeof object.constructor == 'function' && !isPrototype(object) ? baseCreate(getPrototype(object)) : {};
}
/**
 * Initializes an object clone based on its `toStringTag`.
 *
 * **Note:** This function only supports cloning values with tags of
 * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.
 *
 * @private
 * @param {Object} object The object to clone.
 * @param {string} tag The `toStringTag` of the object to clone.
 * @param {Function} cloneFunc The function to clone values.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the initialized clone.
 */


function initCloneByTag(object, tag, cloneFunc, isDeep) {
  var Ctor = object.constructor;

  switch (tag) {
    case arrayBufferTag:
      return cloneArrayBuffer(object);

    case boolTag:
    case dateTag:
      return new Ctor(+object);

    case dataViewTag:
      return cloneDataView(object, isDeep);

    case float32Tag:
    case float64Tag:
    case int8Tag:
    case int16Tag:
    case int32Tag:
    case uint8Tag:
    case uint8ClampedTag:
    case uint16Tag:
    case uint32Tag:
      return cloneTypedArray(object, isDeep);

    case mapTag:
      return cloneMap(object, isDeep, cloneFunc);

    case numberTag:
    case stringTag:
      return new Ctor(object);

    case regexpTag:
      return cloneRegExp(object);

    case setTag:
      return cloneSet(object, isDeep, cloneFunc);

    case symbolTag:
      return cloneSymbol(object);
  }
}
/**
 * Checks if `value` is a valid array-like index.
 *
 * @private
 * @param {*} value The value to check.
 * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.
 * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.
 */


function isIndex(value, length) {
  length = length == null ? MAX_SAFE_INTEGER : length;
  return !!length && (typeof value == 'number' || reIsUint.test(value)) && value > -1 && value % 1 == 0 && value < length;
}
/**
 * Checks if `value` is suitable for use as unique object key.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is suitable, else `false`.
 */


function isKeyable(value) {
  var type = typeof value;
  return type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean' ? value !== '__proto__' : value === null;
}
/**
 * Checks if `func` has its source masked.
 *
 * @private
 * @param {Function} func The function to check.
 * @returns {boolean} Returns `true` if `func` is masked, else `false`.
 */


function isMasked(func) {
  return !!maskSrcKey && maskSrcKey in func;
}
/**
 * Checks if `value` is likely a prototype object.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.
 */


function isPrototype(value) {
  var Ctor = value && value.constructor,
      proto = typeof Ctor == 'function' && Ctor.prototype || objectProto;
  return value === proto;
}
/**
 * Converts `func` to its source code.
 *
 * @private
 * @param {Function} func The function to process.
 * @returns {string} Returns the source code.
 */


function toSource(func) {
  if (func != null) {
    try {
      return funcToString.call(func);
    } catch (e) {}

    try {
      return func + '';
    } catch (e) {}
  }

  return '';
}
/**
 * This method is like `_.clone` except that it recursively clones `value`.
 *
 * @static
 * @memberOf _
 * @since 1.0.0
 * @category Lang
 * @param {*} value The value to recursively clone.
 * @returns {*} Returns the deep cloned value.
 * @see _.clone
 * @example
 *
 * var objects = [{ 'a': 1 }, { 'b': 2 }];
 *
 * var deep = _.cloneDeep(objects);
 * console.log(deep[0] === objects[0]);
 * // => false
 */


function cloneDeep(value) {
  return baseClone(value, true, true);
}
/**
 * Performs a
 * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)
 * comparison between two values to determine if they are equivalent.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 * @example
 *
 * var object = { 'a': 1 };
 * var other = { 'a': 1 };
 *
 * _.eq(object, object);
 * // => true
 *
 * _.eq(object, other);
 * // => false
 *
 * _.eq('a', 'a');
 * // => true
 *
 * _.eq('a', Object('a'));
 * // => false
 *
 * _.eq(NaN, NaN);
 * // => true
 */


function eq(value, other) {
  return value === other || value !== value && other !== other;
}
/**
 * Checks if `value` is likely an `arguments` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an `arguments` object,
 *  else `false`.
 * @example
 *
 * _.isArguments(function() { return arguments; }());
 * // => true
 *
 * _.isArguments([1, 2, 3]);
 * // => false
 */


function isArguments(value) {
  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.
  return isArrayLikeObject(value) && hasOwnProperty.call(value, 'callee') && (!propertyIsEnumerable.call(value, 'callee') || objectToString.call(value) == argsTag);
}
/**
 * Checks if `value` is classified as an `Array` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an array, else `false`.
 * @example
 *
 * _.isArray([1, 2, 3]);
 * // => true
 *
 * _.isArray(document.body.children);
 * // => false
 *
 * _.isArray('abc');
 * // => false
 *
 * _.isArray(_.noop);
 * // => false
 */


var isArray = Array.isArray;
/**
 * Checks if `value` is array-like. A value is considered array-like if it's
 * not a function and has a `value.length` that's an integer greater than or
 * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is array-like, else `false`.
 * @example
 *
 * _.isArrayLike([1, 2, 3]);
 * // => true
 *
 * _.isArrayLike(document.body.children);
 * // => true
 *
 * _.isArrayLike('abc');
 * // => true
 *
 * _.isArrayLike(_.noop);
 * // => false
 */

function isArrayLike(value) {
  return value != null && isLength(value.length) && !isFunction(value);
}
/**
 * This method is like `_.isArrayLike` except that it also checks if `value`
 * is an object.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an array-like object,
 *  else `false`.
 * @example
 *
 * _.isArrayLikeObject([1, 2, 3]);
 * // => true
 *
 * _.isArrayLikeObject(document.body.children);
 * // => true
 *
 * _.isArrayLikeObject('abc');
 * // => false
 *
 * _.isArrayLikeObject(_.noop);
 * // => false
 */


function isArrayLikeObject(value) {
  return isObjectLike(value) && isArrayLike(value);
}
/**
 * Checks if `value` is a buffer.
 *
 * @static
 * @memberOf _
 * @since 4.3.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.
 * @example
 *
 * _.isBuffer(new Buffer(2));
 * // => true
 *
 * _.isBuffer(new Uint8Array(2));
 * // => false
 */


var isBuffer = nativeIsBuffer || stubFalse;
/**
 * Checks if `value` is classified as a `Function` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a function, else `false`.
 * @example
 *
 * _.isFunction(_);
 * // => true
 *
 * _.isFunction(/abc/);
 * // => false
 */

function isFunction(value) {
  // The use of `Object#toString` avoids issues with the `typeof` operator
  // in Safari 8-9 which returns 'object' for typed array and other constructors.
  var tag = isObject(value) ? objectToString.call(value) : '';
  return tag == funcTag || tag == genTag;
}
/**
 * Checks if `value` is a valid array-like length.
 *
 * **Note:** This method is loosely based on
 * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.
 * @example
 *
 * _.isLength(3);
 * // => true
 *
 * _.isLength(Number.MIN_VALUE);
 * // => false
 *
 * _.isLength(Infinity);
 * // => false
 *
 * _.isLength('3');
 * // => false
 */


function isLength(value) {
  return typeof value == 'number' && value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;
}
/**
 * Checks if `value` is the
 * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)
 * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an object, else `false`.
 * @example
 *
 * _.isObject({});
 * // => true
 *
 * _.isObject([1, 2, 3]);
 * // => true
 *
 * _.isObject(_.noop);
 * // => true
 *
 * _.isObject(null);
 * // => false
 */


function isObject(value) {
  var type = typeof value;
  return !!value && (type == 'object' || type == 'function');
}
/**
 * Checks if `value` is object-like. A value is object-like if it's not `null`
 * and has a `typeof` result of "object".
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is object-like, else `false`.
 * @example
 *
 * _.isObjectLike({});
 * // => true
 *
 * _.isObjectLike([1, 2, 3]);
 * // => true
 *
 * _.isObjectLike(_.noop);
 * // => false
 *
 * _.isObjectLike(null);
 * // => false
 */


function isObjectLike(value) {
  return !!value && typeof value == 'object';
}
/**
 * Creates an array of the own enumerable property names of `object`.
 *
 * **Note:** Non-object values are coerced to objects. See the
 * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)
 * for more details.
 *
 * @static
 * @since 0.1.0
 * @memberOf _
 * @category Object
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 * @example
 *
 * function Foo() {
 *   this.a = 1;
 *   this.b = 2;
 * }
 *
 * Foo.prototype.c = 3;
 *
 * _.keys(new Foo);
 * // => ['a', 'b'] (iteration order is not guaranteed)
 *
 * _.keys('hi');
 * // => ['0', '1']
 */


function keys(object) {
  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);
}
/**
 * This method returns a new empty array.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {Array} Returns the new empty array.
 * @example
 *
 * var arrays = _.times(2, _.stubArray);
 *
 * console.log(arrays);
 * // => [[], []]
 *
 * console.log(arrays[0] === arrays[1]);
 * // => false
 */


function stubArray() {
  return [];
}
/**
 * This method returns `false`.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {boolean} Returns `false`.
 * @example
 *
 * _.times(2, _.stubFalse);
 * // => [false, false]
 */


function stubFalse() {
  return false;
}

module.exports = cloneDeep;
/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js"), __webpack_require__(/*! ./../webpack/buildin/module.js */ "./node_modules/webpack/buildin/module.js")(module)))

/***/ }),

/***/ "./node_modules/lodash.isequal/index.js":
/*!**********************************************!*\
  !*** ./node_modules/lodash.isequal/index.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(global, module) {/**
 * Lodash (Custom Build) <https://lodash.com/>
 * Build: `lodash modularize exports="npm" -o ./`
 * Copyright JS Foundation and other contributors <https://js.foundation/>
 * Released under MIT license <https://lodash.com/license>
 * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>
 * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors
 */

/** Used as the size to enable large array optimizations. */
var LARGE_ARRAY_SIZE = 200;
/** Used to stand-in for `undefined` hash values. */

var HASH_UNDEFINED = '__lodash_hash_undefined__';
/** Used to compose bitmasks for value comparisons. */

var COMPARE_PARTIAL_FLAG = 1,
    COMPARE_UNORDERED_FLAG = 2;
/** Used as references for various `Number` constants. */

var MAX_SAFE_INTEGER = 9007199254740991;
/** `Object#toString` result references. */

var argsTag = '[object Arguments]',
    arrayTag = '[object Array]',
    asyncTag = '[object AsyncFunction]',
    boolTag = '[object Boolean]',
    dateTag = '[object Date]',
    errorTag = '[object Error]',
    funcTag = '[object Function]',
    genTag = '[object GeneratorFunction]',
    mapTag = '[object Map]',
    numberTag = '[object Number]',
    nullTag = '[object Null]',
    objectTag = '[object Object]',
    promiseTag = '[object Promise]',
    proxyTag = '[object Proxy]',
    regexpTag = '[object RegExp]',
    setTag = '[object Set]',
    stringTag = '[object String]',
    symbolTag = '[object Symbol]',
    undefinedTag = '[object Undefined]',
    weakMapTag = '[object WeakMap]';
var arrayBufferTag = '[object ArrayBuffer]',
    dataViewTag = '[object DataView]',
    float32Tag = '[object Float32Array]',
    float64Tag = '[object Float64Array]',
    int8Tag = '[object Int8Array]',
    int16Tag = '[object Int16Array]',
    int32Tag = '[object Int32Array]',
    uint8Tag = '[object Uint8Array]',
    uint8ClampedTag = '[object Uint8ClampedArray]',
    uint16Tag = '[object Uint16Array]',
    uint32Tag = '[object Uint32Array]';
/**
 * Used to match `RegExp`
 * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).
 */

var reRegExpChar = /[\\^$.*+?()[\]{}|]/g;
/** Used to detect host constructors (Safari). */

var reIsHostCtor = /^\[object .+?Constructor\]$/;
/** Used to detect unsigned integer values. */

var reIsUint = /^(?:0|[1-9]\d*)$/;
/** Used to identify `toStringTag` values of typed arrays. */

var typedArrayTags = {};
typedArrayTags[float32Tag] = typedArrayTags[float64Tag] = typedArrayTags[int8Tag] = typedArrayTags[int16Tag] = typedArrayTags[int32Tag] = typedArrayTags[uint8Tag] = typedArrayTags[uint8ClampedTag] = typedArrayTags[uint16Tag] = typedArrayTags[uint32Tag] = true;
typedArrayTags[argsTag] = typedArrayTags[arrayTag] = typedArrayTags[arrayBufferTag] = typedArrayTags[boolTag] = typedArrayTags[dataViewTag] = typedArrayTags[dateTag] = typedArrayTags[errorTag] = typedArrayTags[funcTag] = typedArrayTags[mapTag] = typedArrayTags[numberTag] = typedArrayTags[objectTag] = typedArrayTags[regexpTag] = typedArrayTags[setTag] = typedArrayTags[stringTag] = typedArrayTags[weakMapTag] = false;
/** Detect free variable `global` from Node.js. */

var freeGlobal = typeof global == 'object' && global && global.Object === Object && global;
/** Detect free variable `self`. */

var freeSelf = typeof self == 'object' && self && self.Object === Object && self;
/** Used as a reference to the global object. */

var root = freeGlobal || freeSelf || Function('return this')();
/** Detect free variable `exports`. */

var freeExports =  true && exports && !exports.nodeType && exports;
/** Detect free variable `module`. */

var freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;
/** Detect the popular CommonJS extension `module.exports`. */

var moduleExports = freeModule && freeModule.exports === freeExports;
/** Detect free variable `process` from Node.js. */

var freeProcess = moduleExports && freeGlobal.process;
/** Used to access faster Node.js helpers. */

var nodeUtil = function () {
  try {
    return freeProcess && freeProcess.binding && freeProcess.binding('util');
  } catch (e) {}
}();
/* Node.js helper references. */


var nodeIsTypedArray = nodeUtil && nodeUtil.isTypedArray;
/**
 * A specialized version of `_.filter` for arrays without support for
 * iteratee shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} predicate The function invoked per iteration.
 * @returns {Array} Returns the new filtered array.
 */

function arrayFilter(array, predicate) {
  var index = -1,
      length = array == null ? 0 : array.length,
      resIndex = 0,
      result = [];

  while (++index < length) {
    var value = array[index];

    if (predicate(value, index, array)) {
      result[resIndex++] = value;
    }
  }

  return result;
}
/**
 * Appends the elements of `values` to `array`.
 *
 * @private
 * @param {Array} array The array to modify.
 * @param {Array} values The values to append.
 * @returns {Array} Returns `array`.
 */


function arrayPush(array, values) {
  var index = -1,
      length = values.length,
      offset = array.length;

  while (++index < length) {
    array[offset + index] = values[index];
  }

  return array;
}
/**
 * A specialized version of `_.some` for arrays without support for iteratee
 * shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} predicate The function invoked per iteration.
 * @returns {boolean} Returns `true` if any element passes the predicate check,
 *  else `false`.
 */


function arraySome(array, predicate) {
  var index = -1,
      length = array == null ? 0 : array.length;

  while (++index < length) {
    if (predicate(array[index], index, array)) {
      return true;
    }
  }

  return false;
}
/**
 * The base implementation of `_.times` without support for iteratee shorthands
 * or max array length checks.
 *
 * @private
 * @param {number} n The number of times to invoke `iteratee`.
 * @param {Function} iteratee The function invoked per iteration.
 * @returns {Array} Returns the array of results.
 */


function baseTimes(n, iteratee) {
  var index = -1,
      result = Array(n);

  while (++index < n) {
    result[index] = iteratee(index);
  }

  return result;
}
/**
 * The base implementation of `_.unary` without support for storing metadata.
 *
 * @private
 * @param {Function} func The function to cap arguments for.
 * @returns {Function} Returns the new capped function.
 */


function baseUnary(func) {
  return function (value) {
    return func(value);
  };
}
/**
 * Checks if a `cache` value for `key` exists.
 *
 * @private
 * @param {Object} cache The cache to query.
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */


function cacheHas(cache, key) {
  return cache.has(key);
}
/**
 * Gets the value at `key` of `object`.
 *
 * @private
 * @param {Object} [object] The object to query.
 * @param {string} key The key of the property to get.
 * @returns {*} Returns the property value.
 */


function getValue(object, key) {
  return object == null ? undefined : object[key];
}
/**
 * Converts `map` to its key-value pairs.
 *
 * @private
 * @param {Object} map The map to convert.
 * @returns {Array} Returns the key-value pairs.
 */


function mapToArray(map) {
  var index = -1,
      result = Array(map.size);
  map.forEach(function (value, key) {
    result[++index] = [key, value];
  });
  return result;
}
/**
 * Creates a unary function that invokes `func` with its argument transformed.
 *
 * @private
 * @param {Function} func The function to wrap.
 * @param {Function} transform The argument transform.
 * @returns {Function} Returns the new function.
 */


function overArg(func, transform) {
  return function (arg) {
    return func(transform(arg));
  };
}
/**
 * Converts `set` to an array of its values.
 *
 * @private
 * @param {Object} set The set to convert.
 * @returns {Array} Returns the values.
 */


function setToArray(set) {
  var index = -1,
      result = Array(set.size);
  set.forEach(function (value) {
    result[++index] = value;
  });
  return result;
}
/** Used for built-in method references. */


var arrayProto = Array.prototype,
    funcProto = Function.prototype,
    objectProto = Object.prototype;
/** Used to detect overreaching core-js shims. */

var coreJsData = root['__core-js_shared__'];
/** Used to resolve the decompiled source of functions. */

var funcToString = funcProto.toString;
/** Used to check objects for own properties. */

var hasOwnProperty = objectProto.hasOwnProperty;
/** Used to detect methods masquerading as native. */

var maskSrcKey = function () {
  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');
  return uid ? 'Symbol(src)_1.' + uid : '';
}();
/**
 * Used to resolve the
 * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)
 * of values.
 */


var nativeObjectToString = objectProto.toString;
/** Used to detect if a method is native. */

var reIsNative = RegExp('^' + funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\$&').replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g, '$1.*?') + '$');
/** Built-in value references. */

var Buffer = moduleExports ? root.Buffer : undefined,
    Symbol = root.Symbol,
    Uint8Array = root.Uint8Array,
    propertyIsEnumerable = objectProto.propertyIsEnumerable,
    splice = arrayProto.splice,
    symToStringTag = Symbol ? Symbol.toStringTag : undefined;
/* Built-in method references for those with the same name as other `lodash` methods. */

var nativeGetSymbols = Object.getOwnPropertySymbols,
    nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined,
    nativeKeys = overArg(Object.keys, Object);
/* Built-in method references that are verified to be native. */

var DataView = getNative(root, 'DataView'),
    Map = getNative(root, 'Map'),
    Promise = getNative(root, 'Promise'),
    Set = getNative(root, 'Set'),
    WeakMap = getNative(root, 'WeakMap'),
    nativeCreate = getNative(Object, 'create');
/** Used to detect maps, sets, and weakmaps. */

var dataViewCtorString = toSource(DataView),
    mapCtorString = toSource(Map),
    promiseCtorString = toSource(Promise),
    setCtorString = toSource(Set),
    weakMapCtorString = toSource(WeakMap);
/** Used to convert symbols to primitives and strings. */

var symbolProto = Symbol ? Symbol.prototype : undefined,
    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;
/**
 * Creates a hash object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */

function Hash(entries) {
  var index = -1,
      length = entries == null ? 0 : entries.length;
  this.clear();

  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}
/**
 * Removes all key-value entries from the hash.
 *
 * @private
 * @name clear
 * @memberOf Hash
 */


function hashClear() {
  this.__data__ = nativeCreate ? nativeCreate(null) : {};
  this.size = 0;
}
/**
 * Removes `key` and its value from the hash.
 *
 * @private
 * @name delete
 * @memberOf Hash
 * @param {Object} hash The hash to modify.
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */


function hashDelete(key) {
  var result = this.has(key) && delete this.__data__[key];
  this.size -= result ? 1 : 0;
  return result;
}
/**
 * Gets the hash value for `key`.
 *
 * @private
 * @name get
 * @memberOf Hash
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */


function hashGet(key) {
  var data = this.__data__;

  if (nativeCreate) {
    var result = data[key];
    return result === HASH_UNDEFINED ? undefined : result;
  }

  return hasOwnProperty.call(data, key) ? data[key] : undefined;
}
/**
 * Checks if a hash value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Hash
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */


function hashHas(key) {
  var data = this.__data__;
  return nativeCreate ? data[key] !== undefined : hasOwnProperty.call(data, key);
}
/**
 * Sets the hash `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Hash
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the hash instance.
 */


function hashSet(key, value) {
  var data = this.__data__;
  this.size += this.has(key) ? 0 : 1;
  data[key] = nativeCreate && value === undefined ? HASH_UNDEFINED : value;
  return this;
} // Add methods to `Hash`.


Hash.prototype.clear = hashClear;
Hash.prototype['delete'] = hashDelete;
Hash.prototype.get = hashGet;
Hash.prototype.has = hashHas;
Hash.prototype.set = hashSet;
/**
 * Creates an list cache object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */

function ListCache(entries) {
  var index = -1,
      length = entries == null ? 0 : entries.length;
  this.clear();

  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}
/**
 * Removes all key-value entries from the list cache.
 *
 * @private
 * @name clear
 * @memberOf ListCache
 */


function listCacheClear() {
  this.__data__ = [];
  this.size = 0;
}
/**
 * Removes `key` and its value from the list cache.
 *
 * @private
 * @name delete
 * @memberOf ListCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */


function listCacheDelete(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    return false;
  }

  var lastIndex = data.length - 1;

  if (index == lastIndex) {
    data.pop();
  } else {
    splice.call(data, index, 1);
  }

  --this.size;
  return true;
}
/**
 * Gets the list cache value for `key`.
 *
 * @private
 * @name get
 * @memberOf ListCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */


function listCacheGet(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);
  return index < 0 ? undefined : data[index][1];
}
/**
 * Checks if a list cache value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf ListCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */


function listCacheHas(key) {
  return assocIndexOf(this.__data__, key) > -1;
}
/**
 * Sets the list cache `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf ListCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the list cache instance.
 */


function listCacheSet(key, value) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    ++this.size;
    data.push([key, value]);
  } else {
    data[index][1] = value;
  }

  return this;
} // Add methods to `ListCache`.


ListCache.prototype.clear = listCacheClear;
ListCache.prototype['delete'] = listCacheDelete;
ListCache.prototype.get = listCacheGet;
ListCache.prototype.has = listCacheHas;
ListCache.prototype.set = listCacheSet;
/**
 * Creates a map cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */

function MapCache(entries) {
  var index = -1,
      length = entries == null ? 0 : entries.length;
  this.clear();

  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}
/**
 * Removes all key-value entries from the map.
 *
 * @private
 * @name clear
 * @memberOf MapCache
 */


function mapCacheClear() {
  this.size = 0;
  this.__data__ = {
    'hash': new Hash(),
    'map': new (Map || ListCache)(),
    'string': new Hash()
  };
}
/**
 * Removes `key` and its value from the map.
 *
 * @private
 * @name delete
 * @memberOf MapCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */


function mapCacheDelete(key) {
  var result = getMapData(this, key)['delete'](key);
  this.size -= result ? 1 : 0;
  return result;
}
/**
 * Gets the map value for `key`.
 *
 * @private
 * @name get
 * @memberOf MapCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */


function mapCacheGet(key) {
  return getMapData(this, key).get(key);
}
/**
 * Checks if a map value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf MapCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */


function mapCacheHas(key) {
  return getMapData(this, key).has(key);
}
/**
 * Sets the map `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf MapCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the map cache instance.
 */


function mapCacheSet(key, value) {
  var data = getMapData(this, key),
      size = data.size;
  data.set(key, value);
  this.size += data.size == size ? 0 : 1;
  return this;
} // Add methods to `MapCache`.


MapCache.prototype.clear = mapCacheClear;
MapCache.prototype['delete'] = mapCacheDelete;
MapCache.prototype.get = mapCacheGet;
MapCache.prototype.has = mapCacheHas;
MapCache.prototype.set = mapCacheSet;
/**
 *
 * Creates an array cache object to store unique values.
 *
 * @private
 * @constructor
 * @param {Array} [values] The values to cache.
 */

function SetCache(values) {
  var index = -1,
      length = values == null ? 0 : values.length;
  this.__data__ = new MapCache();

  while (++index < length) {
    this.add(values[index]);
  }
}
/**
 * Adds `value` to the array cache.
 *
 * @private
 * @name add
 * @memberOf SetCache
 * @alias push
 * @param {*} value The value to cache.
 * @returns {Object} Returns the cache instance.
 */


function setCacheAdd(value) {
  this.__data__.set(value, HASH_UNDEFINED);

  return this;
}
/**
 * Checks if `value` is in the array cache.
 *
 * @private
 * @name has
 * @memberOf SetCache
 * @param {*} value The value to search for.
 * @returns {number} Returns `true` if `value` is found, else `false`.
 */


function setCacheHas(value) {
  return this.__data__.has(value);
} // Add methods to `SetCache`.


SetCache.prototype.add = SetCache.prototype.push = setCacheAdd;
SetCache.prototype.has = setCacheHas;
/**
 * Creates a stack cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */

function Stack(entries) {
  var data = this.__data__ = new ListCache(entries);
  this.size = data.size;
}
/**
 * Removes all key-value entries from the stack.
 *
 * @private
 * @name clear
 * @memberOf Stack
 */


function stackClear() {
  this.__data__ = new ListCache();
  this.size = 0;
}
/**
 * Removes `key` and its value from the stack.
 *
 * @private
 * @name delete
 * @memberOf Stack
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */


function stackDelete(key) {
  var data = this.__data__,
      result = data['delete'](key);
  this.size = data.size;
  return result;
}
/**
 * Gets the stack value for `key`.
 *
 * @private
 * @name get
 * @memberOf Stack
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */


function stackGet(key) {
  return this.__data__.get(key);
}
/**
 * Checks if a stack value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Stack
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */


function stackHas(key) {
  return this.__data__.has(key);
}
/**
 * Sets the stack `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Stack
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the stack cache instance.
 */


function stackSet(key, value) {
  var data = this.__data__;

  if (data instanceof ListCache) {
    var pairs = data.__data__;

    if (!Map || pairs.length < LARGE_ARRAY_SIZE - 1) {
      pairs.push([key, value]);
      this.size = ++data.size;
      return this;
    }

    data = this.__data__ = new MapCache(pairs);
  }

  data.set(key, value);
  this.size = data.size;
  return this;
} // Add methods to `Stack`.


Stack.prototype.clear = stackClear;
Stack.prototype['delete'] = stackDelete;
Stack.prototype.get = stackGet;
Stack.prototype.has = stackHas;
Stack.prototype.set = stackSet;
/**
 * Creates an array of the enumerable property names of the array-like `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @param {boolean} inherited Specify returning inherited property names.
 * @returns {Array} Returns the array of property names.
 */

function arrayLikeKeys(value, inherited) {
  var isArr = isArray(value),
      isArg = !isArr && isArguments(value),
      isBuff = !isArr && !isArg && isBuffer(value),
      isType = !isArr && !isArg && !isBuff && isTypedArray(value),
      skipIndexes = isArr || isArg || isBuff || isType,
      result = skipIndexes ? baseTimes(value.length, String) : [],
      length = result.length;

  for (var key in value) {
    if ((inherited || hasOwnProperty.call(value, key)) && !(skipIndexes && ( // Safari 9 has enumerable `arguments.length` in strict mode.
    key == 'length' || // Node.js 0.10 has enumerable non-index properties on buffers.
    isBuff && (key == 'offset' || key == 'parent') || // PhantomJS 2 has enumerable non-index properties on typed arrays.
    isType && (key == 'buffer' || key == 'byteLength' || key == 'byteOffset') || // Skip index properties.
    isIndex(key, length)))) {
      result.push(key);
    }
  }

  return result;
}
/**
 * Gets the index at which the `key` is found in `array` of key-value pairs.
 *
 * @private
 * @param {Array} array The array to inspect.
 * @param {*} key The key to search for.
 * @returns {number} Returns the index of the matched value, else `-1`.
 */


function assocIndexOf(array, key) {
  var length = array.length;

  while (length--) {
    if (eq(array[length][0], key)) {
      return length;
    }
  }

  return -1;
}
/**
 * The base implementation of `getAllKeys` and `getAllKeysIn` which uses
 * `keysFunc` and `symbolsFunc` to get the enumerable property names and
 * symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {Function} keysFunc The function to get the keys of `object`.
 * @param {Function} symbolsFunc The function to get the symbols of `object`.
 * @returns {Array} Returns the array of property names and symbols.
 */


function baseGetAllKeys(object, keysFunc, symbolsFunc) {
  var result = keysFunc(object);
  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));
}
/**
 * The base implementation of `getTag` without fallbacks for buggy environments.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */


function baseGetTag(value) {
  if (value == null) {
    return value === undefined ? undefinedTag : nullTag;
  }

  return symToStringTag && symToStringTag in Object(value) ? getRawTag(value) : objectToString(value);
}
/**
 * The base implementation of `_.isArguments`.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an `arguments` object,
 */


function baseIsArguments(value) {
  return isObjectLike(value) && baseGetTag(value) == argsTag;
}
/**
 * The base implementation of `_.isEqual` which supports partial comparisons
 * and tracks traversed objects.
 *
 * @private
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @param {boolean} bitmask The bitmask flags.
 *  1 - Unordered comparison
 *  2 - Partial comparison
 * @param {Function} [customizer] The function to customize comparisons.
 * @param {Object} [stack] Tracks traversed `value` and `other` objects.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 */


function baseIsEqual(value, other, bitmask, customizer, stack) {
  if (value === other) {
    return true;
  }

  if (value == null || other == null || !isObjectLike(value) && !isObjectLike(other)) {
    return value !== value && other !== other;
  }

  return baseIsEqualDeep(value, other, bitmask, customizer, baseIsEqual, stack);
}
/**
 * A specialized version of `baseIsEqual` for arrays and objects which performs
 * deep comparisons and tracks traversed objects enabling objects with circular
 * references to be compared.
 *
 * @private
 * @param {Object} object The object to compare.
 * @param {Object} other The other object to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} [stack] Tracks traversed `object` and `other` objects.
 * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.
 */


function baseIsEqualDeep(object, other, bitmask, customizer, equalFunc, stack) {
  var objIsArr = isArray(object),
      othIsArr = isArray(other),
      objTag = objIsArr ? arrayTag : getTag(object),
      othTag = othIsArr ? arrayTag : getTag(other);
  objTag = objTag == argsTag ? objectTag : objTag;
  othTag = othTag == argsTag ? objectTag : othTag;
  var objIsObj = objTag == objectTag,
      othIsObj = othTag == objectTag,
      isSameTag = objTag == othTag;

  if (isSameTag && isBuffer(object)) {
    if (!isBuffer(other)) {
      return false;
    }

    objIsArr = true;
    objIsObj = false;
  }

  if (isSameTag && !objIsObj) {
    stack || (stack = new Stack());
    return objIsArr || isTypedArray(object) ? equalArrays(object, other, bitmask, customizer, equalFunc, stack) : equalByTag(object, other, objTag, bitmask, customizer, equalFunc, stack);
  }

  if (!(bitmask & COMPARE_PARTIAL_FLAG)) {
    var objIsWrapped = objIsObj && hasOwnProperty.call(object, '__wrapped__'),
        othIsWrapped = othIsObj && hasOwnProperty.call(other, '__wrapped__');

    if (objIsWrapped || othIsWrapped) {
      var objUnwrapped = objIsWrapped ? object.value() : object,
          othUnwrapped = othIsWrapped ? other.value() : other;
      stack || (stack = new Stack());
      return equalFunc(objUnwrapped, othUnwrapped, bitmask, customizer, stack);
    }
  }

  if (!isSameTag) {
    return false;
  }

  stack || (stack = new Stack());
  return equalObjects(object, other, bitmask, customizer, equalFunc, stack);
}
/**
 * The base implementation of `_.isNative` without bad shim checks.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a native function,
 *  else `false`.
 */


function baseIsNative(value) {
  if (!isObject(value) || isMasked(value)) {
    return false;
  }

  var pattern = isFunction(value) ? reIsNative : reIsHostCtor;
  return pattern.test(toSource(value));
}
/**
 * The base implementation of `_.isTypedArray` without Node.js optimizations.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.
 */


function baseIsTypedArray(value) {
  return isObjectLike(value) && isLength(value.length) && !!typedArrayTags[baseGetTag(value)];
}
/**
 * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 */


function baseKeys(object) {
  if (!isPrototype(object)) {
    return nativeKeys(object);
  }

  var result = [];

  for (var key in Object(object)) {
    if (hasOwnProperty.call(object, key) && key != 'constructor') {
      result.push(key);
    }
  }

  return result;
}
/**
 * A specialized version of `baseIsEqualDeep` for arrays with support for
 * partial deep comparisons.
 *
 * @private
 * @param {Array} array The array to compare.
 * @param {Array} other The other array to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} stack Tracks traversed `array` and `other` objects.
 * @returns {boolean} Returns `true` if the arrays are equivalent, else `false`.
 */


function equalArrays(array, other, bitmask, customizer, equalFunc, stack) {
  var isPartial = bitmask & COMPARE_PARTIAL_FLAG,
      arrLength = array.length,
      othLength = other.length;

  if (arrLength != othLength && !(isPartial && othLength > arrLength)) {
    return false;
  } // Assume cyclic values are equal.


  var stacked = stack.get(array);

  if (stacked && stack.get(other)) {
    return stacked == other;
  }

  var index = -1,
      result = true,
      seen = bitmask & COMPARE_UNORDERED_FLAG ? new SetCache() : undefined;
  stack.set(array, other);
  stack.set(other, array); // Ignore non-index properties.

  while (++index < arrLength) {
    var arrValue = array[index],
        othValue = other[index];

    if (customizer) {
      var compared = isPartial ? customizer(othValue, arrValue, index, other, array, stack) : customizer(arrValue, othValue, index, array, other, stack);
    }

    if (compared !== undefined) {
      if (compared) {
        continue;
      }

      result = false;
      break;
    } // Recursively compare arrays (susceptible to call stack limits).


    if (seen) {
      if (!arraySome(other, function (othValue, othIndex) {
        if (!cacheHas(seen, othIndex) && (arrValue === othValue || equalFunc(arrValue, othValue, bitmask, customizer, stack))) {
          return seen.push(othIndex);
        }
      })) {
        result = false;
        break;
      }
    } else if (!(arrValue === othValue || equalFunc(arrValue, othValue, bitmask, customizer, stack))) {
      result = false;
      break;
    }
  }

  stack['delete'](array);
  stack['delete'](other);
  return result;
}
/**
 * A specialized version of `baseIsEqualDeep` for comparing objects of
 * the same `toStringTag`.
 *
 * **Note:** This function only supports comparing values with tags of
 * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.
 *
 * @private
 * @param {Object} object The object to compare.
 * @param {Object} other The other object to compare.
 * @param {string} tag The `toStringTag` of the objects to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} stack Tracks traversed `object` and `other` objects.
 * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.
 */


function equalByTag(object, other, tag, bitmask, customizer, equalFunc, stack) {
  switch (tag) {
    case dataViewTag:
      if (object.byteLength != other.byteLength || object.byteOffset != other.byteOffset) {
        return false;
      }

      object = object.buffer;
      other = other.buffer;

    case arrayBufferTag:
      if (object.byteLength != other.byteLength || !equalFunc(new Uint8Array(object), new Uint8Array(other))) {
        return false;
      }

      return true;

    case boolTag:
    case dateTag:
    case numberTag:
      // Coerce booleans to `1` or `0` and dates to milliseconds.
      // Invalid dates are coerced to `NaN`.
      return eq(+object, +other);

    case errorTag:
      return object.name == other.name && object.message == other.message;

    case regexpTag:
    case stringTag:
      // Coerce regexes to strings and treat strings, primitives and objects,
      // as equal. See http://www.ecma-international.org/ecma-262/7.0/#sec-regexp.prototype.tostring
      // for more details.
      return object == other + '';

    case mapTag:
      var convert = mapToArray;

    case setTag:
      var isPartial = bitmask & COMPARE_PARTIAL_FLAG;
      convert || (convert = setToArray);

      if (object.size != other.size && !isPartial) {
        return false;
      } // Assume cyclic values are equal.


      var stacked = stack.get(object);

      if (stacked) {
        return stacked == other;
      }

      bitmask |= COMPARE_UNORDERED_FLAG; // Recursively compare objects (susceptible to call stack limits).

      stack.set(object, other);
      var result = equalArrays(convert(object), convert(other), bitmask, customizer, equalFunc, stack);
      stack['delete'](object);
      return result;

    case symbolTag:
      if (symbolValueOf) {
        return symbolValueOf.call(object) == symbolValueOf.call(other);
      }

  }

  return false;
}
/**
 * A specialized version of `baseIsEqualDeep` for objects with support for
 * partial deep comparisons.
 *
 * @private
 * @param {Object} object The object to compare.
 * @param {Object} other The other object to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} stack Tracks traversed `object` and `other` objects.
 * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.
 */


function equalObjects(object, other, bitmask, customizer, equalFunc, stack) {
  var isPartial = bitmask & COMPARE_PARTIAL_FLAG,
      objProps = getAllKeys(object),
      objLength = objProps.length,
      othProps = getAllKeys(other),
      othLength = othProps.length;

  if (objLength != othLength && !isPartial) {
    return false;
  }

  var index = objLength;

  while (index--) {
    var key = objProps[index];

    if (!(isPartial ? key in other : hasOwnProperty.call(other, key))) {
      return false;
    }
  } // Assume cyclic values are equal.


  var stacked = stack.get(object);

  if (stacked && stack.get(other)) {
    return stacked == other;
  }

  var result = true;
  stack.set(object, other);
  stack.set(other, object);
  var skipCtor = isPartial;

  while (++index < objLength) {
    key = objProps[index];
    var objValue = object[key],
        othValue = other[key];

    if (customizer) {
      var compared = isPartial ? customizer(othValue, objValue, key, other, object, stack) : customizer(objValue, othValue, key, object, other, stack);
    } // Recursively compare objects (susceptible to call stack limits).


    if (!(compared === undefined ? objValue === othValue || equalFunc(objValue, othValue, bitmask, customizer, stack) : compared)) {
      result = false;
      break;
    }

    skipCtor || (skipCtor = key == 'constructor');
  }

  if (result && !skipCtor) {
    var objCtor = object.constructor,
        othCtor = other.constructor; // Non `Object` object instances with different constructors are not equal.

    if (objCtor != othCtor && 'constructor' in object && 'constructor' in other && !(typeof objCtor == 'function' && objCtor instanceof objCtor && typeof othCtor == 'function' && othCtor instanceof othCtor)) {
      result = false;
    }
  }

  stack['delete'](object);
  stack['delete'](other);
  return result;
}
/**
 * Creates an array of own enumerable property names and symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names and symbols.
 */


function getAllKeys(object) {
  return baseGetAllKeys(object, keys, getSymbols);
}
/**
 * Gets the data for `map`.
 *
 * @private
 * @param {Object} map The map to query.
 * @param {string} key The reference key.
 * @returns {*} Returns the map data.
 */


function getMapData(map, key) {
  var data = map.__data__;
  return isKeyable(key) ? data[typeof key == 'string' ? 'string' : 'hash'] : data.map;
}
/**
 * Gets the native function at `key` of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {string} key The key of the method to get.
 * @returns {*} Returns the function if it's native, else `undefined`.
 */


function getNative(object, key) {
  var value = getValue(object, key);
  return baseIsNative(value) ? value : undefined;
}
/**
 * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the raw `toStringTag`.
 */


function getRawTag(value) {
  var isOwn = hasOwnProperty.call(value, symToStringTag),
      tag = value[symToStringTag];

  try {
    value[symToStringTag] = undefined;
    var unmasked = true;
  } catch (e) {}

  var result = nativeObjectToString.call(value);

  if (unmasked) {
    if (isOwn) {
      value[symToStringTag] = tag;
    } else {
      delete value[symToStringTag];
    }
  }

  return result;
}
/**
 * Creates an array of the own enumerable symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of symbols.
 */


var getSymbols = !nativeGetSymbols ? stubArray : function (object) {
  if (object == null) {
    return [];
  }

  object = Object(object);
  return arrayFilter(nativeGetSymbols(object), function (symbol) {
    return propertyIsEnumerable.call(object, symbol);
  });
};
/**
 * Gets the `toStringTag` of `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */

var getTag = baseGetTag; // Fallback for data views, maps, sets, and weak maps in IE 11 and promises in Node.js < 6.

if (DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag || Map && getTag(new Map()) != mapTag || Promise && getTag(Promise.resolve()) != promiseTag || Set && getTag(new Set()) != setTag || WeakMap && getTag(new WeakMap()) != weakMapTag) {
  getTag = function (value) {
    var result = baseGetTag(value),
        Ctor = result == objectTag ? value.constructor : undefined,
        ctorString = Ctor ? toSource(Ctor) : '';

    if (ctorString) {
      switch (ctorString) {
        case dataViewCtorString:
          return dataViewTag;

        case mapCtorString:
          return mapTag;

        case promiseCtorString:
          return promiseTag;

        case setCtorString:
          return setTag;

        case weakMapCtorString:
          return weakMapTag;
      }
    }

    return result;
  };
}
/**
 * Checks if `value` is a valid array-like index.
 *
 * @private
 * @param {*} value The value to check.
 * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.
 * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.
 */


function isIndex(value, length) {
  length = length == null ? MAX_SAFE_INTEGER : length;
  return !!length && (typeof value == 'number' || reIsUint.test(value)) && value > -1 && value % 1 == 0 && value < length;
}
/**
 * Checks if `value` is suitable for use as unique object key.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is suitable, else `false`.
 */


function isKeyable(value) {
  var type = typeof value;
  return type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean' ? value !== '__proto__' : value === null;
}
/**
 * Checks if `func` has its source masked.
 *
 * @private
 * @param {Function} func The function to check.
 * @returns {boolean} Returns `true` if `func` is masked, else `false`.
 */


function isMasked(func) {
  return !!maskSrcKey && maskSrcKey in func;
}
/**
 * Checks if `value` is likely a prototype object.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.
 */


function isPrototype(value) {
  var Ctor = value && value.constructor,
      proto = typeof Ctor == 'function' && Ctor.prototype || objectProto;
  return value === proto;
}
/**
 * Converts `value` to a string using `Object.prototype.toString`.
 *
 * @private
 * @param {*} value The value to convert.
 * @returns {string} Returns the converted string.
 */


function objectToString(value) {
  return nativeObjectToString.call(value);
}
/**
 * Converts `func` to its source code.
 *
 * @private
 * @param {Function} func The function to convert.
 * @returns {string} Returns the source code.
 */


function toSource(func) {
  if (func != null) {
    try {
      return funcToString.call(func);
    } catch (e) {}

    try {
      return func + '';
    } catch (e) {}
  }

  return '';
}
/**
 * Performs a
 * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)
 * comparison between two values to determine if they are equivalent.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 * @example
 *
 * var object = { 'a': 1 };
 * var other = { 'a': 1 };
 *
 * _.eq(object, object);
 * // => true
 *
 * _.eq(object, other);
 * // => false
 *
 * _.eq('a', 'a');
 * // => true
 *
 * _.eq('a', Object('a'));
 * // => false
 *
 * _.eq(NaN, NaN);
 * // => true
 */


function eq(value, other) {
  return value === other || value !== value && other !== other;
}
/**
 * Checks if `value` is likely an `arguments` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an `arguments` object,
 *  else `false`.
 * @example
 *
 * _.isArguments(function() { return arguments; }());
 * // => true
 *
 * _.isArguments([1, 2, 3]);
 * // => false
 */


var isArguments = baseIsArguments(function () {
  return arguments;
}()) ? baseIsArguments : function (value) {
  return isObjectLike(value) && hasOwnProperty.call(value, 'callee') && !propertyIsEnumerable.call(value, 'callee');
};
/**
 * Checks if `value` is classified as an `Array` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an array, else `false`.
 * @example
 *
 * _.isArray([1, 2, 3]);
 * // => true
 *
 * _.isArray(document.body.children);
 * // => false
 *
 * _.isArray('abc');
 * // => false
 *
 * _.isArray(_.noop);
 * // => false
 */

var isArray = Array.isArray;
/**
 * Checks if `value` is array-like. A value is considered array-like if it's
 * not a function and has a `value.length` that's an integer greater than or
 * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is array-like, else `false`.
 * @example
 *
 * _.isArrayLike([1, 2, 3]);
 * // => true
 *
 * _.isArrayLike(document.body.children);
 * // => true
 *
 * _.isArrayLike('abc');
 * // => true
 *
 * _.isArrayLike(_.noop);
 * // => false
 */

function isArrayLike(value) {
  return value != null && isLength(value.length) && !isFunction(value);
}
/**
 * Checks if `value` is a buffer.
 *
 * @static
 * @memberOf _
 * @since 4.3.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.
 * @example
 *
 * _.isBuffer(new Buffer(2));
 * // => true
 *
 * _.isBuffer(new Uint8Array(2));
 * // => false
 */


var isBuffer = nativeIsBuffer || stubFalse;
/**
 * Performs a deep comparison between two values to determine if they are
 * equivalent.
 *
 * **Note:** This method supports comparing arrays, array buffers, booleans,
 * date objects, error objects, maps, numbers, `Object` objects, regexes,
 * sets, strings, symbols, and typed arrays. `Object` objects are compared
 * by their own, not inherited, enumerable properties. Functions and DOM
 * nodes are compared by strict equality, i.e. `===`.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 * @example
 *
 * var object = { 'a': 1 };
 * var other = { 'a': 1 };
 *
 * _.isEqual(object, other);
 * // => true
 *
 * object === other;
 * // => false
 */

function isEqual(value, other) {
  return baseIsEqual(value, other);
}
/**
 * Checks if `value` is classified as a `Function` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a function, else `false`.
 * @example
 *
 * _.isFunction(_);
 * // => true
 *
 * _.isFunction(/abc/);
 * // => false
 */


function isFunction(value) {
  if (!isObject(value)) {
    return false;
  } // The use of `Object#toString` avoids issues with the `typeof` operator
  // in Safari 9 which returns 'object' for typed arrays and other constructors.


  var tag = baseGetTag(value);
  return tag == funcTag || tag == genTag || tag == asyncTag || tag == proxyTag;
}
/**
 * Checks if `value` is a valid array-like length.
 *
 * **Note:** This method is loosely based on
 * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.
 * @example
 *
 * _.isLength(3);
 * // => true
 *
 * _.isLength(Number.MIN_VALUE);
 * // => false
 *
 * _.isLength(Infinity);
 * // => false
 *
 * _.isLength('3');
 * // => false
 */


function isLength(value) {
  return typeof value == 'number' && value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;
}
/**
 * Checks if `value` is the
 * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)
 * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an object, else `false`.
 * @example
 *
 * _.isObject({});
 * // => true
 *
 * _.isObject([1, 2, 3]);
 * // => true
 *
 * _.isObject(_.noop);
 * // => true
 *
 * _.isObject(null);
 * // => false
 */


function isObject(value) {
  var type = typeof value;
  return value != null && (type == 'object' || type == 'function');
}
/**
 * Checks if `value` is object-like. A value is object-like if it's not `null`
 * and has a `typeof` result of "object".
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is object-like, else `false`.
 * @example
 *
 * _.isObjectLike({});
 * // => true
 *
 * _.isObjectLike([1, 2, 3]);
 * // => true
 *
 * _.isObjectLike(_.noop);
 * // => false
 *
 * _.isObjectLike(null);
 * // => false
 */


function isObjectLike(value) {
  return value != null && typeof value == 'object';
}
/**
 * Checks if `value` is classified as a typed array.
 *
 * @static
 * @memberOf _
 * @since 3.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.
 * @example
 *
 * _.isTypedArray(new Uint8Array);
 * // => true
 *
 * _.isTypedArray([]);
 * // => false
 */


var isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;
/**
 * Creates an array of the own enumerable property names of `object`.
 *
 * **Note:** Non-object values are coerced to objects. See the
 * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)
 * for more details.
 *
 * @static
 * @since 0.1.0
 * @memberOf _
 * @category Object
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 * @example
 *
 * function Foo() {
 *   this.a = 1;
 *   this.b = 2;
 * }
 *
 * Foo.prototype.c = 3;
 *
 * _.keys(new Foo);
 * // => ['a', 'b'] (iteration order is not guaranteed)
 *
 * _.keys('hi');
 * // => ['0', '1']
 */

function keys(object) {
  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);
}
/**
 * This method returns a new empty array.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {Array} Returns the new empty array.
 * @example
 *
 * var arrays = _.times(2, _.stubArray);
 *
 * console.log(arrays);
 * // => [[], []]
 *
 * console.log(arrays[0] === arrays[1]);
 * // => false
 */


function stubArray() {
  return [];
}
/**
 * This method returns `false`.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {boolean} Returns `false`.
 * @example
 *
 * _.times(2, _.stubFalse);
 * // => [false, false]
 */


function stubFalse() {
  return false;
}

module.exports = isEqual;
/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js"), __webpack_require__(/*! ./../webpack/buildin/module.js */ "./node_modules/webpack/buildin/module.js")(module)))

/***/ }),

/***/ "./node_modules/process/browser.js":
/*!*****************************************!*\
  !*** ./node_modules/process/browser.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// shim for using process in browser
var process = module.exports = {}; // cached from whatever global is present so that test runners that stub it
// don't break things.  But we need to wrap it in a try catch in case it is
// wrapped in strict mode code which doesn't define any globals.  It's inside a
// function because try/catches deoptimize in certain engines.

var cachedSetTimeout;
var cachedClearTimeout;

function defaultSetTimout() {
  throw new Error('setTimeout has not been defined');
}

function defaultClearTimeout() {
  throw new Error('clearTimeout has not been defined');
}

(function () {
  try {
    if (typeof setTimeout === 'function') {
      cachedSetTimeout = setTimeout;
    } else {
      cachedSetTimeout = defaultSetTimout;
    }
  } catch (e) {
    cachedSetTimeout = defaultSetTimout;
  }

  try {
    if (typeof clearTimeout === 'function') {
      cachedClearTimeout = clearTimeout;
    } else {
      cachedClearTimeout = defaultClearTimeout;
    }
  } catch (e) {
    cachedClearTimeout = defaultClearTimeout;
  }
})();

function runTimeout(fun) {
  if (cachedSetTimeout === setTimeout) {
    //normal enviroments in sane situations
    return setTimeout(fun, 0);
  } // if setTimeout wasn't available but was latter defined


  if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
    cachedSetTimeout = setTimeout;
    return setTimeout(fun, 0);
  }

  try {
    // when when somebody has screwed with setTimeout but no I.E. maddness
    return cachedSetTimeout(fun, 0);
  } catch (e) {
    try {
      // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
      return cachedSetTimeout.call(null, fun, 0);
    } catch (e) {
      // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
      return cachedSetTimeout.call(this, fun, 0);
    }
  }
}

function runClearTimeout(marker) {
  if (cachedClearTimeout === clearTimeout) {
    //normal enviroments in sane situations
    return clearTimeout(marker);
  } // if clearTimeout wasn't available but was latter defined


  if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
    cachedClearTimeout = clearTimeout;
    return clearTimeout(marker);
  }

  try {
    // when when somebody has screwed with setTimeout but no I.E. maddness
    return cachedClearTimeout(marker);
  } catch (e) {
    try {
      // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
      return cachedClearTimeout.call(null, marker);
    } catch (e) {
      // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
      // Some versions of I.E. have different rules for clearTimeout vs setTimeout
      return cachedClearTimeout.call(this, marker);
    }
  }
}

var queue = [];
var draining = false;
var currentQueue;
var queueIndex = -1;

function cleanUpNextTick() {
  if (!draining || !currentQueue) {
    return;
  }

  draining = false;

  if (currentQueue.length) {
    queue = currentQueue.concat(queue);
  } else {
    queueIndex = -1;
  }

  if (queue.length) {
    drainQueue();
  }
}

function drainQueue() {
  if (draining) {
    return;
  }

  var timeout = runTimeout(cleanUpNextTick);
  draining = true;
  var len = queue.length;

  while (len) {
    currentQueue = queue;
    queue = [];

    while (++queueIndex < len) {
      if (currentQueue) {
        currentQueue[queueIndex].run();
      }
    }

    queueIndex = -1;
    len = queue.length;
  }

  currentQueue = null;
  draining = false;
  runClearTimeout(timeout);
}

process.nextTick = function (fun) {
  var args = new Array(arguments.length - 1);

  if (arguments.length > 1) {
    for (var i = 1; i < arguments.length; i++) {
      args[i - 1] = arguments[i];
    }
  }

  queue.push(new Item(fun, args));

  if (queue.length === 1 && !draining) {
    runTimeout(drainQueue);
  }
}; // v8 likes predictible objects


function Item(fun, array) {
  this.fun = fun;
  this.array = array;
}

Item.prototype.run = function () {
  this.fun.apply(null, this.array);
};

process.title = 'browser';
process.browser = true;
process.env = {};
process.argv = [];
process.version = ''; // empty string to avoid regexp issues

process.versions = {};

function noop() {}

process.on = noop;
process.addListener = noop;
process.once = noop;
process.off = noop;
process.removeListener = noop;
process.removeAllListeners = noop;
process.emit = noop;
process.prependListener = noop;
process.prependOnceListener = noop;

process.listeners = function (name) {
  return [];
};

process.binding = function (name) {
  throw new Error('process.binding is not supported');
};

process.cwd = function () {
  return '/';
};

process.chdir = function (dir) {
  throw new Error('process.chdir is not supported');
};

process.umask = function () {
  return 0;
};

/***/ }),

/***/ "./node_modules/rtcpeerconnection-shim/rtcpeerconnection.js":
/*!******************************************************************!*\
  !*** ./node_modules/rtcpeerconnection-shim/rtcpeerconnection.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/*
 *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */


var SDPUtils = __webpack_require__(/*! sdp */ "./node_modules/sdp/sdp.js");

function fixStatsType(stat) {
  return {
    inboundrtp: 'inbound-rtp',
    outboundrtp: 'outbound-rtp',
    candidatepair: 'candidate-pair',
    localcandidate: 'local-candidate',
    remotecandidate: 'remote-candidate'
  }[stat.type] || stat.type;
}

function writeMediaSection(transceiver, caps, type, stream, dtlsRole) {
  var sdp = SDPUtils.writeRtpDescription(transceiver.kind, caps); // Map ICE parameters (ufrag, pwd) to SDP.

  sdp += SDPUtils.writeIceParameters(transceiver.iceGatherer.getLocalParameters()); // Map DTLS parameters to SDP.

  sdp += SDPUtils.writeDtlsParameters(transceiver.dtlsTransport.getLocalParameters(), type === 'offer' ? 'actpass' : dtlsRole || 'active');
  sdp += 'a=mid:' + transceiver.mid + '\r\n';

  if (transceiver.rtpSender && transceiver.rtpReceiver) {
    sdp += 'a=sendrecv\r\n';
  } else if (transceiver.rtpSender) {
    sdp += 'a=sendonly\r\n';
  } else if (transceiver.rtpReceiver) {
    sdp += 'a=recvonly\r\n';
  } else {
    sdp += 'a=inactive\r\n';
  }

  if (transceiver.rtpSender) {
    var trackId = transceiver.rtpSender._initialTrackId || transceiver.rtpSender.track.id;
    transceiver.rtpSender._initialTrackId = trackId; // spec.

    var msid = 'msid:' + (stream ? stream.id : '-') + ' ' + trackId + '\r\n';
    sdp += 'a=' + msid; // for Chrome. Legacy should no longer be required.

    sdp += 'a=ssrc:' + transceiver.sendEncodingParameters[0].ssrc + ' ' + msid; // RTX

    if (transceiver.sendEncodingParameters[0].rtx) {
      sdp += 'a=ssrc:' + transceiver.sendEncodingParameters[0].rtx.ssrc + ' ' + msid;
      sdp += 'a=ssrc-group:FID ' + transceiver.sendEncodingParameters[0].ssrc + ' ' + transceiver.sendEncodingParameters[0].rtx.ssrc + '\r\n';
    }
  } // FIXME: this should be written by writeRtpDescription.


  sdp += 'a=ssrc:' + transceiver.sendEncodingParameters[0].ssrc + ' cname:' + SDPUtils.localCName + '\r\n';

  if (transceiver.rtpSender && transceiver.sendEncodingParameters[0].rtx) {
    sdp += 'a=ssrc:' + transceiver.sendEncodingParameters[0].rtx.ssrc + ' cname:' + SDPUtils.localCName + '\r\n';
  }

  return sdp;
} // Edge does not like
// 1) stun: filtered after 14393 unless ?transport=udp is present
// 2) turn: that does not have all of turn:host:port?transport=udp
// 3) turn: with ipv6 addresses
// 4) turn: occurring muliple times


function filterIceServers(iceServers, edgeVersion) {
  var hasTurn = false;
  iceServers = JSON.parse(JSON.stringify(iceServers));
  return iceServers.filter(function (server) {
    if (server && (server.urls || server.url)) {
      var urls = server.urls || server.url;

      if (server.url && !server.urls) {
        console.warn('RTCIceServer.url is deprecated! Use urls instead.');
      }

      var isString = typeof urls === 'string';

      if (isString) {
        urls = [urls];
      }

      urls = urls.filter(function (url) {
        var validTurn = url.indexOf('turn:') === 0 && url.indexOf('transport=udp') !== -1 && url.indexOf('turn:[') === -1 && !hasTurn;

        if (validTurn) {
          hasTurn = true;
          return true;
        }

        return url.indexOf('stun:') === 0 && edgeVersion >= 14393 && url.indexOf('?transport=udp') === -1;
      });
      delete server.url;
      server.urls = isString ? urls[0] : urls;
      return !!urls.length;
    }
  });
} // Determines the intersection of local and remote capabilities.


function getCommonCapabilities(localCapabilities, remoteCapabilities) {
  var commonCapabilities = {
    codecs: [],
    headerExtensions: [],
    fecMechanisms: []
  };

  var findCodecByPayloadType = function (pt, codecs) {
    pt = parseInt(pt, 10);

    for (var i = 0; i < codecs.length; i++) {
      if (codecs[i].payloadType === pt || codecs[i].preferredPayloadType === pt) {
        return codecs[i];
      }
    }
  };

  var rtxCapabilityMatches = function (lRtx, rRtx, lCodecs, rCodecs) {
    var lCodec = findCodecByPayloadType(lRtx.parameters.apt, lCodecs);
    var rCodec = findCodecByPayloadType(rRtx.parameters.apt, rCodecs);
    return lCodec && rCodec && lCodec.name.toLowerCase() === rCodec.name.toLowerCase();
  };

  localCapabilities.codecs.forEach(function (lCodec) {
    for (var i = 0; i < remoteCapabilities.codecs.length; i++) {
      var rCodec = remoteCapabilities.codecs[i];

      if (lCodec.name.toLowerCase() === rCodec.name.toLowerCase() && lCodec.clockRate === rCodec.clockRate) {
        if (lCodec.name.toLowerCase() === 'rtx' && lCodec.parameters && rCodec.parameters.apt) {
          // for RTX we need to find the local rtx that has a apt
          // which points to the same local codec as the remote one.
          if (!rtxCapabilityMatches(lCodec, rCodec, localCapabilities.codecs, remoteCapabilities.codecs)) {
            continue;
          }
        }

        rCodec = JSON.parse(JSON.stringify(rCodec)); // deepcopy
        // number of channels is the highest common number of channels

        rCodec.numChannels = Math.min(lCodec.numChannels, rCodec.numChannels); // push rCodec so we reply with offerer payload type

        commonCapabilities.codecs.push(rCodec); // determine common feedback mechanisms

        rCodec.rtcpFeedback = rCodec.rtcpFeedback.filter(function (fb) {
          for (var j = 0; j < lCodec.rtcpFeedback.length; j++) {
            if (lCodec.rtcpFeedback[j].type === fb.type && lCodec.rtcpFeedback[j].parameter === fb.parameter) {
              return true;
            }
          }

          return false;
        }); // FIXME: also need to determine .parameters
        //  see https://github.com/openpeer/ortc/issues/569

        break;
      }
    }
  });
  localCapabilities.headerExtensions.forEach(function (lHeaderExtension) {
    for (var i = 0; i < remoteCapabilities.headerExtensions.length; i++) {
      var rHeaderExtension = remoteCapabilities.headerExtensions[i];

      if (lHeaderExtension.uri === rHeaderExtension.uri) {
        commonCapabilities.headerExtensions.push(rHeaderExtension);
        break;
      }
    }
  }); // FIXME: fecMechanisms

  return commonCapabilities;
} // is action=setLocalDescription with type allowed in signalingState


function isActionAllowedInSignalingState(action, type, signalingState) {
  return {
    offer: {
      setLocalDescription: ['stable', 'have-local-offer'],
      setRemoteDescription: ['stable', 'have-remote-offer']
    },
    answer: {
      setLocalDescription: ['have-remote-offer', 'have-local-pranswer'],
      setRemoteDescription: ['have-local-offer', 'have-remote-pranswer']
    }
  }[type][action].indexOf(signalingState) !== -1;
}

function maybeAddCandidate(iceTransport, candidate) {
  // Edge's internal representation adds some fields therefore
  // not all fieldѕ are taken into account.
  var alreadyAdded = iceTransport.getRemoteCandidates().find(function (remoteCandidate) {
    return candidate.foundation === remoteCandidate.foundation && candidate.ip === remoteCandidate.ip && candidate.port === remoteCandidate.port && candidate.priority === remoteCandidate.priority && candidate.protocol === remoteCandidate.protocol && candidate.type === remoteCandidate.type;
  });

  if (!alreadyAdded) {
    iceTransport.addRemoteCandidate(candidate);
  }

  return !alreadyAdded;
}

function makeError(name, description) {
  var e = new Error(description);
  e.name = name; // legacy error codes from https://heycam.github.io/webidl/#idl-DOMException-error-names

  e.code = {
    NotSupportedError: 9,
    InvalidStateError: 11,
    InvalidAccessError: 15,
    TypeError: undefined,
    OperationError: undefined
  }[name];
  return e;
}

module.exports = function (window, edgeVersion) {
  // https://w3c.github.io/mediacapture-main/#mediastream
  // Helper function to add the track to the stream and
  // dispatch the event ourselves.
  function addTrackToStreamAndFireEvent(track, stream) {
    stream.addTrack(track);
    stream.dispatchEvent(new window.MediaStreamTrackEvent('addtrack', {
      track: track
    }));
  }

  function removeTrackFromStreamAndFireEvent(track, stream) {
    stream.removeTrack(track);
    stream.dispatchEvent(new window.MediaStreamTrackEvent('removetrack', {
      track: track
    }));
  }

  function fireAddTrack(pc, track, receiver, streams) {
    var trackEvent = new Event('track');
    trackEvent.track = track;
    trackEvent.receiver = receiver;
    trackEvent.transceiver = {
      receiver: receiver
    };
    trackEvent.streams = streams;
    window.setTimeout(function () {
      pc._dispatchEvent('track', trackEvent);
    });
  }

  var RTCPeerConnection = function (config) {
    var pc = this;

    var _eventTarget = document.createDocumentFragment();

    ['addEventListener', 'removeEventListener', 'dispatchEvent'].forEach(function (method) {
      pc[method] = _eventTarget[method].bind(_eventTarget);
    });
    this.canTrickleIceCandidates = null;
    this.needNegotiation = false;
    this.localStreams = [];
    this.remoteStreams = [];
    this._localDescription = null;
    this._remoteDescription = null;
    this.signalingState = 'stable';
    this.iceConnectionState = 'new';
    this.connectionState = 'new';
    this.iceGatheringState = 'new';
    config = JSON.parse(JSON.stringify(config || {}));
    this.usingBundle = config.bundlePolicy === 'max-bundle';

    if (config.rtcpMuxPolicy === 'negotiate') {
      throw makeError('NotSupportedError', 'rtcpMuxPolicy \'negotiate\' is not supported');
    } else if (!config.rtcpMuxPolicy) {
      config.rtcpMuxPolicy = 'require';
    }

    switch (config.iceTransportPolicy) {
      case 'all':
      case 'relay':
        break;

      default:
        config.iceTransportPolicy = 'all';
        break;
    }

    switch (config.bundlePolicy) {
      case 'balanced':
      case 'max-compat':
      case 'max-bundle':
        break;

      default:
        config.bundlePolicy = 'balanced';
        break;
    }

    config.iceServers = filterIceServers(config.iceServers || [], edgeVersion);
    this._iceGatherers = [];

    if (config.iceCandidatePoolSize) {
      for (var i = config.iceCandidatePoolSize; i > 0; i--) {
        this._iceGatherers.push(new window.RTCIceGatherer({
          iceServers: config.iceServers,
          gatherPolicy: config.iceTransportPolicy
        }));
      }
    } else {
      config.iceCandidatePoolSize = 0;
    }

    this._config = config; // per-track iceGathers, iceTransports, dtlsTransports, rtpSenders, ...
    // everything that is needed to describe a SDP m-line.

    this.transceivers = [];
    this._sdpSessionId = SDPUtils.generateSessionId();
    this._sdpSessionVersion = 0;
    this._dtlsRole = undefined; // role for a=setup to use in answers.

    this._isClosed = false;
  };

  Object.defineProperty(RTCPeerConnection.prototype, 'localDescription', {
    configurable: true,
    get: function () {
      return this._localDescription;
    }
  });
  Object.defineProperty(RTCPeerConnection.prototype, 'remoteDescription', {
    configurable: true,
    get: function () {
      return this._remoteDescription;
    }
  }); // set up event handlers on prototype

  RTCPeerConnection.prototype.onicecandidate = null;
  RTCPeerConnection.prototype.onaddstream = null;
  RTCPeerConnection.prototype.ontrack = null;
  RTCPeerConnection.prototype.onremovestream = null;
  RTCPeerConnection.prototype.onsignalingstatechange = null;
  RTCPeerConnection.prototype.oniceconnectionstatechange = null;
  RTCPeerConnection.prototype.onconnectionstatechange = null;
  RTCPeerConnection.prototype.onicegatheringstatechange = null;
  RTCPeerConnection.prototype.onnegotiationneeded = null;
  RTCPeerConnection.prototype.ondatachannel = null;

  RTCPeerConnection.prototype._dispatchEvent = function (name, event) {
    if (this._isClosed) {
      return;
    }

    this.dispatchEvent(event);

    if (typeof this['on' + name] === 'function') {
      this['on' + name](event);
    }
  };

  RTCPeerConnection.prototype._emitGatheringStateChange = function () {
    var event = new Event('icegatheringstatechange');

    this._dispatchEvent('icegatheringstatechange', event);
  };

  RTCPeerConnection.prototype.getConfiguration = function () {
    return this._config;
  };

  RTCPeerConnection.prototype.getLocalStreams = function () {
    return this.localStreams;
  };

  RTCPeerConnection.prototype.getRemoteStreams = function () {
    return this.remoteStreams;
  }; // internal helper to create a transceiver object.
  // (which is not yet the same as the WebRTC 1.0 transceiver)


  RTCPeerConnection.prototype._createTransceiver = function (kind, doNotAdd) {
    var hasBundleTransport = this.transceivers.length > 0;
    var transceiver = {
      track: null,
      iceGatherer: null,
      iceTransport: null,
      dtlsTransport: null,
      localCapabilities: null,
      remoteCapabilities: null,
      rtpSender: null,
      rtpReceiver: null,
      kind: kind,
      mid: null,
      sendEncodingParameters: null,
      recvEncodingParameters: null,
      stream: null,
      associatedRemoteMediaStreams: [],
      wantReceive: true
    };

    if (this.usingBundle && hasBundleTransport) {
      transceiver.iceTransport = this.transceivers[0].iceTransport;
      transceiver.dtlsTransport = this.transceivers[0].dtlsTransport;
    } else {
      var transports = this._createIceAndDtlsTransports();

      transceiver.iceTransport = transports.iceTransport;
      transceiver.dtlsTransport = transports.dtlsTransport;
    }

    if (!doNotAdd) {
      this.transceivers.push(transceiver);
    }

    return transceiver;
  };

  RTCPeerConnection.prototype.addTrack = function (track, stream) {
    if (this._isClosed) {
      throw makeError('InvalidStateError', 'Attempted to call addTrack on a closed peerconnection.');
    }

    var alreadyExists = this.transceivers.find(function (s) {
      return s.track === track;
    });

    if (alreadyExists) {
      throw makeError('InvalidAccessError', 'Track already exists.');
    }

    var transceiver;

    for (var i = 0; i < this.transceivers.length; i++) {
      if (!this.transceivers[i].track && this.transceivers[i].kind === track.kind) {
        transceiver = this.transceivers[i];
      }
    }

    if (!transceiver) {
      transceiver = this._createTransceiver(track.kind);
    }

    this._maybeFireNegotiationNeeded();

    if (this.localStreams.indexOf(stream) === -1) {
      this.localStreams.push(stream);
    }

    transceiver.track = track;
    transceiver.stream = stream;
    transceiver.rtpSender = new window.RTCRtpSender(track, transceiver.dtlsTransport);
    return transceiver.rtpSender;
  };

  RTCPeerConnection.prototype.addStream = function (stream) {
    var pc = this;

    if (edgeVersion >= 15025) {
      stream.getTracks().forEach(function (track) {
        pc.addTrack(track, stream);
      });
    } else {
      // Clone is necessary for local demos mostly, attaching directly
      // to two different senders does not work (build 10547).
      // Fixed in 15025 (or earlier)
      var clonedStream = stream.clone();
      stream.getTracks().forEach(function (track, idx) {
        var clonedTrack = clonedStream.getTracks()[idx];
        track.addEventListener('enabled', function (event) {
          clonedTrack.enabled = event.enabled;
        });
      });
      clonedStream.getTracks().forEach(function (track) {
        pc.addTrack(track, clonedStream);
      });
    }
  };

  RTCPeerConnection.prototype.removeTrack = function (sender) {
    if (this._isClosed) {
      throw makeError('InvalidStateError', 'Attempted to call removeTrack on a closed peerconnection.');
    }

    if (!(sender instanceof window.RTCRtpSender)) {
      throw new TypeError('Argument 1 of RTCPeerConnection.removeTrack ' + 'does not implement interface RTCRtpSender.');
    }

    var transceiver = this.transceivers.find(function (t) {
      return t.rtpSender === sender;
    });

    if (!transceiver) {
      throw makeError('InvalidAccessError', 'Sender was not created by this connection.');
    }

    var stream = transceiver.stream;
    transceiver.rtpSender.stop();
    transceiver.rtpSender = null;
    transceiver.track = null;
    transceiver.stream = null; // remove the stream from the set of local streams

    var localStreams = this.transceivers.map(function (t) {
      return t.stream;
    });

    if (localStreams.indexOf(stream) === -1 && this.localStreams.indexOf(stream) > -1) {
      this.localStreams.splice(this.localStreams.indexOf(stream), 1);
    }

    this._maybeFireNegotiationNeeded();
  };

  RTCPeerConnection.prototype.removeStream = function (stream) {
    var pc = this;
    stream.getTracks().forEach(function (track) {
      var sender = pc.getSenders().find(function (s) {
        return s.track === track;
      });

      if (sender) {
        pc.removeTrack(sender);
      }
    });
  };

  RTCPeerConnection.prototype.getSenders = function () {
    return this.transceivers.filter(function (transceiver) {
      return !!transceiver.rtpSender;
    }).map(function (transceiver) {
      return transceiver.rtpSender;
    });
  };

  RTCPeerConnection.prototype.getReceivers = function () {
    return this.transceivers.filter(function (transceiver) {
      return !!transceiver.rtpReceiver;
    }).map(function (transceiver) {
      return transceiver.rtpReceiver;
    });
  };

  RTCPeerConnection.prototype._createIceGatherer = function (sdpMLineIndex, usingBundle) {
    var pc = this;

    if (usingBundle && sdpMLineIndex > 0) {
      return this.transceivers[0].iceGatherer;
    } else if (this._iceGatherers.length) {
      return this._iceGatherers.shift();
    }

    var iceGatherer = new window.RTCIceGatherer({
      iceServers: this._config.iceServers,
      gatherPolicy: this._config.iceTransportPolicy
    });
    Object.defineProperty(iceGatherer, 'state', {
      value: 'new',
      writable: true
    });
    this.transceivers[sdpMLineIndex].bufferedCandidateEvents = [];

    this.transceivers[sdpMLineIndex].bufferCandidates = function (event) {
      var end = !event.candidate || Object.keys(event.candidate).length === 0; // polyfill since RTCIceGatherer.state is not implemented in
      // Edge 10547 yet.

      iceGatherer.state = end ? 'completed' : 'gathering';

      if (pc.transceivers[sdpMLineIndex].bufferedCandidateEvents !== null) {
        pc.transceivers[sdpMLineIndex].bufferedCandidateEvents.push(event);
      }
    };

    iceGatherer.addEventListener('localcandidate', this.transceivers[sdpMLineIndex].bufferCandidates);
    return iceGatherer;
  }; // start gathering from an RTCIceGatherer.


  RTCPeerConnection.prototype._gather = function (mid, sdpMLineIndex) {
    var pc = this;
    var iceGatherer = this.transceivers[sdpMLineIndex].iceGatherer;

    if (iceGatherer.onlocalcandidate) {
      return;
    }

    var bufferedCandidateEvents = this.transceivers[sdpMLineIndex].bufferedCandidateEvents;
    this.transceivers[sdpMLineIndex].bufferedCandidateEvents = null;
    iceGatherer.removeEventListener('localcandidate', this.transceivers[sdpMLineIndex].bufferCandidates);

    iceGatherer.onlocalcandidate = function (evt) {
      if (pc.usingBundle && sdpMLineIndex > 0) {
        // if we know that we use bundle we can drop candidates with
        // ѕdpMLineIndex > 0. If we don't do this then our state gets
        // confused since we dispose the extra ice gatherer.
        return;
      }

      var event = new Event('icecandidate');
      event.candidate = {
        sdpMid: mid,
        sdpMLineIndex: sdpMLineIndex
      };
      var cand = evt.candidate; // Edge emits an empty object for RTCIceCandidateComplete‥

      var end = !cand || Object.keys(cand).length === 0;

      if (end) {
        // polyfill since RTCIceGatherer.state is not implemented in
        // Edge 10547 yet.
        if (iceGatherer.state === 'new' || iceGatherer.state === 'gathering') {
          iceGatherer.state = 'completed';
        }
      } else {
        if (iceGatherer.state === 'new') {
          iceGatherer.state = 'gathering';
        } // RTCIceCandidate doesn't have a component, needs to be added


        cand.component = 1; // also the usernameFragment. TODO: update SDP to take both variants.

        cand.ufrag = iceGatherer.getLocalParameters().usernameFragment;
        var serializedCandidate = SDPUtils.writeCandidate(cand);
        event.candidate = Object.assign(event.candidate, SDPUtils.parseCandidate(serializedCandidate));
        event.candidate.candidate = serializedCandidate;

        event.candidate.toJSON = function () {
          return {
            candidate: event.candidate.candidate,
            sdpMid: event.candidate.sdpMid,
            sdpMLineIndex: event.candidate.sdpMLineIndex,
            usernameFragment: event.candidate.usernameFragment
          };
        };
      } // update local description.


      var sections = SDPUtils.getMediaSections(pc._localDescription.sdp);

      if (!end) {
        sections[event.candidate.sdpMLineIndex] += 'a=' + event.candidate.candidate + '\r\n';
      } else {
        sections[event.candidate.sdpMLineIndex] += 'a=end-of-candidates\r\n';
      }

      pc._localDescription.sdp = SDPUtils.getDescription(pc._localDescription.sdp) + sections.join('');
      var complete = pc.transceivers.every(function (transceiver) {
        return transceiver.iceGatherer && transceiver.iceGatherer.state === 'completed';
      });

      if (pc.iceGatheringState !== 'gathering') {
        pc.iceGatheringState = 'gathering';

        pc._emitGatheringStateChange();
      } // Emit candidate. Also emit null candidate when all gatherers are
      // complete.


      if (!end) {
        pc._dispatchEvent('icecandidate', event);
      }

      if (complete) {
        pc._dispatchEvent('icecandidate', new Event('icecandidate'));

        pc.iceGatheringState = 'complete';

        pc._emitGatheringStateChange();
      }
    }; // emit already gathered candidates.


    window.setTimeout(function () {
      bufferedCandidateEvents.forEach(function (e) {
        iceGatherer.onlocalcandidate(e);
      });
    }, 0);
  }; // Create ICE transport and DTLS transport.


  RTCPeerConnection.prototype._createIceAndDtlsTransports = function () {
    var pc = this;
    var iceTransport = new window.RTCIceTransport(null);

    iceTransport.onicestatechange = function () {
      pc._updateIceConnectionState();

      pc._updateConnectionState();
    };

    var dtlsTransport = new window.RTCDtlsTransport(iceTransport);

    dtlsTransport.ondtlsstatechange = function () {
      pc._updateConnectionState();
    };

    dtlsTransport.onerror = function () {
      // onerror does not set state to failed by itself.
      Object.defineProperty(dtlsTransport, 'state', {
        value: 'failed',
        writable: true
      });

      pc._updateConnectionState();
    };

    return {
      iceTransport: iceTransport,
      dtlsTransport: dtlsTransport
    };
  }; // Destroy ICE gatherer, ICE transport and DTLS transport.
  // Without triggering the callbacks.


  RTCPeerConnection.prototype._disposeIceAndDtlsTransports = function (sdpMLineIndex) {
    var iceGatherer = this.transceivers[sdpMLineIndex].iceGatherer;

    if (iceGatherer) {
      delete iceGatherer.onlocalcandidate;
      delete this.transceivers[sdpMLineIndex].iceGatherer;
    }

    var iceTransport = this.transceivers[sdpMLineIndex].iceTransport;

    if (iceTransport) {
      delete iceTransport.onicestatechange;
      delete this.transceivers[sdpMLineIndex].iceTransport;
    }

    var dtlsTransport = this.transceivers[sdpMLineIndex].dtlsTransport;

    if (dtlsTransport) {
      delete dtlsTransport.ondtlsstatechange;
      delete dtlsTransport.onerror;
      delete this.transceivers[sdpMLineIndex].dtlsTransport;
    }
  }; // Start the RTP Sender and Receiver for a transceiver.


  RTCPeerConnection.prototype._transceive = function (transceiver, send, recv) {
    var params = getCommonCapabilities(transceiver.localCapabilities, transceiver.remoteCapabilities);

    if (send && transceiver.rtpSender) {
      params.encodings = transceiver.sendEncodingParameters;
      params.rtcp = {
        cname: SDPUtils.localCName,
        compound: transceiver.rtcpParameters.compound
      };

      if (transceiver.recvEncodingParameters.length) {
        params.rtcp.ssrc = transceiver.recvEncodingParameters[0].ssrc;
      }

      transceiver.rtpSender.send(params);
    }

    if (recv && transceiver.rtpReceiver && params.codecs.length > 0) {
      // remove RTX field in Edge 14942
      if (transceiver.kind === 'video' && transceiver.recvEncodingParameters && edgeVersion < 15019) {
        transceiver.recvEncodingParameters.forEach(function (p) {
          delete p.rtx;
        });
      }

      if (transceiver.recvEncodingParameters.length) {
        params.encodings = transceiver.recvEncodingParameters;
      } else {
        params.encodings = [{}];
      }

      params.rtcp = {
        compound: transceiver.rtcpParameters.compound
      };

      if (transceiver.rtcpParameters.cname) {
        params.rtcp.cname = transceiver.rtcpParameters.cname;
      }

      if (transceiver.sendEncodingParameters.length) {
        params.rtcp.ssrc = transceiver.sendEncodingParameters[0].ssrc;
      }

      transceiver.rtpReceiver.receive(params);
    }
  };

  RTCPeerConnection.prototype.setLocalDescription = function (description) {
    var pc = this; // Note: pranswer is not supported.

    if (['offer', 'answer'].indexOf(description.type) === -1) {
      return Promise.reject(makeError('TypeError', 'Unsupported type "' + description.type + '"'));
    }

    if (!isActionAllowedInSignalingState('setLocalDescription', description.type, pc.signalingState) || pc._isClosed) {
      return Promise.reject(makeError('InvalidStateError', 'Can not set local ' + description.type + ' in state ' + pc.signalingState));
    }

    var sections;
    var sessionpart;

    if (description.type === 'offer') {
      // VERY limited support for SDP munging. Limited to:
      // * changing the order of codecs
      sections = SDPUtils.splitSections(description.sdp);
      sessionpart = sections.shift();
      sections.forEach(function (mediaSection, sdpMLineIndex) {
        var caps = SDPUtils.parseRtpParameters(mediaSection);
        pc.transceivers[sdpMLineIndex].localCapabilities = caps;
      });
      pc.transceivers.forEach(function (transceiver, sdpMLineIndex) {
        pc._gather(transceiver.mid, sdpMLineIndex);
      });
    } else if (description.type === 'answer') {
      sections = SDPUtils.splitSections(pc._remoteDescription.sdp);
      sessionpart = sections.shift();
      var isIceLite = SDPUtils.matchPrefix(sessionpart, 'a=ice-lite').length > 0;
      sections.forEach(function (mediaSection, sdpMLineIndex) {
        var transceiver = pc.transceivers[sdpMLineIndex];
        var iceGatherer = transceiver.iceGatherer;
        var iceTransport = transceiver.iceTransport;
        var dtlsTransport = transceiver.dtlsTransport;
        var localCapabilities = transceiver.localCapabilities;
        var remoteCapabilities = transceiver.remoteCapabilities; // treat bundle-only as not-rejected.

        var rejected = SDPUtils.isRejected(mediaSection) && SDPUtils.matchPrefix(mediaSection, 'a=bundle-only').length === 0;

        if (!rejected && !transceiver.rejected) {
          var remoteIceParameters = SDPUtils.getIceParameters(mediaSection, sessionpart);
          var remoteDtlsParameters = SDPUtils.getDtlsParameters(mediaSection, sessionpart);

          if (isIceLite) {
            remoteDtlsParameters.role = 'server';
          }

          if (!pc.usingBundle || sdpMLineIndex === 0) {
            pc._gather(transceiver.mid, sdpMLineIndex);

            if (iceTransport.state === 'new') {
              iceTransport.start(iceGatherer, remoteIceParameters, isIceLite ? 'controlling' : 'controlled');
            }

            if (dtlsTransport.state === 'new') {
              dtlsTransport.start(remoteDtlsParameters);
            }
          } // Calculate intersection of capabilities.


          var params = getCommonCapabilities(localCapabilities, remoteCapabilities); // Start the RTCRtpSender. The RTCRtpReceiver for this
          // transceiver has already been started in setRemoteDescription.

          pc._transceive(transceiver, params.codecs.length > 0, false);
        }
      });
    }

    pc._localDescription = {
      type: description.type,
      sdp: description.sdp
    };

    if (description.type === 'offer') {
      pc._updateSignalingState('have-local-offer');
    } else {
      pc._updateSignalingState('stable');
    }

    return Promise.resolve();
  };

  RTCPeerConnection.prototype.setRemoteDescription = function (description) {
    var pc = this; // Note: pranswer is not supported.

    if (['offer', 'answer'].indexOf(description.type) === -1) {
      return Promise.reject(makeError('TypeError', 'Unsupported type "' + description.type + '"'));
    }

    if (!isActionAllowedInSignalingState('setRemoteDescription', description.type, pc.signalingState) || pc._isClosed) {
      return Promise.reject(makeError('InvalidStateError', 'Can not set remote ' + description.type + ' in state ' + pc.signalingState));
    }

    var streams = {};
    pc.remoteStreams.forEach(function (stream) {
      streams[stream.id] = stream;
    });
    var receiverList = [];
    var sections = SDPUtils.splitSections(description.sdp);
    var sessionpart = sections.shift();
    var isIceLite = SDPUtils.matchPrefix(sessionpart, 'a=ice-lite').length > 0;
    var usingBundle = SDPUtils.matchPrefix(sessionpart, 'a=group:BUNDLE ').length > 0;
    pc.usingBundle = usingBundle;
    var iceOptions = SDPUtils.matchPrefix(sessionpart, 'a=ice-options:')[0];

    if (iceOptions) {
      pc.canTrickleIceCandidates = iceOptions.substr(14).split(' ').indexOf('trickle') >= 0;
    } else {
      pc.canTrickleIceCandidates = false;
    }

    sections.forEach(function (mediaSection, sdpMLineIndex) {
      var lines = SDPUtils.splitLines(mediaSection);
      var kind = SDPUtils.getKind(mediaSection); // treat bundle-only as not-rejected.

      var rejected = SDPUtils.isRejected(mediaSection) && SDPUtils.matchPrefix(mediaSection, 'a=bundle-only').length === 0;
      var protocol = lines[0].substr(2).split(' ')[2];
      var direction = SDPUtils.getDirection(mediaSection, sessionpart);
      var remoteMsid = SDPUtils.parseMsid(mediaSection);
      var mid = SDPUtils.getMid(mediaSection) || SDPUtils.generateIdentifier(); // Reject datachannels which are not implemented yet.

      if (rejected || kind === 'application' && (protocol === 'DTLS/SCTP' || protocol === 'UDP/DTLS/SCTP')) {
        // TODO: this is dangerous in the case where a non-rejected m-line
        //     becomes rejected.
        pc.transceivers[sdpMLineIndex] = {
          mid: mid,
          kind: kind,
          protocol: protocol,
          rejected: true
        };
        return;
      }

      if (!rejected && pc.transceivers[sdpMLineIndex] && pc.transceivers[sdpMLineIndex].rejected) {
        // recycle a rejected transceiver.
        pc.transceivers[sdpMLineIndex] = pc._createTransceiver(kind, true);
      }

      var transceiver;
      var iceGatherer;
      var iceTransport;
      var dtlsTransport;
      var rtpReceiver;
      var sendEncodingParameters;
      var recvEncodingParameters;
      var localCapabilities;
      var track; // FIXME: ensure the mediaSection has rtcp-mux set.

      var remoteCapabilities = SDPUtils.parseRtpParameters(mediaSection);
      var remoteIceParameters;
      var remoteDtlsParameters;

      if (!rejected) {
        remoteIceParameters = SDPUtils.getIceParameters(mediaSection, sessionpart);
        remoteDtlsParameters = SDPUtils.getDtlsParameters(mediaSection, sessionpart);
        remoteDtlsParameters.role = 'client';
      }

      recvEncodingParameters = SDPUtils.parseRtpEncodingParameters(mediaSection);
      var rtcpParameters = SDPUtils.parseRtcpParameters(mediaSection);
      var isComplete = SDPUtils.matchPrefix(mediaSection, 'a=end-of-candidates', sessionpart).length > 0;
      var cands = SDPUtils.matchPrefix(mediaSection, 'a=candidate:').map(function (cand) {
        return SDPUtils.parseCandidate(cand);
      }).filter(function (cand) {
        return cand.component === 1;
      }); // Check if we can use BUNDLE and dispose transports.

      if ((description.type === 'offer' || description.type === 'answer') && !rejected && usingBundle && sdpMLineIndex > 0 && pc.transceivers[sdpMLineIndex]) {
        pc._disposeIceAndDtlsTransports(sdpMLineIndex);

        pc.transceivers[sdpMLineIndex].iceGatherer = pc.transceivers[0].iceGatherer;
        pc.transceivers[sdpMLineIndex].iceTransport = pc.transceivers[0].iceTransport;
        pc.transceivers[sdpMLineIndex].dtlsTransport = pc.transceivers[0].dtlsTransport;

        if (pc.transceivers[sdpMLineIndex].rtpSender) {
          pc.transceivers[sdpMLineIndex].rtpSender.setTransport(pc.transceivers[0].dtlsTransport);
        }

        if (pc.transceivers[sdpMLineIndex].rtpReceiver) {
          pc.transceivers[sdpMLineIndex].rtpReceiver.setTransport(pc.transceivers[0].dtlsTransport);
        }
      }

      if (description.type === 'offer' && !rejected) {
        transceiver = pc.transceivers[sdpMLineIndex] || pc._createTransceiver(kind);
        transceiver.mid = mid;

        if (!transceiver.iceGatherer) {
          transceiver.iceGatherer = pc._createIceGatherer(sdpMLineIndex, usingBundle);
        }

        if (cands.length && transceiver.iceTransport.state === 'new') {
          if (isComplete && (!usingBundle || sdpMLineIndex === 0)) {
            transceiver.iceTransport.setRemoteCandidates(cands);
          } else {
            cands.forEach(function (candidate) {
              maybeAddCandidate(transceiver.iceTransport, candidate);
            });
          }
        }

        localCapabilities = window.RTCRtpReceiver.getCapabilities(kind); // filter RTX until additional stuff needed for RTX is implemented
        // in adapter.js

        if (edgeVersion < 15019) {
          localCapabilities.codecs = localCapabilities.codecs.filter(function (codec) {
            return codec.name !== 'rtx';
          });
        }

        sendEncodingParameters = transceiver.sendEncodingParameters || [{
          ssrc: (2 * sdpMLineIndex + 2) * 1001
        }]; // TODO: rewrite to use http://w3c.github.io/webrtc-pc/#set-associated-remote-streams

        var isNewTrack = false;

        if (direction === 'sendrecv' || direction === 'sendonly') {
          isNewTrack = !transceiver.rtpReceiver;
          rtpReceiver = transceiver.rtpReceiver || new window.RTCRtpReceiver(transceiver.dtlsTransport, kind);

          if (isNewTrack) {
            var stream;
            track = rtpReceiver.track; // FIXME: does not work with Plan B.

            if (remoteMsid && remoteMsid.stream === '-') {// no-op. a stream id of '-' means: no associated stream.
            } else if (remoteMsid) {
              if (!streams[remoteMsid.stream]) {
                streams[remoteMsid.stream] = new window.MediaStream();
                Object.defineProperty(streams[remoteMsid.stream], 'id', {
                  get: function () {
                    return remoteMsid.stream;
                  }
                });
              }

              Object.defineProperty(track, 'id', {
                get: function () {
                  return remoteMsid.track;
                }
              });
              stream = streams[remoteMsid.stream];
            } else {
              if (!streams.default) {
                streams.default = new window.MediaStream();
              }

              stream = streams.default;
            }

            if (stream) {
              addTrackToStreamAndFireEvent(track, stream);
              transceiver.associatedRemoteMediaStreams.push(stream);
            }

            receiverList.push([track, rtpReceiver, stream]);
          }
        } else if (transceiver.rtpReceiver && transceiver.rtpReceiver.track) {
          transceiver.associatedRemoteMediaStreams.forEach(function (s) {
            var nativeTrack = s.getTracks().find(function (t) {
              return t.id === transceiver.rtpReceiver.track.id;
            });

            if (nativeTrack) {
              removeTrackFromStreamAndFireEvent(nativeTrack, s);
            }
          });
          transceiver.associatedRemoteMediaStreams = [];
        }

        transceiver.localCapabilities = localCapabilities;
        transceiver.remoteCapabilities = remoteCapabilities;
        transceiver.rtpReceiver = rtpReceiver;
        transceiver.rtcpParameters = rtcpParameters;
        transceiver.sendEncodingParameters = sendEncodingParameters;
        transceiver.recvEncodingParameters = recvEncodingParameters; // Start the RTCRtpReceiver now. The RTPSender is started in
        // setLocalDescription.

        pc._transceive(pc.transceivers[sdpMLineIndex], false, isNewTrack);
      } else if (description.type === 'answer' && !rejected) {
        transceiver = pc.transceivers[sdpMLineIndex];
        iceGatherer = transceiver.iceGatherer;
        iceTransport = transceiver.iceTransport;
        dtlsTransport = transceiver.dtlsTransport;
        rtpReceiver = transceiver.rtpReceiver;
        sendEncodingParameters = transceiver.sendEncodingParameters;
        localCapabilities = transceiver.localCapabilities;
        pc.transceivers[sdpMLineIndex].recvEncodingParameters = recvEncodingParameters;
        pc.transceivers[sdpMLineIndex].remoteCapabilities = remoteCapabilities;
        pc.transceivers[sdpMLineIndex].rtcpParameters = rtcpParameters;

        if (cands.length && iceTransport.state === 'new') {
          if ((isIceLite || isComplete) && (!usingBundle || sdpMLineIndex === 0)) {
            iceTransport.setRemoteCandidates(cands);
          } else {
            cands.forEach(function (candidate) {
              maybeAddCandidate(transceiver.iceTransport, candidate);
            });
          }
        }

        if (!usingBundle || sdpMLineIndex === 0) {
          if (iceTransport.state === 'new') {
            iceTransport.start(iceGatherer, remoteIceParameters, 'controlling');
          }

          if (dtlsTransport.state === 'new') {
            dtlsTransport.start(remoteDtlsParameters);
          }
        } // If the offer contained RTX but the answer did not,
        // remove RTX from sendEncodingParameters.


        var commonCapabilities = getCommonCapabilities(transceiver.localCapabilities, transceiver.remoteCapabilities);
        var hasRtx = commonCapabilities.codecs.filter(function (c) {
          return c.name.toLowerCase() === 'rtx';
        }).length;

        if (!hasRtx && transceiver.sendEncodingParameters[0].rtx) {
          delete transceiver.sendEncodingParameters[0].rtx;
        }

        pc._transceive(transceiver, direction === 'sendrecv' || direction === 'recvonly', direction === 'sendrecv' || direction === 'sendonly'); // TODO: rewrite to use http://w3c.github.io/webrtc-pc/#set-associated-remote-streams


        if (rtpReceiver && (direction === 'sendrecv' || direction === 'sendonly')) {
          track = rtpReceiver.track;

          if (remoteMsid) {
            if (!streams[remoteMsid.stream]) {
              streams[remoteMsid.stream] = new window.MediaStream();
            }

            addTrackToStreamAndFireEvent(track, streams[remoteMsid.stream]);
            receiverList.push([track, rtpReceiver, streams[remoteMsid.stream]]);
          } else {
            if (!streams.default) {
              streams.default = new window.MediaStream();
            }

            addTrackToStreamAndFireEvent(track, streams.default);
            receiverList.push([track, rtpReceiver, streams.default]);
          }
        } else {
          // FIXME: actually the receiver should be created later.
          delete transceiver.rtpReceiver;
        }
      }
    });

    if (pc._dtlsRole === undefined) {
      pc._dtlsRole = description.type === 'offer' ? 'active' : 'passive';
    }

    pc._remoteDescription = {
      type: description.type,
      sdp: description.sdp
    };

    if (description.type === 'offer') {
      pc._updateSignalingState('have-remote-offer');
    } else {
      pc._updateSignalingState('stable');
    }

    Object.keys(streams).forEach(function (sid) {
      var stream = streams[sid];

      if (stream.getTracks().length) {
        if (pc.remoteStreams.indexOf(stream) === -1) {
          pc.remoteStreams.push(stream);
          var event = new Event('addstream');
          event.stream = stream;
          window.setTimeout(function () {
            pc._dispatchEvent('addstream', event);
          });
        }

        receiverList.forEach(function (item) {
          var track = item[0];
          var receiver = item[1];

          if (stream.id !== item[2].id) {
            return;
          }

          fireAddTrack(pc, track, receiver, [stream]);
        });
      }
    });
    receiverList.forEach(function (item) {
      if (item[2]) {
        return;
      }

      fireAddTrack(pc, item[0], item[1], []);
    }); // check whether addIceCandidate({}) was called within four seconds after
    // setRemoteDescription.

    window.setTimeout(function () {
      if (!(pc && pc.transceivers)) {
        return;
      }

      pc.transceivers.forEach(function (transceiver) {
        if (transceiver.iceTransport && transceiver.iceTransport.state === 'new' && transceiver.iceTransport.getRemoteCandidates().length > 0) {
          console.warn('Timeout for addRemoteCandidate. Consider sending ' + 'an end-of-candidates notification');
          transceiver.iceTransport.addRemoteCandidate({});
        }
      });
    }, 4000);
    return Promise.resolve();
  };

  RTCPeerConnection.prototype.close = function () {
    this.transceivers.forEach(function (transceiver) {
      /* not yet
      if (transceiver.iceGatherer) {
        transceiver.iceGatherer.close();
      }
      */
      if (transceiver.iceTransport) {
        transceiver.iceTransport.stop();
      }

      if (transceiver.dtlsTransport) {
        transceiver.dtlsTransport.stop();
      }

      if (transceiver.rtpSender) {
        transceiver.rtpSender.stop();
      }

      if (transceiver.rtpReceiver) {
        transceiver.rtpReceiver.stop();
      }
    }); // FIXME: clean up tracks, local streams, remote streams, etc

    this._isClosed = true;

    this._updateSignalingState('closed');
  }; // Update the signaling state.


  RTCPeerConnection.prototype._updateSignalingState = function (newState) {
    this.signalingState = newState;
    var event = new Event('signalingstatechange');

    this._dispatchEvent('signalingstatechange', event);
  }; // Determine whether to fire the negotiationneeded event.


  RTCPeerConnection.prototype._maybeFireNegotiationNeeded = function () {
    var pc = this;

    if (this.signalingState !== 'stable' || this.needNegotiation === true) {
      return;
    }

    this.needNegotiation = true;
    window.setTimeout(function () {
      if (pc.needNegotiation) {
        pc.needNegotiation = false;
        var event = new Event('negotiationneeded');

        pc._dispatchEvent('negotiationneeded', event);
      }
    }, 0);
  }; // Update the ice connection state.


  RTCPeerConnection.prototype._updateIceConnectionState = function () {
    var newState;
    var states = {
      'new': 0,
      closed: 0,
      checking: 0,
      connected: 0,
      completed: 0,
      disconnected: 0,
      failed: 0
    };
    this.transceivers.forEach(function (transceiver) {
      if (transceiver.iceTransport && !transceiver.rejected) {
        states[transceiver.iceTransport.state]++;
      }
    });
    newState = 'new';

    if (states.failed > 0) {
      newState = 'failed';
    } else if (states.checking > 0) {
      newState = 'checking';
    } else if (states.disconnected > 0) {
      newState = 'disconnected';
    } else if (states.new > 0) {
      newState = 'new';
    } else if (states.connected > 0) {
      newState = 'connected';
    } else if (states.completed > 0) {
      newState = 'completed';
    }

    if (newState !== this.iceConnectionState) {
      this.iceConnectionState = newState;
      var event = new Event('iceconnectionstatechange');

      this._dispatchEvent('iceconnectionstatechange', event);
    }
  }; // Update the connection state.


  RTCPeerConnection.prototype._updateConnectionState = function () {
    var newState;
    var states = {
      'new': 0,
      closed: 0,
      connecting: 0,
      connected: 0,
      completed: 0,
      disconnected: 0,
      failed: 0
    };
    this.transceivers.forEach(function (transceiver) {
      if (transceiver.iceTransport && transceiver.dtlsTransport && !transceiver.rejected) {
        states[transceiver.iceTransport.state]++;
        states[transceiver.dtlsTransport.state]++;
      }
    }); // ICETransport.completed and connected are the same for this purpose.

    states.connected += states.completed;
    newState = 'new';

    if (states.failed > 0) {
      newState = 'failed';
    } else if (states.connecting > 0) {
      newState = 'connecting';
    } else if (states.disconnected > 0) {
      newState = 'disconnected';
    } else if (states.new > 0) {
      newState = 'new';
    } else if (states.connected > 0) {
      newState = 'connected';
    }

    if (newState !== this.connectionState) {
      this.connectionState = newState;
      var event = new Event('connectionstatechange');

      this._dispatchEvent('connectionstatechange', event);
    }
  };

  RTCPeerConnection.prototype.createOffer = function () {
    var pc = this;

    if (pc._isClosed) {
      return Promise.reject(makeError('InvalidStateError', 'Can not call createOffer after close'));
    }

    var numAudioTracks = pc.transceivers.filter(function (t) {
      return t.kind === 'audio';
    }).length;
    var numVideoTracks = pc.transceivers.filter(function (t) {
      return t.kind === 'video';
    }).length; // Determine number of audio and video tracks we need to send/recv.

    var offerOptions = arguments[0];

    if (offerOptions) {
      // Reject Chrome legacy constraints.
      if (offerOptions.mandatory || offerOptions.optional) {
        throw new TypeError('Legacy mandatory/optional constraints not supported.');
      }

      if (offerOptions.offerToReceiveAudio !== undefined) {
        if (offerOptions.offerToReceiveAudio === true) {
          numAudioTracks = 1;
        } else if (offerOptions.offerToReceiveAudio === false) {
          numAudioTracks = 0;
        } else {
          numAudioTracks = offerOptions.offerToReceiveAudio;
        }
      }

      if (offerOptions.offerToReceiveVideo !== undefined) {
        if (offerOptions.offerToReceiveVideo === true) {
          numVideoTracks = 1;
        } else if (offerOptions.offerToReceiveVideo === false) {
          numVideoTracks = 0;
        } else {
          numVideoTracks = offerOptions.offerToReceiveVideo;
        }
      }
    }

    pc.transceivers.forEach(function (transceiver) {
      if (transceiver.kind === 'audio') {
        numAudioTracks--;

        if (numAudioTracks < 0) {
          transceiver.wantReceive = false;
        }
      } else if (transceiver.kind === 'video') {
        numVideoTracks--;

        if (numVideoTracks < 0) {
          transceiver.wantReceive = false;
        }
      }
    }); // Create M-lines for recvonly streams.

    while (numAudioTracks > 0 || numVideoTracks > 0) {
      if (numAudioTracks > 0) {
        pc._createTransceiver('audio');

        numAudioTracks--;
      }

      if (numVideoTracks > 0) {
        pc._createTransceiver('video');

        numVideoTracks--;
      }
    }

    var sdp = SDPUtils.writeSessionBoilerplate(pc._sdpSessionId, pc._sdpSessionVersion++);
    pc.transceivers.forEach(function (transceiver, sdpMLineIndex) {
      // For each track, create an ice gatherer, ice transport,
      // dtls transport, potentially rtpsender and rtpreceiver.
      var track = transceiver.track;
      var kind = transceiver.kind;
      var mid = transceiver.mid || SDPUtils.generateIdentifier();
      transceiver.mid = mid;

      if (!transceiver.iceGatherer) {
        transceiver.iceGatherer = pc._createIceGatherer(sdpMLineIndex, pc.usingBundle);
      }

      var localCapabilities = window.RTCRtpSender.getCapabilities(kind); // filter RTX until additional stuff needed for RTX is implemented
      // in adapter.js

      if (edgeVersion < 15019) {
        localCapabilities.codecs = localCapabilities.codecs.filter(function (codec) {
          return codec.name !== 'rtx';
        });
      }

      localCapabilities.codecs.forEach(function (codec) {
        // work around https://bugs.chromium.org/p/webrtc/issues/detail?id=6552
        // by adding level-asymmetry-allowed=1
        if (codec.name === 'H264' && codec.parameters['level-asymmetry-allowed'] === undefined) {
          codec.parameters['level-asymmetry-allowed'] = '1';
        } // for subsequent offers, we might have to re-use the payload
        // type of the last offer.


        if (transceiver.remoteCapabilities && transceiver.remoteCapabilities.codecs) {
          transceiver.remoteCapabilities.codecs.forEach(function (remoteCodec) {
            if (codec.name.toLowerCase() === remoteCodec.name.toLowerCase() && codec.clockRate === remoteCodec.clockRate) {
              codec.preferredPayloadType = remoteCodec.payloadType;
            }
          });
        }
      });
      localCapabilities.headerExtensions.forEach(function (hdrExt) {
        var remoteExtensions = transceiver.remoteCapabilities && transceiver.remoteCapabilities.headerExtensions || [];
        remoteExtensions.forEach(function (rHdrExt) {
          if (hdrExt.uri === rHdrExt.uri) {
            hdrExt.id = rHdrExt.id;
          }
        });
      }); // generate an ssrc now, to be used later in rtpSender.send

      var sendEncodingParameters = transceiver.sendEncodingParameters || [{
        ssrc: (2 * sdpMLineIndex + 1) * 1001
      }];

      if (track) {
        // add RTX
        if (edgeVersion >= 15019 && kind === 'video' && !sendEncodingParameters[0].rtx) {
          sendEncodingParameters[0].rtx = {
            ssrc: sendEncodingParameters[0].ssrc + 1
          };
        }
      }

      if (transceiver.wantReceive) {
        transceiver.rtpReceiver = new window.RTCRtpReceiver(transceiver.dtlsTransport, kind);
      }

      transceiver.localCapabilities = localCapabilities;
      transceiver.sendEncodingParameters = sendEncodingParameters;
    }); // always offer BUNDLE and dispose on return if not supported.

    if (pc._config.bundlePolicy !== 'max-compat') {
      sdp += 'a=group:BUNDLE ' + pc.transceivers.map(function (t) {
        return t.mid;
      }).join(' ') + '\r\n';
    }

    sdp += 'a=ice-options:trickle\r\n';
    pc.transceivers.forEach(function (transceiver, sdpMLineIndex) {
      sdp += writeMediaSection(transceiver, transceiver.localCapabilities, 'offer', transceiver.stream, pc._dtlsRole);
      sdp += 'a=rtcp-rsize\r\n';

      if (transceiver.iceGatherer && pc.iceGatheringState !== 'new' && (sdpMLineIndex === 0 || !pc.usingBundle)) {
        transceiver.iceGatherer.getLocalCandidates().forEach(function (cand) {
          cand.component = 1;
          sdp += 'a=' + SDPUtils.writeCandidate(cand) + '\r\n';
        });

        if (transceiver.iceGatherer.state === 'completed') {
          sdp += 'a=end-of-candidates\r\n';
        }
      }
    });
    var desc = new window.RTCSessionDescription({
      type: 'offer',
      sdp: sdp
    });
    return Promise.resolve(desc);
  };

  RTCPeerConnection.prototype.createAnswer = function () {
    var pc = this;

    if (pc._isClosed) {
      return Promise.reject(makeError('InvalidStateError', 'Can not call createAnswer after close'));
    }

    if (!(pc.signalingState === 'have-remote-offer' || pc.signalingState === 'have-local-pranswer')) {
      return Promise.reject(makeError('InvalidStateError', 'Can not call createAnswer in signalingState ' + pc.signalingState));
    }

    var sdp = SDPUtils.writeSessionBoilerplate(pc._sdpSessionId, pc._sdpSessionVersion++);

    if (pc.usingBundle) {
      sdp += 'a=group:BUNDLE ' + pc.transceivers.map(function (t) {
        return t.mid;
      }).join(' ') + '\r\n';
    }

    sdp += 'a=ice-options:trickle\r\n';
    var mediaSectionsInOffer = SDPUtils.getMediaSections(pc._remoteDescription.sdp).length;
    pc.transceivers.forEach(function (transceiver, sdpMLineIndex) {
      if (sdpMLineIndex + 1 > mediaSectionsInOffer) {
        return;
      }

      if (transceiver.rejected) {
        if (transceiver.kind === 'application') {
          if (transceiver.protocol === 'DTLS/SCTP') {
            // legacy fmt
            sdp += 'm=application 0 DTLS/SCTP 5000\r\n';
          } else {
            sdp += 'm=application 0 ' + transceiver.protocol + ' webrtc-datachannel\r\n';
          }
        } else if (transceiver.kind === 'audio') {
          sdp += 'm=audio 0 UDP/TLS/RTP/SAVPF 0\r\n' + 'a=rtpmap:0 PCMU/8000\r\n';
        } else if (transceiver.kind === 'video') {
          sdp += 'm=video 0 UDP/TLS/RTP/SAVPF 120\r\n' + 'a=rtpmap:120 VP8/90000\r\n';
        }

        sdp += 'c=IN IP4 0.0.0.0\r\n' + 'a=inactive\r\n' + 'a=mid:' + transceiver.mid + '\r\n';
        return;
      } // FIXME: look at direction.


      if (transceiver.stream) {
        var localTrack;

        if (transceiver.kind === 'audio') {
          localTrack = transceiver.stream.getAudioTracks()[0];
        } else if (transceiver.kind === 'video') {
          localTrack = transceiver.stream.getVideoTracks()[0];
        }

        if (localTrack) {
          // add RTX
          if (edgeVersion >= 15019 && transceiver.kind === 'video' && !transceiver.sendEncodingParameters[0].rtx) {
            transceiver.sendEncodingParameters[0].rtx = {
              ssrc: transceiver.sendEncodingParameters[0].ssrc + 1
            };
          }
        }
      } // Calculate intersection of capabilities.


      var commonCapabilities = getCommonCapabilities(transceiver.localCapabilities, transceiver.remoteCapabilities);
      var hasRtx = commonCapabilities.codecs.filter(function (c) {
        return c.name.toLowerCase() === 'rtx';
      }).length;

      if (!hasRtx && transceiver.sendEncodingParameters[0].rtx) {
        delete transceiver.sendEncodingParameters[0].rtx;
      }

      sdp += writeMediaSection(transceiver, commonCapabilities, 'answer', transceiver.stream, pc._dtlsRole);

      if (transceiver.rtcpParameters && transceiver.rtcpParameters.reducedSize) {
        sdp += 'a=rtcp-rsize\r\n';
      }
    });
    var desc = new window.RTCSessionDescription({
      type: 'answer',
      sdp: sdp
    });
    return Promise.resolve(desc);
  };

  RTCPeerConnection.prototype.addIceCandidate = function (candidate) {
    var pc = this;
    var sections;

    if (candidate && !(candidate.sdpMLineIndex !== undefined || candidate.sdpMid)) {
      return Promise.reject(new TypeError('sdpMLineIndex or sdpMid required'));
    } // TODO: needs to go into ops queue.


    return new Promise(function (resolve, reject) {
      if (!pc._remoteDescription) {
        return reject(makeError('InvalidStateError', 'Can not add ICE candidate without a remote description'));
      } else if (!candidate || candidate.candidate === '') {
        for (var j = 0; j < pc.transceivers.length; j++) {
          if (pc.transceivers[j].rejected) {
            continue;
          }

          pc.transceivers[j].iceTransport.addRemoteCandidate({});
          sections = SDPUtils.getMediaSections(pc._remoteDescription.sdp);
          sections[j] += 'a=end-of-candidates\r\n';
          pc._remoteDescription.sdp = SDPUtils.getDescription(pc._remoteDescription.sdp) + sections.join('');

          if (pc.usingBundle) {
            break;
          }
        }
      } else {
        var sdpMLineIndex = candidate.sdpMLineIndex;

        if (candidate.sdpMid) {
          for (var i = 0; i < pc.transceivers.length; i++) {
            if (pc.transceivers[i].mid === candidate.sdpMid) {
              sdpMLineIndex = i;
              break;
            }
          }
        }

        var transceiver = pc.transceivers[sdpMLineIndex];

        if (transceiver) {
          if (transceiver.rejected) {
            return resolve();
          }

          var cand = Object.keys(candidate.candidate).length > 0 ? SDPUtils.parseCandidate(candidate.candidate) : {}; // Ignore Chrome's invalid candidates since Edge does not like them.

          if (cand.protocol === 'tcp' && (cand.port === 0 || cand.port === 9)) {
            return resolve();
          } // Ignore RTCP candidates, we assume RTCP-MUX.


          if (cand.component && cand.component !== 1) {
            return resolve();
          } // when using bundle, avoid adding candidates to the wrong
          // ice transport. And avoid adding candidates added in the SDP.


          if (sdpMLineIndex === 0 || sdpMLineIndex > 0 && transceiver.iceTransport !== pc.transceivers[0].iceTransport) {
            if (!maybeAddCandidate(transceiver.iceTransport, cand)) {
              return reject(makeError('OperationError', 'Can not add ICE candidate'));
            }
          } // update the remoteDescription.


          var candidateString = candidate.candidate.trim();

          if (candidateString.indexOf('a=') === 0) {
            candidateString = candidateString.substr(2);
          }

          sections = SDPUtils.getMediaSections(pc._remoteDescription.sdp);
          sections[sdpMLineIndex] += 'a=' + (cand.type ? candidateString : 'end-of-candidates') + '\r\n';
          pc._remoteDescription.sdp = SDPUtils.getDescription(pc._remoteDescription.sdp) + sections.join('');
        } else {
          return reject(makeError('OperationError', 'Can not add ICE candidate'));
        }
      }

      resolve();
    });
  };

  RTCPeerConnection.prototype.getStats = function (selector) {
    if (selector && selector instanceof window.MediaStreamTrack) {
      var senderOrReceiver = null;
      this.transceivers.forEach(function (transceiver) {
        if (transceiver.rtpSender && transceiver.rtpSender.track === selector) {
          senderOrReceiver = transceiver.rtpSender;
        } else if (transceiver.rtpReceiver && transceiver.rtpReceiver.track === selector) {
          senderOrReceiver = transceiver.rtpReceiver;
        }
      });

      if (!senderOrReceiver) {
        throw makeError('InvalidAccessError', 'Invalid selector.');
      }

      return senderOrReceiver.getStats();
    }

    var promises = [];
    this.transceivers.forEach(function (transceiver) {
      ['rtpSender', 'rtpReceiver', 'iceGatherer', 'iceTransport', 'dtlsTransport'].forEach(function (method) {
        if (transceiver[method]) {
          promises.push(transceiver[method].getStats());
        }
      });
    });
    return Promise.all(promises).then(function (allStats) {
      var results = new Map();
      allStats.forEach(function (stats) {
        stats.forEach(function (stat) {
          results.set(stat.id, stat);
        });
      });
      return results;
    });
  }; // fix low-level stat names and return Map instead of object.


  var ortcObjects = ['RTCRtpSender', 'RTCRtpReceiver', 'RTCIceGatherer', 'RTCIceTransport', 'RTCDtlsTransport'];
  ortcObjects.forEach(function (ortcObjectName) {
    var obj = window[ortcObjectName];

    if (obj && obj.prototype && obj.prototype.getStats) {
      var nativeGetstats = obj.prototype.getStats;

      obj.prototype.getStats = function () {
        return nativeGetstats.apply(this).then(function (nativeStats) {
          var mapStats = new Map();
          Object.keys(nativeStats).forEach(function (id) {
            nativeStats[id].type = fixStatsType(nativeStats[id]);
            mapStats.set(id, nativeStats[id]);
          });
          return mapStats;
        });
      };
    }
  }); // legacy callback shims. Should be moved to adapter.js some days.

  var methods = ['createOffer', 'createAnswer'];
  methods.forEach(function (method) {
    var nativeMethod = RTCPeerConnection.prototype[method];

    RTCPeerConnection.prototype[method] = function () {
      var args = arguments;

      if (typeof args[0] === 'function' || typeof args[1] === 'function') {
        // legacy
        return nativeMethod.apply(this, [arguments[2]]).then(function (description) {
          if (typeof args[0] === 'function') {
            args[0].apply(null, [description]);
          }
        }, function (error) {
          if (typeof args[1] === 'function') {
            args[1].apply(null, [error]);
          }
        });
      }

      return nativeMethod.apply(this, arguments);
    };
  });
  methods = ['setLocalDescription', 'setRemoteDescription', 'addIceCandidate'];
  methods.forEach(function (method) {
    var nativeMethod = RTCPeerConnection.prototype[method];

    RTCPeerConnection.prototype[method] = function () {
      var args = arguments;

      if (typeof args[1] === 'function' || typeof args[2] === 'function') {
        // legacy
        return nativeMethod.apply(this, arguments).then(function () {
          if (typeof args[1] === 'function') {
            args[1].apply(null);
          }
        }, function (error) {
          if (typeof args[2] === 'function') {
            args[2].apply(null, [error]);
          }
        });
      }

      return nativeMethod.apply(this, arguments);
    };
  }); // getStats is special. It doesn't have a spec legacy method yet we support
  // getStats(something, cb) without error callbacks.

  ['getStats'].forEach(function (method) {
    var nativeMethod = RTCPeerConnection.prototype[method];

    RTCPeerConnection.prototype[method] = function () {
      var args = arguments;

      if (typeof args[1] === 'function') {
        return nativeMethod.apply(this, arguments).then(function () {
          if (typeof args[1] === 'function') {
            args[1].apply(null);
          }
        });
      }

      return nativeMethod.apply(this, arguments);
    };
  });
  return RTCPeerConnection;
};

/***/ }),

/***/ "./node_modules/sdp-transform/lib/grammar.js":
/*!***************************************************!*\
  !*** ./node_modules/sdp-transform/lib/grammar.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

var grammar = module.exports = {
  v: [{
    name: 'version',
    reg: /^(\d*)$/
  }],
  o: [{
    //o=- 20518 0 IN IP4 203.0.113.1
    // NB: sessionId will be a String in most cases because it is huge
    name: 'origin',
    reg: /^(\S*) (\d*) (\d*) (\S*) IP(\d) (\S*)/,
    names: ['username', 'sessionId', 'sessionVersion', 'netType', 'ipVer', 'address'],
    format: '%s %s %d %s IP%d %s'
  }],
  // default parsing of these only (though some of these feel outdated)
  s: [{
    name: 'name'
  }],
  i: [{
    name: 'description'
  }],
  u: [{
    name: 'uri'
  }],
  e: [{
    name: 'email'
  }],
  p: [{
    name: 'phone'
  }],
  z: [{
    name: 'timezones'
  }],
  // TODO: this one can actually be parsed properly..
  r: [{
    name: 'repeats'
  }],
  // TODO: this one can also be parsed properly
  //k: [{}], // outdated thing ignored
  t: [{
    //t=0 0
    name: 'timing',
    reg: /^(\d*) (\d*)/,
    names: ['start', 'stop'],
    format: '%d %d'
  }],
  c: [{
    //c=IN IP4 10.47.197.26
    name: 'connection',
    reg: /^IN IP(\d) (\S*)/,
    names: ['version', 'ip'],
    format: 'IN IP%d %s'
  }],
  b: [{
    //b=AS:4000
    push: 'bandwidth',
    reg: /^(TIAS|AS|CT|RR|RS):(\d*)/,
    names: ['type', 'limit'],
    format: '%s:%s'
  }],
  m: [{
    //m=video 51744 RTP/AVP 126 97 98 34 31
    // NB: special - pushes to session
    // TODO: rtp/fmtp should be filtered by the payloads found here?
    reg: /^(\w*) (\d*) ([\w\/]*)(?: (.*))?/,
    names: ['type', 'port', 'protocol', 'payloads'],
    format: '%s %d %s %s'
  }],
  a: [{
    //a=rtpmap:110 opus/48000/2
    push: 'rtp',
    reg: /^rtpmap:(\d*) ([\w\-\.]*)(?:\s*\/(\d*)(?:\s*\/(\S*))?)?/,
    names: ['payload', 'codec', 'rate', 'encoding'],
    format: function (o) {
      return o.encoding ? 'rtpmap:%d %s/%s/%s' : o.rate ? 'rtpmap:%d %s/%s' : 'rtpmap:%d %s';
    }
  }, {
    //a=fmtp:108 profile-level-id=24;object=23;bitrate=64000
    //a=fmtp:111 minptime=10; useinbandfec=1
    push: 'fmtp',
    reg: /^fmtp:(\d*) ([\S| ]*)/,
    names: ['payload', 'config'],
    format: 'fmtp:%d %s'
  }, {
    //a=control:streamid=0
    name: 'control',
    reg: /^control:(.*)/,
    format: 'control:%s'
  }, {
    //a=rtcp:65179 IN IP4 193.84.77.194
    name: 'rtcp',
    reg: /^rtcp:(\d*)(?: (\S*) IP(\d) (\S*))?/,
    names: ['port', 'netType', 'ipVer', 'address'],
    format: function (o) {
      return o.address != null ? 'rtcp:%d %s IP%d %s' : 'rtcp:%d';
    }
  }, {
    //a=rtcp-fb:98 trr-int 100
    push: 'rtcpFbTrrInt',
    reg: /^rtcp-fb:(\*|\d*) trr-int (\d*)/,
    names: ['payload', 'value'],
    format: 'rtcp-fb:%d trr-int %d'
  }, {
    //a=rtcp-fb:98 nack rpsi
    push: 'rtcpFb',
    reg: /^rtcp-fb:(\*|\d*) ([\w-_]*)(?: ([\w-_]*))?/,
    names: ['payload', 'type', 'subtype'],
    format: function (o) {
      return o.subtype != null ? 'rtcp-fb:%s %s %s' : 'rtcp-fb:%s %s';
    }
  }, {
    //a=extmap:2 urn:ietf:params:rtp-hdrext:toffset
    //a=extmap:1/recvonly URI-gps-string
    push: 'ext',
    reg: /^extmap:(\d+)(?:\/(\w+))? (\S*)(?: (\S*))?/,
    names: ['value', 'direction', 'uri', 'config'],
    format: function (o) {
      return 'extmap:%d' + (o.direction ? '/%s' : '%v') + ' %s' + (o.config ? ' %s' : '');
    }
  }, {
    //a=crypto:1 AES_CM_128_HMAC_SHA1_80 inline:PS1uQCVeeCFCanVmcjkpPywjNWhcYD0mXXtxaVBR|2^20|1:32
    push: 'crypto',
    reg: /^crypto:(\d*) ([\w_]*) (\S*)(?: (\S*))?/,
    names: ['id', 'suite', 'config', 'sessionConfig'],
    format: function (o) {
      return o.sessionConfig != null ? 'crypto:%d %s %s %s' : 'crypto:%d %s %s';
    }
  }, {
    //a=setup:actpass
    name: 'setup',
    reg: /^setup:(\w*)/,
    format: 'setup:%s'
  }, {
    //a=mid:1
    name: 'mid',
    reg: /^mid:([^\s]*)/,
    format: 'mid:%s'
  }, {
    //a=msid:0c8b064d-d807-43b4-b434-f92a889d8587 98178685-d409-46e0-8e16-7ef0db0db64a
    name: 'msid',
    reg: /^msid:(.*)/,
    format: 'msid:%s'
  }, {
    //a=ptime:20
    name: 'ptime',
    reg: /^ptime:(\d*)/,
    format: 'ptime:%d'
  }, {
    //a=maxptime:60
    name: 'maxptime',
    reg: /^maxptime:(\d*)/,
    format: 'maxptime:%d'
  }, {
    //a=sendrecv
    name: 'direction',
    reg: /^(sendrecv|recvonly|sendonly|inactive)/
  }, {
    //a=ice-lite
    name: 'icelite',
    reg: /^(ice-lite)/
  }, {
    //a=ice-ufrag:F7gI
    name: 'iceUfrag',
    reg: /^ice-ufrag:(\S*)/,
    format: 'ice-ufrag:%s'
  }, {
    //a=ice-pwd:x9cml/YzichV2+XlhiMu8g
    name: 'icePwd',
    reg: /^ice-pwd:(\S*)/,
    format: 'ice-pwd:%s'
  }, {
    //a=fingerprint:SHA-1 00:11:22:33:44:55:66:77:88:99:AA:BB:CC:DD:EE:FF:00:11:22:33
    name: 'fingerprint',
    reg: /^fingerprint:(\S*) (\S*)/,
    names: ['type', 'hash'],
    format: 'fingerprint:%s %s'
  }, {
    //a=candidate:0 1 UDP 2113667327 203.0.113.1 54400 typ host
    //a=candidate:1162875081 1 udp 2113937151 192.168.34.75 60017 typ host generation 0 network-id 3 network-cost 10
    //a=candidate:3289912957 2 udp 1845501695 193.84.77.194 60017 typ srflx raddr 192.168.34.75 rport 60017 generation 0 network-id 3 network-cost 10
    //a=candidate:229815620 1 tcp 1518280447 192.168.150.19 60017 typ host tcptype active generation 0 network-id 3 network-cost 10
    //a=candidate:3289912957 2 tcp 1845501695 193.84.77.194 60017 typ srflx raddr 192.168.34.75 rport 60017 tcptype passive generation 0 network-id 3 network-cost 10
    push: 'candidates',
    reg: /^candidate:(\S*) (\d*) (\S*) (\d*) (\S*) (\d*) typ (\S*)(?: raddr (\S*) rport (\d*))?(?: tcptype (\S*))?(?: generation (\d*))?(?: network-id (\d*))?(?: network-cost (\d*))?/,
    names: ['foundation', 'component', 'transport', 'priority', 'ip', 'port', 'type', 'raddr', 'rport', 'tcptype', 'generation', 'network-id', 'network-cost'],
    format: function (o) {
      var str = 'candidate:%s %d %s %d %s %d typ %s';
      str += o.raddr != null ? ' raddr %s rport %d' : '%v%v'; // NB: candidate has three optional chunks, so %void middles one if it's missing

      str += o.tcptype != null ? ' tcptype %s' : '%v';

      if (o.generation != null) {
        str += ' generation %d';
      }

      str += o['network-id'] != null ? ' network-id %d' : '%v';
      str += o['network-cost'] != null ? ' network-cost %d' : '%v';
      return str;
    }
  }, {
    //a=end-of-candidates (keep after the candidates line for readability)
    name: 'endOfCandidates',
    reg: /^(end-of-candidates)/
  }, {
    //a=remote-candidates:1 203.0.113.1 54400 2 203.0.113.1 54401 ...
    name: 'remoteCandidates',
    reg: /^remote-candidates:(.*)/,
    format: 'remote-candidates:%s'
  }, {
    //a=ice-options:google-ice
    name: 'iceOptions',
    reg: /^ice-options:(\S*)/,
    format: 'ice-options:%s'
  }, {
    //a=ssrc:2566107569 cname:t9YU8M1UxTF8Y1A1
    push: 'ssrcs',
    reg: /^ssrc:(\d*) ([\w_]*)(?::(.*))?/,
    names: ['id', 'attribute', 'value'],
    format: function (o) {
      var str = 'ssrc:%d';

      if (o.attribute != null) {
        str += ' %s';

        if (o.value != null) {
          str += ':%s';
        }
      }

      return str;
    }
  }, {
    //a=ssrc-group:FEC 1 2
    //a=ssrc-group:FEC-FR 3004364195 1080772241
    push: 'ssrcGroups',
    // token-char = %x21 / %x23-27 / %x2A-2B / %x2D-2E / %x30-39 / %x41-5A / %x5E-7E
    reg: /^ssrc-group:([\x21\x23\x24\x25\x26\x27\x2A\x2B\x2D\x2E\w]*) (.*)/,
    names: ['semantics', 'ssrcs'],
    format: 'ssrc-group:%s %s'
  }, {
    //a=msid-semantic: WMS Jvlam5X3SX1OP6pn20zWogvaKJz5Hjf9OnlV
    name: 'msidSemantic',
    reg: /^msid-semantic:\s?(\w*) (\S*)/,
    names: ['semantic', 'token'],
    format: 'msid-semantic: %s %s' // space after ':' is not accidental

  }, {
    //a=group:BUNDLE audio video
    push: 'groups',
    reg: /^group:(\w*) (.*)/,
    names: ['type', 'mids'],
    format: 'group:%s %s'
  }, {
    //a=rtcp-mux
    name: 'rtcpMux',
    reg: /^(rtcp-mux)/
  }, {
    //a=rtcp-rsize
    name: 'rtcpRsize',
    reg: /^(rtcp-rsize)/
  }, {
    //a=sctpmap:5000 webrtc-datachannel 1024
    name: 'sctpmap',
    reg: /^sctpmap:([\w_\/]*) (\S*)(?: (\S*))?/,
    names: ['sctpmapNumber', 'app', 'maxMessageSize'],
    format: function (o) {
      return o.maxMessageSize != null ? 'sctpmap:%s %s %s' : 'sctpmap:%s %s';
    }
  }, {
    //a=x-google-flag:conference
    name: 'xGoogleFlag',
    reg: /^x-google-flag:([^\s]*)/,
    format: 'x-google-flag:%s'
  }, {
    //a=rid:1 send max-width=1280;max-height=720;max-fps=30;depend=0
    push: 'rids',
    reg: /^rid:([\d\w]+) (\w+)(?: ([\S| ]*))?/,
    names: ['id', 'direction', 'params'],
    format: function (o) {
      return o.params ? 'rid:%s %s %s' : 'rid:%s %s';
    }
  }, {
    //a=imageattr:97 send [x=800,y=640,sar=1.1,q=0.6] [x=480,y=320] recv [x=330,y=250]
    //a=imageattr:* send [x=800,y=640] recv *
    //a=imageattr:100 recv [x=320,y=240]
    push: 'imageattrs',
    reg: new RegExp( //a=imageattr:97
    '^imageattr:(\\d+|\\*)' + //send [x=800,y=640,sar=1.1,q=0.6] [x=480,y=320]
    '[\\s\\t]+(send|recv)[\\s\\t]+(\\*|\\[\\S+\\](?:[\\s\\t]+\\[\\S+\\])*)' + //recv [x=330,y=250]
    '(?:[\\s\\t]+(recv|send)[\\s\\t]+(\\*|\\[\\S+\\](?:[\\s\\t]+\\[\\S+\\])*))?'),
    names: ['pt', 'dir1', 'attrs1', 'dir2', 'attrs2'],
    format: function (o) {
      return 'imageattr:%s %s %s' + (o.dir2 ? ' %s %s' : '');
    }
  }, {
    //a=simulcast:send 1,2,3;~4,~5 recv 6;~7,~8
    //a=simulcast:recv 1;4,5 send 6;7
    name: 'simulcast',
    reg: new RegExp( //a=simulcast:
    '^simulcast:' + //send 1,2,3;~4,~5
    '(send|recv) ([a-zA-Z0-9\\-_~;,]+)' + //space + recv 6;~7,~8
    '(?:\\s?(send|recv) ([a-zA-Z0-9\\-_~;,]+))?' + //end
    '$'),
    names: ['dir1', 'list1', 'dir2', 'list2'],
    format: function (o) {
      return 'simulcast:%s %s' + (o.dir2 ? ' %s %s' : '');
    }
  }, {
    //Old simulcast draft 03 (implemented by Firefox)
    //  https://tools.ietf.org/html/draft-ietf-mmusic-sdp-simulcast-03
    //a=simulcast: recv pt=97;98 send pt=97
    //a=simulcast: send rid=5;6;7 paused=6,7
    name: 'simulcast_03',
    reg: /^simulcast:[\s\t]+([\S+\s\t]+)$/,
    names: ['value'],
    format: 'simulcast: %s'
  }, {
    //a=framerate:25
    //a=framerate:29.97
    name: 'framerate',
    reg: /^framerate:(\d+(?:$|\.\d+))/,
    format: 'framerate:%s'
  }, {
    // any a= that we don't understand is kepts verbatim on media.invalid
    push: 'invalid',
    names: ['value']
  }]
}; // set sensible defaults to avoid polluting the grammar with boring details

Object.keys(grammar).forEach(function (key) {
  var objs = grammar[key];
  objs.forEach(function (obj) {
    if (!obj.reg) {
      obj.reg = /(.*)/;
    }

    if (!obj.format) {
      obj.format = '%s';
    }
  });
});

/***/ }),

/***/ "./node_modules/sdp-transform/lib/index.js":
/*!*************************************************!*\
  !*** ./node_modules/sdp-transform/lib/index.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var parser = __webpack_require__(/*! ./parser */ "./node_modules/sdp-transform/lib/parser.js");

var writer = __webpack_require__(/*! ./writer */ "./node_modules/sdp-transform/lib/writer.js");

exports.write = writer;
exports.parse = parser.parse;
exports.parseFmtpConfig = parser.parseFmtpConfig;
exports.parseParams = parser.parseParams;
exports.parsePayloads = parser.parsePayloads;
exports.parseRemoteCandidates = parser.parseRemoteCandidates;
exports.parseImageAttributes = parser.parseImageAttributes;
exports.parseSimulcastStreamList = parser.parseSimulcastStreamList;

/***/ }),

/***/ "./node_modules/sdp-transform/lib/parser.js":
/*!**************************************************!*\
  !*** ./node_modules/sdp-transform/lib/parser.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var toIntIfInt = function (v) {
  return String(Number(v)) === v ? Number(v) : v;
};

var attachProperties = function (match, location, names, rawName) {
  if (rawName && !names) {
    location[rawName] = toIntIfInt(match[1]);
  } else {
    for (var i = 0; i < names.length; i += 1) {
      if (match[i + 1] != null) {
        location[names[i]] = toIntIfInt(match[i + 1]);
      }
    }
  }
};

var parseReg = function (obj, location, content) {
  var needsBlank = obj.name && obj.names;

  if (obj.push && !location[obj.push]) {
    location[obj.push] = [];
  } else if (needsBlank && !location[obj.name]) {
    location[obj.name] = {};
  }

  var keyLocation = obj.push ? {} : // blank object that will be pushed
  needsBlank ? location[obj.name] : location; // otherwise, named location or root

  attachProperties(content.match(obj.reg), keyLocation, obj.names, obj.name);

  if (obj.push) {
    location[obj.push].push(keyLocation);
  }
};

var grammar = __webpack_require__(/*! ./grammar */ "./node_modules/sdp-transform/lib/grammar.js");

var validLine = RegExp.prototype.test.bind(/^([a-z])=(.*)/);

exports.parse = function (sdp) {
  var session = {},
      media = [],
      location = session; // points at where properties go under (one of the above)
  // parse lines we understand

  sdp.split(/(\r\n|\r|\n)/).filter(validLine).forEach(function (l) {
    var type = l[0];
    var content = l.slice(2);

    if (type === 'm') {
      media.push({
        rtp: [],
        fmtp: []
      });
      location = media[media.length - 1]; // point at latest media line
    }

    for (var j = 0; j < (grammar[type] || []).length; j += 1) {
      var obj = grammar[type][j];

      if (obj.reg.test(content)) {
        return parseReg(obj, location, content);
      }
    }
  });
  session.media = media; // link it up

  return session;
};

var paramReducer = function (acc, expr) {
  var s = expr.split(/=(.+)/, 2);

  if (s.length === 2) {
    acc[s[0]] = toIntIfInt(s[1]);
  }

  return acc;
};

exports.parseParams = function (str) {
  return str.split(/\;\s?/).reduce(paramReducer, {});
}; // For backward compatibility - alias will be removed in 3.0.0


exports.parseFmtpConfig = exports.parseParams;

exports.parsePayloads = function (str) {
  return str.split(' ').map(Number);
};

exports.parseRemoteCandidates = function (str) {
  var candidates = [];
  var parts = str.split(' ').map(toIntIfInt);

  for (var i = 0; i < parts.length; i += 3) {
    candidates.push({
      component: parts[i],
      ip: parts[i + 1],
      port: parts[i + 2]
    });
  }

  return candidates;
};

exports.parseImageAttributes = function (str) {
  return str.split(' ').map(function (item) {
    return item.substring(1, item.length - 1).split(',').reduce(paramReducer, {});
  });
};

exports.parseSimulcastStreamList = function (str) {
  return str.split(';').map(function (stream) {
    return stream.split(',').map(function (format) {
      var scid,
          paused = false;

      if (format[0] !== '~') {
        scid = toIntIfInt(format);
      } else {
        scid = toIntIfInt(format.substring(1, format.length));
        paused = true;
      }

      return {
        scid: scid,
        paused: paused
      };
    });
  });
};

/***/ }),

/***/ "./node_modules/sdp-transform/lib/writer.js":
/*!**************************************************!*\
  !*** ./node_modules/sdp-transform/lib/writer.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var grammar = __webpack_require__(/*! ./grammar */ "./node_modules/sdp-transform/lib/grammar.js"); // customized util.format - discards excess arguments and can void middle ones


var formatRegExp = /%[sdv%]/g;

var format = function (formatStr) {
  var i = 1;
  var args = arguments;
  var len = args.length;
  return formatStr.replace(formatRegExp, function (x) {
    if (i >= len) {
      return x; // missing argument
    }

    var arg = args[i];
    i += 1;

    switch (x) {
      case '%%':
        return '%';

      case '%s':
        return String(arg);

      case '%d':
        return Number(arg);

      case '%v':
        return '';
    }
  }); // NB: we discard excess arguments - they are typically undefined from makeLine
};

var makeLine = function (type, obj, location) {
  var str = obj.format instanceof Function ? obj.format(obj.push ? location : location[obj.name]) : obj.format;
  var args = [type + '=' + str];

  if (obj.names) {
    for (var i = 0; i < obj.names.length; i += 1) {
      var n = obj.names[i];

      if (obj.name) {
        args.push(location[obj.name][n]);
      } else {
        // for mLine and push attributes
        args.push(location[obj.names[i]]);
      }
    }
  } else {
    args.push(location[obj.name]);
  }

  return format.apply(null, args);
}; // RFC specified order
// TODO: extend this with all the rest


var defaultOuterOrder = ['v', 'o', 's', 'i', 'u', 'e', 'p', 'c', 'b', 't', 'r', 'z', 'a'];
var defaultInnerOrder = ['i', 'c', 'b', 'a'];

module.exports = function (session, opts) {
  opts = opts || {}; // ensure certain properties exist

  if (session.version == null) {
    session.version = 0; // 'v=0' must be there (only defined version atm)
  }

  if (session.name == null) {
    session.name = ' '; // 's= ' must be there if no meaningful name set
  }

  session.media.forEach(function (mLine) {
    if (mLine.payloads == null) {
      mLine.payloads = '';
    }
  });
  var outerOrder = opts.outerOrder || defaultOuterOrder;
  var innerOrder = opts.innerOrder || defaultInnerOrder;
  var sdp = []; // loop through outerOrder for matching properties on session

  outerOrder.forEach(function (type) {
    grammar[type].forEach(function (obj) {
      if (obj.name in session && session[obj.name] != null) {
        sdp.push(makeLine(type, obj, session));
      } else if (obj.push in session && session[obj.push] != null) {
        session[obj.push].forEach(function (el) {
          sdp.push(makeLine(type, obj, el));
        });
      }
    });
  }); // then for each media line, follow the innerOrder

  session.media.forEach(function (mLine) {
    sdp.push(makeLine('m', grammar.m[0], mLine));
    innerOrder.forEach(function (type) {
      grammar[type].forEach(function (obj) {
        if (obj.name in mLine && mLine[obj.name] != null) {
          sdp.push(makeLine(type, obj, mLine));
        } else if (obj.push in mLine && mLine[obj.push] != null) {
          mLine[obj.push].forEach(function (el) {
            sdp.push(makeLine(type, obj, el));
          });
        }
      });
    });
  });
  return sdp.join('\r\n') + '\r\n';
};

/***/ }),

/***/ "./node_modules/sdp/sdp.js":
/*!*********************************!*\
  !*** ./node_modules/sdp/sdp.js ***!
  \*********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/* eslint-env node */
 // SDP helpers.

var SDPUtils = {}; // Generate an alphanumeric identifier for cname or mids.
// TODO: use UUIDs instead? https://gist.github.com/jed/982883

SDPUtils.generateIdentifier = function () {
  return Math.random().toString(36).substr(2, 10);
}; // The RTCP CNAME used by all peerconnections from the same JS.


SDPUtils.localCName = SDPUtils.generateIdentifier(); // Splits SDP into lines, dealing with both CRLF and LF.

SDPUtils.splitLines = function (blob) {
  return blob.trim().split('\n').map(function (line) {
    return line.trim();
  });
}; // Splits SDP into sessionpart and mediasections. Ensures CRLF.


SDPUtils.splitSections = function (blob) {
  var parts = blob.split('\nm=');
  return parts.map(function (part, index) {
    return (index > 0 ? 'm=' + part : part).trim() + '\r\n';
  });
}; // returns the session description.


SDPUtils.getDescription = function (blob) {
  var sections = SDPUtils.splitSections(blob);
  return sections && sections[0];
}; // returns the individual media sections.


SDPUtils.getMediaSections = function (blob) {
  var sections = SDPUtils.splitSections(blob);
  sections.shift();
  return sections;
}; // Returns lines that start with a certain prefix.


SDPUtils.matchPrefix = function (blob, prefix) {
  return SDPUtils.splitLines(blob).filter(function (line) {
    return line.indexOf(prefix) === 0;
  });
}; // Parses an ICE candidate line. Sample input:
// candidate:702786350 2 udp 41819902 8.8.8.8 60769 typ relay raddr 8.8.8.8
// rport 55996"


SDPUtils.parseCandidate = function (line) {
  var parts; // Parse both variants.

  if (line.indexOf('a=candidate:') === 0) {
    parts = line.substring(12).split(' ');
  } else {
    parts = line.substring(10).split(' ');
  }

  var candidate = {
    foundation: parts[0],
    component: parseInt(parts[1], 10),
    protocol: parts[2].toLowerCase(),
    priority: parseInt(parts[3], 10),
    ip: parts[4],
    address: parts[4],
    // address is an alias for ip.
    port: parseInt(parts[5], 10),
    // skip parts[6] == 'typ'
    type: parts[7]
  };

  for (var i = 8; i < parts.length; i += 2) {
    switch (parts[i]) {
      case 'raddr':
        candidate.relatedAddress = parts[i + 1];
        break;

      case 'rport':
        candidate.relatedPort = parseInt(parts[i + 1], 10);
        break;

      case 'tcptype':
        candidate.tcpType = parts[i + 1];
        break;

      case 'ufrag':
        candidate.ufrag = parts[i + 1]; // for backward compability.

        candidate.usernameFragment = parts[i + 1];
        break;

      default:
        // extension handling, in particular ufrag
        candidate[parts[i]] = parts[i + 1];
        break;
    }
  }

  return candidate;
}; // Translates a candidate object into SDP candidate attribute.


SDPUtils.writeCandidate = function (candidate) {
  var sdp = [];
  sdp.push(candidate.foundation);
  sdp.push(candidate.component);
  sdp.push(candidate.protocol.toUpperCase());
  sdp.push(candidate.priority);
  sdp.push(candidate.address || candidate.ip);
  sdp.push(candidate.port);
  var type = candidate.type;
  sdp.push('typ');
  sdp.push(type);

  if (type !== 'host' && candidate.relatedAddress && candidate.relatedPort) {
    sdp.push('raddr');
    sdp.push(candidate.relatedAddress);
    sdp.push('rport');
    sdp.push(candidate.relatedPort);
  }

  if (candidate.tcpType && candidate.protocol.toLowerCase() === 'tcp') {
    sdp.push('tcptype');
    sdp.push(candidate.tcpType);
  }

  if (candidate.usernameFragment || candidate.ufrag) {
    sdp.push('ufrag');
    sdp.push(candidate.usernameFragment || candidate.ufrag);
  }

  return 'candidate:' + sdp.join(' ');
}; // Parses an ice-options line, returns an array of option tags.
// a=ice-options:foo bar


SDPUtils.parseIceOptions = function (line) {
  return line.substr(14).split(' ');
}; // Parses an rtpmap line, returns RTCRtpCoddecParameters. Sample input:
// a=rtpmap:111 opus/48000/2


SDPUtils.parseRtpMap = function (line) {
  var parts = line.substr(9).split(' ');
  var parsed = {
    payloadType: parseInt(parts.shift(), 10) // was: id

  };
  parts = parts[0].split('/');
  parsed.name = parts[0];
  parsed.clockRate = parseInt(parts[1], 10); // was: clockrate

  parsed.channels = parts.length === 3 ? parseInt(parts[2], 10) : 1; // legacy alias, got renamed back to channels in ORTC.

  parsed.numChannels = parsed.channels;
  return parsed;
}; // Generate an a=rtpmap line from RTCRtpCodecCapability or
// RTCRtpCodecParameters.


SDPUtils.writeRtpMap = function (codec) {
  var pt = codec.payloadType;

  if (codec.preferredPayloadType !== undefined) {
    pt = codec.preferredPayloadType;
  }

  var channels = codec.channels || codec.numChannels || 1;
  return 'a=rtpmap:' + pt + ' ' + codec.name + '/' + codec.clockRate + (channels !== 1 ? '/' + channels : '') + '\r\n';
}; // Parses an a=extmap line (headerextension from RFC 5285). Sample input:
// a=extmap:2 urn:ietf:params:rtp-hdrext:toffset
// a=extmap:2/sendonly urn:ietf:params:rtp-hdrext:toffset


SDPUtils.parseExtmap = function (line) {
  var parts = line.substr(9).split(' ');
  return {
    id: parseInt(parts[0], 10),
    direction: parts[0].indexOf('/') > 0 ? parts[0].split('/')[1] : 'sendrecv',
    uri: parts[1]
  };
}; // Generates a=extmap line from RTCRtpHeaderExtensionParameters or
// RTCRtpHeaderExtension.


SDPUtils.writeExtmap = function (headerExtension) {
  return 'a=extmap:' + (headerExtension.id || headerExtension.preferredId) + (headerExtension.direction && headerExtension.direction !== 'sendrecv' ? '/' + headerExtension.direction : '') + ' ' + headerExtension.uri + '\r\n';
}; // Parses an ftmp line, returns dictionary. Sample input:
// a=fmtp:96 vbr=on;cng=on
// Also deals with vbr=on; cng=on


SDPUtils.parseFmtp = function (line) {
  var parsed = {};
  var kv;
  var parts = line.substr(line.indexOf(' ') + 1).split(';');

  for (var j = 0; j < parts.length; j++) {
    kv = parts[j].trim().split('=');
    parsed[kv[0].trim()] = kv[1];
  }

  return parsed;
}; // Generates an a=ftmp line from RTCRtpCodecCapability or RTCRtpCodecParameters.


SDPUtils.writeFmtp = function (codec) {
  var line = '';
  var pt = codec.payloadType;

  if (codec.preferredPayloadType !== undefined) {
    pt = codec.preferredPayloadType;
  }

  if (codec.parameters && Object.keys(codec.parameters).length) {
    var params = [];
    Object.keys(codec.parameters).forEach(function (param) {
      if (codec.parameters[param]) {
        params.push(param + '=' + codec.parameters[param]);
      } else {
        params.push(param);
      }
    });
    line += 'a=fmtp:' + pt + ' ' + params.join(';') + '\r\n';
  }

  return line;
}; // Parses an rtcp-fb line, returns RTCPRtcpFeedback object. Sample input:
// a=rtcp-fb:98 nack rpsi


SDPUtils.parseRtcpFb = function (line) {
  var parts = line.substr(line.indexOf(' ') + 1).split(' ');
  return {
    type: parts.shift(),
    parameter: parts.join(' ')
  };
}; // Generate a=rtcp-fb lines from RTCRtpCodecCapability or RTCRtpCodecParameters.


SDPUtils.writeRtcpFb = function (codec) {
  var lines = '';
  var pt = codec.payloadType;

  if (codec.preferredPayloadType !== undefined) {
    pt = codec.preferredPayloadType;
  }

  if (codec.rtcpFeedback && codec.rtcpFeedback.length) {
    // FIXME: special handling for trr-int?
    codec.rtcpFeedback.forEach(function (fb) {
      lines += 'a=rtcp-fb:' + pt + ' ' + fb.type + (fb.parameter && fb.parameter.length ? ' ' + fb.parameter : '') + '\r\n';
    });
  }

  return lines;
}; // Parses an RFC 5576 ssrc media attribute. Sample input:
// a=ssrc:3735928559 cname:something


SDPUtils.parseSsrcMedia = function (line) {
  var sp = line.indexOf(' ');
  var parts = {
    ssrc: parseInt(line.substr(7, sp - 7), 10)
  };
  var colon = line.indexOf(':', sp);

  if (colon > -1) {
    parts.attribute = line.substr(sp + 1, colon - sp - 1);
    parts.value = line.substr(colon + 1);
  } else {
    parts.attribute = line.substr(sp + 1);
  }

  return parts;
};

SDPUtils.parseSsrcGroup = function (line) {
  var parts = line.substr(13).split(' ');
  return {
    semantics: parts.shift(),
    ssrcs: parts.map(function (ssrc) {
      return parseInt(ssrc, 10);
    })
  };
}; // Extracts the MID (RFC 5888) from a media section.
// returns the MID or undefined if no mid line was found.


SDPUtils.getMid = function (mediaSection) {
  var mid = SDPUtils.matchPrefix(mediaSection, 'a=mid:')[0];

  if (mid) {
    return mid.substr(6);
  }
};

SDPUtils.parseFingerprint = function (line) {
  var parts = line.substr(14).split(' ');
  return {
    algorithm: parts[0].toLowerCase(),
    // algorithm is case-sensitive in Edge.
    value: parts[1]
  };
}; // Extracts DTLS parameters from SDP media section or sessionpart.
// FIXME: for consistency with other functions this should only
//   get the fingerprint line as input. See also getIceParameters.


SDPUtils.getDtlsParameters = function (mediaSection, sessionpart) {
  var lines = SDPUtils.matchPrefix(mediaSection + sessionpart, 'a=fingerprint:'); // Note: a=setup line is ignored since we use the 'auto' role.
  // Note2: 'algorithm' is not case sensitive except in Edge.

  return {
    role: 'auto',
    fingerprints: lines.map(SDPUtils.parseFingerprint)
  };
}; // Serializes DTLS parameters to SDP.


SDPUtils.writeDtlsParameters = function (params, setupType) {
  var sdp = 'a=setup:' + setupType + '\r\n';
  params.fingerprints.forEach(function (fp) {
    sdp += 'a=fingerprint:' + fp.algorithm + ' ' + fp.value + '\r\n';
  });
  return sdp;
}; // Parses a=crypto lines into
//   https://rawgit.com/aboba/edgertc/master/msortc-rs4.html#dictionary-rtcsrtpsdesparameters-members


SDPUtils.parseCryptoLine = function (line) {
  var parts = line.substr(9).split(' ');
  return {
    tag: parseInt(parts[0], 10),
    cryptoSuite: parts[1],
    keyParams: parts[2],
    sessionParams: parts.slice(3)
  };
};

SDPUtils.writeCryptoLine = function (parameters) {
  return 'a=crypto:' + parameters.tag + ' ' + parameters.cryptoSuite + ' ' + (typeof parameters.keyParams === 'object' ? SDPUtils.writeCryptoKeyParams(parameters.keyParams) : parameters.keyParams) + (parameters.sessionParams ? ' ' + parameters.sessionParams.join(' ') : '') + '\r\n';
}; // Parses the crypto key parameters into
//   https://rawgit.com/aboba/edgertc/master/msortc-rs4.html#rtcsrtpkeyparam*


SDPUtils.parseCryptoKeyParams = function (keyParams) {
  if (keyParams.indexOf('inline:') !== 0) {
    return null;
  }

  var parts = keyParams.substr(7).split('|');
  return {
    keyMethod: 'inline',
    keySalt: parts[0],
    lifeTime: parts[1],
    mkiValue: parts[2] ? parts[2].split(':')[0] : undefined,
    mkiLength: parts[2] ? parts[2].split(':')[1] : undefined
  };
};

SDPUtils.writeCryptoKeyParams = function (keyParams) {
  return keyParams.keyMethod + ':' + keyParams.keySalt + (keyParams.lifeTime ? '|' + keyParams.lifeTime : '') + (keyParams.mkiValue && keyParams.mkiLength ? '|' + keyParams.mkiValue + ':' + keyParams.mkiLength : '');
}; // Extracts all SDES paramters.


SDPUtils.getCryptoParameters = function (mediaSection, sessionpart) {
  var lines = SDPUtils.matchPrefix(mediaSection + sessionpart, 'a=crypto:');
  return lines.map(SDPUtils.parseCryptoLine);
}; // Parses ICE information from SDP media section or sessionpart.
// FIXME: for consistency with other functions this should only
//   get the ice-ufrag and ice-pwd lines as input.


SDPUtils.getIceParameters = function (mediaSection, sessionpart) {
  var ufrag = SDPUtils.matchPrefix(mediaSection + sessionpart, 'a=ice-ufrag:')[0];
  var pwd = SDPUtils.matchPrefix(mediaSection + sessionpart, 'a=ice-pwd:')[0];

  if (!(ufrag && pwd)) {
    return null;
  }

  return {
    usernameFragment: ufrag.substr(12),
    password: pwd.substr(10)
  };
}; // Serializes ICE parameters to SDP.


SDPUtils.writeIceParameters = function (params) {
  return 'a=ice-ufrag:' + params.usernameFragment + '\r\n' + 'a=ice-pwd:' + params.password + '\r\n';
}; // Parses the SDP media section and returns RTCRtpParameters.


SDPUtils.parseRtpParameters = function (mediaSection) {
  var description = {
    codecs: [],
    headerExtensions: [],
    fecMechanisms: [],
    rtcp: []
  };
  var lines = SDPUtils.splitLines(mediaSection);
  var mline = lines[0].split(' ');

  for (var i = 3; i < mline.length; i++) {
    // find all codecs from mline[3..]
    var pt = mline[i];
    var rtpmapline = SDPUtils.matchPrefix(mediaSection, 'a=rtpmap:' + pt + ' ')[0];

    if (rtpmapline) {
      var codec = SDPUtils.parseRtpMap(rtpmapline);
      var fmtps = SDPUtils.matchPrefix(mediaSection, 'a=fmtp:' + pt + ' '); // Only the first a=fmtp:<pt> is considered.

      codec.parameters = fmtps.length ? SDPUtils.parseFmtp(fmtps[0]) : {};
      codec.rtcpFeedback = SDPUtils.matchPrefix(mediaSection, 'a=rtcp-fb:' + pt + ' ').map(SDPUtils.parseRtcpFb);
      description.codecs.push(codec); // parse FEC mechanisms from rtpmap lines.

      switch (codec.name.toUpperCase()) {
        case 'RED':
        case 'ULPFEC':
          description.fecMechanisms.push(codec.name.toUpperCase());
          break;

        default:
          // only RED and ULPFEC are recognized as FEC mechanisms.
          break;
      }
    }
  }

  SDPUtils.matchPrefix(mediaSection, 'a=extmap:').forEach(function (line) {
    description.headerExtensions.push(SDPUtils.parseExtmap(line));
  }); // FIXME: parse rtcp.

  return description;
}; // Generates parts of the SDP media section describing the capabilities /
// parameters.


SDPUtils.writeRtpDescription = function (kind, caps) {
  var sdp = ''; // Build the mline.

  sdp += 'm=' + kind + ' ';
  sdp += caps.codecs.length > 0 ? '9' : '0'; // reject if no codecs.

  sdp += ' UDP/TLS/RTP/SAVPF ';
  sdp += caps.codecs.map(function (codec) {
    if (codec.preferredPayloadType !== undefined) {
      return codec.preferredPayloadType;
    }

    return codec.payloadType;
  }).join(' ') + '\r\n';
  sdp += 'c=IN IP4 0.0.0.0\r\n';
  sdp += 'a=rtcp:9 IN IP4 0.0.0.0\r\n'; // Add a=rtpmap lines for each codec. Also fmtp and rtcp-fb.

  caps.codecs.forEach(function (codec) {
    sdp += SDPUtils.writeRtpMap(codec);
    sdp += SDPUtils.writeFmtp(codec);
    sdp += SDPUtils.writeRtcpFb(codec);
  });
  var maxptime = 0;
  caps.codecs.forEach(function (codec) {
    if (codec.maxptime > maxptime) {
      maxptime = codec.maxptime;
    }
  });

  if (maxptime > 0) {
    sdp += 'a=maxptime:' + maxptime + '\r\n';
  }

  sdp += 'a=rtcp-mux\r\n';

  if (caps.headerExtensions) {
    caps.headerExtensions.forEach(function (extension) {
      sdp += SDPUtils.writeExtmap(extension);
    });
  } // FIXME: write fecMechanisms.


  return sdp;
}; // Parses the SDP media section and returns an array of
// RTCRtpEncodingParameters.


SDPUtils.parseRtpEncodingParameters = function (mediaSection) {
  var encodingParameters = [];
  var description = SDPUtils.parseRtpParameters(mediaSection);
  var hasRed = description.fecMechanisms.indexOf('RED') !== -1;
  var hasUlpfec = description.fecMechanisms.indexOf('ULPFEC') !== -1; // filter a=ssrc:... cname:, ignore PlanB-msid

  var ssrcs = SDPUtils.matchPrefix(mediaSection, 'a=ssrc:').map(function (line) {
    return SDPUtils.parseSsrcMedia(line);
  }).filter(function (parts) {
    return parts.attribute === 'cname';
  });
  var primarySsrc = ssrcs.length > 0 && ssrcs[0].ssrc;
  var secondarySsrc;
  var flows = SDPUtils.matchPrefix(mediaSection, 'a=ssrc-group:FID').map(function (line) {
    var parts = line.substr(17).split(' ');
    return parts.map(function (part) {
      return parseInt(part, 10);
    });
  });

  if (flows.length > 0 && flows[0].length > 1 && flows[0][0] === primarySsrc) {
    secondarySsrc = flows[0][1];
  }

  description.codecs.forEach(function (codec) {
    if (codec.name.toUpperCase() === 'RTX' && codec.parameters.apt) {
      var encParam = {
        ssrc: primarySsrc,
        codecPayloadType: parseInt(codec.parameters.apt, 10)
      };

      if (primarySsrc && secondarySsrc) {
        encParam.rtx = {
          ssrc: secondarySsrc
        };
      }

      encodingParameters.push(encParam);

      if (hasRed) {
        encParam = JSON.parse(JSON.stringify(encParam));
        encParam.fec = {
          ssrc: primarySsrc,
          mechanism: hasUlpfec ? 'red+ulpfec' : 'red'
        };
        encodingParameters.push(encParam);
      }
    }
  });

  if (encodingParameters.length === 0 && primarySsrc) {
    encodingParameters.push({
      ssrc: primarySsrc
    });
  } // we support both b=AS and b=TIAS but interpret AS as TIAS.


  var bandwidth = SDPUtils.matchPrefix(mediaSection, 'b=');

  if (bandwidth.length) {
    if (bandwidth[0].indexOf('b=TIAS:') === 0) {
      bandwidth = parseInt(bandwidth[0].substr(7), 10);
    } else if (bandwidth[0].indexOf('b=AS:') === 0) {
      // use formula from JSEP to convert b=AS to TIAS value.
      bandwidth = parseInt(bandwidth[0].substr(5), 10) * 1000 * 0.95 - 50 * 40 * 8;
    } else {
      bandwidth = undefined;
    }

    encodingParameters.forEach(function (params) {
      params.maxBitrate = bandwidth;
    });
  }

  return encodingParameters;
}; // parses http://draft.ortc.org/#rtcrtcpparameters*


SDPUtils.parseRtcpParameters = function (mediaSection) {
  var rtcpParameters = {}; // Gets the first SSRC. Note tha with RTX there might be multiple
  // SSRCs.

  var remoteSsrc = SDPUtils.matchPrefix(mediaSection, 'a=ssrc:').map(function (line) {
    return SDPUtils.parseSsrcMedia(line);
  }).filter(function (obj) {
    return obj.attribute === 'cname';
  })[0];

  if (remoteSsrc) {
    rtcpParameters.cname = remoteSsrc.value;
    rtcpParameters.ssrc = remoteSsrc.ssrc;
  } // Edge uses the compound attribute instead of reducedSize
  // compound is !reducedSize


  var rsize = SDPUtils.matchPrefix(mediaSection, 'a=rtcp-rsize');
  rtcpParameters.reducedSize = rsize.length > 0;
  rtcpParameters.compound = rsize.length === 0; // parses the rtcp-mux attrіbute.
  // Note that Edge does not support unmuxed RTCP.

  var mux = SDPUtils.matchPrefix(mediaSection, 'a=rtcp-mux');
  rtcpParameters.mux = mux.length > 0;
  return rtcpParameters;
}; // parses either a=msid: or a=ssrc:... msid lines and returns
// the id of the MediaStream and MediaStreamTrack.


SDPUtils.parseMsid = function (mediaSection) {
  var parts;
  var spec = SDPUtils.matchPrefix(mediaSection, 'a=msid:');

  if (spec.length === 1) {
    parts = spec[0].substr(7).split(' ');
    return {
      stream: parts[0],
      track: parts[1]
    };
  }

  var planB = SDPUtils.matchPrefix(mediaSection, 'a=ssrc:').map(function (line) {
    return SDPUtils.parseSsrcMedia(line);
  }).filter(function (msidParts) {
    return msidParts.attribute === 'msid';
  });

  if (planB.length > 0) {
    parts = planB[0].value.split(' ');
    return {
      stream: parts[0],
      track: parts[1]
    };
  }
}; // SCTP
// parses draft-ietf-mmusic-sctp-sdp-26 first and falls back
// to draft-ietf-mmusic-sctp-sdp-05


SDPUtils.parseSctpDescription = function (mediaSection) {
  var mline = SDPUtils.parseMLine(mediaSection);
  var maxSizeLine = SDPUtils.matchPrefix(mediaSection, 'a=max-message-size:');
  var maxMessageSize;

  if (maxSizeLine.length > 0) {
    maxMessageSize = parseInt(maxSizeLine[0].substr(19), 10);
  }

  if (isNaN(maxMessageSize)) {
    maxMessageSize = 65536;
  }

  var sctpPort = SDPUtils.matchPrefix(mediaSection, 'a=sctp-port:');

  if (sctpPort.length > 0) {
    return {
      port: parseInt(sctpPort[0].substr(12), 10),
      protocol: mline.fmt,
      maxMessageSize: maxMessageSize
    };
  }

  var sctpMapLines = SDPUtils.matchPrefix(mediaSection, 'a=sctpmap:');

  if (sctpMapLines.length > 0) {
    var parts = SDPUtils.matchPrefix(mediaSection, 'a=sctpmap:')[0].substr(10).split(' ');
    return {
      port: parseInt(parts[0], 10),
      protocol: parts[1],
      maxMessageSize: maxMessageSize
    };
  }
}; // SCTP
// outputs the draft-ietf-mmusic-sctp-sdp-26 version that all browsers
// support by now receiving in this format, unless we originally parsed
// as the draft-ietf-mmusic-sctp-sdp-05 format (indicated by the m-line
// protocol of DTLS/SCTP -- without UDP/ or TCP/)


SDPUtils.writeSctpDescription = function (media, sctp) {
  var output = [];

  if (media.protocol !== 'DTLS/SCTP') {
    output = ['m=' + media.kind + ' 9 ' + media.protocol + ' ' + sctp.protocol + '\r\n', 'c=IN IP4 0.0.0.0\r\n', 'a=sctp-port:' + sctp.port + '\r\n'];
  } else {
    output = ['m=' + media.kind + ' 9 ' + media.protocol + ' ' + sctp.port + '\r\n', 'c=IN IP4 0.0.0.0\r\n', 'a=sctpmap:' + sctp.port + ' ' + sctp.protocol + ' 65535\r\n'];
  }

  if (sctp.maxMessageSize !== undefined) {
    output.push('a=max-message-size:' + sctp.maxMessageSize + '\r\n');
  }

  return output.join('');
}; // Generate a session ID for SDP.
// https://tools.ietf.org/html/draft-ietf-rtcweb-jsep-20#section-5.2.1
// recommends using a cryptographically random +ve 64-bit value
// but right now this should be acceptable and within the right range


SDPUtils.generateSessionId = function () {
  return Math.random().toString().substr(2, 21);
}; // Write boilder plate for start of SDP
// sessId argument is optional - if not supplied it will
// be generated randomly
// sessVersion is optional and defaults to 2
// sessUser is optional and defaults to 'thisisadapterortc'


SDPUtils.writeSessionBoilerplate = function (sessId, sessVer, sessUser) {
  var sessionId;
  var version = sessVer !== undefined ? sessVer : 2;

  if (sessId) {
    sessionId = sessId;
  } else {
    sessionId = SDPUtils.generateSessionId();
  }

  var user = sessUser || 'thisisadapterortc'; // FIXME: sess-id should be an NTP timestamp.

  return 'v=0\r\n' + 'o=' + user + ' ' + sessionId + ' ' + version + ' IN IP4 127.0.0.1\r\n' + 's=-\r\n' + 't=0 0\r\n';
};

SDPUtils.writeMediaSection = function (transceiver, caps, type, stream) {
  var sdp = SDPUtils.writeRtpDescription(transceiver.kind, caps); // Map ICE parameters (ufrag, pwd) to SDP.

  sdp += SDPUtils.writeIceParameters(transceiver.iceGatherer.getLocalParameters()); // Map DTLS parameters to SDP.

  sdp += SDPUtils.writeDtlsParameters(transceiver.dtlsTransport.getLocalParameters(), type === 'offer' ? 'actpass' : 'active');
  sdp += 'a=mid:' + transceiver.mid + '\r\n';

  if (transceiver.direction) {
    sdp += 'a=' + transceiver.direction + '\r\n';
  } else if (transceiver.rtpSender && transceiver.rtpReceiver) {
    sdp += 'a=sendrecv\r\n';
  } else if (transceiver.rtpSender) {
    sdp += 'a=sendonly\r\n';
  } else if (transceiver.rtpReceiver) {
    sdp += 'a=recvonly\r\n';
  } else {
    sdp += 'a=inactive\r\n';
  }

  if (transceiver.rtpSender) {
    // spec.
    var msid = 'msid:' + stream.id + ' ' + transceiver.rtpSender.track.id + '\r\n';
    sdp += 'a=' + msid; // for Chrome.

    sdp += 'a=ssrc:' + transceiver.sendEncodingParameters[0].ssrc + ' ' + msid;

    if (transceiver.sendEncodingParameters[0].rtx) {
      sdp += 'a=ssrc:' + transceiver.sendEncodingParameters[0].rtx.ssrc + ' ' + msid;
      sdp += 'a=ssrc-group:FID ' + transceiver.sendEncodingParameters[0].ssrc + ' ' + transceiver.sendEncodingParameters[0].rtx.ssrc + '\r\n';
    }
  } // FIXME: this should be written by writeRtpDescription.


  sdp += 'a=ssrc:' + transceiver.sendEncodingParameters[0].ssrc + ' cname:' + SDPUtils.localCName + '\r\n';

  if (transceiver.rtpSender && transceiver.sendEncodingParameters[0].rtx) {
    sdp += 'a=ssrc:' + transceiver.sendEncodingParameters[0].rtx.ssrc + ' cname:' + SDPUtils.localCName + '\r\n';
  }

  return sdp;
}; // Gets the direction from the mediaSection or the sessionpart.


SDPUtils.getDirection = function (mediaSection, sessionpart) {
  // Look for sendrecv, sendonly, recvonly, inactive, default to sendrecv.
  var lines = SDPUtils.splitLines(mediaSection);

  for (var i = 0; i < lines.length; i++) {
    switch (lines[i]) {
      case 'a=sendrecv':
      case 'a=sendonly':
      case 'a=recvonly':
      case 'a=inactive':
        return lines[i].substr(2);

      default: // FIXME: What should happen here?

    }
  }

  if (sessionpart) {
    return SDPUtils.getDirection(sessionpart);
  }

  return 'sendrecv';
};

SDPUtils.getKind = function (mediaSection) {
  var lines = SDPUtils.splitLines(mediaSection);
  var mline = lines[0].split(' ');
  return mline[0].substr(2);
};

SDPUtils.isRejected = function (mediaSection) {
  return mediaSection.split(' ', 2)[1] === '0';
};

SDPUtils.parseMLine = function (mediaSection) {
  var lines = SDPUtils.splitLines(mediaSection);
  var parts = lines[0].substr(2).split(' ');
  return {
    kind: parts[0],
    port: parseInt(parts[1], 10),
    protocol: parts[2],
    fmt: parts.slice(3).join(' ')
  };
};

SDPUtils.parseOLine = function (mediaSection) {
  var line = SDPUtils.matchPrefix(mediaSection, 'o=')[0];
  var parts = line.substr(2).split(' ');
  return {
    username: parts[0],
    sessionId: parts[1],
    sessionVersion: parseInt(parts[2], 10),
    netType: parts[3],
    addressType: parts[4],
    address: parts[5]
  };
}; // a very naive interpretation of a valid SDP.


SDPUtils.isValidSDP = function (blob) {
  if (typeof blob !== 'string' || blob.length === 0) {
    return false;
  }

  var lines = SDPUtils.splitLines(blob);

  for (var i = 0; i < lines.length; i++) {
    if (lines[i].length < 2 || lines[i].charAt(1) !== '=') {
      return false;
    } // TODO: check the modifier a bit more.

  }

  return true;
}; // Expose public methods.


if (true) {
  module.exports = SDPUtils;
}

/***/ }),

/***/ "./node_modules/setimmediate/setImmediate.js":
/*!***************************************************!*\
  !*** ./node_modules/setimmediate/setImmediate.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(global, process) {(function (global, undefined) {
  "use strict";

  if (global.setImmediate) {
    return;
  }

  var nextHandle = 1; // Spec says greater than zero

  var tasksByHandle = {};
  var currentlyRunningATask = false;
  var doc = global.document;
  var registerImmediate;

  function setImmediate(callback) {
    // Callback can either be a function or a string
    if (typeof callback !== "function") {
      callback = new Function("" + callback);
    } // Copy function arguments


    var args = new Array(arguments.length - 1);

    for (var i = 0; i < args.length; i++) {
      args[i] = arguments[i + 1];
    } // Store and register the task


    var task = {
      callback: callback,
      args: args
    };
    tasksByHandle[nextHandle] = task;
    registerImmediate(nextHandle);
    return nextHandle++;
  }

  function clearImmediate(handle) {
    delete tasksByHandle[handle];
  }

  function run(task) {
    var callback = task.callback;
    var args = task.args;

    switch (args.length) {
      case 0:
        callback();
        break;

      case 1:
        callback(args[0]);
        break;

      case 2:
        callback(args[0], args[1]);
        break;

      case 3:
        callback(args[0], args[1], args[2]);
        break;

      default:
        callback.apply(undefined, args);
        break;
    }
  }

  function runIfPresent(handle) {
    // From the spec: "Wait until any invocations of this algorithm started before this one have completed."
    // So if we're currently running a task, we'll need to delay this invocation.
    if (currentlyRunningATask) {
      // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a
      // "too much recursion" error.
      setTimeout(runIfPresent, 0, handle);
    } else {
      var task = tasksByHandle[handle];

      if (task) {
        currentlyRunningATask = true;

        try {
          run(task);
        } finally {
          clearImmediate(handle);
          currentlyRunningATask = false;
        }
      }
    }
  }

  function installNextTickImplementation() {
    registerImmediate = function (handle) {
      process.nextTick(function () {
        runIfPresent(handle);
      });
    };
  }

  function canUsePostMessage() {
    // The test against `importScripts` prevents this implementation from being installed inside a web worker,
    // where `global.postMessage` means something completely different and can't be used for this purpose.
    if (global.postMessage && !global.importScripts) {
      var postMessageIsAsynchronous = true;
      var oldOnMessage = global.onmessage;

      global.onmessage = function () {
        postMessageIsAsynchronous = false;
      };

      global.postMessage("", "*");
      global.onmessage = oldOnMessage;
      return postMessageIsAsynchronous;
    }
  }

  function installPostMessageImplementation() {
    // Installs an event handler on `global` for the `message` event: see
    // * https://developer.mozilla.org/en/DOM/window.postMessage
    // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages
    var messagePrefix = "setImmediate$" + Math.random() + "$";

    var onGlobalMessage = function (event) {
      if (event.source === global && typeof event.data === "string" && event.data.indexOf(messagePrefix) === 0) {
        runIfPresent(+event.data.slice(messagePrefix.length));
      }
    };

    if (global.addEventListener) {
      global.addEventListener("message", onGlobalMessage, false);
    } else {
      global.attachEvent("onmessage", onGlobalMessage);
    }

    registerImmediate = function (handle) {
      global.postMessage(messagePrefix + handle, "*");
    };
  }

  function installMessageChannelImplementation() {
    var channel = new MessageChannel();

    channel.port1.onmessage = function (event) {
      var handle = event.data;
      runIfPresent(handle);
    };

    registerImmediate = function (handle) {
      channel.port2.postMessage(handle);
    };
  }

  function installReadyStateChangeImplementation() {
    var html = doc.documentElement;

    registerImmediate = function (handle) {
      // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted
      // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.
      var script = doc.createElement("script");

      script.onreadystatechange = function () {
        runIfPresent(handle);
        script.onreadystatechange = null;
        html.removeChild(script);
        script = null;
      };

      html.appendChild(script);
    };
  }

  function installSetTimeoutImplementation() {
    registerImmediate = function (handle) {
      setTimeout(runIfPresent, 0, handle);
    };
  } // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.


  var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);
  attachTo = attachTo && attachTo.setTimeout ? attachTo : global; // Don't get fooled by e.g. browserify environments.

  if ({}.toString.call(global.process) === "[object process]") {
    // For Node.js before 0.9
    installNextTickImplementation();
  } else if (canUsePostMessage()) {
    // For non-IE10 modern browsers
    installPostMessageImplementation();
  } else if (global.MessageChannel) {
    // For web workers, where supported
    installMessageChannelImplementation();
  } else if (doc && "onreadystatechange" in doc.createElement("script")) {
    // For IE 6–8
    installReadyStateChangeImplementation();
  } else {
    // For older browsers
    installSetTimeoutImplementation();
  }

  attachTo.setImmediate = setImmediate;
  attachTo.clearImmediate = clearImmediate;
})(typeof self === "undefined" ? typeof global === "undefined" ? this : global : self);
/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js"), __webpack_require__(/*! ./../process/browser.js */ "./node_modules/process/browser.js")))

/***/ }),

/***/ "./node_modules/strophe.js/dist/strophe.umd.js":
/*!*****************************************************!*\
  !*** ./node_modules/strophe.js/dist/strophe.umd.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(global) {(function (global, factory) {
   true ? module.exports = factory() : undefined;
})(this, function () {
  'use strict';

  var global$1 = typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {};

  function _typeof(obj) {
    if (typeof Symbol === "function" && typeof Symbol.iterator === "symbol") {
      _typeof = function (obj) {
        return typeof obj;
      };
    } else {
      _typeof = function (obj) {
        return obj && typeof Symbol === "function" && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj;
      };
    }

    return _typeof(obj);
  }

  function _toConsumableArray(arr) {
    return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _nonIterableSpread();
  }

  function _arrayWithoutHoles(arr) {
    if (Array.isArray(arr)) {
      for (var i = 0, arr2 = new Array(arr.length); i < arr.length; i++) arr2[i] = arr[i];

      return arr2;
    }
  }

  function _iterableToArray(iter) {
    if (Symbol.iterator in Object(iter) || Object.prototype.toString.call(iter) === "[object Arguments]") return Array.from(iter);
  }

  function _nonIterableSpread() {
    throw new TypeError("Invalid attempt to spread non-iterable instance");
  }
  /*
   * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message
   * Digest Algorithm, as defined in RFC 1321.
   * Version 2.1 Copyright (C) Paul Johnston 1999 - 2002.
   * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
   * Distributed under the BSD License
   * See http://pajhome.org.uk/crypt/md5 for more info.
   */

  /*
   * Everything that isn't used by Strophe has been stripped here!
   */

  /*
   * Add integers, wrapping at 2^32. This uses 16-bit operations internally
   * to work around bugs in some JS interpreters.
   */


  var safe_add = function safe_add(x, y) {
    var lsw = (x & 0xFFFF) + (y & 0xFFFF);
    var msw = (x >> 16) + (y >> 16) + (lsw >> 16);
    return msw << 16 | lsw & 0xFFFF;
  };
  /*
   * Bitwise rotate a 32-bit number to the left.
   */


  var bit_rol = function bit_rol(num, cnt) {
    return num << cnt | num >>> 32 - cnt;
  };
  /*
   * Convert a string to an array of little-endian words
   */


  var str2binl = function str2binl(str) {
    if (typeof str !== "string") {
      throw new Error("str2binl was passed a non-string");
    }

    var bin = [];

    for (var i = 0; i < str.length * 8; i += 8) {
      bin[i >> 5] |= (str.charCodeAt(i / 8) & 255) << i % 32;
    }

    return bin;
  };
  /*
   * Convert an array of little-endian words to a string
   */


  var binl2str = function binl2str(bin) {
    var str = "";

    for (var i = 0; i < bin.length * 32; i += 8) {
      str += String.fromCharCode(bin[i >> 5] >>> i % 32 & 255);
    }

    return str;
  };
  /*
   * Convert an array of little-endian words to a hex string.
   */


  var binl2hex = function binl2hex(binarray) {
    var hex_tab = "0123456789abcdef";
    var str = "";

    for (var i = 0; i < binarray.length * 4; i++) {
      str += hex_tab.charAt(binarray[i >> 2] >> i % 4 * 8 + 4 & 0xF) + hex_tab.charAt(binarray[i >> 2] >> i % 4 * 8 & 0xF);
    }

    return str;
  };
  /*
   * These functions implement the four basic operations the algorithm uses.
   */


  var md5_cmn = function md5_cmn(q, a, b, x, s, t) {
    return safe_add(bit_rol(safe_add(safe_add(a, q), safe_add(x, t)), s), b);
  };

  var md5_ff = function md5_ff(a, b, c, d, x, s, t) {
    return md5_cmn(b & c | ~b & d, a, b, x, s, t);
  };

  var md5_gg = function md5_gg(a, b, c, d, x, s, t) {
    return md5_cmn(b & d | c & ~d, a, b, x, s, t);
  };

  var md5_hh = function md5_hh(a, b, c, d, x, s, t) {
    return md5_cmn(b ^ c ^ d, a, b, x, s, t);
  };

  var md5_ii = function md5_ii(a, b, c, d, x, s, t) {
    return md5_cmn(c ^ (b | ~d), a, b, x, s, t);
  };
  /*
   * Calculate the MD5 of an array of little-endian words, and a bit length
   */


  var core_md5 = function core_md5(x, len) {
    /* append padding */
    x[len >> 5] |= 0x80 << len % 32;
    x[(len + 64 >>> 9 << 4) + 14] = len;
    var a = 1732584193;
    var b = -271733879;
    var c = -1732584194;
    var d = 271733878;
    var olda, oldb, oldc, oldd;

    for (var i = 0; i < x.length; i += 16) {
      olda = a;
      oldb = b;
      oldc = c;
      oldd = d;
      a = md5_ff(a, b, c, d, x[i + 0], 7, -680876936);
      d = md5_ff(d, a, b, c, x[i + 1], 12, -389564586);
      c = md5_ff(c, d, a, b, x[i + 2], 17, 606105819);
      b = md5_ff(b, c, d, a, x[i + 3], 22, -1044525330);
      a = md5_ff(a, b, c, d, x[i + 4], 7, -176418897);
      d = md5_ff(d, a, b, c, x[i + 5], 12, 1200080426);
      c = md5_ff(c, d, a, b, x[i + 6], 17, -1473231341);
      b = md5_ff(b, c, d, a, x[i + 7], 22, -45705983);
      a = md5_ff(a, b, c, d, x[i + 8], 7, 1770035416);
      d = md5_ff(d, a, b, c, x[i + 9], 12, -1958414417);
      c = md5_ff(c, d, a, b, x[i + 10], 17, -42063);
      b = md5_ff(b, c, d, a, x[i + 11], 22, -1990404162);
      a = md5_ff(a, b, c, d, x[i + 12], 7, 1804603682);
      d = md5_ff(d, a, b, c, x[i + 13], 12, -40341101);
      c = md5_ff(c, d, a, b, x[i + 14], 17, -1502002290);
      b = md5_ff(b, c, d, a, x[i + 15], 22, 1236535329);
      a = md5_gg(a, b, c, d, x[i + 1], 5, -165796510);
      d = md5_gg(d, a, b, c, x[i + 6], 9, -1069501632);
      c = md5_gg(c, d, a, b, x[i + 11], 14, 643717713);
      b = md5_gg(b, c, d, a, x[i + 0], 20, -373897302);
      a = md5_gg(a, b, c, d, x[i + 5], 5, -701558691);
      d = md5_gg(d, a, b, c, x[i + 10], 9, 38016083);
      c = md5_gg(c, d, a, b, x[i + 15], 14, -660478335);
      b = md5_gg(b, c, d, a, x[i + 4], 20, -405537848);
      a = md5_gg(a, b, c, d, x[i + 9], 5, 568446438);
      d = md5_gg(d, a, b, c, x[i + 14], 9, -1019803690);
      c = md5_gg(c, d, a, b, x[i + 3], 14, -187363961);
      b = md5_gg(b, c, d, a, x[i + 8], 20, 1163531501);
      a = md5_gg(a, b, c, d, x[i + 13], 5, -1444681467);
      d = md5_gg(d, a, b, c, x[i + 2], 9, -51403784);
      c = md5_gg(c, d, a, b, x[i + 7], 14, 1735328473);
      b = md5_gg(b, c, d, a, x[i + 12], 20, -1926607734);
      a = md5_hh(a, b, c, d, x[i + 5], 4, -378558);
      d = md5_hh(d, a, b, c, x[i + 8], 11, -2022574463);
      c = md5_hh(c, d, a, b, x[i + 11], 16, 1839030562);
      b = md5_hh(b, c, d, a, x[i + 14], 23, -35309556);
      a = md5_hh(a, b, c, d, x[i + 1], 4, -1530992060);
      d = md5_hh(d, a, b, c, x[i + 4], 11, 1272893353);
      c = md5_hh(c, d, a, b, x[i + 7], 16, -155497632);
      b = md5_hh(b, c, d, a, x[i + 10], 23, -1094730640);
      a = md5_hh(a, b, c, d, x[i + 13], 4, 681279174);
      d = md5_hh(d, a, b, c, x[i + 0], 11, -358537222);
      c = md5_hh(c, d, a, b, x[i + 3], 16, -722521979);
      b = md5_hh(b, c, d, a, x[i + 6], 23, 76029189);
      a = md5_hh(a, b, c, d, x[i + 9], 4, -640364487);
      d = md5_hh(d, a, b, c, x[i + 12], 11, -421815835);
      c = md5_hh(c, d, a, b, x[i + 15], 16, 530742520);
      b = md5_hh(b, c, d, a, x[i + 2], 23, -995338651);
      a = md5_ii(a, b, c, d, x[i + 0], 6, -198630844);
      d = md5_ii(d, a, b, c, x[i + 7], 10, 1126891415);
      c = md5_ii(c, d, a, b, x[i + 14], 15, -1416354905);
      b = md5_ii(b, c, d, a, x[i + 5], 21, -57434055);
      a = md5_ii(a, b, c, d, x[i + 12], 6, 1700485571);
      d = md5_ii(d, a, b, c, x[i + 3], 10, -1894986606);
      c = md5_ii(c, d, a, b, x[i + 10], 15, -1051523);
      b = md5_ii(b, c, d, a, x[i + 1], 21, -2054922799);
      a = md5_ii(a, b, c, d, x[i + 8], 6, 1873313359);
      d = md5_ii(d, a, b, c, x[i + 15], 10, -30611744);
      c = md5_ii(c, d, a, b, x[i + 6], 15, -1560198380);
      b = md5_ii(b, c, d, a, x[i + 13], 21, 1309151649);
      a = md5_ii(a, b, c, d, x[i + 4], 6, -145523070);
      d = md5_ii(d, a, b, c, x[i + 11], 10, -1120210379);
      c = md5_ii(c, d, a, b, x[i + 2], 15, 718787259);
      b = md5_ii(b, c, d, a, x[i + 9], 21, -343485551);
      a = safe_add(a, olda);
      b = safe_add(b, oldb);
      c = safe_add(c, oldc);
      d = safe_add(d, oldd);
    }

    return [a, b, c, d];
  };
  /*
   * These are the functions you'll usually want to call.
   * They take string arguments and return either hex or base-64 encoded
   * strings.
   */


  var MD5 = {
    hexdigest: function hexdigest(s) {
      return binl2hex(core_md5(str2binl(s), s.length * 8));
    },
    hash: function hash(s) {
      return binl2str(core_md5(str2binl(s), s.length * 8));
    }
  };
  /*
   * A JavaScript implementation of the Secure Hash Algorithm, SHA-1, as defined
   * in FIPS PUB 180-1
   * Version 2.1a Copyright Paul Johnston 2000 - 2002.
   * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
   * Distributed under the BSD License
   * See http://pajhome.org.uk/crypt/md5 for details.
   */

  /* global define */

  /* Some functions and variables have been stripped for use with Strophe */

  /*
   * Calculate the SHA-1 of an array of big-endian words, and a bit length
   */

  function core_sha1(x, len) {
    /* append padding */
    x[len >> 5] |= 0x80 << 24 - len % 32;
    x[(len + 64 >> 9 << 4) + 15] = len;
    var w = new Array(80);
    var a = 1732584193;
    var b = -271733879;
    var c = -1732584194;
    var d = 271733878;
    var e = -1009589776;
    var i, j, t, olda, oldb, oldc, oldd, olde;

    for (i = 0; i < x.length; i += 16) {
      olda = a;
      oldb = b;
      oldc = c;
      oldd = d;
      olde = e;

      for (j = 0; j < 80; j++) {
        if (j < 16) {
          w[j] = x[i + j];
        } else {
          w[j] = rol(w[j - 3] ^ w[j - 8] ^ w[j - 14] ^ w[j - 16], 1);
        }

        t = safe_add$1(safe_add$1(rol(a, 5), sha1_ft(j, b, c, d)), safe_add$1(safe_add$1(e, w[j]), sha1_kt(j)));
        e = d;
        d = c;
        c = rol(b, 30);
        b = a;
        a = t;
      }

      a = safe_add$1(a, olda);
      b = safe_add$1(b, oldb);
      c = safe_add$1(c, oldc);
      d = safe_add$1(d, oldd);
      e = safe_add$1(e, olde);
    }

    return [a, b, c, d, e];
  }
  /*
   * Perform the appropriate triplet combination function for the current
   * iteration
   */


  function sha1_ft(t, b, c, d) {
    if (t < 20) {
      return b & c | ~b & d;
    }

    if (t < 40) {
      return b ^ c ^ d;
    }

    if (t < 60) {
      return b & c | b & d | c & d;
    }

    return b ^ c ^ d;
  }
  /*
   * Determine the appropriate additive constant for the current iteration
   */


  function sha1_kt(t) {
    return t < 20 ? 1518500249 : t < 40 ? 1859775393 : t < 60 ? -1894007588 : -899497514;
  }
  /*
   * Calculate the HMAC-SHA1 of a key and some data
   */


  function core_hmac_sha1(key, data) {
    var bkey = str2binb(key);

    if (bkey.length > 16) {
      bkey = core_sha1(bkey, key.length * 8);
    }

    var ipad = new Array(16),
        opad = new Array(16);

    for (var i = 0; i < 16; i++) {
      ipad[i] = bkey[i] ^ 0x36363636;
      opad[i] = bkey[i] ^ 0x5C5C5C5C;
    }

    var hash = core_sha1(ipad.concat(str2binb(data)), 512 + data.length * 8);
    return core_sha1(opad.concat(hash), 512 + 160);
  }
  /*
   * Add integers, wrapping at 2^32. This uses 16-bit operations internally
   * to work around bugs in some JS interpreters.
   */


  function safe_add$1(x, y) {
    var lsw = (x & 0xFFFF) + (y & 0xFFFF);
    var msw = (x >> 16) + (y >> 16) + (lsw >> 16);
    return msw << 16 | lsw & 0xFFFF;
  }
  /*
   * Bitwise rotate a 32-bit number to the left.
   */


  function rol(num, cnt) {
    return num << cnt | num >>> 32 - cnt;
  }
  /*
   * Convert an 8-bit or 16-bit string to an array of big-endian words
   * In 8-bit function, characters >255 have their hi-byte silently ignored.
   */


  function str2binb(str) {
    var bin = [];
    var mask = 255;

    for (var i = 0; i < str.length * 8; i += 8) {
      bin[i >> 5] |= (str.charCodeAt(i / 8) & mask) << 24 - i % 32;
    }

    return bin;
  }
  /*
   * Convert an array of big-endian words to a base-64 string
   */


  function binb2b64(binarray) {
    var tab = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    var str = "";
    var triplet, j;

    for (var i = 0; i < binarray.length * 4; i += 3) {
      triplet = (binarray[i >> 2] >> 8 * (3 - i % 4) & 0xFF) << 16 | (binarray[i + 1 >> 2] >> 8 * (3 - (i + 1) % 4) & 0xFF) << 8 | binarray[i + 2 >> 2] >> 8 * (3 - (i + 2) % 4) & 0xFF;

      for (j = 0; j < 4; j++) {
        if (i * 8 + j * 6 > binarray.length * 32) {
          str += "=";
        } else {
          str += tab.charAt(triplet >> 6 * (3 - j) & 0x3F);
        }
      }
    }

    return str;
  }
  /*
   * Convert an array of big-endian words to a string
   */


  function binb2str(bin) {
    var str = "";
    var mask = 255;

    for (var i = 0; i < bin.length * 32; i += 8) {
      str += String.fromCharCode(bin[i >> 5] >>> 24 - i % 32 & mask);
    }

    return str;
  }
  /*
   * These are the functions you'll usually want to call
   * They take string arguments and return either hex or base-64 encoded strings
   */


  var SHA1 = {
    b64_hmac_sha1: function b64_hmac_sha1(key, data) {
      return binb2b64(core_hmac_sha1(key, data));
    },
    b64_sha1: function b64_sha1(s) {
      return binb2b64(core_sha1(str2binb(s), s.length * 8));
    },
    binb2str: binb2str,
    core_hmac_sha1: core_hmac_sha1,
    str_hmac_sha1: function str_hmac_sha1(key, data) {
      return binb2str(core_hmac_sha1(key, data));
    },
    str_sha1: function str_sha1(s) {
      return binb2str(core_sha1(str2binb(s), s.length * 8));
    }
  };
  var utils = {
    utf16to8: function utf16to8(str) {
      var i, c;
      var out = "";
      var len = str.length;

      for (i = 0; i < len; i++) {
        c = str.charCodeAt(i);

        if (c >= 0x0000 && c <= 0x007F) {
          out += str.charAt(i);
        } else if (c > 0x07FF) {
          out += String.fromCharCode(0xE0 | c >> 12 & 0x0F);
          out += String.fromCharCode(0x80 | c >> 6 & 0x3F);
          out += String.fromCharCode(0x80 | c >> 0 & 0x3F);
        } else {
          out += String.fromCharCode(0xC0 | c >> 6 & 0x1F);
          out += String.fromCharCode(0x80 | c >> 0 & 0x3F);
        }
      }

      return out;
    },
    addCookies: function addCookies(cookies) {
      /* Parameters:
       *  (Object) cookies - either a map of cookie names
       *    to string values or to maps of cookie values.
       *
       * For example:
       * { "myCookie": "1234" }
       *
       * or:
       * { "myCookie": {
       *      "value": "1234",
       *      "domain": ".example.org",
       *      "path": "/",
       *      "expires": expirationDate
       *      }
       *  }
       *
       *  These values get passed to Strophe.Connection via
       *   options.cookies
       */
      cookies = cookies || {};

      for (var cookieName in cookies) {
        if (Object.prototype.hasOwnProperty.call(cookies, cookieName)) {
          var expires = '';
          var domain = '';
          var path = '';
          var cookieObj = cookies[cookieName];
          var isObj = _typeof(cookieObj) === "object";
          var cookieValue = escape(unescape(isObj ? cookieObj.value : cookieObj));

          if (isObj) {
            expires = cookieObj.expires ? ";expires=" + cookieObj.expires : '';
            domain = cookieObj.domain ? ";domain=" + cookieObj.domain : '';
            path = cookieObj.path ? ";path=" + cookieObj.path : '';
          }

          document.cookie = cookieName + '=' + cookieValue + expires + domain + path;
        }
      }
    }
  };
  /** Function: $build
   *  Create a Strophe.Builder.
   *  This is an alias for 'new Strophe.Builder(name, attrs)'.
   *
   *  Parameters:
   *    (String) name - The root element name.
   *    (Object) attrs - The attributes for the root element in object notation.
   *
   *  Returns:
   *    A new Strophe.Builder object.
   */

  function $build(name, attrs) {
    return new Strophe.Builder(name, attrs);
  }
  /** Function: $msg
   *  Create a Strophe.Builder with a <message/> element as the root.
   *
   *  Parameters:
   *    (Object) attrs - The <message/> element attributes in object notation.
   *
   *  Returns:
   *    A new Strophe.Builder object.
   */


  function $msg(attrs) {
    return new Strophe.Builder("message", attrs);
  }
  /** Function: $iq
   *  Create a Strophe.Builder with an <iq/> element as the root.
   *
   *  Parameters:
   *    (Object) attrs - The <iq/> element attributes in object notation.
   *
   *  Returns:
   *    A new Strophe.Builder object.
   */


  function $iq(attrs) {
    return new Strophe.Builder("iq", attrs);
  }
  /** Function: $pres
   *  Create a Strophe.Builder with a <presence/> element as the root.
   *
   *  Parameters:
   *    (Object) attrs - The <presence/> element attributes in object notation.
   *
   *  Returns:
   *    A new Strophe.Builder object.
   */


  function $pres(attrs) {
    return new Strophe.Builder("presence", attrs);
  }
  /** Class: Strophe
   *  An object container for all Strophe library functions.
   *
   *  This class is just a container for all the objects and constants
   *  used in the library.  It is not meant to be instantiated, but to
   *  provide a namespace for library objects, constants, and functions.
   */


  var Strophe = {
    /** Constant: VERSION */
    VERSION: "@VERSION@",

    /** Constants: XMPP Namespace Constants
     *  Common namespace constants from the XMPP RFCs and XEPs.
     *
     *  NS.HTTPBIND - HTTP BIND namespace from XEP 124.
     *  NS.BOSH - BOSH namespace from XEP 206.
     *  NS.CLIENT - Main XMPP client namespace.
     *  NS.AUTH - Legacy authentication namespace.
     *  NS.ROSTER - Roster operations namespace.
     *  NS.PROFILE - Profile namespace.
     *  NS.DISCO_INFO - Service discovery info namespace from XEP 30.
     *  NS.DISCO_ITEMS - Service discovery items namespace from XEP 30.
     *  NS.MUC - Multi-User Chat namespace from XEP 45.
     *  NS.SASL - XMPP SASL namespace from RFC 3920.
     *  NS.STREAM - XMPP Streams namespace from RFC 3920.
     *  NS.BIND - XMPP Binding namespace from RFC 3920 and RFC 6120.
     *  NS.SESSION - XMPP Session namespace from RFC 3920.
     *  NS.XHTML_IM - XHTML-IM namespace from XEP 71.
     *  NS.XHTML - XHTML body namespace from XEP 71.
     */
    NS: {
      HTTPBIND: "http://jabber.org/protocol/httpbind",
      BOSH: "urn:xmpp:xbosh",
      CLIENT: "jabber:client",
      AUTH: "jabber:iq:auth",
      ROSTER: "jabber:iq:roster",
      PROFILE: "jabber:iq:profile",
      DISCO_INFO: "http://jabber.org/protocol/disco#info",
      DISCO_ITEMS: "http://jabber.org/protocol/disco#items",
      MUC: "http://jabber.org/protocol/muc",
      SASL: "urn:ietf:params:xml:ns:xmpp-sasl",
      STREAM: "http://etherx.jabber.org/streams",
      FRAMING: "urn:ietf:params:xml:ns:xmpp-framing",
      BIND: "urn:ietf:params:xml:ns:xmpp-bind",
      SESSION: "urn:ietf:params:xml:ns:xmpp-session",
      VERSION: "jabber:iq:version",
      STANZAS: "urn:ietf:params:xml:ns:xmpp-stanzas",
      XHTML_IM: "http://jabber.org/protocol/xhtml-im",
      XHTML: "http://www.w3.org/1999/xhtml"
    },

    /** Constants: XHTML_IM Namespace
     *  contains allowed tags, tag attributes, and css properties.
     *  Used in the createHtml function to filter incoming html into the allowed XHTML-IM subset.
     *  See http://xmpp.org/extensions/xep-0071.html#profile-summary for the list of recommended
     *  allowed tags and their attributes.
     */
    XHTML: {
      tags: ['a', 'blockquote', 'br', 'cite', 'em', 'img', 'li', 'ol', 'p', 'span', 'strong', 'ul', 'body'],
      attributes: {
        'a': ['href'],
        'blockquote': ['style'],
        'br': [],
        'cite': ['style'],
        'em': [],
        'img': ['src', 'alt', 'style', 'height', 'width'],
        'li': ['style'],
        'ol': ['style'],
        'p': ['style'],
        'span': ['style'],
        'strong': [],
        'ul': ['style'],
        'body': []
      },
      css: ['background-color', 'color', 'font-family', 'font-size', 'font-style', 'font-weight', 'margin-left', 'margin-right', 'text-align', 'text-decoration'],

      /** Function: XHTML.validTag
       *
       * Utility method to determine whether a tag is allowed
       * in the XHTML_IM namespace.
       *
       * XHTML tag names are case sensitive and must be lower case.
       */
      validTag: function validTag(tag) {
        for (var i = 0; i < Strophe.XHTML.tags.length; i++) {
          if (tag === Strophe.XHTML.tags[i]) {
            return true;
          }
        }

        return false;
      },

      /** Function: XHTML.validAttribute
       *
       * Utility method to determine whether an attribute is allowed
       * as recommended per XEP-0071
       *
       * XHTML attribute names are case sensitive and must be lower case.
       */
      validAttribute: function validAttribute(tag, attribute) {
        if (typeof Strophe.XHTML.attributes[tag] !== 'undefined' && Strophe.XHTML.attributes[tag].length > 0) {
          for (var i = 0; i < Strophe.XHTML.attributes[tag].length; i++) {
            if (attribute === Strophe.XHTML.attributes[tag][i]) {
              return true;
            }
          }
        }

        return false;
      },
      validCSS: function validCSS(style) {
        for (var i = 0; i < Strophe.XHTML.css.length; i++) {
          if (style === Strophe.XHTML.css[i]) {
            return true;
          }
        }

        return false;
      }
    },

    /** Constants: Connection Status Constants
     *  Connection status constants for use by the connection handler
     *  callback.
     *
     *  Status.ERROR - An error has occurred
     *  Status.CONNECTING - The connection is currently being made
     *  Status.CONNFAIL - The connection attempt failed
     *  Status.AUTHENTICATING - The connection is authenticating
     *  Status.AUTHFAIL - The authentication attempt failed
     *  Status.CONNECTED - The connection has succeeded
     *  Status.DISCONNECTED - The connection has been terminated
     *  Status.DISCONNECTING - The connection is currently being terminated
     *  Status.ATTACHED - The connection has been attached
     *  Status.REDIRECT - The connection has been redirected
     *  Status.CONNTIMEOUT - The connection has timed out
     */
    Status: {
      ERROR: 0,
      CONNECTING: 1,
      CONNFAIL: 2,
      AUTHENTICATING: 3,
      AUTHFAIL: 4,
      CONNECTED: 5,
      DISCONNECTED: 6,
      DISCONNECTING: 7,
      ATTACHED: 8,
      REDIRECT: 9,
      CONNTIMEOUT: 10,
      BINDREQUIRED: 11
    },
    ErrorCondition: {
      BAD_FORMAT: "bad-format",
      CONFLICT: "conflict",
      MISSING_JID_NODE: "x-strophe-bad-non-anon-jid",
      NO_AUTH_MECH: "no-auth-mech",
      UNKNOWN_REASON: "unknown"
    },

    /** Constants: Log Level Constants
     *  Logging level indicators.
     *
     *  LogLevel.DEBUG - Debug output
     *  LogLevel.INFO - Informational output
     *  LogLevel.WARN - Warnings
     *  LogLevel.ERROR - Errors
     *  LogLevel.FATAL - Fatal errors
     */
    LogLevel: {
      DEBUG: 0,
      INFO: 1,
      WARN: 2,
      ERROR: 3,
      FATAL: 4
    },

    /** PrivateConstants: DOM Element Type Constants
     *  DOM element types.
     *
     *  ElementType.NORMAL - Normal element.
     *  ElementType.TEXT - Text data element.
     *  ElementType.FRAGMENT - XHTML fragment element.
     */
    ElementType: {
      NORMAL: 1,
      TEXT: 3,
      CDATA: 4,
      FRAGMENT: 11
    },

    /** PrivateConstants: Timeout Values
     *  Timeout values for error states.  These values are in seconds.
     *  These should not be changed unless you know exactly what you are
     *  doing.
     *
     *  TIMEOUT - Timeout multiplier. A waiting request will be considered
     *      failed after Math.floor(TIMEOUT * wait) seconds have elapsed.
     *      This defaults to 1.1, and with default wait, 66 seconds.
     *  SECONDARY_TIMEOUT - Secondary timeout multiplier. In cases where
     *      Strophe can detect early failure, it will consider the request
     *      failed if it doesn't return after
     *      Math.floor(SECONDARY_TIMEOUT * wait) seconds have elapsed.
     *      This defaults to 0.1, and with default wait, 6 seconds.
     */
    TIMEOUT: 1.1,
    SECONDARY_TIMEOUT: 0.1,

    /** Function: addNamespace
     *  This function is used to extend the current namespaces in
     *  Strophe.NS.  It takes a key and a value with the key being the
     *  name of the new namespace, with its actual value.
     *  For example:
     *  Strophe.addNamespace('PUBSUB', "http://jabber.org/protocol/pubsub");
     *
     *  Parameters:
     *    (String) name - The name under which the namespace will be
     *      referenced under Strophe.NS
     *    (String) value - The actual namespace.
     */
    addNamespace: function addNamespace(name, value) {
      Strophe.NS[name] = value;
    },

    /** Function: forEachChild
     *  Map a function over some or all child elements of a given element.
     *
     *  This is a small convenience function for mapping a function over
     *  some or all of the children of an element.  If elemName is null, all
     *  children will be passed to the function, otherwise only children
     *  whose tag names match elemName will be passed.
     *
     *  Parameters:
     *    (XMLElement) elem - The element to operate on.
     *    (String) elemName - The child element tag name filter.
     *    (Function) func - The function to apply to each child.  This
     *      function should take a single argument, a DOM element.
     */
    forEachChild: function forEachChild(elem, elemName, func) {
      for (var i = 0; i < elem.childNodes.length; i++) {
        var childNode = elem.childNodes[i];

        if (childNode.nodeType === Strophe.ElementType.NORMAL && (!elemName || this.isTagEqual(childNode, elemName))) {
          func(childNode);
        }
      }
    },

    /** Function: isTagEqual
     *  Compare an element's tag name with a string.
     *
     *  This function is case sensitive.
     *
     *  Parameters:
     *    (XMLElement) el - A DOM element.
     *    (String) name - The element name.
     *
     *  Returns:
     *    true if the element's tag name matches _el_, and false
     *    otherwise.
     */
    isTagEqual: function isTagEqual(el, name) {
      return el.tagName === name;
    },

    /** PrivateVariable: _xmlGenerator
     *  _Private_ variable that caches a DOM document to
     *  generate elements.
     */
    _xmlGenerator: null,

    /** PrivateFunction: _makeGenerator
     *  _Private_ function that creates a dummy XML DOM document to serve as
     *  an element and text node generator.
     */
    _makeGenerator: function _makeGenerator() {
      var doc; // IE9 does implement createDocument(); however, using it will cause the browser to leak memory on page unload.
      // Here, we test for presence of createDocument() plus IE's proprietary documentMode attribute, which would be
      // less than 10 in the case of IE9 and below.

      if (document.implementation.createDocument === undefined || document.implementation.createDocument && document.documentMode && document.documentMode < 10) {
        doc = this._getIEXmlDom();
        doc.appendChild(doc.createElement('strophe'));
      } else {
        doc = document.implementation.createDocument('jabber:client', 'strophe', null);
      }

      return doc;
    },

    /** Function: xmlGenerator
     *  Get the DOM document to generate elements.
     *
     *  Returns:
     *    The currently used DOM document.
     */
    xmlGenerator: function xmlGenerator() {
      if (!Strophe._xmlGenerator) {
        Strophe._xmlGenerator = Strophe._makeGenerator();
      }

      return Strophe._xmlGenerator;
    },

    /** PrivateFunction: _getIEXmlDom
     *  Gets IE xml doc object
     *
     *  Returns:
     *    A Microsoft XML DOM Object
     *  See Also:
     *    http://msdn.microsoft.com/en-us/library/ms757837%28VS.85%29.aspx
     */
    _getIEXmlDom: function _getIEXmlDom() {
      var doc = null;
      var docStrings = ["Msxml2.DOMDocument.6.0", "Msxml2.DOMDocument.5.0", "Msxml2.DOMDocument.4.0", "MSXML2.DOMDocument.3.0", "MSXML2.DOMDocument", "MSXML.DOMDocument", "Microsoft.XMLDOM"];

      for (var d = 0; d < docStrings.length; d++) {
        if (doc === null) {
          try {
            doc = new ActiveXObject(docStrings[d]);
          } catch (e) {
            doc = null;
          }
        } else {
          break;
        }
      }

      return doc;
    },

    /** Function: xmlElement
     *  Create an XML DOM element.
     *
     *  This function creates an XML DOM element correctly across all
     *  implementations. Note that these are not HTML DOM elements, which
     *  aren't appropriate for XMPP stanzas.
     *
     *  Parameters:
     *    (String) name - The name for the element.
     *    (Array|Object) attrs - An optional array or object containing
     *      key/value pairs to use as element attributes. The object should
     *      be in the format {'key': 'value'} or {key: 'value'}. The array
     *      should have the format [['key1', 'value1'], ['key2', 'value2']].
     *    (String) text - The text child data for the element.
     *
     *  Returns:
     *    A new XML DOM element.
     */
    xmlElement: function xmlElement(name) {
      if (!name) {
        return null;
      }

      var node = Strophe.xmlGenerator().createElement(name); // FIXME: this should throw errors if args are the wrong type or
      // there are more than two optional args

      for (var a = 1; a < arguments.length; a++) {
        var arg = arguments[a];

        if (!arg) {
          continue;
        }

        if (typeof arg === "string" || typeof arg === "number") {
          node.appendChild(Strophe.xmlTextNode(arg));
        } else if (_typeof(arg) === "object" && typeof arg.sort === "function") {
          for (var i = 0; i < arg.length; i++) {
            var attr = arg[i];

            if (_typeof(attr) === "object" && typeof attr.sort === "function" && attr[1] !== undefined && attr[1] !== null) {
              node.setAttribute(attr[0], attr[1]);
            }
          }
        } else if (_typeof(arg) === "object") {
          for (var k in arg) {
            if (Object.prototype.hasOwnProperty.call(arg, k) && arg[k] !== undefined && arg[k] !== null) {
              node.setAttribute(k, arg[k]);
            }
          }
        }
      }

      return node;
    },

    /*  Function: xmlescape
     *  Excapes invalid xml characters.
     *
     *  Parameters:
     *     (String) text - text to escape.
     *
     *  Returns:
     *      Escaped text.
     */
    xmlescape: function xmlescape(text) {
      text = text.replace(/\&/g, "&amp;");
      text = text.replace(/</g, "&lt;");
      text = text.replace(/>/g, "&gt;");
      text = text.replace(/'/g, "&apos;");
      text = text.replace(/"/g, "&quot;");
      return text;
    },

    /*  Function: xmlunescape
    *  Unexcapes invalid xml characters.
    *
    *  Parameters:
    *     (String) text - text to unescape.
    *
    *  Returns:
    *      Unescaped text.
    */
    xmlunescape: function xmlunescape(text) {
      text = text.replace(/\&amp;/g, "&");
      text = text.replace(/&lt;/g, "<");
      text = text.replace(/&gt;/g, ">");
      text = text.replace(/&apos;/g, "'");
      text = text.replace(/&quot;/g, "\"");
      return text;
    },

    /** Function: xmlTextNode
     *  Creates an XML DOM text node.
     *
     *  Provides a cross implementation version of document.createTextNode.
     *
     *  Parameters:
     *    (String) text - The content of the text node.
     *
     *  Returns:
     *    A new XML DOM text node.
     */
    xmlTextNode: function xmlTextNode(text) {
      return Strophe.xmlGenerator().createTextNode(text);
    },

    /** Function: xmlHtmlNode
     *  Creates an XML DOM html node.
     *
     *  Parameters:
     *    (String) html - The content of the html node.
     *
     *  Returns:
     *    A new XML DOM text node.
     */
    xmlHtmlNode: function xmlHtmlNode(html) {
      var node; //ensure text is escaped

      if (DOMParser) {
        var parser = new DOMParser();
        node = parser.parseFromString(html, "text/xml");
      } else {
        node = new ActiveXObject("Microsoft.XMLDOM");
        node.async = "false";
        node.loadXML(html);
      }

      return node;
    },

    /** Function: getText
     *  Get the concatenation of all text children of an element.
     *
     *  Parameters:
     *    (XMLElement) elem - A DOM element.
     *
     *  Returns:
     *    A String with the concatenated text of all text element children.
     */
    getText: function getText(elem) {
      if (!elem) {
        return null;
      }

      var str = "";

      if (elem.childNodes.length === 0 && elem.nodeType === Strophe.ElementType.TEXT) {
        str += elem.nodeValue;
      }

      for (var i = 0; i < elem.childNodes.length; i++) {
        if (elem.childNodes[i].nodeType === Strophe.ElementType.TEXT) {
          str += elem.childNodes[i].nodeValue;
        }
      }

      return Strophe.xmlescape(str);
    },

    /** Function: copyElement
     *  Copy an XML DOM element.
     *
     *  This function copies a DOM element and all its descendants and returns
     *  the new copy.
     *
     *  Parameters:
     *    (XMLElement) elem - A DOM element.
     *
     *  Returns:
     *    A new, copied DOM element tree.
     */
    copyElement: function copyElement(elem) {
      var el;

      if (elem.nodeType === Strophe.ElementType.NORMAL) {
        el = Strophe.xmlElement(elem.tagName);

        for (var i = 0; i < elem.attributes.length; i++) {
          el.setAttribute(elem.attributes[i].nodeName, elem.attributes[i].value);
        }

        for (var _i = 0; _i < elem.childNodes.length; _i++) {
          el.appendChild(Strophe.copyElement(elem.childNodes[_i]));
        }
      } else if (elem.nodeType === Strophe.ElementType.TEXT) {
        el = Strophe.xmlGenerator().createTextNode(elem.nodeValue);
      }

      return el;
    },

    /** Function: createHtml
     *  Copy an HTML DOM element into an XML DOM.
     *
     *  This function copies a DOM element and all its descendants and returns
     *  the new copy.
     *
     *  Parameters:
     *    (HTMLElement) elem - A DOM element.
     *
     *  Returns:
     *    A new, copied DOM element tree.
     */
    createHtml: function createHtml(elem) {
      var el;

      if (elem.nodeType === Strophe.ElementType.NORMAL) {
        var tag = elem.nodeName.toLowerCase(); // XHTML tags must be lower case.

        if (Strophe.XHTML.validTag(tag)) {
          try {
            el = Strophe.xmlElement(tag);

            for (var i = 0; i < Strophe.XHTML.attributes[tag].length; i++) {
              var attribute = Strophe.XHTML.attributes[tag][i];
              var value = elem.getAttribute(attribute);

              if (typeof value === 'undefined' || value === null || value === '' || value === false || value === 0) {
                continue;
              }

              if (attribute === 'style' && _typeof(value) === 'object' && typeof value.cssText !== 'undefined') {
                value = value.cssText; // we're dealing with IE, need to get CSS out
              } // filter out invalid css styles


              if (attribute === 'style') {
                var css = [];
                var cssAttrs = value.split(';');

                for (var j = 0; j < cssAttrs.length; j++) {
                  var attr = cssAttrs[j].split(':');
                  var cssName = attr[0].replace(/^\s*/, "").replace(/\s*$/, "").toLowerCase();

                  if (Strophe.XHTML.validCSS(cssName)) {
                    var cssValue = attr[1].replace(/^\s*/, "").replace(/\s*$/, "");
                    css.push(cssName + ': ' + cssValue);
                  }
                }

                if (css.length > 0) {
                  value = css.join('; ');
                  el.setAttribute(attribute, value);
                }
              } else {
                el.setAttribute(attribute, value);
              }
            }

            for (var _i2 = 0; _i2 < elem.childNodes.length; _i2++) {
              el.appendChild(Strophe.createHtml(elem.childNodes[_i2]));
            }
          } catch (e) {
            // invalid elements
            el = Strophe.xmlTextNode('');
          }
        } else {
          el = Strophe.xmlGenerator().createDocumentFragment();

          for (var _i3 = 0; _i3 < elem.childNodes.length; _i3++) {
            el.appendChild(Strophe.createHtml(elem.childNodes[_i3]));
          }
        }
      } else if (elem.nodeType === Strophe.ElementType.FRAGMENT) {
        el = Strophe.xmlGenerator().createDocumentFragment();

        for (var _i4 = 0; _i4 < elem.childNodes.length; _i4++) {
          el.appendChild(Strophe.createHtml(elem.childNodes[_i4]));
        }
      } else if (elem.nodeType === Strophe.ElementType.TEXT) {
        el = Strophe.xmlTextNode(elem.nodeValue);
      }

      return el;
    },

    /** Function: escapeNode
     *  Escape the node part (also called local part) of a JID.
     *
     *  Parameters:
     *    (String) node - A node (or local part).
     *
     *  Returns:
     *    An escaped node (or local part).
     */
    escapeNode: function escapeNode(node) {
      if (typeof node !== "string") {
        return node;
      }

      return node.replace(/^\s+|\s+$/g, '').replace(/\\/g, "\\5c").replace(/ /g, "\\20").replace(/\"/g, "\\22").replace(/\&/g, "\\26").replace(/\'/g, "\\27").replace(/\//g, "\\2f").replace(/:/g, "\\3a").replace(/</g, "\\3c").replace(/>/g, "\\3e").replace(/@/g, "\\40");
    },

    /** Function: unescapeNode
     *  Unescape a node part (also called local part) of a JID.
     *
     *  Parameters:
     *    (String) node - A node (or local part).
     *
     *  Returns:
     *    An unescaped node (or local part).
     */
    unescapeNode: function unescapeNode(node) {
      if (typeof node !== "string") {
        return node;
      }

      return node.replace(/\\20/g, " ").replace(/\\22/g, '"').replace(/\\26/g, "&").replace(/\\27/g, "'").replace(/\\2f/g, "/").replace(/\\3a/g, ":").replace(/\\3c/g, "<").replace(/\\3e/g, ">").replace(/\\40/g, "@").replace(/\\5c/g, "\\");
    },

    /** Function: getNodeFromJid
     *  Get the node portion of a JID String.
     *
     *  Parameters:
     *    (String) jid - A JID.
     *
     *  Returns:
     *    A String containing the node.
     */
    getNodeFromJid: function getNodeFromJid(jid) {
      if (jid.indexOf("@") < 0) {
        return null;
      }

      return jid.split("@")[0];
    },

    /** Function: getDomainFromJid
     *  Get the domain portion of a JID String.
     *
     *  Parameters:
     *    (String) jid - A JID.
     *
     *  Returns:
     *    A String containing the domain.
     */
    getDomainFromJid: function getDomainFromJid(jid) {
      var bare = Strophe.getBareJidFromJid(jid);

      if (bare.indexOf("@") < 0) {
        return bare;
      } else {
        var parts = bare.split("@");
        parts.splice(0, 1);
        return parts.join('@');
      }
    },

    /** Function: getResourceFromJid
     *  Get the resource portion of a JID String.
     *
     *  Parameters:
     *    (String) jid - A JID.
     *
     *  Returns:
     *    A String containing the resource.
     */
    getResourceFromJid: function getResourceFromJid(jid) {
      if (!jid) {
        return null;
      }

      var s = jid.split("/");

      if (s.length < 2) {
        return null;
      }

      s.splice(0, 1);
      return s.join('/');
    },

    /** Function: getBareJidFromJid
     *  Get the bare JID from a JID String.
     *
     *  Parameters:
     *    (String) jid - A JID.
     *
     *  Returns:
     *    A String containing the bare JID.
     */
    getBareJidFromJid: function getBareJidFromJid(jid) {
      return jid ? jid.split("/")[0] : null;
    },

    /** PrivateFunction: _handleError
     *  _Private_ function that properly logs an error to the console
     */
    _handleError: function _handleError(e) {
      if (typeof e.stack !== "undefined") {
        Strophe.fatal(e.stack);
      }

      if (e.sourceURL) {
        Strophe.fatal("error: " + this.handler + " " + e.sourceURL + ":" + e.line + " - " + e.name + ": " + e.message);
      } else if (e.fileName) {
        Strophe.fatal("error: " + this.handler + " " + e.fileName + ":" + e.lineNumber + " - " + e.name + ": " + e.message);
      } else {
        Strophe.fatal("error: " + e.message);
      }
    },

    /** Function: log
     *  User overrideable logging function.
     *
     *  This function is called whenever the Strophe library calls any
     *  of the logging functions.  The default implementation of this
     *  function logs only fatal errors.  If client code wishes to handle the logging
     *  messages, it should override this with
     *  > Strophe.log = function (level, msg) {
     *  >   (user code here)
     *  > };
     *
     *  Please note that data sent and received over the wire is logged
     *  via Strophe.Connection.rawInput() and Strophe.Connection.rawOutput().
     *
     *  The different levels and their meanings are
     *
     *    DEBUG - Messages useful for debugging purposes.
     *    INFO - Informational messages.  This is mostly information like
     *      'disconnect was called' or 'SASL auth succeeded'.
     *    WARN - Warnings about potential problems.  This is mostly used
     *      to report transient connection errors like request timeouts.
     *    ERROR - Some error occurred.
     *    FATAL - A non-recoverable fatal error occurred.
     *
     *  Parameters:
     *    (Integer) level - The log level of the log message.  This will
     *      be one of the values in Strophe.LogLevel.
     *    (String) msg - The log message.
     */
    log: function log(level, msg) {
      if (level === this.LogLevel.FATAL && _typeof(window.console) === 'object' && typeof window.console.error === 'function') {
        window.console.error(msg);
      }
    },

    /** Function: debug
     *  Log a message at the Strophe.LogLevel.DEBUG level.
     *
     *  Parameters:
     *    (String) msg - The log message.
     */
    debug: function debug(msg) {
      this.log(this.LogLevel.DEBUG, msg);
    },

    /** Function: info
     *  Log a message at the Strophe.LogLevel.INFO level.
     *
     *  Parameters:
     *    (String) msg - The log message.
     */
    info: function info(msg) {
      this.log(this.LogLevel.INFO, msg);
    },

    /** Function: warn
     *  Log a message at the Strophe.LogLevel.WARN level.
     *
     *  Parameters:
     *    (String) msg - The log message.
     */
    warn: function warn(msg) {
      this.log(this.LogLevel.WARN, msg);
    },

    /** Function: error
     *  Log a message at the Strophe.LogLevel.ERROR level.
     *
     *  Parameters:
     *    (String) msg - The log message.
     */
    error: function error(msg) {
      this.log(this.LogLevel.ERROR, msg);
    },

    /** Function: fatal
     *  Log a message at the Strophe.LogLevel.FATAL level.
     *
     *  Parameters:
     *    (String) msg - The log message.
     */
    fatal: function fatal(msg) {
      this.log(this.LogLevel.FATAL, msg);
    },

    /** Function: serialize
     *  Render a DOM element and all descendants to a String.
     *
     *  Parameters:
     *    (XMLElement) elem - A DOM element.
     *
     *  Returns:
     *    The serialized element tree as a String.
     */
    serialize: function serialize(elem) {
      if (!elem) {
        return null;
      }

      if (typeof elem.tree === "function") {
        elem = elem.tree();
      }

      var names = _toConsumableArray(Array(elem.attributes.length).keys()).map(function (i) {
        return elem.attributes[i].nodeName;
      });

      names.sort();
      var result = names.reduce(function (a, n) {
        return "".concat(a, " ").concat(n, "=\"").concat(Strophe.xmlescape(elem.attributes.getNamedItem(n).value), "\"");
      }, "<".concat(elem.nodeName));

      if (elem.childNodes.length > 0) {
        result += ">";

        for (var i = 0; i < elem.childNodes.length; i++) {
          var child = elem.childNodes[i];

          switch (child.nodeType) {
            case Strophe.ElementType.NORMAL:
              // normal element, so recurse
              result += Strophe.serialize(child);
              break;

            case Strophe.ElementType.TEXT:
              // text element to escape values
              result += Strophe.xmlescape(child.nodeValue);
              break;

            case Strophe.ElementType.CDATA:
              // cdata section so don't escape values
              result += "<![CDATA[" + child.nodeValue + "]]>";
          }
        }

        result += "</" + elem.nodeName + ">";
      } else {
        result += "/>";
      }

      return result;
    },

    /** PrivateVariable: _requestId
     *  _Private_ variable that keeps track of the request ids for
     *  connections.
     */
    _requestId: 0,

    /** PrivateVariable: Strophe.connectionPlugins
     *  _Private_ variable Used to store plugin names that need
     *  initialization on Strophe.Connection construction.
     */
    _connectionPlugins: {},

    /** Function: addConnectionPlugin
     *  Extends the Strophe.Connection object with the given plugin.
     *
     *  Parameters:
     *    (String) name - The name of the extension.
     *    (Object) ptype - The plugin's prototype.
     */
    addConnectionPlugin: function addConnectionPlugin(name, ptype) {
      Strophe._connectionPlugins[name] = ptype;
    }
  };
  /** Class: Strophe.Builder
   *  XML DOM builder.
   *
   *  This object provides an interface similar to JQuery but for building
   *  DOM elements easily and rapidly.  All the functions except for toString()
   *  and tree() return the object, so calls can be chained.  Here's an
   *  example using the $iq() builder helper.
   *  > $iq({to: 'you', from: 'me', type: 'get', id: '1'})
   *  >     .c('query', {xmlns: 'strophe:example'})
   *  >     .c('example')
   *  >     .toString()
   *
   *  The above generates this XML fragment
   *  > <iq to='you' from='me' type='get' id='1'>
   *  >   <query xmlns='strophe:example'>
   *  >     <example/>
   *  >   </query>
   *  > </iq>
   *  The corresponding DOM manipulations to get a similar fragment would be
   *  a lot more tedious and probably involve several helper variables.
   *
   *  Since adding children makes new operations operate on the child, up()
   *  is provided to traverse up the tree.  To add two children, do
   *  > builder.c('child1', ...).up().c('child2', ...)
   *  The next operation on the Builder will be relative to the second child.
   */

  /** Constructor: Strophe.Builder
   *  Create a Strophe.Builder object.
   *
   *  The attributes should be passed in object notation.  For example
   *  > let b = new Builder('message', {to: 'you', from: 'me'});
   *  or
   *  > let b = new Builder('messsage', {'xml:lang': 'en'});
   *
   *  Parameters:
   *    (String) name - The name of the root element.
   *    (Object) attrs - The attributes for the root element in object notation.
   *
   *  Returns:
   *    A new Strophe.Builder.
   */

  Strophe.Builder = function (name, attrs) {
    // Set correct namespace for jabber:client elements
    if (name === "presence" || name === "message" || name === "iq") {
      if (attrs && !attrs.xmlns) {
        attrs.xmlns = Strophe.NS.CLIENT;
      } else if (!attrs) {
        attrs = {
          xmlns: Strophe.NS.CLIENT
        };
      }
    } // Holds the tree being built.


    this.nodeTree = Strophe.xmlElement(name, attrs); // Points to the current operation node.

    this.node = this.nodeTree;
  };

  Strophe.Builder.prototype = {
    /** Function: tree
     *  Return the DOM tree.
     *
     *  This function returns the current DOM tree as an element object.  This
     *  is suitable for passing to functions like Strophe.Connection.send().
     *
     *  Returns:
     *    The DOM tree as a element object.
     */
    tree: function tree() {
      return this.nodeTree;
    },

    /** Function: toString
     *  Serialize the DOM tree to a String.
     *
     *  This function returns a string serialization of the current DOM
     *  tree.  It is often used internally to pass data to a
     *  Strophe.Request object.
     *
     *  Returns:
     *    The serialized DOM tree in a String.
     */
    toString: function toString() {
      return Strophe.serialize(this.nodeTree);
    },

    /** Function: up
     *  Make the current parent element the new current element.
     *
     *  This function is often used after c() to traverse back up the tree.
     *  For example, to add two children to the same element
     *  > builder.c('child1', {}).up().c('child2', {});
     *
     *  Returns:
     *    The Stophe.Builder object.
     */
    up: function up() {
      this.node = this.node.parentNode;
      return this;
    },

    /** Function: root
     *  Make the root element the new current element.
     *
     *  When at a deeply nested element in the tree, this function can be used
     *  to jump back to the root of the tree, instead of having to repeatedly
     *  call up().
     *
     *  Returns:
     *    The Stophe.Builder object.
     */
    root: function root() {
      this.node = this.nodeTree;
      return this;
    },

    /** Function: attrs
     *  Add or modify attributes of the current element.
     *
     *  The attributes should be passed in object notation.  This function
     *  does not move the current element pointer.
     *
     *  Parameters:
     *    (Object) moreattrs - The attributes to add/modify in object notation.
     *
     *  Returns:
     *    The Strophe.Builder object.
     */
    attrs: function attrs(moreattrs) {
      for (var k in moreattrs) {
        if (Object.prototype.hasOwnProperty.call(moreattrs, k)) {
          if (moreattrs[k] === undefined) {
            this.node.removeAttribute(k);
          } else {
            this.node.setAttribute(k, moreattrs[k]);
          }
        }
      }

      return this;
    },

    /** Function: c
     *  Add a child to the current element and make it the new current
     *  element.
     *
     *  This function moves the current element pointer to the child,
     *  unless text is provided.  If you need to add another child, it
     *  is necessary to use up() to go back to the parent in the tree.
     *
     *  Parameters:
     *    (String) name - The name of the child.
     *    (Object) attrs - The attributes of the child in object notation.
     *    (String) text - The text to add to the child.
     *
     *  Returns:
     *    The Strophe.Builder object.
     */
    c: function c(name, attrs, text) {
      var child = Strophe.xmlElement(name, attrs, text);
      this.node.appendChild(child);

      if (typeof text !== "string" && typeof text !== "number") {
        this.node = child;
      }

      return this;
    },

    /** Function: cnode
     *  Add a child to the current element and make it the new current
     *  element.
     *
     *  This function is the same as c() except that instead of using a
     *  name and an attributes object to create the child it uses an
     *  existing DOM element object.
     *
     *  Parameters:
     *    (XMLElement) elem - A DOM element.
     *
     *  Returns:
     *    The Strophe.Builder object.
     */
    cnode: function cnode(elem) {
      var impNode;
      var xmlGen = Strophe.xmlGenerator();

      try {
        impNode = xmlGen.importNode !== undefined;
      } catch (e) {
        impNode = false;
      }

      var newElem = impNode ? xmlGen.importNode(elem, true) : Strophe.copyElement(elem);
      this.node.appendChild(newElem);
      this.node = newElem;
      return this;
    },

    /** Function: t
     *  Add a child text element.
     *
     *  This *does not* make the child the new current element since there
     *  are no children of text elements.
     *
     *  Parameters:
     *    (String) text - The text data to append to the current element.
     *
     *  Returns:
     *    The Strophe.Builder object.
     */
    t: function t(text) {
      var child = Strophe.xmlTextNode(text);
      this.node.appendChild(child);
      return this;
    },

    /** Function: h
     *  Replace current element contents with the HTML passed in.
     *
     *  This *does not* make the child the new current element
     *
     *  Parameters:
     *    (String) html - The html to insert as contents of current element.
     *
     *  Returns:
     *    The Strophe.Builder object.
     */
    h: function h(html) {
      var fragment = document.createElement('body'); // force the browser to try and fix any invalid HTML tags

      fragment.innerHTML = html; // copy cleaned html into an xml dom

      var xhtml = Strophe.createHtml(fragment);

      while (xhtml.childNodes.length > 0) {
        this.node.appendChild(xhtml.childNodes[0]);
      }

      return this;
    }
  };
  /** PrivateClass: Strophe.Handler
   *  _Private_ helper class for managing stanza handlers.
   *
   *  A Strophe.Handler encapsulates a user provided callback function to be
   *  executed when matching stanzas are received by the connection.
   *  Handlers can be either one-off or persistant depending on their
   *  return value. Returning true will cause a Handler to remain active, and
   *  returning false will remove the Handler.
   *
   *  Users will not use Strophe.Handler objects directly, but instead they
   *  will use Strophe.Connection.addHandler() and
   *  Strophe.Connection.deleteHandler().
   */

  /** PrivateConstructor: Strophe.Handler
   *  Create and initialize a new Strophe.Handler.
   *
   *  Parameters:
   *    (Function) handler - A function to be executed when the handler is run.
   *    (String) ns - The namespace to match.
   *    (String) name - The element name to match.
   *    (String) type - The element type to match.
   *    (String) id - The element id attribute to match.
   *    (String) from - The element from attribute to match.
   *    (Object) options - Handler options
   *
   *  Returns:
   *    A new Strophe.Handler object.
   */

  Strophe.Handler = function (handler, ns, name, type, id, from, options) {
    this.handler = handler;
    this.ns = ns;
    this.name = name;
    this.type = type;
    this.id = id;
    this.options = options || {
      'matchBareFromJid': false,
      'ignoreNamespaceFragment': false
    }; // BBB: Maintain backward compatibility with old `matchBare` option

    if (this.options.matchBare) {
      Strophe.warn('The "matchBare" option is deprecated, use "matchBareFromJid" instead.');
      this.options.matchBareFromJid = this.options.matchBare;
      delete this.options.matchBare;
    }

    if (this.options.matchBareFromJid) {
      this.from = from ? Strophe.getBareJidFromJid(from) : null;
    } else {
      this.from = from;
    } // whether the handler is a user handler or a system handler


    this.user = true;
  };

  Strophe.Handler.prototype = {
    /** PrivateFunction: getNamespace
     *  Returns the XML namespace attribute on an element.
     *  If `ignoreNamespaceFragment` was passed in for this handler, then the
     *  URL fragment will be stripped.
     *
     *  Parameters:
     *    (XMLElement) elem - The XML element with the namespace.
     *
     *  Returns:
     *    The namespace, with optionally the fragment stripped.
     */
    getNamespace: function getNamespace(elem) {
      var elNamespace = elem.getAttribute("xmlns");

      if (elNamespace && this.options.ignoreNamespaceFragment) {
        elNamespace = elNamespace.split('#')[0];
      }

      return elNamespace;
    },

    /** PrivateFunction: namespaceMatch
     *  Tests if a stanza matches the namespace set for this Strophe.Handler.
     *
     *  Parameters:
     *    (XMLElement) elem - The XML element to test.
     *
     *  Returns:
     *    true if the stanza matches and false otherwise.
     */
    namespaceMatch: function namespaceMatch(elem) {
      var _this = this;

      var nsMatch = false;

      if (!this.ns) {
        return true;
      } else {
        Strophe.forEachChild(elem, null, function (elem) {
          if (_this.getNamespace(elem) === _this.ns) {
            nsMatch = true;
          }
        });
        return nsMatch || this.getNamespace(elem) === this.ns;
      }
    },

    /** PrivateFunction: isMatch
     *  Tests if a stanza matches the Strophe.Handler.
     *
     *  Parameters:
     *    (XMLElement) elem - The XML element to test.
     *
     *  Returns:
     *    true if the stanza matches and false otherwise.
     */
    isMatch: function isMatch(elem) {
      var from = elem.getAttribute('from');

      if (this.options.matchBareFromJid) {
        from = Strophe.getBareJidFromJid(from);
      }

      var elem_type = elem.getAttribute("type");

      if (this.namespaceMatch(elem) && (!this.name || Strophe.isTagEqual(elem, this.name)) && (!this.type || (Array.isArray(this.type) ? this.type.indexOf(elem_type) !== -1 : elem_type === this.type)) && (!this.id || elem.getAttribute("id") === this.id) && (!this.from || from === this.from)) {
        return true;
      }

      return false;
    },

    /** PrivateFunction: run
     *  Run the callback on a matching stanza.
     *
     *  Parameters:
     *    (XMLElement) elem - The DOM element that triggered the
     *      Strophe.Handler.
     *
     *  Returns:
     *    A boolean indicating if the handler should remain active.
     */
    run: function run(elem) {
      var result = null;

      try {
        result = this.handler(elem);
      } catch (e) {
        Strophe._handleError(e);

        throw e;
      }

      return result;
    },

    /** PrivateFunction: toString
     *  Get a String representation of the Strophe.Handler object.
     *
     *  Returns:
     *    A String.
     */
    toString: function toString() {
      return "{Handler: " + this.handler + "(" + this.name + "," + this.id + "," + this.ns + ")}";
    }
  };
  /** PrivateClass: Strophe.TimedHandler
   *  _Private_ helper class for managing timed handlers.
   *
   *  A Strophe.TimedHandler encapsulates a user provided callback that
   *  should be called after a certain period of time or at regular
   *  intervals.  The return value of the callback determines whether the
   *  Strophe.TimedHandler will continue to fire.
   *
   *  Users will not use Strophe.TimedHandler objects directly, but instead
   *  they will use Strophe.Connection.addTimedHandler() and
   *  Strophe.Connection.deleteTimedHandler().
   */

  /** PrivateConstructor: Strophe.TimedHandler
   *  Create and initialize a new Strophe.TimedHandler object.
   *
   *  Parameters:
   *    (Integer) period - The number of milliseconds to wait before the
   *      handler is called.
   *    (Function) handler - The callback to run when the handler fires.  This
   *      function should take no arguments.
   *
   *  Returns:
   *    A new Strophe.TimedHandler object.
   */

  Strophe.TimedHandler = function (period, handler) {
    this.period = period;
    this.handler = handler;
    this.lastCalled = new Date().getTime();
    this.user = true;
  };

  Strophe.TimedHandler.prototype = {
    /** PrivateFunction: run
     *  Run the callback for the Strophe.TimedHandler.
     *
     *  Returns:
     *    true if the Strophe.TimedHandler should be called again, and false
     *      otherwise.
     */
    run: function run() {
      this.lastCalled = new Date().getTime();
      return this.handler();
    },

    /** PrivateFunction: reset
     *  Reset the last called time for the Strophe.TimedHandler.
     */
    reset: function reset() {
      this.lastCalled = new Date().getTime();
    },

    /** PrivateFunction: toString
     *  Get a string representation of the Strophe.TimedHandler object.
     *
     *  Returns:
     *    The string representation.
     */
    toString: function toString() {
      return "{TimedHandler: " + this.handler + "(" + this.period + ")}";
    }
  };
  /** Class: Strophe.Connection
   *  XMPP Connection manager.
   *
   *  This class is the main part of Strophe.  It manages a BOSH or websocket
   *  connection to an XMPP server and dispatches events to the user callbacks
   *  as data arrives. It supports SASL PLAIN, SASL DIGEST-MD5, SASL SCRAM-SHA1
   *  and legacy authentication.
   *
   *  After creating a Strophe.Connection object, the user will typically
   *  call connect() with a user supplied callback to handle connection level
   *  events like authentication failure, disconnection, or connection
   *  complete.
   *
   *  The user will also have several event handlers defined by using
   *  addHandler() and addTimedHandler().  These will allow the user code to
   *  respond to interesting stanzas or do something periodically with the
   *  connection. These handlers will be active once authentication is
   *  finished.
   *
   *  To send data to the connection, use send().
   */

  /** Constructor: Strophe.Connection
   *  Create and initialize a Strophe.Connection object.
   *
   *  The transport-protocol for this connection will be chosen automatically
   *  based on the given service parameter. URLs starting with "ws://" or
   *  "wss://" will use WebSockets, URLs starting with "http://", "https://"
   *  or without a protocol will use BOSH.
   *
   *  To make Strophe connect to the current host you can leave out the protocol
   *  and host part and just pass the path, e.g.
   *
   *  > let conn = new Strophe.Connection("/http-bind/");
   *
   *  Options common to both Websocket and BOSH:
   *  ------------------------------------------
   *
   *  cookies:
   *
   *  The *cookies* option allows you to pass in cookies to be added to the
   *  document. These cookies will then be included in the BOSH XMLHttpRequest
   *  or in the websocket connection.
   *
   *  The passed in value must be a map of cookie names and string values.
   *
   *  > { "myCookie": {
   *  >     "value": "1234",
   *  >     "domain": ".example.org",
   *  >     "path": "/",
   *  >     "expires": expirationDate
   *  >     }
   *  > }
   *
   *  Note that cookies can't be set in this way for other domains (i.e. cross-domain).
   *  Those cookies need to be set under those domains, for example they can be
   *  set server-side by making a XHR call to that domain to ask it to set any
   *  necessary cookies.
   *
   *  mechanisms:
   *
   *  The *mechanisms* option allows you to specify the SASL mechanisms that this
   *  instance of Strophe.Connection (and therefore your XMPP client) will
   *  support.
   *
   *  The value must be an array of objects with Strophe.SASLMechanism
   *  prototypes.
   *
   *  If nothing is specified, then the following mechanisms (and their
   *  priorities) are registered:
   *
   *      SCRAM-SHA1 - 70
   *      DIGEST-MD5 - 60
   *      PLAIN - 50
   *      OAUTH-BEARER - 40
   *      OAUTH-2 - 30
   *      ANONYMOUS - 20
   *      EXTERNAL - 10
   *
   *  explicitResourceBinding:
   *
   *  If `explicitResourceBinding` is set to a truthy value, then the XMPP client
   *  needs to explicitly call `Strophe.Connection.prototype.bind` once the XMPP
   *  server has advertised the "urn:ietf:params:xml:ns:xmpp-bind" feature.
   *
   *  Making this step explicit allows client authors to first finish other
   *  stream related tasks, such as setting up an XEP-0198 Stream Management
   *  session, before binding the JID resource for this session.
   *
   *  WebSocket options:
   *  ------------------
   *
   *  If you want to connect to the current host with a WebSocket connection you
   *  can tell Strophe to use WebSockets through a "protocol" attribute in the
   *  optional options parameter. Valid values are "ws" for WebSocket and "wss"
   *  for Secure WebSocket.
   *  So to connect to "wss://CURRENT_HOSTNAME/xmpp-websocket" you would call
   *
   *  > let conn = new Strophe.Connection("/xmpp-websocket/", {protocol: "wss"});
   *
   *  Note that relative URLs _NOT_ starting with a "/" will also include the path
   *  of the current site.
   *
   *  Also because downgrading security is not permitted by browsers, when using
   *  relative URLs both BOSH and WebSocket connections will use their secure
   *  variants if the current connection to the site is also secure (https).
   *
   *  BOSH options:
   *  -------------
   *
   *  By adding "sync" to the options, you can control if requests will
   *  be made synchronously or not. The default behaviour is asynchronous.
   *  If you want to make requests synchronous, make "sync" evaluate to true.
   *  > let conn = new Strophe.Connection("/http-bind/", {sync: true});
   *
   *  You can also toggle this on an already established connection.
   *  > conn.options.sync = true;
   *
   *  The *customHeaders* option can be used to provide custom HTTP headers to be
   *  included in the XMLHttpRequests made.
   *
   *  The *keepalive* option can be used to instruct Strophe to maintain the
   *  current BOSH session across interruptions such as webpage reloads.
   *
   *  It will do this by caching the sessions tokens in sessionStorage, and when
   *  "restore" is called it will check whether there are cached tokens with
   *  which it can resume an existing session.
   *
   *  The *withCredentials* option should receive a Boolean value and is used to
   *  indicate wether cookies should be included in ajax requests (by default
   *  they're not).
   *  Set this value to true if you are connecting to a BOSH service
   *  and for some reason need to send cookies to it.
   *  In order for this to work cross-domain, the server must also enable
   *  credentials by setting the Access-Control-Allow-Credentials response header
   *  to "true". For most usecases however this setting should be false (which
   *  is the default).
   *  Additionally, when using Access-Control-Allow-Credentials, the
   *  Access-Control-Allow-Origin header can't be set to the wildcard "*", but
   *  instead must be restricted to actual domains.
   *
   *  The *contentType* option can be set to change the default Content-Type
   *  of "text/xml; charset=utf-8", which can be useful to reduce the amount of
   *  CORS preflight requests that are sent to the server.
   *
   *  Parameters:
   *    (String) service - The BOSH or WebSocket service URL.
   *    (Object) options - A hash of configuration options
   *
   *  Returns:
   *    A new Strophe.Connection object.
   */

  Strophe.Connection = function (service, options) {
    var _this2 = this; // The service URL


    this.service = service; // Configuration options

    this.options = options || {};
    var proto = this.options.protocol || ""; // Select protocal based on service or options

    if (service.indexOf("ws:") === 0 || service.indexOf("wss:") === 0 || proto.indexOf("ws") === 0) {
      this._proto = new Strophe.Websocket(this);
    } else {
      this._proto = new Strophe.Bosh(this);
    }
    /* The connected JID. */


    this.jid = "";
    /* the JIDs domain */

    this.domain = null;
    /* stream:features */

    this.features = null; // SASL

    this._sasl_data = {};
    this.do_session = false;
    this.do_bind = false; // handler lists

    this.timedHandlers = [];
    this.handlers = [];
    this.removeTimeds = [];
    this.removeHandlers = [];
    this.addTimeds = [];
    this.addHandlers = [];
    this.protocolErrorHandlers = {
      'HTTP': {},
      'websocket': {}
    };
    this._idleTimeout = null;
    this._disconnectTimeout = null;
    this.authenticated = false;
    this.connected = false;
    this.disconnecting = false;
    this.do_authentication = true;
    this.paused = false;
    this.restored = false;
    this._data = [];
    this._uniqueId = 0;
    this._sasl_success_handler = null;
    this._sasl_failure_handler = null;
    this._sasl_challenge_handler = null; // Max retries before disconnecting

    this.maxRetries = 5; // Call onIdle callback every 1/10th of a second

    this._idleTimeout = setTimeout(function () {
      return _this2._onIdle();
    }, 100);
    utils.addCookies(this.options.cookies);
    this.registerSASLMechanisms(this.options.mechanisms); // initialize plugins

    for (var k in Strophe._connectionPlugins) {
      if (Object.prototype.hasOwnProperty.call(Strophe._connectionPlugins, k)) {
        var F = function F() {};

        F.prototype = Strophe._connectionPlugins[k];
        this[k] = new F();
        this[k].init(this);
      }
    }
  };

  Strophe.Connection.prototype = {
    /** Function: reset
     *  Reset the connection.
     *
     *  This function should be called after a connection is disconnected
     *  before that connection is reused.
     */
    reset: function reset() {
      this._proto._reset(); // SASL


      this.do_session = false;
      this.do_bind = false; // handler lists

      this.timedHandlers = [];
      this.handlers = [];
      this.removeTimeds = [];
      this.removeHandlers = [];
      this.addTimeds = [];
      this.addHandlers = [];
      this.authenticated = false;
      this.connected = false;
      this.disconnecting = false;
      this.restored = false;
      this._data = [];
      this._requests = [];
      this._uniqueId = 0;
    },

    /** Function: pause
     *  Pause the request manager.
     *
     *  This will prevent Strophe from sending any more requests to the
     *  server.  This is very useful for temporarily pausing
     *  BOSH-Connections while a lot of send() calls are happening quickly.
     *  This causes Strophe to send the data in a single request, saving
     *  many request trips.
     */
    pause: function pause() {
      this.paused = true;
    },

    /** Function: resume
     *  Resume the request manager.
     *
     *  This resumes after pause() has been called.
     */
    resume: function resume() {
      this.paused = false;
    },

    /** Function: getUniqueId
     *  Generate a unique ID for use in <iq/> elements.
     *
     *  All <iq/> stanzas are required to have unique id attributes.  This
     *  function makes creating these easy.  Each connection instance has
     *  a counter which starts from zero, and the value of this counter
     *  plus a colon followed by the suffix becomes the unique id. If no
     *  suffix is supplied, the counter is used as the unique id.
     *
     *  Suffixes are used to make debugging easier when reading the stream
     *  data, and their use is recommended.  The counter resets to 0 for
     *  every new connection for the same reason.  For connections to the
     *  same server that authenticate the same way, all the ids should be
     *  the same, which makes it easy to see changes.  This is useful for
     *  automated testing as well.
     *
     *  Parameters:
     *    (String) suffix - A optional suffix to append to the id.
     *
     *  Returns:
     *    A unique string to be used for the id attribute.
     */
    getUniqueId: function getUniqueId(suffix) {
      var uuid = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {
        var r = Math.random() * 16 | 0,
            v = c === 'x' ? r : r & 0x3 | 0x8;
        return v.toString(16);
      });

      if (typeof suffix === "string" || typeof suffix === "number") {
        return uuid + ":" + suffix;
      } else {
        return uuid + "";
      }
    },

    /** Function: addProtocolErrorHandler
     *  Register a handler function for when a protocol (websocker or HTTP)
     *  error occurs.
     *
     *  NOTE: Currently only HTTP errors for BOSH requests are handled.
     *  Patches that handle websocket errors would be very welcome.
     *
     *  Parameters:
     *    (String) protocol - 'HTTP' or 'websocket'
     *    (Integer) status_code - Error status code (e.g 500, 400 or 404)
     *    (Function) callback - Function that will fire on Http error
     *
     *  Example:
     *  function onError(err_code){
     *    //do stuff
     *  }
     *
     *  let conn = Strophe.connect('http://example.com/http-bind');
     *  conn.addProtocolErrorHandler('HTTP', 500, onError);
     *  // Triggers HTTP 500 error and onError handler will be called
     *  conn.connect('user_jid@incorrect_jabber_host', 'secret', onConnect);
     */
    addProtocolErrorHandler: function addProtocolErrorHandler(protocol, status_code, callback) {
      this.protocolErrorHandlers[protocol][status_code] = callback;
    },

    /** Function: connect
     *  Starts the connection process.
     *
     *  As the connection process proceeds, the user supplied callback will
     *  be triggered multiple times with status updates.  The callback
     *  should take two arguments - the status code and the error condition.
     *
     *  The status code will be one of the values in the Strophe.Status
     *  constants.  The error condition will be one of the conditions
     *  defined in RFC 3920 or the condition 'strophe-parsererror'.
     *
     *  The Parameters _wait_, _hold_ and _route_ are optional and only relevant
     *  for BOSH connections. Please see XEP 124 for a more detailed explanation
     *  of the optional parameters.
     *
     *  Parameters:
     *    (String) jid - The user's JID.  This may be a bare JID,
     *      or a full JID.  If a node is not supplied, SASL OAUTHBEARER or
     *      SASL ANONYMOUS authentication will be attempted (OAUTHBEARER will
     *      process the provided password value as an access token).
     *    (String) pass - The user's password.
     *    (Function) callback - The connect callback function.
     *    (Integer) wait - The optional HTTPBIND wait value.  This is the
     *      time the server will wait before returning an empty result for
     *      a request.  The default setting of 60 seconds is recommended.
     *    (Integer) hold - The optional HTTPBIND hold value.  This is the
     *      number of connections the server will hold at one time.  This
     *      should almost always be set to 1 (the default).
     *    (String) route - The optional route value.
     *    (String) authcid - The optional alternative authentication identity
     *      (username) if intending to impersonate another user.
     *      When using the SASL-EXTERNAL authentication mechanism, for example
     *      with client certificates, then the authcid value is used to
     *      determine whether an authorization JID (authzid) should be sent to
     *      the server. The authzid should not be sent to the server if the
     *      authzid and authcid are the same. So to prevent it from being sent
     *      (for example when the JID is already contained in the client
     *      certificate), set authcid to that same JID. See XEP-178 for more
     *      details.
     */
    connect: function connect(jid, pass, callback, wait, hold, route, authcid) {
      this.jid = jid;
      /** Variable: authzid
       *  Authorization identity.
       */

      this.authzid = Strophe.getBareJidFromJid(this.jid);
      /** Variable: authcid
       *  Authentication identity (User name).
       */

      this.authcid = authcid || Strophe.getNodeFromJid(this.jid);
      /** Variable: pass
       *  Authentication identity (User password).
       */

      this.pass = pass;
      /** Variable: servtype
       *  Digest MD5 compatibility.
       */

      this.servtype = "xmpp";
      this.connect_callback = callback;
      this.disconnecting = false;
      this.connected = false;
      this.authenticated = false;
      this.restored = false; // parse jid for domain

      this.domain = Strophe.getDomainFromJid(this.jid);

      this._changeConnectStatus(Strophe.Status.CONNECTING, null);

      this._proto._connect(wait, hold, route);
    },

    /** Function: attach
     *  Attach to an already created and authenticated BOSH session.
     *
     *  This function is provided to allow Strophe to attach to BOSH
     *  sessions which have been created externally, perhaps by a Web
     *  application.  This is often used to support auto-login type features
     *  without putting user credentials into the page.
     *
     *  Parameters:
     *    (String) jid - The full JID that is bound by the session.
     *    (String) sid - The SID of the BOSH session.
     *    (String) rid - The current RID of the BOSH session.  This RID
     *      will be used by the next request.
     *    (Function) callback The connect callback function.
     *    (Integer) wait - The optional HTTPBIND wait value.  This is the
     *      time the server will wait before returning an empty result for
     *      a request.  The default setting of 60 seconds is recommended.
     *      Other settings will require tweaks to the Strophe.TIMEOUT value.
     *    (Integer) hold - The optional HTTPBIND hold value.  This is the
     *      number of connections the server will hold at one time.  This
     *      should almost always be set to 1 (the default).
     *    (Integer) wind - The optional HTTBIND window value.  This is the
     *      allowed range of request ids that are valid.  The default is 5.
     */
    attach: function attach(jid, sid, rid, callback, wait, hold, wind) {
      if (this._proto instanceof Strophe.Bosh) {
        this._proto._attach(jid, sid, rid, callback, wait, hold, wind);
      } else {
        var error = new Error('The "attach" method can only be used with a BOSH connection.');
        error.name = 'StropheSessionError';
        throw error;
      }
    },

    /** Function: restore
     *  Attempt to restore a cached BOSH session.
     *
     *  This function is only useful in conjunction with providing the
     *  "keepalive":true option when instantiating a new Strophe.Connection.
     *
     *  When "keepalive" is set to true, Strophe will cache the BOSH tokens
     *  RID (Request ID) and SID (Session ID) and then when this function is
     *  called, it will attempt to restore the session from those cached
     *  tokens.
     *
     *  This function must therefore be called instead of connect or attach.
     *
     *  For an example on how to use it, please see examples/restore.js
     *
     *  Parameters:
     *    (String) jid - The user's JID.  This may be a bare JID or a full JID.
     *    (Function) callback - The connect callback function.
     *    (Integer) wait - The optional HTTPBIND wait value.  This is the
     *      time the server will wait before returning an empty result for
     *      a request.  The default setting of 60 seconds is recommended.
     *    (Integer) hold - The optional HTTPBIND hold value.  This is the
     *      number of connections the server will hold at one time.  This
     *      should almost always be set to 1 (the default).
     *    (Integer) wind - The optional HTTBIND window value.  This is the
     *      allowed range of request ids that are valid.  The default is 5.
     */
    restore: function restore(jid, callback, wait, hold, wind) {
      if (this._sessionCachingSupported()) {
        this._proto._restore(jid, callback, wait, hold, wind);
      } else {
        var error = new Error('The "restore" method can only be used with a BOSH connection.');
        error.name = 'StropheSessionError';
        throw error;
      }
    },

    /** PrivateFunction: _sessionCachingSupported
     * Checks whether sessionStorage and JSON are supported and whether we're
     * using BOSH.
     */
    _sessionCachingSupported: function _sessionCachingSupported() {
      if (this._proto instanceof Strophe.Bosh) {
        if (!JSON) {
          return false;
        }

        try {
          sessionStorage.setItem('_strophe_', '_strophe_');
          sessionStorage.removeItem('_strophe_');
        } catch (e) {
          return false;
        }

        return true;
      }

      return false;
    },

    /** Function: xmlInput
     *  User overrideable function that receives XML data coming into the
     *  connection.
     *
     *  The default function does nothing.  User code can override this with
     *  > Strophe.Connection.xmlInput = function (elem) {
     *  >   (user code)
     *  > };
     *
     *  Due to limitations of current Browsers' XML-Parsers the opening and closing
     *  <stream> tag for WebSocket-Connoctions will be passed as selfclosing here.
     *
     *  BOSH-Connections will have all stanzas wrapped in a <body> tag. See
     *  <Strophe.Bosh.strip> if you want to strip this tag.
     *
     *  Parameters:
     *    (XMLElement) elem - The XML data received by the connection.
     */
    xmlInput: function xmlInput(elem) {
      return;
    },

    /** Function: xmlOutput
     *  User overrideable function that receives XML data sent to the
     *  connection.
     *
     *  The default function does nothing.  User code can override this with
     *  > Strophe.Connection.xmlOutput = function (elem) {
     *  >   (user code)
     *  > };
     *
     *  Due to limitations of current Browsers' XML-Parsers the opening and closing
     *  <stream> tag for WebSocket-Connoctions will be passed as selfclosing here.
     *
     *  BOSH-Connections will have all stanzas wrapped in a <body> tag. See
     *  <Strophe.Bosh.strip> if you want to strip this tag.
     *
     *  Parameters:
     *    (XMLElement) elem - The XMLdata sent by the connection.
     */
    xmlOutput: function xmlOutput(elem) {
      return;
    },

    /** Function: rawInput
     *  User overrideable function that receives raw data coming into the
     *  connection.
     *
     *  The default function does nothing.  User code can override this with
     *  > Strophe.Connection.rawInput = function (data) {
     *  >   (user code)
     *  > };
     *
     *  Parameters:
     *    (String) data - The data received by the connection.
     */
    rawInput: function rawInput(data) {
      return;
    },

    /** Function: rawOutput
     *  User overrideable function that receives raw data sent to the
     *  connection.
     *
     *  The default function does nothing.  User code can override this with
     *  > Strophe.Connection.rawOutput = function (data) {
     *  >   (user code)
     *  > };
     *
     *  Parameters:
     *    (String) data - The data sent by the connection.
     */
    rawOutput: function rawOutput(data) {
      return;
    },

    /** Function: nextValidRid
     *  User overrideable function that receives the new valid rid.
     *
     *  The default function does nothing. User code can override this with
     *  > Strophe.Connection.nextValidRid = function (rid) {
     *  >    (user code)
     *  > };
     *
     *  Parameters:
     *    (Number) rid - The next valid rid
     */
    nextValidRid: function nextValidRid(rid) {
      return;
    },

    /** Function: send
     *  Send a stanza.
     *
     *  This function is called to push data onto the send queue to
     *  go out over the wire.  Whenever a request is sent to the BOSH
     *  server, all pending data is sent and the queue is flushed.
     *
     *  Parameters:
     *    (XMLElement |
     *     [XMLElement] |
     *     Strophe.Builder) elem - The stanza to send.
     */
    send: function send(elem) {
      if (elem === null) {
        return;
      }

      if (typeof elem.sort === "function") {
        for (var i = 0; i < elem.length; i++) {
          this._queueData(elem[i]);
        }
      } else if (typeof elem.tree === "function") {
        this._queueData(elem.tree());
      } else {
        this._queueData(elem);
      }

      this._proto._send();
    },

    /** Function: flush
     *  Immediately send any pending outgoing data.
     *
     *  Normally send() queues outgoing data until the next idle period
     *  (100ms), which optimizes network use in the common cases when
     *  several send()s are called in succession. flush() can be used to
     *  immediately send all pending data.
     */
    flush: function flush() {
      // cancel the pending idle period and run the idle function
      // immediately
      clearTimeout(this._idleTimeout);

      this._onIdle();
    },

    /** Function: sendPresence
     *  Helper function to send presence stanzas. The main benefit is for
     *  sending presence stanzas for which you expect a responding presence
     *  stanza with the same id (for example when leaving a chat room).
     *
     *  Parameters:
     *    (XMLElement) elem - The stanza to send.
     *    (Function) callback - The callback function for a successful request.
     *    (Function) errback - The callback function for a failed or timed
     *      out request.  On timeout, the stanza will be null.
     *    (Integer) timeout - The time specified in milliseconds for a
     *      timeout to occur.
     *
     *  Returns:
     *    The id used to send the presence.
     */
    sendPresence: function sendPresence(elem, callback, errback, timeout) {
      var _this3 = this;

      var timeoutHandler = null;

      if (typeof elem.tree === "function") {
        elem = elem.tree();
      }

      var id = elem.getAttribute('id');

      if (!id) {
        // inject id if not found
        id = this.getUniqueId("sendPresence");
        elem.setAttribute("id", id);
      }

      if (typeof callback === "function" || typeof errback === "function") {
        var handler = this.addHandler(function (stanza) {
          // remove timeout handler if there is one
          if (timeoutHandler) {
            _this3.deleteTimedHandler(timeoutHandler);
          }

          if (stanza.getAttribute('type') === 'error') {
            if (errback) {
              errback(stanza);
            }
          } else if (callback) {
            callback(stanza);
          }
        }, null, 'presence', null, id); // if timeout specified, set up a timeout handler.

        if (timeout) {
          timeoutHandler = this.addTimedHandler(timeout, function () {
            // get rid of normal handler
            _this3.deleteHandler(handler); // call errback on timeout with null stanza


            if (errback) {
              errback(null);
            }

            return false;
          });
        }
      }

      this.send(elem);
      return id;
    },

    /** Function: sendIQ
     *  Helper function to send IQ stanzas.
     *
     *  Parameters:
     *    (XMLElement) elem - The stanza to send.
     *    (Function) callback - The callback function for a successful request.
     *    (Function) errback - The callback function for a failed or timed
     *      out request.  On timeout, the stanza will be null.
     *    (Integer) timeout - The time specified in milliseconds for a
     *      timeout to occur.
     *
     *  Returns:
     *    The id used to send the IQ.
    */
    sendIQ: function sendIQ(elem, callback, errback, timeout) {
      var _this4 = this;

      var timeoutHandler = null;

      if (typeof elem.tree === "function") {
        elem = elem.tree();
      }

      var id = elem.getAttribute('id');

      if (!id) {
        // inject id if not found
        id = this.getUniqueId("sendIQ");
        elem.setAttribute("id", id);
      }

      if (typeof callback === "function" || typeof errback === "function") {
        var handler = this.addHandler(function (stanza) {
          // remove timeout handler if there is one
          if (timeoutHandler) {
            _this4.deleteTimedHandler(timeoutHandler);
          }

          var iqtype = stanza.getAttribute('type');

          if (iqtype === 'result') {
            if (callback) {
              callback(stanza);
            }
          } else if (iqtype === 'error') {
            if (errback) {
              errback(stanza);
            }
          } else {
            var error = new Error("Got bad IQ type of ".concat(iqtype));
            error.name = "StropheError";
            throw error;
          }
        }, null, 'iq', ['error', 'result'], id); // if timeout specified, set up a timeout handler.

        if (timeout) {
          timeoutHandler = this.addTimedHandler(timeout, function () {
            // get rid of normal handler
            _this4.deleteHandler(handler); // call errback on timeout with null stanza


            if (errback) {
              errback(null);
            }

            return false;
          });
        }
      }

      this.send(elem);
      return id;
    },

    /** PrivateFunction: _queueData
     *  Queue outgoing data for later sending.  Also ensures that the data
     *  is a DOMElement.
     */
    _queueData: function _queueData(element) {
      if (element === null || !element.tagName || !element.childNodes) {
        var error = new Error("Cannot queue non-DOMElement.");
        error.name = "StropheError";
        throw error;
      }

      this._data.push(element);
    },

    /** PrivateFunction: _sendRestart
     *  Send an xmpp:restart stanza.
     */
    _sendRestart: function _sendRestart() {
      var _this5 = this;

      this._data.push("restart");

      this._proto._sendRestart();

      this._idleTimeout = setTimeout(function () {
        return _this5._onIdle();
      }, 100);
    },

    /** Function: addTimedHandler
     *  Add a timed handler to the connection.
     *
     *  This function adds a timed handler.  The provided handler will
     *  be called every period milliseconds until it returns false,
     *  the connection is terminated, or the handler is removed.  Handlers
     *  that wish to continue being invoked should return true.
     *
     *  Because of method binding it is necessary to save the result of
     *  this function if you wish to remove a handler with
     *  deleteTimedHandler().
     *
     *  Note that user handlers are not active until authentication is
     *  successful.
     *
     *  Parameters:
     *    (Integer) period - The period of the handler.
     *    (Function) handler - The callback function.
     *
     *  Returns:
     *    A reference to the handler that can be used to remove it.
     */
    addTimedHandler: function addTimedHandler(period, handler) {
      var thand = new Strophe.TimedHandler(period, handler);
      this.addTimeds.push(thand);
      return thand;
    },

    /** Function: deleteTimedHandler
     *  Delete a timed handler for a connection.
     *
     *  This function removes a timed handler from the connection.  The
     *  handRef parameter is *not* the function passed to addTimedHandler(),
     *  but is the reference returned from addTimedHandler().
     *
     *  Parameters:
     *    (Strophe.TimedHandler) handRef - The handler reference.
     */
    deleteTimedHandler: function deleteTimedHandler(handRef) {
      // this must be done in the Idle loop so that we don't change
      // the handlers during iteration
      this.removeTimeds.push(handRef);
    },

    /** Function: addHandler
     *  Add a stanza handler for the connection.
     *
     *  This function adds a stanza handler to the connection.  The
     *  handler callback will be called for any stanza that matches
     *  the parameters.  Note that if multiple parameters are supplied,
     *  they must all match for the handler to be invoked.
     *
     *  The handler will receive the stanza that triggered it as its argument.
     *  *The handler should return true if it is to be invoked again;
     *  returning false will remove the handler after it returns.*
     *
     *  As a convenience, the ns parameters applies to the top level element
     *  and also any of its immediate children.  This is primarily to make
     *  matching /iq/query elements easy.
     *
     *  Options
     *  ~~~~~~~
     *  With the options argument, you can specify boolean flags that affect how
     *  matches are being done.
     *
     *  Currently two flags exist:
     *
     *  - matchBareFromJid:
     *      When set to true, the from parameter and the
     *      from attribute on the stanza will be matched as bare JIDs instead
     *      of full JIDs. To use this, pass {matchBareFromJid: true} as the
     *      value of options. The default value for matchBareFromJid is false.
     *
     *  - ignoreNamespaceFragment:
     *      When set to true, a fragment specified on the stanza's namespace
     *      URL will be ignored when it's matched with the one configured for
     *      the handler.
     *
     *      This means that if you register like this:
     *      >   connection.addHandler(
     *      >       handler,
     *      >       'http://jabber.org/protocol/muc',
     *      >       null, null, null, null,
     *      >       {'ignoreNamespaceFragment': true}
     *      >   );
     *
     *      Then a stanza with XML namespace of
     *      'http://jabber.org/protocol/muc#user' will also be matched. If
     *      'ignoreNamespaceFragment' is false, then only stanzas with
     *      'http://jabber.org/protocol/muc' will be matched.
     *
     *  Deleting the handler
     *  ~~~~~~~~~~~~~~~~~~~~
     *  The return value should be saved if you wish to remove the handler
     *  with deleteHandler().
     *
     *  Parameters:
     *    (Function) handler - The user callback.
     *    (String) ns - The namespace to match.
     *    (String) name - The stanza name to match.
     *    (String|Array) type - The stanza type (or types if an array) to match.
     *    (String) id - The stanza id attribute to match.
     *    (String) from - The stanza from attribute to match.
     *    (String) options - The handler options
     *
     *  Returns:
     *    A reference to the handler that can be used to remove it.
     */
    addHandler: function addHandler(handler, ns, name, type, id, from, options) {
      var hand = new Strophe.Handler(handler, ns, name, type, id, from, options);
      this.addHandlers.push(hand);
      return hand;
    },

    /** Function: deleteHandler
     *  Delete a stanza handler for a connection.
     *
     *  This function removes a stanza handler from the connection.  The
     *  handRef parameter is *not* the function passed to addHandler(),
     *  but is the reference returned from addHandler().
     *
     *  Parameters:
     *    (Strophe.Handler) handRef - The handler reference.
     */
    deleteHandler: function deleteHandler(handRef) {
      // this must be done in the Idle loop so that we don't change
      // the handlers during iteration
      this.removeHandlers.push(handRef); // If a handler is being deleted while it is being added,
      // prevent it from getting added

      var i = this.addHandlers.indexOf(handRef);

      if (i >= 0) {
        this.addHandlers.splice(i, 1);
      }
    },

    /** Function: registerSASLMechanisms
     *
     * Register the SASL mechanisms which will be supported by this instance of
     * Strophe.Connection (i.e. which this XMPP client will support).
     *
     *  Parameters:
     *    (Array) mechanisms - Array of objects with Strophe.SASLMechanism prototypes
     *
     */
    registerSASLMechanisms: function registerSASLMechanisms(mechanisms) {
      this.mechanisms = {};
      mechanisms = mechanisms || [Strophe.SASLAnonymous, Strophe.SASLExternal, Strophe.SASLMD5, Strophe.SASLOAuthBearer, Strophe.SASLXOAuth2, Strophe.SASLPlain, Strophe.SASLSHA1];
      mechanisms.forEach(this.registerSASLMechanism.bind(this));
    },

    /** Function: registerSASLMechanism
     *
     * Register a single SASL mechanism, to be supported by this client.
     *
     *  Parameters:
     *    (Object) mechanism - Object with a Strophe.SASLMechanism prototype
     *
     */
    registerSASLMechanism: function registerSASLMechanism(mechanism) {
      this.mechanisms[mechanism.prototype.name] = mechanism;
    },

    /** Function: disconnect
     *  Start the graceful disconnection process.
     *
     *  This function starts the disconnection process.  This process starts
     *  by sending unavailable presence and sending BOSH body of type
     *  terminate.  A timeout handler makes sure that disconnection happens
     *  even if the BOSH server does not respond.
     *  If the Connection object isn't connected, at least tries to abort all pending requests
     *  so the connection object won't generate successful requests (which were already opened).
     *
     *  The user supplied connection callback will be notified of the
     *  progress as this process happens.
     *
     *  Parameters:
     *    (String) reason - The reason the disconnect is occuring.
     */
    disconnect: function disconnect(reason) {
      this._changeConnectStatus(Strophe.Status.DISCONNECTING, reason);

      Strophe.warn("Disconnect was called because: " + reason);

      if (this.connected) {
        var pres = false;
        this.disconnecting = true;

        if (this.authenticated) {
          pres = $pres({
            'xmlns': Strophe.NS.CLIENT,
            'type': 'unavailable'
          });
        } // setup timeout handler


        this._disconnectTimeout = this._addSysTimedHandler(3000, this._onDisconnectTimeout.bind(this));

        this._proto._disconnect(pres);
      } else {
        Strophe.warn("Disconnect was called before Strophe connected to the server");

        this._proto._abortAllRequests();

        this._doDisconnect();
      }
    },

    /** PrivateFunction: _changeConnectStatus
     *  _Private_ helper function that makes sure plugins and the user's
     *  callback are notified of connection status changes.
     *
     *  Parameters:
     *    (Integer) status - the new connection status, one of the values
     *      in Strophe.Status
     *    (String) condition - the error condition or null
     *    (XMLElement) elem - The triggering stanza.
     */
    _changeConnectStatus: function _changeConnectStatus(status, condition, elem) {
      // notify all plugins listening for status changes
      for (var k in Strophe._connectionPlugins) {
        if (Object.prototype.hasOwnProperty.call(Strophe._connectionPlugins, k)) {
          var plugin = this[k];

          if (plugin.statusChanged) {
            try {
              plugin.statusChanged(status, condition);
            } catch (err) {
              Strophe.error("".concat(k, " plugin caused an exception changing status: ").concat(err));
            }
          }
        }
      } // notify the user's callback


      if (this.connect_callback) {
        try {
          this.connect_callback(status, condition, elem);
        } catch (e) {
          Strophe._handleError(e);

          Strophe.error("User connection callback caused an exception: ".concat(e));
        }
      }
    },

    /** PrivateFunction: _doDisconnect
     *  _Private_ function to disconnect.
     *
     *  This is the last piece of the disconnection logic.  This resets the
     *  connection and alerts the user's connection callback.
     */
    _doDisconnect: function _doDisconnect(condition) {
      if (typeof this._idleTimeout === "number") {
        clearTimeout(this._idleTimeout);
      } // Cancel Disconnect Timeout


      if (this._disconnectTimeout !== null) {
        this.deleteTimedHandler(this._disconnectTimeout);
        this._disconnectTimeout = null;
      }

      Strophe.debug("_doDisconnect was called");

      this._proto._doDisconnect();

      this.authenticated = false;
      this.disconnecting = false;
      this.restored = false; // delete handlers

      this.handlers = [];
      this.timedHandlers = [];
      this.removeTimeds = [];
      this.removeHandlers = [];
      this.addTimeds = [];
      this.addHandlers = []; // tell the parent we disconnected

      this._changeConnectStatus(Strophe.Status.DISCONNECTED, condition);

      this.connected = false;
    },

    /** PrivateFunction: _dataRecv
     *  _Private_ handler to processes incoming data from the the connection.
     *
     *  Except for _connect_cb handling the initial connection request,
     *  this function handles the incoming data for all requests.  This
     *  function also fires stanza handlers that match each incoming
     *  stanza.
     *
     *  Parameters:
     *    (Strophe.Request) req - The request that has data ready.
     *    (string) req - The stanza a raw string (optiona).
     */
    _dataRecv: function _dataRecv(req, raw) {
      var _this6 = this;

      Strophe.debug("_dataRecv called");

      var elem = this._proto._reqToData(req);

      if (elem === null) {
        return;
      }

      if (this.xmlInput !== Strophe.Connection.prototype.xmlInput) {
        if (elem.nodeName === this._proto.strip && elem.childNodes.length) {
          this.xmlInput(elem.childNodes[0]);
        } else {
          this.xmlInput(elem);
        }
      }

      if (this.rawInput !== Strophe.Connection.prototype.rawInput) {
        if (raw) {
          this.rawInput(raw);
        } else {
          this.rawInput(Strophe.serialize(elem));
        }
      } // remove handlers scheduled for deletion


      while (this.removeHandlers.length > 0) {
        var hand = this.removeHandlers.pop();
        var i = this.handlers.indexOf(hand);

        if (i >= 0) {
          this.handlers.splice(i, 1);
        }
      } // add handlers scheduled for addition


      while (this.addHandlers.length > 0) {
        this.handlers.push(this.addHandlers.pop());
      } // handle graceful disconnect


      if (this.disconnecting && this._proto._emptyQueue()) {
        this._doDisconnect();

        return;
      }

      var type = elem.getAttribute("type");

      if (type !== null && type === "terminate") {
        // Don't process stanzas that come in after disconnect
        if (this.disconnecting) {
          return;
        } // an error occurred


        var cond = elem.getAttribute("condition");
        var conflict = elem.getElementsByTagName("conflict");

        if (cond !== null) {
          if (cond === "remote-stream-error" && conflict.length > 0) {
            cond = "conflict";
          }

          this._changeConnectStatus(Strophe.Status.CONNFAIL, cond);
        } else {
          this._changeConnectStatus(Strophe.Status.CONNFAIL, Strophe.ErrorCondition.UNKOWN_REASON);
        }

        this._doDisconnect(cond);

        return;
      } // send each incoming stanza through the handler chain


      Strophe.forEachChild(elem, null, function (child) {
        // process handlers
        var newList = _this6.handlers;
        _this6.handlers = [];

        for (var _i5 = 0; _i5 < newList.length; _i5++) {
          var _hand = newList[_i5]; // encapsulate 'handler.run' not to lose the whole handler list if
          // one of the handlers throws an exception

          try {
            if (_hand.isMatch(child) && (_this6.authenticated || !_hand.user)) {
              if (_hand.run(child)) {
                _this6.handlers.push(_hand);
              }
            } else {
              _this6.handlers.push(_hand);
            }
          } catch (e) {
            // if the handler throws an exception, we consider it as false
            Strophe.warn('Removing Strophe handlers due to uncaught exception: ' + e.message);
          }
        }
      });
    },

    /** Attribute: mechanisms
     *  SASL Mechanisms available for Connection.
     */
    mechanisms: {},

    /** PrivateFunction: _connect_cb
     *  _Private_ handler for initial connection request.
     *
     *  This handler is used to process the initial connection request
     *  response from the BOSH server. It is used to set up authentication
     *  handlers and start the authentication process.
     *
     *  SASL authentication will be attempted if available, otherwise
     *  the code will fall back to legacy authentication.
     *
     *  Parameters:
     *    (Strophe.Request) req - The current request.
     *    (Function) _callback - low level (xmpp) connect callback function.
     *      Useful for plugins with their own xmpp connect callback (when they
     *      want to do something special).
     */
    _connect_cb: function _connect_cb(req, _callback, raw) {
      Strophe.debug("_connect_cb was called");
      this.connected = true;
      var bodyWrap;

      try {
        bodyWrap = this._proto._reqToData(req);
      } catch (e) {
        if (e.name !== Strophe.ErrorCondition.BAD_FORMAT) {
          throw e;
        }

        this._changeConnectStatus(Strophe.Status.CONNFAIL, Strophe.ErrorCondition.BAD_FORMAT);

        this._doDisconnect(Strophe.ErrorCondition.BAD_FORMAT);
      }

      if (!bodyWrap) {
        return;
      }

      if (this.xmlInput !== Strophe.Connection.prototype.xmlInput) {
        if (bodyWrap.nodeName === this._proto.strip && bodyWrap.childNodes.length) {
          this.xmlInput(bodyWrap.childNodes[0]);
        } else {
          this.xmlInput(bodyWrap);
        }
      }

      if (this.rawInput !== Strophe.Connection.prototype.rawInput) {
        if (raw) {
          this.rawInput(raw);
        } else {
          this.rawInput(Strophe.serialize(bodyWrap));
        }
      }

      var conncheck = this._proto._connect_cb(bodyWrap);

      if (conncheck === Strophe.Status.CONNFAIL) {
        return;
      } // Check for the stream:features tag


      var hasFeatures;

      if (bodyWrap.getElementsByTagNameNS) {
        hasFeatures = bodyWrap.getElementsByTagNameNS(Strophe.NS.STREAM, "features").length > 0;
      } else {
        hasFeatures = bodyWrap.getElementsByTagName("stream:features").length > 0 || bodyWrap.getElementsByTagName("features").length > 0;
      }

      if (!hasFeatures) {
        this._proto._no_auth_received(_callback);

        return;
      }

      var matched = [];
      var mechanisms = bodyWrap.getElementsByTagName("mechanism");

      if (mechanisms.length > 0) {
        for (var i = 0; i < mechanisms.length; i++) {
          var mech = Strophe.getText(mechanisms[i]);
          if (this.mechanisms[mech]) matched.push(this.mechanisms[mech]);
        }
      }

      if (matched.length === 0) {
        if (bodyWrap.getElementsByTagName("auth").length === 0) {
          // There are no matching SASL mechanisms and also no legacy
          // auth available.
          this._proto._no_auth_received(_callback);

          return;
        }
      }

      if (this.do_authentication !== false) {
        this.authenticate(matched);
      }
    },

    /** Function: sortMechanismsByPriority
     *
     *  Sorts an array of objects with prototype SASLMechanism according to
     *  their priorities.
     *
     *  Parameters:
     *    (Array) mechanisms - Array of SASL mechanisms.
     *
     */
    sortMechanismsByPriority: function sortMechanismsByPriority(mechanisms) {
      // Sorting mechanisms according to priority.
      for (var i = 0; i < mechanisms.length - 1; ++i) {
        var higher = i;

        for (var j = i + 1; j < mechanisms.length; ++j) {
          if (mechanisms[j].prototype.priority > mechanisms[higher].prototype.priority) {
            higher = j;
          }
        }

        if (higher !== i) {
          var swap = mechanisms[i];
          mechanisms[i] = mechanisms[higher];
          mechanisms[higher] = swap;
        }
      }

      return mechanisms;
    },

    /** Function: authenticate
     * Set up authentication
     *
     *  Continues the initial connection request by setting up authentication
     *  handlers and starting the authentication process.
     *
     *  SASL authentication will be attempted if available, otherwise
     *  the code will fall back to legacy authentication.
     *
     *  Parameters:
     *    (Array) matched - Array of SASL mechanisms supported.
     *
     */
    authenticate: function authenticate(matched) {
      if (!this._attemptSASLAuth(matched)) {
        this._attemptLegacyAuth();
      }
    },

    /** PrivateFunction: _attemptSASLAuth
     *
     *  Iterate through an array of SASL mechanisms and attempt authentication
     *  with the highest priority (enabled) mechanism.
     *
     *  Parameters:
     *    (Array) mechanisms - Array of SASL mechanisms.
     *
     *  Returns:
     *    (Boolean) mechanism_found - true or false, depending on whether a
     *          valid SASL mechanism was found with which authentication could be
     *          started.
     */
    _attemptSASLAuth: function _attemptSASLAuth(mechanisms) {
      mechanisms = this.sortMechanismsByPriority(mechanisms || []);
      var mechanism_found = false;

      for (var i = 0; i < mechanisms.length; ++i) {
        if (!mechanisms[i].prototype.test(this)) {
          continue;
        }

        this._sasl_success_handler = this._addSysHandler(this._sasl_success_cb.bind(this), null, "success", null, null);
        this._sasl_failure_handler = this._addSysHandler(this._sasl_failure_cb.bind(this), null, "failure", null, null);
        this._sasl_challenge_handler = this._addSysHandler(this._sasl_challenge_cb.bind(this), null, "challenge", null, null);
        this._sasl_mechanism = new mechanisms[i]();

        this._sasl_mechanism.onStart(this);

        var request_auth_exchange = $build("auth", {
          'xmlns': Strophe.NS.SASL,
          'mechanism': this._sasl_mechanism.name
        });

        if (this._sasl_mechanism.isClientFirst) {
          var response = this._sasl_mechanism.onChallenge(this, null);

          request_auth_exchange.t(btoa(response));
        }

        this.send(request_auth_exchange.tree());
        mechanism_found = true;
        break;
      }

      return mechanism_found;
    },

    /** PrivateFunction: _sasl_challenge_cb
     *  _Private_ handler for the SASL challenge
     *
     */
    _sasl_challenge_cb: function _sasl_challenge_cb(elem) {
      var challenge = atob(Strophe.getText(elem));

      var response = this._sasl_mechanism.onChallenge(this, challenge);

      var stanza = $build('response', {
        'xmlns': Strophe.NS.SASL
      });

      if (response !== "") {
        stanza.t(btoa(response));
      }

      this.send(stanza.tree());
      return true;
    },

    /** PrivateFunction: _attemptLegacyAuth
     *
     *  Attempt legacy (i.e. non-SASL) authentication.
     */
    _attemptLegacyAuth: function _attemptLegacyAuth() {
      if (Strophe.getNodeFromJid(this.jid) === null) {
        // we don't have a node, which is required for non-anonymous
        // client connections
        this._changeConnectStatus(Strophe.Status.CONNFAIL, Strophe.ErrorCondition.MISSING_JID_NODE);

        this.disconnect(Strophe.ErrorCondition.MISSING_JID_NODE);
      } else {
        // Fall back to legacy authentication
        this._changeConnectStatus(Strophe.Status.AUTHENTICATING, null);

        this._addSysHandler(this._onLegacyAuthIQResult.bind(this), null, null, null, "_auth_1");

        this.send($iq({
          'type': "get",
          'to': this.domain,
          'id': "_auth_1"
        }).c("query", {
          xmlns: Strophe.NS.AUTH
        }).c("username", {}).t(Strophe.getNodeFromJid(this.jid)).tree());
      }
    },

    /** PrivateFunction: _onLegacyAuthIQResult
     *  _Private_ handler for legacy authentication.
     *
     *  This handler is called in response to the initial <iq type='get'/>
     *  for legacy authentication.  It builds an authentication <iq/> and
     *  sends it, creating a handler (calling back to _auth2_cb()) to
     *  handle the result
     *
     *  Parameters:
     *    (XMLElement) elem - The stanza that triggered the callback.
     *
     *  Returns:
     *    false to remove the handler.
     */
    _onLegacyAuthIQResult: function _onLegacyAuthIQResult(elem) {
      // build plaintext auth iq
      var iq = $iq({
        type: "set",
        id: "_auth_2"
      }).c('query', {
        xmlns: Strophe.NS.AUTH
      }).c('username', {}).t(Strophe.getNodeFromJid(this.jid)).up().c('password').t(this.pass);

      if (!Strophe.getResourceFromJid(this.jid)) {
        // since the user has not supplied a resource, we pick
        // a default one here.  unlike other auth methods, the server
        // cannot do this for us.
        this.jid = Strophe.getBareJidFromJid(this.jid) + '/strophe';
      }

      iq.up().c('resource', {}).t(Strophe.getResourceFromJid(this.jid));

      this._addSysHandler(this._auth2_cb.bind(this), null, null, null, "_auth_2");

      this.send(iq.tree());
      return false;
    },

    /** PrivateFunction: _sasl_success_cb
     *  _Private_ handler for succesful SASL authentication.
     *
     *  Parameters:
     *    (XMLElement) elem - The matching stanza.
     *
     *  Returns:
     *    false to remove the handler.
     */
    _sasl_success_cb: function _sasl_success_cb(elem) {
      var _this7 = this;

      if (this._sasl_data["server-signature"]) {
        var serverSignature;
        var success = atob(Strophe.getText(elem));
        var attribMatch = /([a-z]+)=([^,]+)(,|$)/;
        var matches = success.match(attribMatch);

        if (matches[1] === "v") {
          serverSignature = matches[2];
        }

        if (serverSignature !== this._sasl_data["server-signature"]) {
          // remove old handlers
          this.deleteHandler(this._sasl_failure_handler);
          this._sasl_failure_handler = null;

          if (this._sasl_challenge_handler) {
            this.deleteHandler(this._sasl_challenge_handler);
            this._sasl_challenge_handler = null;
          }

          this._sasl_data = {};
          return this._sasl_failure_cb(null);
        }
      }

      Strophe.info("SASL authentication succeeded.");

      if (this._sasl_mechanism) {
        this._sasl_mechanism.onSuccess();
      } // remove old handlers


      this.deleteHandler(this._sasl_failure_handler);
      this._sasl_failure_handler = null;

      if (this._sasl_challenge_handler) {
        this.deleteHandler(this._sasl_challenge_handler);
        this._sasl_challenge_handler = null;
      }

      var streamfeature_handlers = [];

      var wrapper = function wrapper(handlers, elem) {
        while (handlers.length) {
          _this7.deleteHandler(handlers.pop());
        }

        _this7._onStreamFeaturesAfterSASL(elem);

        return false;
      };

      streamfeature_handlers.push(this._addSysHandler(function (elem) {
        return wrapper(streamfeature_handlers, elem);
      }, null, "stream:features", null, null));
      streamfeature_handlers.push(this._addSysHandler(function (elem) {
        return wrapper(streamfeature_handlers, elem);
      }, Strophe.NS.STREAM, "features", null, null)); // we must send an xmpp:restart now

      this._sendRestart();

      return false;
    },

    /** PrivateFunction: _onStreamFeaturesAfterSASL
     *  Parameters:
     *    (XMLElement) elem - The matching stanza.
     *
     *  Returns:
     *    false to remove the handler.
     */
    _onStreamFeaturesAfterSASL: function _onStreamFeaturesAfterSASL(elem) {
      // save stream:features for future usage
      this.features = elem;

      for (var i = 0; i < elem.childNodes.length; i++) {
        var child = elem.childNodes[i];

        if (child.nodeName === 'bind') {
          this.do_bind = true;
        }

        if (child.nodeName === 'session') {
          this.do_session = true;
        }
      }

      if (!this.do_bind) {
        this._changeConnectStatus(Strophe.Status.AUTHFAIL, null);

        return false;
      } else if (!this.options.explicitResourceBinding) {
        this.bind();
      } else {
        this._changeConnectStatus(Strophe.Status.BINDREQUIRED, null);
      }

      return false;
    },

    /** Function: bind
     *
     *  Sends an IQ to the XMPP server to bind a JID resource for this session.
     *
     *  https://tools.ietf.org/html/rfc6120#section-7.5
     *
     *  If `explicitResourceBinding` was set to a truthy value in the options
     *  passed to the Strophe.Connection constructor, then this function needs
     *  to be called explicitly by the client author.
     *
     *  Otherwise it'll be called automatically as soon as the XMPP server
     *  advertises the "urn:ietf:params:xml:ns:xmpp-bind" stream feature.
     */
    bind: function bind() {
      if (!this.do_bind) {
        Strophe.log(Strophe.LogLevel.INFO, "Strophe.Connection.prototype.bind called but \"do_bind\" is false");
        return;
      }

      this._addSysHandler(this._onResourceBindResultIQ.bind(this), null, null, null, "_bind_auth_2");

      var resource = Strophe.getResourceFromJid(this.jid);

      if (resource) {
        this.send($iq({
          type: "set",
          id: "_bind_auth_2"
        }).c('bind', {
          xmlns: Strophe.NS.BIND
        }).c('resource', {}).t(resource).tree());
      } else {
        this.send($iq({
          type: "set",
          id: "_bind_auth_2"
        }).c('bind', {
          xmlns: Strophe.NS.BIND
        }).tree());
      }
    },

    /** PrivateFunction: _onResourceBindIQ
     *  _Private_ handler for binding result and session start.
     *
     *  Parameters:
     *    (XMLElement) elem - The matching stanza.
     *
     *  Returns:
     *    false to remove the handler.
     */
    _onResourceBindResultIQ: function _onResourceBindResultIQ(elem) {
      if (elem.getAttribute("type") === "error") {
        Strophe.warn("Resource binding failed.");
        var conflict = elem.getElementsByTagName("conflict");
        var condition;

        if (conflict.length > 0) {
          condition = Strophe.ErrorCondition.CONFLICT;
        }

        this._changeConnectStatus(Strophe.Status.AUTHFAIL, condition, elem);

        return false;
      } // TODO - need to grab errors


      var bind = elem.getElementsByTagName("bind");

      if (bind.length > 0) {
        var jidNode = bind[0].getElementsByTagName("jid");

        if (jidNode.length > 0) {
          this.jid = Strophe.getText(jidNode[0]);

          if (this.do_session) {
            this._establishSession();
          } else {
            this.authenticated = true;

            this._changeConnectStatus(Strophe.Status.CONNECTED, null);
          }
        }
      } else {
        Strophe.warn("Resource binding failed.");

        this._changeConnectStatus(Strophe.Status.AUTHFAIL, null, elem);

        return false;
      }
    },

    /** PrivateFunction: _establishSession
     *  Send IQ request to establish a session with the XMPP server.
     *
     *  See https://xmpp.org/rfcs/rfc3921.html#session
     *
     *  Note: The protocol for session establishment has been determined as
     *  unnecessary and removed in RFC-6121.
     */
    _establishSession: function _establishSession() {
      if (!this.do_session) {
        throw new Error("Strophe.Connection.prototype._establishSession " + "called but apparently ".concat(Strophe.NS.SESSION, " wasn't advertised by the server"));
      }

      this._addSysHandler(this._onSessionResultIQ.bind(this), null, null, null, "_session_auth_2");

      this.send($iq({
        type: "set",
        id: "_session_auth_2"
      }).c('session', {
        xmlns: Strophe.NS.SESSION
      }).tree());
    },

    /** PrivateFunction: _onSessionResultIQ
     *  _Private_ handler for the server's IQ response to a client's session
     *  request.
     *
     *  This sets Connection.authenticated to true on success, which
     *  starts the processing of user handlers.
     *
     *  See https://xmpp.org/rfcs/rfc3921.html#session
     *
     *  Note: The protocol for session establishment has been determined as
     *  unnecessary and removed in RFC-6121.
     *
     *  Parameters:
     *    (XMLElement) elem - The matching stanza.
     *
     *  Returns:
     *    false to remove the handler.
     */
    _onSessionResultIQ: function _onSessionResultIQ(elem) {
      if (elem.getAttribute("type") === "result") {
        this.authenticated = true;

        this._changeConnectStatus(Strophe.Status.CONNECTED, null);
      } else if (elem.getAttribute("type") === "error") {
        Strophe.warn("Session creation failed.");

        this._changeConnectStatus(Strophe.Status.AUTHFAIL, null, elem);

        return false;
      }

      return false;
    },

    /** PrivateFunction: _sasl_failure_cb
     *  _Private_ handler for SASL authentication failure.
     *
     *  Parameters:
     *    (XMLElement) elem - The matching stanza.
     *
     *  Returns:
     *    false to remove the handler.
     */
    _sasl_failure_cb: function _sasl_failure_cb(elem) {
      // delete unneeded handlers
      if (this._sasl_success_handler) {
        this.deleteHandler(this._sasl_success_handler);
        this._sasl_success_handler = null;
      }

      if (this._sasl_challenge_handler) {
        this.deleteHandler(this._sasl_challenge_handler);
        this._sasl_challenge_handler = null;
      }

      if (this._sasl_mechanism) this._sasl_mechanism.onFailure();

      this._changeConnectStatus(Strophe.Status.AUTHFAIL, null, elem);

      return false;
    },

    /** PrivateFunction: _auth2_cb
     *  _Private_ handler to finish legacy authentication.
     *
     *  This handler is called when the result from the jabber:iq:auth
     *  <iq/> stanza is returned.
     *
     *  Parameters:
     *    (XMLElement) elem - The stanza that triggered the callback.
     *
     *  Returns:
     *    false to remove the handler.
     */
    _auth2_cb: function _auth2_cb(elem) {
      if (elem.getAttribute("type") === "result") {
        this.authenticated = true;

        this._changeConnectStatus(Strophe.Status.CONNECTED, null);
      } else if (elem.getAttribute("type") === "error") {
        this._changeConnectStatus(Strophe.Status.AUTHFAIL, null, elem);

        this.disconnect('authentication failed');
      }

      return false;
    },

    /** PrivateFunction: _addSysTimedHandler
     *  _Private_ function to add a system level timed handler.
     *
     *  This function is used to add a Strophe.TimedHandler for the
     *  library code.  System timed handlers are allowed to run before
     *  authentication is complete.
     *
     *  Parameters:
     *    (Integer) period - The period of the handler.
     *    (Function) handler - The callback function.
     */
    _addSysTimedHandler: function _addSysTimedHandler(period, handler) {
      var thand = new Strophe.TimedHandler(period, handler);
      thand.user = false;
      this.addTimeds.push(thand);
      return thand;
    },

    /** PrivateFunction: _addSysHandler
     *  _Private_ function to add a system level stanza handler.
     *
     *  This function is used to add a Strophe.Handler for the
     *  library code.  System stanza handlers are allowed to run before
     *  authentication is complete.
     *
     *  Parameters:
     *    (Function) handler - The callback function.
     *    (String) ns - The namespace to match.
     *    (String) name - The stanza name to match.
     *    (String) type - The stanza type attribute to match.
     *    (String) id - The stanza id attribute to match.
     */
    _addSysHandler: function _addSysHandler(handler, ns, name, type, id) {
      var hand = new Strophe.Handler(handler, ns, name, type, id);
      hand.user = false;
      this.addHandlers.push(hand);
      return hand;
    },

    /** PrivateFunction: _onDisconnectTimeout
     *  _Private_ timeout handler for handling non-graceful disconnection.
     *
     *  If the graceful disconnect process does not complete within the
     *  time allotted, this handler finishes the disconnect anyway.
     *
     *  Returns:
     *    false to remove the handler.
     */
    _onDisconnectTimeout: function _onDisconnectTimeout() {
      Strophe.debug("_onDisconnectTimeout was called");

      this._changeConnectStatus(Strophe.Status.CONNTIMEOUT, null);

      this._proto._onDisconnectTimeout(); // actually disconnect


      this._doDisconnect();

      return false;
    },

    /** PrivateFunction: _onIdle
     *  _Private_ handler to process events during idle cycle.
     *
     *  This handler is called every 100ms to fire timed handlers that
     *  are ready and keep poll requests going.
     */
    _onIdle: function _onIdle() {
      var _this8 = this; // add timed handlers scheduled for addition
      // NOTE: we add before remove in the case a timed handler is
      // added and then deleted before the next _onIdle() call.


      while (this.addTimeds.length > 0) {
        this.timedHandlers.push(this.addTimeds.pop());
      } // remove timed handlers that have been scheduled for deletion


      while (this.removeTimeds.length > 0) {
        var thand = this.removeTimeds.pop();
        var i = this.timedHandlers.indexOf(thand);

        if (i >= 0) {
          this.timedHandlers.splice(i, 1);
        }
      } // call ready timed handlers


      var now = new Date().getTime();
      var newList = [];

      for (var _i6 = 0; _i6 < this.timedHandlers.length; _i6++) {
        var _thand = this.timedHandlers[_i6];

        if (this.authenticated || !_thand.user) {
          var since = _thand.lastCalled + _thand.period;

          if (since - now <= 0) {
            if (_thand.run()) {
              newList.push(_thand);
            }
          } else {
            newList.push(_thand);
          }
        }
      }

      this.timedHandlers = newList;
      clearTimeout(this._idleTimeout);

      this._proto._onIdle(); // reactivate the timer only if connected


      if (this.connected) {
        this._idleTimeout = setTimeout(function () {
          return _this8._onIdle();
        }, 100);
      }
    }
  };
  /** Class: Strophe.SASLMechanism
   *
   *  encapsulates SASL authentication mechanisms.
   *
   *  User code may override the priority for each mechanism or disable it completely.
   *  See <priority> for information about changing priority and <test> for informatian on
   *  how to disable a mechanism.
   *
   *  By default, all mechanisms are enabled and the priorities are
   *
   *      OAUTHBEARER - 60
   *      SCRAM-SHA1 - 50
   *      DIGEST-MD5 - 40
   *      PLAIN - 30
   *      ANONYMOUS - 20
   *      EXTERNAL - 10
   *
   *  See: Strophe.Connection.addSupportedSASLMechanisms
   */

  /**
   * PrivateConstructor: Strophe.SASLMechanism
   * SASL auth mechanism abstraction.
   *
   *  Parameters:
   *    (String) name - SASL Mechanism name.
   *    (Boolean) isClientFirst - If client should send response first without challenge.
   *    (Number) priority - Priority.
   *
   *  Returns:
   *    A new Strophe.SASLMechanism object.
   */

  Strophe.SASLMechanism = function (name, isClientFirst, priority) {
    /** PrivateVariable: name
     *  Mechanism name.
     */
    this.name = name;
    /** PrivateVariable: isClientFirst
     *  If client sends response without initial server challenge.
     */

    this.isClientFirst = isClientFirst;
    /** Variable: priority
     *  Determines which <SASLMechanism> is chosen for authentication (Higher is better).
     *  Users may override this to prioritize mechanisms differently.
     *
     *  In the default configuration the priorities are
     *
     *  SCRAM-SHA1 - 40
     *  DIGEST-MD5 - 30
     *  Plain - 20
     *
     *  Example: (This will cause Strophe to choose the mechanism that the server sent first)
     *
     *  > Strophe.SASLMD5.priority = Strophe.SASLSHA1.priority;
     *
     *  See <SASL mechanisms> for a list of available mechanisms.
     *
     */

    this.priority = priority;
  };

  Strophe.SASLMechanism.prototype = {
    /**
     *  Function: test
     *  Checks if mechanism able to run.
     *  To disable a mechanism, make this return false;
     *
     *  To disable plain authentication run
     *  > Strophe.SASLPlain.test = function() {
     *  >   return false;
     *  > }
     *
     *  See <SASL mechanisms> for a list of available mechanisms.
     *
     *  Parameters:
     *    (Strophe.Connection) connection - Target Connection.
     *
     *  Returns:
     *    (Boolean) If mechanism was able to run.
     */
    test: function test(connection) {
      return true;
    },

    /** PrivateFunction: onStart
     *  Called before starting mechanism on some connection.
     *
     *  Parameters:
     *    (Strophe.Connection) connection - Target Connection.
     */
    onStart: function onStart(connection) {
      this._connection = connection;
    },

    /** PrivateFunction: onChallenge
     *  Called by protocol implementation on incoming challenge. If client is
     *  first (isClientFirst === true) challenge will be null on the first call.
     *
     *  Parameters:
     *    (Strophe.Connection) connection - Target Connection.
     *    (String) challenge - current challenge to handle.
     *
     *  Returns:
     *    (String) Mechanism response.
     */
    onChallenge: function onChallenge(connection, challenge) {
      throw new Error("You should implement challenge handling!");
    },

    /** PrivateFunction: onFailure
     *  Protocol informs mechanism implementation about SASL failure.
     */
    onFailure: function onFailure() {
      this._connection = null;
    },

    /** PrivateFunction: onSuccess
     *  Protocol informs mechanism implementation about SASL success.
     */
    onSuccess: function onSuccess() {
      this._connection = null;
    }
  };
  /** Constants: SASL mechanisms
   *  Available authentication mechanisms
   *
   *  Strophe.SASLAnonymous - SASL ANONYMOUS authentication.
   *  Strophe.SASLPlain - SASL PLAIN authentication.
   *  Strophe.SASLMD5 - SASL DIGEST-MD5 authentication
   *  Strophe.SASLSHA1 - SASL SCRAM-SHA1 authentication
   *  Strophe.SASLOAuthBearer - SASL OAuth Bearer authentication
   *  Strophe.SASLExternal - SASL EXTERNAL authentication
   *  Strophe.SASLXOAuth2 - SASL X-OAuth2 authentication
   */
  // Building SASL callbacks

  /** PrivateConstructor: SASLAnonymous
   *  SASL ANONYMOUS authentication.
   */

  Strophe.SASLAnonymous = function () {};

  Strophe.SASLAnonymous.prototype = new Strophe.SASLMechanism("ANONYMOUS", false, 20);

  Strophe.SASLAnonymous.prototype.test = function (connection) {
    return connection.authcid === null;
  };
  /** PrivateConstructor: SASLPlain
   *  SASL PLAIN authentication.
   */


  Strophe.SASLPlain = function () {};

  Strophe.SASLPlain.prototype = new Strophe.SASLMechanism("PLAIN", true, 50);

  Strophe.SASLPlain.prototype.test = function (connection) {
    return connection.authcid !== null;
  };

  Strophe.SASLPlain.prototype.onChallenge = function (connection) {
    var auth_str = connection.authzid;
    auth_str = auth_str + "\0";
    auth_str = auth_str + connection.authcid;
    auth_str = auth_str + "\0";
    auth_str = auth_str + connection.pass;
    return utils.utf16to8(auth_str);
  };
  /** PrivateConstructor: SASLSHA1
   *  SASL SCRAM SHA 1 authentication.
   */


  Strophe.SASLSHA1 = function () {};

  Strophe.SASLSHA1.prototype = new Strophe.SASLMechanism("SCRAM-SHA-1", true, 70);

  Strophe.SASLSHA1.prototype.test = function (connection) {
    return connection.authcid !== null;
  };

  Strophe.SASLSHA1.prototype.onChallenge = function (connection, challenge, test_cnonce) {
    var cnonce = test_cnonce || MD5.hexdigest("" + Math.random() * 1234567890);
    var auth_str = "n=" + utils.utf16to8(connection.authcid);
    auth_str += ",r=";
    auth_str += cnonce;
    connection._sasl_data.cnonce = cnonce;
    connection._sasl_data["client-first-message-bare"] = auth_str;
    auth_str = "n,," + auth_str;

    this.onChallenge = function (connection, challenge) {
      var nonce, salt, iter, Hi, U, U_old, i, k;
      var responseText = "c=biws,";
      var authMessage = "".concat(connection._sasl_data["client-first-message-bare"], ",").concat(challenge, ",");
      var cnonce = connection._sasl_data.cnonce;
      var attribMatch = /([a-z]+)=([^,]+)(,|$)/;

      while (challenge.match(attribMatch)) {
        var matches = challenge.match(attribMatch);
        challenge = challenge.replace(matches[0], "");

        switch (matches[1]) {
          case "r":
            nonce = matches[2];
            break;

          case "s":
            salt = matches[2];
            break;

          case "i":
            iter = matches[2];
            break;
        }
      }

      if (nonce.substr(0, cnonce.length) !== cnonce) {
        connection._sasl_data = {};
        return connection._sasl_failure_cb();
      }

      responseText += "r=" + nonce;
      authMessage += responseText;
      salt = atob(salt);
      salt += "\x00\x00\x00\x01";
      var pass = utils.utf16to8(connection.pass);
      Hi = U_old = SHA1.core_hmac_sha1(pass, salt);

      for (i = 1; i < iter; i++) {
        U = SHA1.core_hmac_sha1(pass, SHA1.binb2str(U_old));

        for (k = 0; k < 5; k++) {
          Hi[k] ^= U[k];
        }

        U_old = U;
      }

      Hi = SHA1.binb2str(Hi);
      var clientKey = SHA1.core_hmac_sha1(Hi, "Client Key");
      var serverKey = SHA1.str_hmac_sha1(Hi, "Server Key");
      var clientSignature = SHA1.core_hmac_sha1(SHA1.str_sha1(SHA1.binb2str(clientKey)), authMessage);
      connection._sasl_data["server-signature"] = SHA1.b64_hmac_sha1(serverKey, authMessage);

      for (k = 0; k < 5; k++) {
        clientKey[k] ^= clientSignature[k];
      }

      responseText += ",p=" + btoa(SHA1.binb2str(clientKey));
      return responseText;
    };

    return auth_str;
  };
  /** PrivateConstructor: SASLMD5
   *  SASL DIGEST MD5 authentication.
   */


  Strophe.SASLMD5 = function () {};

  Strophe.SASLMD5.prototype = new Strophe.SASLMechanism("DIGEST-MD5", false, 60);

  Strophe.SASLMD5.prototype.test = function (connection) {
    return connection.authcid !== null;
  };
  /** PrivateFunction: _quote
   *  _Private_ utility function to backslash escape and quote strings.
   *
   *  Parameters:
   *    (String) str - The string to be quoted.
   *
   *  Returns:
   *    quoted string
   */


  Strophe.SASLMD5.prototype._quote = function (str) {
    return '"' + str.replace(/\\/g, "\\\\").replace(/"/g, '\\"') + '"'; //" end string workaround for emacs
  };

  Strophe.SASLMD5.prototype.onChallenge = function (connection, challenge, test_cnonce) {
    var attribMatch = /([a-z]+)=("[^"]+"|[^,"]+)(?:,|$)/;
    var cnonce = test_cnonce || MD5.hexdigest("" + Math.random() * 1234567890);
    var realm = "";
    var host = null;
    var nonce = "";
    var qop = "";

    while (challenge.match(attribMatch)) {
      var matches = challenge.match(attribMatch);
      challenge = challenge.replace(matches[0], "");
      matches[2] = matches[2].replace(/^"(.+)"$/, "$1");

      switch (matches[1]) {
        case "realm":
          realm = matches[2];
          break;

        case "nonce":
          nonce = matches[2];
          break;

        case "qop":
          qop = matches[2];
          break;

        case "host":
          host = matches[2];
          break;
      }
    }

    var digest_uri = connection.servtype + "/" + connection.domain;

    if (host !== null) {
      digest_uri = digest_uri + "/" + host;
    }

    var cred = utils.utf16to8(connection.authcid + ":" + realm + ":" + this._connection.pass);
    var A1 = MD5.hash(cred) + ":" + nonce + ":" + cnonce;
    var A2 = 'AUTHENTICATE:' + digest_uri;
    var responseText = "";
    responseText += 'charset=utf-8,';
    responseText += 'username=' + this._quote(utils.utf16to8(connection.authcid)) + ',';
    responseText += 'realm=' + this._quote(realm) + ',';
    responseText += 'nonce=' + this._quote(nonce) + ',';
    responseText += 'nc=00000001,';
    responseText += 'cnonce=' + this._quote(cnonce) + ',';
    responseText += 'digest-uri=' + this._quote(digest_uri) + ',';
    responseText += 'response=' + MD5.hexdigest(MD5.hexdigest(A1) + ":" + nonce + ":00000001:" + cnonce + ":auth:" + MD5.hexdigest(A2)) + ",";
    responseText += 'qop=auth';

    this.onChallenge = function () {
      return "";
    };

    return responseText;
  };
  /** PrivateConstructor: SASLOAuthBearer
   *  SASL OAuth Bearer authentication.
   */


  Strophe.SASLOAuthBearer = function () {};

  Strophe.SASLOAuthBearer.prototype = new Strophe.SASLMechanism("OAUTHBEARER", true, 40);

  Strophe.SASLOAuthBearer.prototype.test = function (connection) {
    return connection.pass !== null;
  };

  Strophe.SASLOAuthBearer.prototype.onChallenge = function (connection) {
    var auth_str = 'n,';

    if (connection.authcid !== null) {
      auth_str = auth_str + 'a=' + connection.authzid;
    }

    auth_str = auth_str + ',';
    auth_str = auth_str + "\x01";
    auth_str = auth_str + 'auth=Bearer ';
    auth_str = auth_str + connection.pass;
    auth_str = auth_str + "\x01";
    auth_str = auth_str + "\x01";
    return utils.utf16to8(auth_str);
  };
  /** PrivateConstructor: SASLExternal
   *  SASL EXTERNAL authentication.
   *
   *  The EXTERNAL mechanism allows a client to request the server to use
   *  credentials established by means external to the mechanism to
   *  authenticate the client. The external means may be, for instance,
   *  TLS services.
   */


  Strophe.SASLExternal = function () {};

  Strophe.SASLExternal.prototype = new Strophe.SASLMechanism("EXTERNAL", true, 10);

  Strophe.SASLExternal.prototype.onChallenge = function (connection) {
    /** According to XEP-178, an authzid SHOULD NOT be presented when the
     * authcid contained or implied in the client certificate is the JID (i.e.
     * authzid) with which the user wants to log in as.
     *
     * To NOT send the authzid, the user should therefore set the authcid equal
     * to the JID when instantiating a new Strophe.Connection object.
     */
    return connection.authcid === connection.authzid ? '' : connection.authzid;
  };
  /** PrivateConstructor: SASLXOAuth2
   *  SASL X-OAuth2 authentication.
   */


  Strophe.SASLXOAuth2 = function () {};

  Strophe.SASLXOAuth2.prototype = new Strophe.SASLMechanism("X-OAUTH2", true, 30);

  Strophe.SASLXOAuth2.prototype.test = function (connection) {
    return connection.pass !== null;
  };

  Strophe.SASLXOAuth2.prototype.onChallenge = function (connection) {
    var auth_str = "\0";

    if (connection.authcid !== null) {
      auth_str = auth_str + connection.authzid;
    }

    auth_str = auth_str + "\0";
    auth_str = auth_str + connection.pass;
    return utils.utf16to8(auth_str);
  };

  var core = {
    'Strophe': Strophe,
    '$build': $build,
    '$iq': $iq,
    '$msg': $msg,
    '$pres': $pres,
    'SHA1': SHA1,
    'MD5': MD5,
    'b64_hmac_sha1': SHA1.b64_hmac_sha1,
    'b64_sha1': SHA1.b64_sha1,
    'str_hmac_sha1': SHA1.str_hmac_sha1,
    'str_sha1': SHA1.str_sha1
  };
  /*
      This program is distributed under the terms of the MIT license.
      Please see the LICENSE file for details.
       Copyright 2006-2008, OGG, LLC
  */

  var Strophe$1 = core.Strophe;
  var $build$1 = core.$build;
  /** PrivateClass: Strophe.Request
   *  _Private_ helper class that provides a cross implementation abstraction
   *  for a BOSH related XMLHttpRequest.
   *
   *  The Strophe.Request class is used internally to encapsulate BOSH request
   *  information.  It is not meant to be used from user's code.
   */

  /** PrivateConstructor: Strophe.Request
   *  Create and initialize a new Strophe.Request object.
   *
   *  Parameters:
   *    (XMLElement) elem - The XML data to be sent in the request.
   *    (Function) func - The function that will be called when the
   *      XMLHttpRequest readyState changes.
   *    (Integer) rid - The BOSH rid attribute associated with this request.
   *    (Integer) sends - The number of times this same request has been sent.
   */

  Strophe$1.Request = function (elem, func, rid, sends) {
    this.id = ++Strophe$1._requestId;
    this.xmlData = elem;
    this.data = Strophe$1.serialize(elem); // save original function in case we need to make a new request
    // from this one.

    this.origFunc = func;
    this.func = func;
    this.rid = rid;
    this.date = NaN;
    this.sends = sends || 0;
    this.abort = false;
    this.dead = null;

    this.age = function () {
      if (!this.date) {
        return 0;
      }

      var now = new Date();
      return (now - this.date) / 1000;
    };

    this.timeDead = function () {
      if (!this.dead) {
        return 0;
      }

      var now = new Date();
      return (now - this.dead) / 1000;
    };

    this.xhr = this._newXHR();
  };

  Strophe$1.Request.prototype = {
    /** PrivateFunction: getResponse
     *  Get a response from the underlying XMLHttpRequest.
     *
     *  This function attempts to get a response from the request and checks
     *  for errors.
     *
     *  Throws:
     *    "parsererror" - A parser error occured.
     *    "bad-format" - The entity has sent XML that cannot be processed.
     *
     *  Returns:
     *    The DOM element tree of the response.
     */
    getResponse: function getResponse() {
      var node = null;

      if (this.xhr.responseXML && this.xhr.responseXML.documentElement) {
        node = this.xhr.responseXML.documentElement;

        if (node.tagName === "parsererror") {
          Strophe$1.error("invalid response received");
          Strophe$1.error("responseText: " + this.xhr.responseText);
          Strophe$1.error("responseXML: " + Strophe$1.serialize(this.xhr.responseXML));
          throw new Error("parsererror");
        }
      } else if (this.xhr.responseText) {
        // In React Native, we may get responseText but no responseXML.  We can try to parse it manually.
        Strophe$1.debug("Got responseText but no responseXML; attempting to parse it with DOMParser...");
        node = new DOMParser().parseFromString(this.xhr.responseText, 'application/xml').documentElement;

        if (!node) {
          throw new Error('Parsing produced null node');
        } else if (node.querySelector('parsererror')) {
          Strophe$1.error("invalid response received: " + node.querySelector('parsererror').textContent);
          Strophe$1.error("responseText: " + this.xhr.responseText);
          var error = new Error();
          error.name = Strophe$1.ErrorCondition.BAD_FORMAT;
          throw error;
        }
      }

      return node;
    },

    /** PrivateFunction: _newXHR
     *  _Private_ helper function to create XMLHttpRequests.
     *
     *  This function creates XMLHttpRequests across all implementations.
     *
     *  Returns:
     *    A new XMLHttpRequest.
     */
    _newXHR: function _newXHR() {
      var xhr = null;

      if (window.XMLHttpRequest) {
        xhr = new XMLHttpRequest();

        if (xhr.overrideMimeType) {
          xhr.overrideMimeType("text/xml; charset=utf-8");
        }
      } else if (window.ActiveXObject) {
        xhr = new ActiveXObject("Microsoft.XMLHTTP");
      } // use Function.bind() to prepend ourselves as an argument


      xhr.onreadystatechange = this.func.bind(null, this);
      return xhr;
    }
  };
  /** Class: Strophe.Bosh
   *  _Private_ helper class that handles BOSH Connections
   *
   *  The Strophe.Bosh class is used internally by Strophe.Connection
   *  to encapsulate BOSH sessions. It is not meant to be used from user's code.
   */

  /** File: bosh.js
   *  A JavaScript library to enable BOSH in Strophejs.
   *
   *  this library uses Bidirectional-streams Over Synchronous HTTP (BOSH)
   *  to emulate a persistent, stateful, two-way connection to an XMPP server.
   *  More information on BOSH can be found in XEP 124.
   */

  /** PrivateConstructor: Strophe.Bosh
   *  Create and initialize a Strophe.Bosh object.
   *
   *  Parameters:
   *    (Strophe.Connection) connection - The Strophe.Connection that will use BOSH.
   *
   *  Returns:
   *    A new Strophe.Bosh object.
   */

  Strophe$1.Bosh = function (connection) {
    this._conn = connection;
    /* request id for body tags */

    this.rid = Math.floor(Math.random() * 4294967295);
    /* The current session ID. */

    this.sid = null; // default BOSH values

    this.hold = 1;
    this.wait = 60;
    this.window = 5;
    this.errors = 0;
    this.inactivity = null;
    this.lastResponseHeaders = null;
    this._requests = [];
  };

  Strophe$1.Bosh.prototype = {
    /** Variable: strip
     *
     *  BOSH-Connections will have all stanzas wrapped in a <body> tag when
     *  passed to <Strophe.Connection.xmlInput> or <Strophe.Connection.xmlOutput>.
     *  To strip this tag, User code can set <Strophe.Bosh.strip> to "body":
     *
     *  > Strophe.Bosh.prototype.strip = "body";
     *
     *  This will enable stripping of the body tag in both
     *  <Strophe.Connection.xmlInput> and <Strophe.Connection.xmlOutput>.
     */
    strip: null,

    /** PrivateFunction: _buildBody
     *  _Private_ helper function to generate the <body/> wrapper for BOSH.
     *
     *  Returns:
     *    A Strophe.Builder with a <body/> element.
     */
    _buildBody: function _buildBody() {
      var bodyWrap = $build$1('body', {
        'rid': this.rid++,
        'xmlns': Strophe$1.NS.HTTPBIND
      });

      if (this.sid !== null) {
        bodyWrap.attrs({
          'sid': this.sid
        });
      }

      if (this._conn.options.keepalive && this._conn._sessionCachingSupported()) {
        this._cacheSession();
      }

      return bodyWrap;
    },

    /** PrivateFunction: _reset
     *  Reset the connection.
     *
     *  This function is called by the reset function of the Strophe Connection
     */
    _reset: function _reset() {
      this.rid = Math.floor(Math.random() * 4294967295);
      this.sid = null;
      this.errors = 0;

      if (this._conn._sessionCachingSupported()) {
        window.sessionStorage.removeItem('strophe-bosh-session');
      }

      this._conn.nextValidRid(this.rid);
    },

    /** PrivateFunction: _connect
     *  _Private_ function that initializes the BOSH connection.
     *
     *  Creates and sends the Request that initializes the BOSH connection.
     */
    _connect: function _connect(wait, hold, route) {
      this.wait = wait || this.wait;
      this.hold = hold || this.hold;
      this.errors = 0;

      var body = this._buildBody().attrs({
        "to": this._conn.domain,
        "xml:lang": "en",
        "wait": this.wait,
        "hold": this.hold,
        "content": "text/xml; charset=utf-8",
        "ver": "1.6",
        "xmpp:version": "1.0",
        "xmlns:xmpp": Strophe$1.NS.BOSH
      });

      if (route) {
        body.attrs({
          'route': route
        });
      }

      var _connect_cb = this._conn._connect_cb;

      this._requests.push(new Strophe$1.Request(body.tree(), this._onRequestStateChange.bind(this, _connect_cb.bind(this._conn)), body.tree().getAttribute("rid")));

      this._throttledRequestHandler();
    },

    /** PrivateFunction: _attach
     *  Attach to an already created and authenticated BOSH session.
     *
     *  This function is provided to allow Strophe to attach to BOSH
     *  sessions which have been created externally, perhaps by a Web
     *  application.  This is often used to support auto-login type features
     *  without putting user credentials into the page.
     *
     *  Parameters:
     *    (String) jid - The full JID that is bound by the session.
     *    (String) sid - The SID of the BOSH session.
     *    (String) rid - The current RID of the BOSH session.  This RID
     *      will be used by the next request.
     *    (Function) callback The connect callback function.
     *    (Integer) wait - The optional HTTPBIND wait value.  This is the
     *      time the server will wait before returning an empty result for
     *      a request.  The default setting of 60 seconds is recommended.
     *      Other settings will require tweaks to the Strophe.TIMEOUT value.
     *    (Integer) hold - The optional HTTPBIND hold value.  This is the
     *      number of connections the server will hold at one time.  This
     *      should almost always be set to 1 (the default).
     *    (Integer) wind - The optional HTTBIND window value.  This is the
     *      allowed range of request ids that are valid.  The default is 5.
     */
    _attach: function _attach(jid, sid, rid, callback, wait, hold, wind) {
      this._conn.jid = jid;
      this.sid = sid;
      this.rid = rid;
      this._conn.connect_callback = callback;
      this._conn.domain = Strophe$1.getDomainFromJid(this._conn.jid);
      this._conn.authenticated = true;
      this._conn.connected = true;
      this.wait = wait || this.wait;
      this.hold = hold || this.hold;
      this.window = wind || this.window;

      this._conn._changeConnectStatus(Strophe$1.Status.ATTACHED, null);
    },

    /** PrivateFunction: _restore
     *  Attempt to restore a cached BOSH session
     *
     *  Parameters:
     *    (String) jid - The full JID that is bound by the session.
     *      This parameter is optional but recommended, specifically in cases
     *      where prebinded BOSH sessions are used where it's important to know
     *      that the right session is being restored.
     *    (Function) callback The connect callback function.
     *    (Integer) wait - The optional HTTPBIND wait value.  This is the
     *      time the server will wait before returning an empty result for
     *      a request.  The default setting of 60 seconds is recommended.
     *      Other settings will require tweaks to the Strophe.TIMEOUT value.
     *    (Integer) hold - The optional HTTPBIND hold value.  This is the
     *      number of connections the server will hold at one time.  This
     *      should almost always be set to 1 (the default).
     *    (Integer) wind - The optional HTTBIND window value.  This is the
     *      allowed range of request ids that are valid.  The default is 5.
     */
    _restore: function _restore(jid, callback, wait, hold, wind) {
      var session = JSON.parse(window.sessionStorage.getItem('strophe-bosh-session'));

      if (typeof session !== "undefined" && session !== null && session.rid && session.sid && session.jid && (typeof jid === "undefined" || jid === null || Strophe$1.getBareJidFromJid(session.jid) === Strophe$1.getBareJidFromJid(jid) || // If authcid is null, then it's an anonymous login, so
      // we compare only the domains:
      Strophe$1.getNodeFromJid(jid) === null && Strophe$1.getDomainFromJid(session.jid) === jid)) {
        this._conn.restored = true;

        this._attach(session.jid, session.sid, session.rid, callback, wait, hold, wind);
      } else {
        var error = new Error("_restore: no restoreable session.");
        error.name = "StropheSessionError";
        throw error;
      }
    },

    /** PrivateFunction: _cacheSession
     *  _Private_ handler for the beforeunload event.
     *
     *  This handler is used to process the Bosh-part of the initial request.
     *  Parameters:
     *    (Strophe.Request) bodyWrap - The received stanza.
     */
    _cacheSession: function _cacheSession() {
      if (this._conn.authenticated) {
        if (this._conn.jid && this.rid && this.sid) {
          window.sessionStorage.setItem('strophe-bosh-session', JSON.stringify({
            'jid': this._conn.jid,
            'rid': this.rid,
            'sid': this.sid
          }));
        }
      } else {
        window.sessionStorage.removeItem('strophe-bosh-session');
      }
    },

    /** PrivateFunction: _connect_cb
     *  _Private_ handler for initial connection request.
     *
     *  This handler is used to process the Bosh-part of the initial request.
     *  Parameters:
     *    (Strophe.Request) bodyWrap - The received stanza.
     */
    _connect_cb: function _connect_cb(bodyWrap) {
      var typ = bodyWrap.getAttribute("type");

      if (typ !== null && typ === "terminate") {
        // an error occurred
        var cond = bodyWrap.getAttribute("condition");
        Strophe$1.error("BOSH-Connection failed: " + cond);
        var conflict = bodyWrap.getElementsByTagName("conflict");

        if (cond !== null) {
          if (cond === "remote-stream-error" && conflict.length > 0) {
            cond = "conflict";
          }

          this._conn._changeConnectStatus(Strophe$1.Status.CONNFAIL, cond);
        } else {
          this._conn._changeConnectStatus(Strophe$1.Status.CONNFAIL, "unknown");
        }

        this._conn._doDisconnect(cond);

        return Strophe$1.Status.CONNFAIL;
      } // check to make sure we don't overwrite these if _connect_cb is
      // called multiple times in the case of missing stream:features


      if (!this.sid) {
        this.sid = bodyWrap.getAttribute("sid");
      }

      var wind = bodyWrap.getAttribute('requests');

      if (wind) {
        this.window = parseInt(wind, 10);
      }

      var hold = bodyWrap.getAttribute('hold');

      if (hold) {
        this.hold = parseInt(hold, 10);
      }

      var wait = bodyWrap.getAttribute('wait');

      if (wait) {
        this.wait = parseInt(wait, 10);
      }

      var inactivity = bodyWrap.getAttribute('inactivity');

      if (inactivity) {
        this.inactivity = parseInt(inactivity, 10);
      }
    },

    /** PrivateFunction: _disconnect
     *  _Private_ part of Connection.disconnect for Bosh
     *
     *  Parameters:
     *    (Request) pres - This stanza will be sent before disconnecting.
     */
    _disconnect: function _disconnect(pres) {
      this._sendTerminate(pres);
    },

    /** PrivateFunction: _doDisconnect
     *  _Private_ function to disconnect.
     *
     *  Resets the SID and RID.
     */
    _doDisconnect: function _doDisconnect() {
      this.sid = null;
      this.rid = Math.floor(Math.random() * 4294967295);

      if (this._conn._sessionCachingSupported()) {
        window.sessionStorage.removeItem('strophe-bosh-session');
      }

      this._conn.nextValidRid(this.rid);
    },

    /** PrivateFunction: _emptyQueue
     * _Private_ function to check if the Request queue is empty.
     *
     *  Returns:
     *    True, if there are no Requests queued, False otherwise.
     */
    _emptyQueue: function _emptyQueue() {
      return this._requests.length === 0;
    },

    /** PrivateFunction: _callProtocolErrorHandlers
     *  _Private_ function to call error handlers registered for HTTP errors.
     *
     *  Parameters:
     *    (Strophe.Request) req - The request that is changing readyState.
     */
    _callProtocolErrorHandlers: function _callProtocolErrorHandlers(req) {
      var reqStatus = this._getRequestStatus(req);

      var err_callback = this._conn.protocolErrorHandlers.HTTP[reqStatus];

      if (err_callback) {
        err_callback.call(this, reqStatus);
      }
    },

    /** PrivateFunction: _hitError
     *  _Private_ function to handle the error count.
     *
     *  Requests are resent automatically until their error count reaches
     *  5.  Each time an error is encountered, this function is called to
     *  increment the count and disconnect if the count is too high.
     *
     *  Parameters:
     *    (Integer) reqStatus - The request status.
     */
    _hitError: function _hitError(reqStatus) {
      this.errors++;
      Strophe$1.warn("request errored, status: " + reqStatus + ", number of errors: " + this.errors);

      if (this.errors > 4) {
        this._conn._onDisconnectTimeout();
      }
    },

    /** PrivateFunction: _no_auth_received
     *
     * Called on stream start/restart when no stream:features
     * has been received and sends a blank poll request.
     */
    _no_auth_received: function _no_auth_received(callback) {
      Strophe$1.warn("Server did not yet offer a supported authentication " + "mechanism. Sending a blank poll request.");

      if (callback) {
        callback = callback.bind(this._conn);
      } else {
        callback = this._conn._connect_cb.bind(this._conn);
      }

      var body = this._buildBody();

      this._requests.push(new Strophe$1.Request(body.tree(), this._onRequestStateChange.bind(this, callback), body.tree().getAttribute("rid")));

      this._throttledRequestHandler();
    },

    /** PrivateFunction: _onDisconnectTimeout
     *  _Private_ timeout handler for handling non-graceful disconnection.
     *
     *  Cancels all remaining Requests and clears the queue.
     */
    _onDisconnectTimeout: function _onDisconnectTimeout() {
      this._abortAllRequests();
    },

    /** PrivateFunction: _abortAllRequests
     *  _Private_ helper function that makes sure all pending requests are aborted.
     */
    _abortAllRequests: function _abortAllRequests() {
      while (this._requests.length > 0) {
        var req = this._requests.pop();

        req.abort = true;
        req.xhr.abort();

        req.xhr.onreadystatechange = function () {};
      }
    },

    /** PrivateFunction: _onIdle
     *  _Private_ handler called by Strophe.Connection._onIdle
     *
     *  Sends all queued Requests or polls with empty Request if there are none.
     */
    _onIdle: function _onIdle() {
      var data = this._conn._data; // if no requests are in progress, poll

      if (this._conn.authenticated && this._requests.length === 0 && data.length === 0 && !this._conn.disconnecting) {
        Strophe$1.debug("no requests during idle cycle, sending blank request");
        data.push(null);
      }

      if (this._conn.paused) {
        return;
      }

      if (this._requests.length < 2 && data.length > 0) {
        var body = this._buildBody();

        for (var i = 0; i < data.length; i++) {
          if (data[i] !== null) {
            if (data[i] === "restart") {
              body.attrs({
                "to": this._conn.domain,
                "xml:lang": "en",
                "xmpp:restart": "true",
                "xmlns:xmpp": Strophe$1.NS.BOSH
              });
            } else {
              body.cnode(data[i]).up();
            }
          }
        }

        delete this._conn._data;
        this._conn._data = [];

        this._requests.push(new Strophe$1.Request(body.tree(), this._onRequestStateChange.bind(this, this._conn._dataRecv.bind(this._conn)), body.tree().getAttribute("rid")));

        this._throttledRequestHandler();
      }

      if (this._requests.length > 0) {
        var time_elapsed = this._requests[0].age();

        if (this._requests[0].dead !== null) {
          if (this._requests[0].timeDead() > Math.floor(Strophe$1.SECONDARY_TIMEOUT * this.wait)) {
            this._throttledRequestHandler();
          }
        }

        if (time_elapsed > Math.floor(Strophe$1.TIMEOUT * this.wait)) {
          Strophe$1.warn("Request " + this._requests[0].id + " timed out, over " + Math.floor(Strophe$1.TIMEOUT * this.wait) + " seconds since last activity");

          this._throttledRequestHandler();
        }
      }
    },

    /** PrivateFunction: _getRequestStatus
     *
     *  Returns the HTTP status code from a Strophe.Request
     *
     *  Parameters:
     *    (Strophe.Request) req - The Strophe.Request instance.
     *    (Integer) def - The default value that should be returned if no
     *          status value was found.
     */
    _getRequestStatus: function _getRequestStatus(req, def) {
      var reqStatus;

      if (req.xhr.readyState === 4) {
        try {
          reqStatus = req.xhr.status;
        } catch (e) {
          // ignore errors from undefined status attribute. Works
          // around a browser bug
          Strophe$1.error("Caught an error while retrieving a request's status, " + "reqStatus: " + reqStatus);
        }
      }

      if (typeof reqStatus === "undefined") {
        reqStatus = typeof def === 'number' ? def : 0;
      }

      return reqStatus;
    },

    /** PrivateFunction: _onRequestStateChange
     *  _Private_ handler for Strophe.Request state changes.
     *
     *  This function is called when the XMLHttpRequest readyState changes.
     *  It contains a lot of error handling logic for the many ways that
     *  requests can fail, and calls the request callback when requests
     *  succeed.
     *
     *  Parameters:
     *    (Function) func - The handler for the request.
     *    (Strophe.Request) req - The request that is changing readyState.
     */
    _onRequestStateChange: function _onRequestStateChange(func, req) {
      Strophe$1.debug("request id " + req.id + "." + req.sends + " state changed to " + req.xhr.readyState);

      if (req.abort) {
        req.abort = false;
        return;
      }

      if (req.xhr.readyState !== 4) {
        // The request is not yet complete
        return;
      }

      var reqStatus = this._getRequestStatus(req);

      this.lastResponseHeaders = req.xhr.getAllResponseHeaders();

      if (this.disconnecting && reqStatus >= 400) {
        this._hitError(reqStatus);

        this._callProtocolErrorHandlers(req);

        return;
      }

      var valid_request = reqStatus > 0 && reqStatus < 500;
      var too_many_retries = req.sends > this._conn.maxRetries;

      if (valid_request || too_many_retries) {
        // remove from internal queue
        this._removeRequest(req);

        Strophe$1.debug("request id " + req.id + " should now be removed");
      }

      if (reqStatus === 200) {
        // request succeeded
        var reqIs0 = this._requests[0] === req;
        var reqIs1 = this._requests[1] === req; // if request 1 finished, or request 0 finished and request
        // 1 is over Strophe.SECONDARY_TIMEOUT seconds old, we need to
        // restart the other - both will be in the first spot, as the
        // completed request has been removed from the queue already

        if (reqIs1 || reqIs0 && this._requests.length > 0 && this._requests[0].age() > Math.floor(Strophe$1.SECONDARY_TIMEOUT * this.wait)) {
          this._restartRequest(0);
        }

        this._conn.nextValidRid(Number(req.rid) + 1);

        Strophe$1.debug("request id " + req.id + "." + req.sends + " got 200");
        func(req); // call handler

        this.errors = 0;
      } else if (reqStatus === 0 || reqStatus >= 400 && reqStatus < 600 || reqStatus >= 12000) {
        // request failed
        Strophe$1.error("request id " + req.id + "." + req.sends + " error " + reqStatus + " happened");

        this._hitError(reqStatus);

        this._callProtocolErrorHandlers(req);

        if (reqStatus >= 400 && reqStatus < 500) {
          this._conn._changeConnectStatus(Strophe$1.Status.DISCONNECTING, null);

          this._conn._doDisconnect();
        }
      } else {
        Strophe$1.error("request id " + req.id + "." + req.sends + " error " + reqStatus + " happened");
      }

      if (!valid_request && !too_many_retries) {
        this._throttledRequestHandler();
      } else if (too_many_retries && !this._conn.connected) {
        this._conn._changeConnectStatus(Strophe$1.Status.CONNFAIL, "giving-up");
      }
    },

    /** PrivateFunction: _processRequest
     *  _Private_ function to process a request in the queue.
     *
     *  This function takes requests off the queue and sends them and
     *  restarts dead requests.
     *
     *  Parameters:
     *    (Integer) i - The index of the request in the queue.
     */
    _processRequest: function _processRequest(i) {
      var _this = this;

      var req = this._requests[i];

      var reqStatus = this._getRequestStatus(req, -1); // make sure we limit the number of retries


      if (req.sends > this._conn.maxRetries) {
        this._conn._onDisconnectTimeout();

        return;
      }

      var time_elapsed = req.age();
      var primary_timeout = !isNaN(time_elapsed) && time_elapsed > Math.floor(Strophe$1.TIMEOUT * this.wait);
      var secondary_timeout = req.dead !== null && req.timeDead() > Math.floor(Strophe$1.SECONDARY_TIMEOUT * this.wait);
      var server_error = req.xhr.readyState === 4 && (reqStatus < 1 || reqStatus >= 500);

      if (primary_timeout || secondary_timeout || server_error) {
        if (secondary_timeout) {
          Strophe$1.error("Request ".concat(this._requests[i].id, " timed out (secondary), restarting"));
        }

        req.abort = true;
        req.xhr.abort(); // setting to null fails on IE6, so set to empty function

        req.xhr.onreadystatechange = function () {};

        this._requests[i] = new Strophe$1.Request(req.xmlData, req.origFunc, req.rid, req.sends);
        req = this._requests[i];
      }

      if (req.xhr.readyState === 0) {
        Strophe$1.debug("request id " + req.id + "." + req.sends + " posting");

        try {
          var content_type = this._conn.options.contentType || "text/xml; charset=utf-8";
          req.xhr.open("POST", this._conn.service, this._conn.options.sync ? false : true);

          if (typeof req.xhr.setRequestHeader !== 'undefined') {
            // IE9 doesn't have setRequestHeader
            req.xhr.setRequestHeader("Content-Type", content_type);
          }

          if (this._conn.options.withCredentials) {
            req.xhr.withCredentials = true;
          }
        } catch (e2) {
          Strophe$1.error("XHR open failed: " + e2.toString());

          if (!this._conn.connected) {
            this._conn._changeConnectStatus(Strophe$1.Status.CONNFAIL, "bad-service");
          }

          this._conn.disconnect();

          return;
        } // Fires the XHR request -- may be invoked immediately
        // or on a gradually expanding retry window for reconnects


        var sendFunc = function sendFunc() {
          req.date = new Date();

          if (_this._conn.options.customHeaders) {
            var headers = _this._conn.options.customHeaders;

            for (var header in headers) {
              if (Object.prototype.hasOwnProperty.call(headers, header)) {
                req.xhr.setRequestHeader(header, headers[header]);
              }
            }
          }

          req.xhr.send(req.data);
        }; // Implement progressive backoff for reconnects --
        // First retry (send === 1) should also be instantaneous


        if (req.sends > 1) {
          // Using a cube of the retry number creates a nicely
          // expanding retry window
          var backoff = Math.min(Math.floor(Strophe$1.TIMEOUT * this.wait), Math.pow(req.sends, 3)) * 1000;
          setTimeout(function () {
            // XXX: setTimeout should be called only with function expressions (23974bc1)
            sendFunc();
          }, backoff);
        } else {
          sendFunc();
        }

        req.sends++;

        if (this._conn.xmlOutput !== Strophe$1.Connection.prototype.xmlOutput) {
          if (req.xmlData.nodeName === this.strip && req.xmlData.childNodes.length) {
            this._conn.xmlOutput(req.xmlData.childNodes[0]);
          } else {
            this._conn.xmlOutput(req.xmlData);
          }
        }

        if (this._conn.rawOutput !== Strophe$1.Connection.prototype.rawOutput) {
          this._conn.rawOutput(req.data);
        }
      } else {
        Strophe$1.debug("_processRequest: " + (i === 0 ? "first" : "second") + " request has readyState of " + req.xhr.readyState);
      }
    },

    /** PrivateFunction: _removeRequest
     *  _Private_ function to remove a request from the queue.
     *
     *  Parameters:
     *    (Strophe.Request) req - The request to remove.
     */
    _removeRequest: function _removeRequest(req) {
      Strophe$1.debug("removing request");

      for (var i = this._requests.length - 1; i >= 0; i--) {
        if (req === this._requests[i]) {
          this._requests.splice(i, 1);
        }
      } // IE6 fails on setting to null, so set to empty function


      req.xhr.onreadystatechange = function () {};

      this._throttledRequestHandler();
    },

    /** PrivateFunction: _restartRequest
     *  _Private_ function to restart a request that is presumed dead.
     *
     *  Parameters:
     *    (Integer) i - The index of the request in the queue.
     */
    _restartRequest: function _restartRequest(i) {
      var req = this._requests[i];

      if (req.dead === null) {
        req.dead = new Date();
      }

      this._processRequest(i);
    },

    /** PrivateFunction: _reqToData
     * _Private_ function to get a stanza out of a request.
     *
     * Tries to extract a stanza out of a Request Object.
     * When this fails the current connection will be disconnected.
     *
     *  Parameters:
     *    (Object) req - The Request.
     *
     *  Returns:
     *    The stanza that was passed.
     */
    _reqToData: function _reqToData(req) {
      try {
        return req.getResponse();
      } catch (e) {
        if (e.message !== "parsererror") {
          throw e;
        }

        this._conn.disconnect("strophe-parsererror");
      }
    },

    /** PrivateFunction: _sendTerminate
     *  _Private_ function to send initial disconnect sequence.
     *
     *  This is the first step in a graceful disconnect.  It sends
     *  the BOSH server a terminate body and includes an unavailable
     *  presence if authentication has completed.
     */
    _sendTerminate: function _sendTerminate(pres) {
      Strophe$1.debug("_sendTerminate was called");

      var body = this._buildBody().attrs({
        type: "terminate"
      });

      if (pres) {
        body.cnode(pres.tree());
      }

      var req = new Strophe$1.Request(body.tree(), this._onRequestStateChange.bind(this, this._conn._dataRecv.bind(this._conn)), body.tree().getAttribute("rid"));

      this._requests.push(req);

      this._throttledRequestHandler();
    },

    /** PrivateFunction: _send
     *  _Private_ part of the Connection.send function for BOSH
     *
     * Just triggers the RequestHandler to send the messages that are in the queue
     */
    _send: function _send() {
      var _this2 = this;

      clearTimeout(this._conn._idleTimeout);

      this._throttledRequestHandler();

      this._conn._idleTimeout = setTimeout(function () {
        return _this2._conn._onIdle();
      }, 100);
    },

    /** PrivateFunction: _sendRestart
     *
     *  Send an xmpp:restart stanza.
     */
    _sendRestart: function _sendRestart() {
      this._throttledRequestHandler();

      clearTimeout(this._conn._idleTimeout);
    },

    /** PrivateFunction: _throttledRequestHandler
     *  _Private_ function to throttle requests to the connection window.
     *
     *  This function makes sure we don't send requests so fast that the
     *  request ids overflow the connection window in the case that one
     *  request died.
     */
    _throttledRequestHandler: function _throttledRequestHandler() {
      if (!this._requests) {
        Strophe$1.debug("_throttledRequestHandler called with " + "undefined requests");
      } else {
        Strophe$1.debug("_throttledRequestHandler called with " + this._requests.length + " requests");
      }

      if (!this._requests || this._requests.length === 0) {
        return;
      }

      if (this._requests.length > 0) {
        this._processRequest(0);
      }

      if (this._requests.length > 1 && Math.abs(this._requests[0].rid - this._requests[1].rid) < this.window) {
        this._processRequest(1);
      }
    }
  };
  /*
      This program is distributed under the terms of the MIT license.
      Please see the LICENSE file for details.
       Copyright 2006-2008, OGG, LLC
  */

  var Strophe$2 = core.Strophe;
  var $build$2 = core.$build;
  /** Class: Strophe.WebSocket
   *  _Private_ helper class that handles WebSocket Connections
   *
   *  The Strophe.WebSocket class is used internally by Strophe.Connection
   *  to encapsulate WebSocket sessions. It is not meant to be used from user's code.
   */

  /** File: websocket.js
   *  A JavaScript library to enable XMPP over Websocket in Strophejs.
   *
   *  This file implements XMPP over WebSockets for Strophejs.
   *  If a Connection is established with a Websocket url (ws://...)
   *  Strophe will use WebSockets.
   *  For more information on XMPP-over-WebSocket see RFC 7395:
   *  http://tools.ietf.org/html/rfc7395
   *
   *  WebSocket support implemented by Andreas Guth (andreas.guth@rwth-aachen.de)
   */

  /** PrivateConstructor: Strophe.Websocket
   *  Create and initialize a Strophe.WebSocket object.
   *  Currently only sets the connection Object.
   *
   *  Parameters:
   *    (Strophe.Connection) connection - The Strophe.Connection that will use WebSockets.
   *
   *  Returns:
   *    A new Strophe.WebSocket object.
   */

  Strophe$2.Websocket = function (connection) {
    this._conn = connection;
    this.strip = "wrapper";
    var service = connection.service;

    if (service.indexOf("ws:") !== 0 && service.indexOf("wss:") !== 0) {
      // If the service is not an absolute URL, assume it is a path and put the absolute
      // URL together from options, current URL and the path.
      var new_service = "";

      if (connection.options.protocol === "ws" && window.location.protocol !== "https:") {
        new_service += "ws";
      } else {
        new_service += "wss";
      }

      new_service += "://" + window.location.host;

      if (service.indexOf("/") !== 0) {
        new_service += window.location.pathname + service;
      } else {
        new_service += service;
      }

      connection.service = new_service;
    }
  };

  Strophe$2.Websocket.prototype = {
    /** PrivateFunction: _buildStream
     *  _Private_ helper function to generate the <stream> start tag for WebSockets
     *
     *  Returns:
     *    A Strophe.Builder with a <stream> element.
     */
    _buildStream: function _buildStream() {
      return $build$2("open", {
        "xmlns": Strophe$2.NS.FRAMING,
        "to": this._conn.domain,
        "version": '1.0'
      });
    },

    /** PrivateFunction: _check_streamerror
     * _Private_ checks a message for stream:error
     *
     *  Parameters:
     *    (Strophe.Request) bodyWrap - The received stanza.
     *    connectstatus - The ConnectStatus that will be set on error.
     *  Returns:
     *     true if there was a streamerror, false otherwise.
     */
    _check_streamerror: function _check_streamerror(bodyWrap, connectstatus) {
      var errors;

      if (bodyWrap.getElementsByTagNameNS) {
        errors = bodyWrap.getElementsByTagNameNS(Strophe$2.NS.STREAM, "error");
      } else {
        errors = bodyWrap.getElementsByTagName("stream:error");
      }

      if (errors.length === 0) {
        return false;
      }

      var error = errors[0];
      var condition = "";
      var text = "";
      var ns = "urn:ietf:params:xml:ns:xmpp-streams";

      for (var i = 0; i < error.childNodes.length; i++) {
        var e = error.childNodes[i];

        if (e.getAttribute("xmlns") !== ns) {
          break;
        }

        if (e.nodeName === "text") {
          text = e.textContent;
        } else {
          condition = e.nodeName;
        }
      }

      var errorString = "WebSocket stream error: ";

      if (condition) {
        errorString += condition;
      } else {
        errorString += "unknown";
      }

      if (text) {
        errorString += " - " + text;
      }

      Strophe$2.error(errorString); // close the connection on stream_error

      this._conn._changeConnectStatus(connectstatus, condition);

      this._conn._doDisconnect();

      return true;
    },

    /** PrivateFunction: _reset
     *  Reset the connection.
     *
     *  This function is called by the reset function of the Strophe Connection.
     *  Is not needed by WebSockets.
     */
    _reset: function _reset() {
      return;
    },

    /** PrivateFunction: _connect
     *  _Private_ function called by Strophe.Connection.connect
     *
     *  Creates a WebSocket for a connection and assigns Callbacks to it.
     *  Does nothing if there already is a WebSocket.
     */
    _connect: function _connect() {
      // Ensure that there is no open WebSocket from a previous Connection.
      this._closeSocket(); // Create the new WobSocket


      this.socket = new WebSocket(this._conn.service, "xmpp");
      this.socket.onopen = this._onOpen.bind(this);
      this.socket.onerror = this._onError.bind(this);
      this.socket.onclose = this._onClose.bind(this);
      this.socket.onmessage = this._connect_cb_wrapper.bind(this);
    },

    /** PrivateFunction: _connect_cb
     *  _Private_ function called by Strophe.Connection._connect_cb
     *
     * checks for stream:error
     *
     *  Parameters:
     *    (Strophe.Request) bodyWrap - The received stanza.
     */
    _connect_cb: function _connect_cb(bodyWrap) {
      var error = this._check_streamerror(bodyWrap, Strophe$2.Status.CONNFAIL);

      if (error) {
        return Strophe$2.Status.CONNFAIL;
      }
    },

    /** PrivateFunction: _handleStreamStart
     * _Private_ function that checks the opening <open /> tag for errors.
     *
     * Disconnects if there is an error and returns false, true otherwise.
     *
     *  Parameters:
     *    (Node) message - Stanza containing the <open /> tag.
     */
    _handleStreamStart: function _handleStreamStart(message) {
      var error = false; // Check for errors in the <open /> tag

      var ns = message.getAttribute("xmlns");

      if (typeof ns !== "string") {
        error = "Missing xmlns in <open />";
      } else if (ns !== Strophe$2.NS.FRAMING) {
        error = "Wrong xmlns in <open />: " + ns;
      }

      var ver = message.getAttribute("version");

      if (typeof ver !== "string") {
        error = "Missing version in <open />";
      } else if (ver !== "1.0") {
        error = "Wrong version in <open />: " + ver;
      }

      if (error) {
        this._conn._changeConnectStatus(Strophe$2.Status.CONNFAIL, error);

        this._conn._doDisconnect();

        return false;
      }

      return true;
    },

    /** PrivateFunction: _connect_cb_wrapper
     * _Private_ function that handles the first connection messages.
     *
     * On receiving an opening stream tag this callback replaces itself with the real
     * message handler. On receiving a stream error the connection is terminated.
     */
    _connect_cb_wrapper: function _connect_cb_wrapper(message) {
      if (message.data.indexOf("<open ") === 0 || message.data.indexOf("<?xml") === 0) {
        // Strip the XML Declaration, if there is one
        var data = message.data.replace(/^(<\?.*?\?>\s*)*/, "");
        if (data === '') return;
        var streamStart = new DOMParser().parseFromString(data, "text/xml").documentElement;

        this._conn.xmlInput(streamStart);

        this._conn.rawInput(message.data); //_handleStreamSteart will check for XML errors and disconnect on error


        if (this._handleStreamStart(streamStart)) {
          //_connect_cb will check for stream:error and disconnect on error
          this._connect_cb(streamStart);
        }
      } else if (message.data.indexOf("<close ") === 0) {
        // <close xmlns="urn:ietf:params:xml:ns:xmpp-framing />
        // Parse the raw string to an XML element
        var parsedMessage = new DOMParser().parseFromString(message.data, "text/xml").documentElement; // Report this input to the raw and xml handlers

        this._conn.xmlInput(parsedMessage);

        this._conn.rawInput(message.data);

        var see_uri = parsedMessage.getAttribute("see-other-uri");

        if (see_uri) {
          var service = this._conn.service; // Valid scenarios: WSS->WSS, WS->ANY

          var isSecureRedirect = service.indexOf("wss:") >= 0 && see_uri.indexOf("wss:") >= 0 || service.indexOf("ws:") >= 0;

          if (isSecureRedirect) {
            this._conn._changeConnectStatus(Strophe$2.Status.REDIRECT, "Received see-other-uri, resetting connection");

            this._conn.reset();

            this._conn.service = see_uri;

            this._connect();
          }
        } else {
          this._conn._changeConnectStatus(Strophe$2.Status.CONNFAIL, "Received closing stream");

          this._conn._doDisconnect();
        }
      } else {
        var string = this._streamWrap(message.data);

        var elem = new DOMParser().parseFromString(string, "text/xml").documentElement;
        this.socket.onmessage = this._onMessage.bind(this);

        this._conn._connect_cb(elem, null, message.data);
      }
    },

    /** PrivateFunction: _disconnect
     *  _Private_ function called by Strophe.Connection.disconnect
     *
     *  Disconnects and sends a last stanza if one is given
     *
     *  Parameters:
     *    (Request) pres - This stanza will be sent before disconnecting.
     */
    _disconnect: function _disconnect(pres) {
      if (this.socket && this.socket.readyState !== WebSocket.CLOSED) {
        if (pres) {
          this._conn.send(pres);
        }

        var close = $build$2("close", {
          "xmlns": Strophe$2.NS.FRAMING
        });

        this._conn.xmlOutput(close.tree());

        var closeString = Strophe$2.serialize(close);

        this._conn.rawOutput(closeString);

        try {
          this.socket.send(closeString);
        } catch (e) {
          Strophe$2.warn("Couldn't send <close /> tag.");
        }
      }

      this._conn._doDisconnect();
    },

    /** PrivateFunction: _doDisconnect
     *  _Private_ function to disconnect.
     *
     *  Just closes the Socket for WebSockets
     */
    _doDisconnect: function _doDisconnect() {
      Strophe$2.debug("WebSockets _doDisconnect was called");

      this._closeSocket();
    },

    /** PrivateFunction _streamWrap
     *  _Private_ helper function to wrap a stanza in a <stream> tag.
     *  This is used so Strophe can process stanzas from WebSockets like BOSH
     */
    _streamWrap: function _streamWrap(stanza) {
      return "<wrapper>" + stanza + '</wrapper>';
    },

    /** PrivateFunction: _closeSocket
     *  _Private_ function to close the WebSocket.
     *
     *  Closes the socket if it is still open and deletes it
     */
    _closeSocket: function _closeSocket() {
      if (this.socket) {
        try {
          this.socket.onclose = null;
          this.socket.onerror = null;
          this.socket.onmessage = null;
          this.socket.close();
        } catch (e) {
          Strophe$2.debug(e.message);
        }
      }

      this.socket = null;
    },

    /** PrivateFunction: _emptyQueue
     * _Private_ function to check if the message queue is empty.
     *
     *  Returns:
     *    True, because WebSocket messages are send immediately after queueing.
     */
    _emptyQueue: function _emptyQueue() {
      return true;
    },

    /** PrivateFunction: _onClose
     * _Private_ function to handle websockets closing.
     *
     * Nothing to do here for WebSockets
     */
    _onClose: function _onClose(e) {
      if (this._conn.connected && !this._conn.disconnecting) {
        Strophe$2.error("Websocket closed unexpectedly");

        this._conn._doDisconnect();
      } else if (e && e.code === 1006 && !this._conn.connected && this.socket) {
        // in case the onError callback was not called (Safari 10 does not
        // call onerror when the initial connection fails) we need to
        // dispatch a CONNFAIL status update to be consistent with the
        // behavior on other browsers.
        Strophe$2.error("Websocket closed unexcectedly");

        this._conn._changeConnectStatus(Strophe$2.Status.CONNFAIL, "The WebSocket connection could not be established or was disconnected.");

        this._conn._doDisconnect();
      } else {
        Strophe$2.debug("Websocket closed");
      }
    },

    /** PrivateFunction: _no_auth_received
     *
     * Called on stream start/restart when no stream:features
     * has been received.
     */
    _no_auth_received: function _no_auth_received(callback) {
      Strophe$2.error("Server did not offer a supported authentication mechanism");

      this._conn._changeConnectStatus(Strophe$2.Status.CONNFAIL, Strophe$2.ErrorCondition.NO_AUTH_MECH);

      if (callback) {
        callback.call(this._conn);
      }

      this._conn._doDisconnect();
    },

    /** PrivateFunction: _onDisconnectTimeout
     *  _Private_ timeout handler for handling non-graceful disconnection.
     *
     *  This does nothing for WebSockets
     */
    _onDisconnectTimeout: function _onDisconnectTimeout() {},

    /** PrivateFunction: _abortAllRequests
     *  _Private_ helper function that makes sure all pending requests are aborted.
     */
    _abortAllRequests: function _abortAllRequests() {},

    /** PrivateFunction: _onError
     * _Private_ function to handle websockets errors.
     *
     * Parameters:
     * (Object) error - The websocket error.
     */
    _onError: function _onError(error) {
      Strophe$2.error("Websocket error " + error);

      this._conn._changeConnectStatus(Strophe$2.Status.CONNFAIL, "The WebSocket connection could not be established or was disconnected.");

      this._disconnect();
    },

    /** PrivateFunction: _onIdle
     *  _Private_ function called by Strophe.Connection._onIdle
     *
     *  sends all queued stanzas
     */
    _onIdle: function _onIdle() {
      var data = this._conn._data;

      if (data.length > 0 && !this._conn.paused) {
        for (var i = 0; i < data.length; i++) {
          if (data[i] !== null) {
            var stanza = void 0;

            if (data[i] === "restart") {
              stanza = this._buildStream().tree();
            } else {
              stanza = data[i];
            }

            var rawStanza = Strophe$2.serialize(stanza);

            this._conn.xmlOutput(stanza);

            this._conn.rawOutput(rawStanza);

            this.socket.send(rawStanza);
          }
        }

        this._conn._data = [];
      }
    },

    /** PrivateFunction: _onMessage
     * _Private_ function to handle websockets messages.
     *
     * This function parses each of the messages as if they are full documents.
     * [TODO : We may actually want to use a SAX Push parser].
     *
     * Since all XMPP traffic starts with
     *  <stream:stream version='1.0'
     *                 xml:lang='en'
     *                 xmlns='jabber:client'
     *                 xmlns:stream='http://etherx.jabber.org/streams'
     *                 id='3697395463'
     *                 from='SERVER'>
     *
     * The first stanza will always fail to be parsed.
     *
     * Additionally, the seconds stanza will always be <stream:features> with
     * the stream NS defined in the previous stanza, so we need to 'force'
     * the inclusion of the NS in this stanza.
     *
     * Parameters:
     * (string) message - The websocket message.
     */
    _onMessage: function _onMessage(message) {
      var elem; // check for closing stream

      var close = '<close xmlns="urn:ietf:params:xml:ns:xmpp-framing" />';

      if (message.data === close) {
        this._conn.rawInput(close);

        this._conn.xmlInput(message);

        if (!this._conn.disconnecting) {
          this._conn._doDisconnect();
        }

        return;
      } else if (message.data.search("<open ") === 0) {
        // This handles stream restarts
        elem = new DOMParser().parseFromString(message.data, "text/xml").documentElement;

        if (!this._handleStreamStart(elem)) {
          return;
        }
      } else {
        var data = this._streamWrap(message.data);

        elem = new DOMParser().parseFromString(data, "text/xml").documentElement;
      }

      if (this._check_streamerror(elem, Strophe$2.Status.ERROR)) {
        return;
      } //handle unavailable presence stanza before disconnecting


      if (this._conn.disconnecting && elem.firstChild.nodeName === "presence" && elem.firstChild.getAttribute("type") === "unavailable") {
        this._conn.xmlInput(elem);

        this._conn.rawInput(Strophe$2.serialize(elem)); // if we are already disconnecting we will ignore the unavailable stanza and
        // wait for the </stream:stream> tag before we close the connection


        return;
      }

      this._conn._dataRecv(elem, message.data);
    },

    /** PrivateFunction: _onOpen
     * _Private_ function to handle websockets connection setup.
     *
     * The opening stream tag is sent here.
     */
    _onOpen: function _onOpen() {
      Strophe$2.debug("Websocket open");

      var start = this._buildStream();

      this._conn.xmlOutput(start.tree());

      var startString = Strophe$2.serialize(start);

      this._conn.rawOutput(startString);

      this.socket.send(startString);
    },

    /** PrivateFunction: _reqToData
     * _Private_ function to get a stanza out of a request.
     *
     * WebSockets don't use requests, so the passed argument is just returned.
     *
     *  Parameters:
     *    (Object) stanza - The stanza.
     *
     *  Returns:
     *    The stanza that was passed.
     */
    _reqToData: function _reqToData(stanza) {
      return stanza;
    },

    /** PrivateFunction: _send
     *  _Private_ part of the Connection.send function for WebSocket
     *
     * Just flushes the messages that are in the queue
     */
    _send: function _send() {
      this._conn.flush();
    },

    /** PrivateFunction: _sendRestart
     *
     *  Send an xmpp:restart stanza.
     */
    _sendRestart: function _sendRestart() {
      clearTimeout(this._conn._idleTimeout);

      this._conn._onIdle.bind(this._conn)();
    }
  };
  global$1.Strophe = core.Strophe;
  global$1.$build = core.$build;
  global$1.$iq = core.$iq;
  global$1.$msg = core.$msg;
  global$1.$pres = core.$pres;
  return core;
});
/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js")))

/***/ }),

/***/ "./node_modules/strophejs-plugin-disco/lib/strophe.disco.js":
/*!******************************************************************!*\
  !*** ./node_modules/strophejs-plugin-disco/lib/strophe.disco.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

(function (global, factory) {
   true ? factory(__webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js")) : undefined;
})(this, function (strophe_js) {
  'use strict';

  strophe_js.Strophe.addConnectionPlugin('disco', {
    _connection: null,
    _identities: [],
    _features: [],
    _items: [],

    /** Function: init
     * Plugin init
     *
     * Parameters:
     *   (Strophe.Connection) conn - Strophe connection
     */
    init: function (conn) {
      this._connection = conn;
      this._identities = [];
      this._features = [];
      this._items = []; // disco info

      conn.addHandler(this._onDiscoInfo.bind(this), strophe_js.Strophe.NS.DISCO_INFO, 'iq', 'get', null, null); // disco items

      conn.addHandler(this._onDiscoItems.bind(this), strophe_js.Strophe.NS.DISCO_ITEMS, 'iq', 'get', null, null);
    },

    /** Function: addIdentity
     * See http://xmpp.org/registrar/disco-categories.html
     * Parameters:
     *   (String) category - category of identity (like client, automation, etc ...)
     *   (String) type - type of identity (like pc, web, bot , etc ...)
     *   (String) name - name of identity in natural language
     *   (String) lang - lang of name parameter
     *
     * Returns:
     *   Boolean
     */
    addIdentity: function (category, type, name, lang) {
      for (var i = 0; i < this._identities.length; i++) {
        if (this._identities[i].category == category && this._identities[i].type == type && this._identities[i].name == name && this._identities[i].lang == lang) {
          return false;
        }
      }

      this._identities.push({
        category: category,
        type: type,
        name: name,
        lang: lang
      });

      return true;
    },

    /** Function: addFeature
     *
     * Parameters:
     *   (String) var_name - feature name (like jabber:iq:version)
     *
     * Returns:
     *   boolean
     */
    addFeature: function (var_name) {
      for (var i = 0; i < this._features.length; i++) {
        if (this._features[i] == var_name) return false;
      }

      this._features.push(var_name);

      return true;
    },

    /** Function: removeFeature
     *
     * Parameters:
     *   (String) var_name - feature name (like jabber:iq:version)
     *
     * Returns:
     *   boolean
     */
    removeFeature: function (var_name) {
      for (var i = 0; i < this._features.length; i++) {
        if (this._features[i] === var_name) {
          this._features.splice(i, 1);

          return true;
        }
      }

      return false;
    },

    /** Function: addItem
     *
     * Parameters:
     *   (String) jid
     *   (String) name
     *   (String) node
     *   (Function) call_back
     *
     * Returns:
     *   boolean
     */
    addItem: function (jid, name, node, call_back) {
      if (node && !call_back) return false;

      this._items.push({
        jid: jid,
        name: name,
        node: node,
        call_back: call_back
      });

      return true;
    },

    /** Function: info
     * Info query
     *
     * Parameters:
     *   (Function) call_back
     *   (String) jid
     *   (String) node
     */
    info: function (jid, node, success, error, timeout) {
      var attrs = {
        xmlns: strophe_js.Strophe.NS.DISCO_INFO
      };
      if (node) attrs.node = node;
      var info = strophe_js.$iq({
        from: this._connection.jid,
        to: jid,
        type: 'get'
      }).c('query', attrs);

      this._connection.sendIQ(info, success, error, timeout);
    },

    /** Function: items
     * Items query
     *
     * Parameters:
     *   (Function) call_back
     *   (String) jid
     *   (String) node
     */
    items: function (jid, node, success, error, timeout) {
      var attrs = {
        xmlns: strophe_js.Strophe.NS.DISCO_ITEMS
      };
      if (node) attrs.node = node;
      var items = strophe_js.$iq({
        from: this._connection.jid,
        to: jid,
        type: 'get'
      }).c('query', attrs);

      this._connection.sendIQ(items, success, error, timeout);
    },

    /** PrivateFunction: _buildIQResult
     */
    _buildIQResult: function (stanza, query_attrs) {
      var id = stanza.getAttribute('id');
      var from = stanza.getAttribute('from');
      var iqresult = strophe_js.$iq({
        type: 'result',
        id: id
      });

      if (from !== null) {
        iqresult.attrs({
          to: from
        });
      }

      return iqresult.c('query', query_attrs);
    },

    /** PrivateFunction: _onDiscoInfo
     * Called when receive info request
     */
    _onDiscoInfo: function (stanza) {
      var node = stanza.getElementsByTagName('query')[0].getAttribute('node');
      var attrs = {
        xmlns: strophe_js.Strophe.NS.DISCO_INFO
      };
      var i;

      if (node) {
        attrs.node = node;
      }

      var iqresult = this._buildIQResult(stanza, attrs);

      for (i = 0; i < this._identities.length; i++) {
        attrs = {
          category: this._identities[i].category,
          type: this._identities[i].type
        };
        if (this._identities[i].name) attrs.name = this._identities[i].name;
        if (this._identities[i].lang) attrs['xml:lang'] = this._identities[i].lang;
        iqresult.c('identity', attrs).up();
      }

      for (i = 0; i < this._features.length; i++) {
        iqresult.c('feature', {
          'var': this._features[i]
        }).up();
      }

      this._connection.send(iqresult.tree());

      return true;
    },

    /** PrivateFunction: _onDiscoItems
     * Called when receive items request
     */
    _onDiscoItems: function (stanza) {
      var query_attrs = {
        xmlns: strophe_js.Strophe.NS.DISCO_ITEMS
      };
      var node = stanza.getElementsByTagName('query')[0].getAttribute('node');
      var items, i;

      if (node) {
        query_attrs.node = node;
        items = [];

        for (i = 0; i < this._items.length; i++) {
          if (this._items[i].node == node) {
            items = this._items[i].call_back(stanza);
            break;
          }
        }
      } else {
        items = this._items;
      }

      var iqresult = this._buildIQResult(stanza, query_attrs);

      for (i = 0; i < items.length; i++) {
        var attrs = {
          jid: items[i].jid
        };
        if (items[i].name) attrs.name = items[i].name;
        if (items[i].node) attrs.node = items[i].node;
        iqresult.c('item', attrs).up();
      }

      this._connection.send(iqresult.tree());

      return true;
    }
  });
});

/***/ }),

/***/ "./node_modules/strophejs-plugin-stream-management/lib/strophe.stream-management.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/strophejs-plugin-stream-management/lib/strophe.stream-management.js ***!
  \******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

(function (global, factory) {
   true ? factory(__webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js")) : undefined;
})(this, function (strophe_js) {
  'use strict';
  /**
  * StropheJS - Stream Management XEP-0198
  *
  * This plugin implements stream management ACK capabilities of the specs XEP-0198.
  * Note: Resumption is not supported in this current implementation.
  *
  * Reference: http://xmpp.org/extensions/xep-0198.html
  *
  * @class streamManagement
  */

  strophe_js.Strophe.addConnectionPlugin('streamManagement', {
    /**
    * @property {Boolean} logging: Set to true to enable logging regarding out of sync stanzas.
    */
    logging: false,

    /**
    * @property {Boolean} autoSendCountOnEveryIncomingStanza: Set to true to send an 'a' response after every stanza.
    * @default false
    * @public
    */
    autoSendCountOnEveryIncomingStanza: false,

    /**
    * @property {Integer} requestResponseInterval: Set this value to send a request for counter on very interval
    * number of stanzas sent. Set to 0 to disable.
    * @default 5
    * @public
    */
    requestResponseInterval: 5,

    /**
    * @property {Pointer} _c: Strophe connection instance.
    * @private
    */
    _c: null,

    /**
    * @property {String} _NS XMPP Namespace.
    * @private
    */
    _NS: 'urn:xmpp:sm:3',

    /**
    * @property {Boolean} _isStreamManagementEnabled
    * @private
    */
    _isStreamManagementEnabled: false,

    /**
    * @property {Integer} _serverProcesssedStanzasCounter: Keeps count of stanzas confirmed processed by the server.
    * The server is the source of truth of this value. It is the 'h' attribute on the latest 'a' element received
    * from the server.
    * @private
    */
    _serverProcesssedStanzasCounter: null,

    /**
    * @property {Integer} _clientProcessedStanzasCounter: Counter of stanzas received by the client from the server.
    * Client is the source of truth of this value. It is the 'h' attribute in the 'a' sent from the client to
    * the server.
    * @private
    */
    _clientProcessedStanzasCounter: null,

    /**
    * @property {Integer} _clientSentStanzasCounter
    * @private
    */
    _clientSentStanzasCounter: null,

    /**
    * Stores a reference to Strophe connection xmlOutput function to wrap counting functionality.
    * @method _originalXMLOutput
    * @type {Handler}
    * @private
    */
    _originalXMLOutput: null,

    /**
    * @property {Handler} _requestHandler: Stores reference to handler that process count request from server.
    * @private
    */
    _requestHandler: null,

    /**
    * @property {Handler} _incomingHandler: Stores reference to handler that processes incoming stanzas count.
    * @private
    */
    _incomingHandler: null,

    /**
    * @property {Integer} _requestResponseIntervalCount: Counts sent stanzas since last response request.
    */
    _requestResponseIntervalCount: 0,

    /**
     * @property {boolean} _isSupported: indicates whether or not the server has advertised support for the stream
     * management namespace.
     */
    _isSupported: false,

    /**
    * @property {Queue} _unacknowledgedStanzas: Maintains a list of packet ids for stanzas which have yet to be acknowledged.
    */
    _unacknowledgedStanzas: [],

    /**
    * @property {Array} _acknowledgedStanzaListeners: Stores callbacks for each stanza acknowledged by the server.
    * Provides the packet id of the stanza as a parameter.
    * @private
    */
    _acknowledgedStanzaListeners: [],
    addAcknowledgedStanzaListener: function (listener) {
      this._acknowledgedStanzaListeners.push(listener);
    },
    enable: function (resume) {
      if (!this._isSupported) {
        throw new Error('The server doesn\'t support urn:xmpp:sm:3 namespace');
      }

      this._c.send(strophe_js.$build('enable', {
        xmlns: this._NS,
        resume
      }));

      this._c.flush();

      this._c.pause();
    },
    getResumeToken: function () {
      return this._resumeToken;
    },

    isSupported() {
      return this._isSupported;
    },

    resume: function () {
      if (!this.getResumeToken()) {
        throw new Error('No resume token');
      } // FIXME add a check for proto/connection state DISCONNECTED


      this._c.options.explicitResourceBinding = true;
      this._resuming = true;

      this._originalConnect.apply(this._c, this._connectArgs);
    },
    requestAcknowledgement: function () {
      this._requestResponseIntervalCount = 0;

      this._c.send(strophe_js.$build('r', {
        xmlns: this._NS
      }));
    },
    getOutgoingCounter: function () {
      return this._clientSentStanzasCounter;
    },
    getIncomingCounter: function () {
      return this._clientProcessedStanzasCounter;
    },
    init: function (conn) {
      this._c = conn;
      strophe_js.Strophe.addNamespace('SM', this._NS); // Storing original xmlOutput function to use additional logic

      this._originalXMLOutput = this._c.xmlOutput;
      this._c.xmlOutput = this.xmlOutput.bind(this);
      this._originalConnect = this._c.connect;
      this._c.connect = this._interceptConnectArgs.bind(this);
      this._originalOnStreamFeaturesAfterSASL = this._c._onStreamFeaturesAfterSASL;
      this._c._onStreamFeaturesAfterSASL = this._onStreamFeaturesAfterSASL.bind(this);
      this._originalDoDisconnect = this._c._doDisconnect;
      this._c._doDisconnect = this._interceptDoDisconnect.bind(this);
      this._originalDisconnect = this._c.disconnect;
      this._c.disconnect = this._interceptDisconnect.bind(this);
    },
    _interceptDisconnect: function () {
      this._resumeToken = undefined;

      this._originalDisconnect.apply(this._c, arguments);
    },
    _interceptDoDisconnect: function () {
      if (this.getResumeToken() && !this._resuming && this._c.connected && !this._c.disconnecting) {
        this._resumeState = {
          handlers: this._c.handlers,
          timedHandlers: this._c.timedHandlers,
          removeTimeds: this._c.removeTimeds,
          removeHandlers: this._c.removeHandlers,
          addTimeds: this._c.addTimeds,
          addHandlers: this._c.addHandlers
        };
        this._storedJid = this._c.jid;
        this.logging && strophe_js.Strophe.debug('SM stored resume state, handler count: ' + this._resumeState.handlers.length);
      }

      this._originalDoDisconnect.apply(this._c, arguments);
    },
    _interceptConnectArgs: function () {
      this._connectArgs = arguments;

      this._originalConnect.apply(this._c, arguments);
    },
    _onStreamFeaturesAfterSASL: function (elem) {
      this._isSupported = elem.getElementsByTagNameNS(this._NS, "sm").length > 0;
      return this._originalOnStreamFeaturesAfterSASL.apply(this._c, arguments);
    },
    statusChanged: function (status) {
      if (!this.getResumeToken() && (status === strophe_js.Strophe.Status.CONNECTED || status === strophe_js.Strophe.Status.DISCONNECTED)) {
        this.logging && strophe_js.Strophe.debug('SM reset state');
        this._serverProcesssedStanzasCounter = 0;
        this._clientProcessedStanzasCounter = 0;
        this._clientSentStanzasCounter = 0;
        this._isStreamManagementEnabled = false;
        this._requestResponseIntervalCount = 0; // FIXME not described in JSDocs

        this._resuming = false;

        if (status === strophe_js.Strophe.Status.DISCONNECTED) {
          this._isSupported = false;
        }

        this._unacknowledgedStanzas = [];

        if (this._requestHandler) {
          this._c.deleteHandler(this._requestHandler);
        }

        if (this._incomingHandler) {
          this._c.deleteHandler(this._incomingHandler);
        }

        this._requestHandler = this._c.addHandler(this._handleServerRequestHandler.bind(this), this._NS, 'r');
        this._ackHandler = this._c.addHandler(this._handleServerAck.bind(this), this._NS, 'a');
        this._incomingHandler = this._c.addHandler(this._incomingStanzaHandler.bind(this)); // FIXME handler instances stored, but never used

        this._enabledHandler = this._c._addSysHandler(this._handleEnabled.bind(this), this._NS, 'enabled');
        this._resumeFailedHandler = this._c._addSysHandler(this._handleResumeFailed.bind(this), this._NS, 'failed');
        this._resumedHandler = this._c._addSysHandler(this._handleResumed.bind(this), this._NS, 'resumed');
      } else if (status === strophe_js.Strophe.Status.BINDREQUIRED) {
        this._c.jid = this._storedJid; // Restore Strophe handlers

        for (const property in this._resumeState) {
          this._c[property] = this._resumeState[property];
        } // FIXME check conditions if there's session ID and if enabled


        this._c.send(strophe_js.$build('resume', {
          xmlns: this._NS,
          h: this._clientProcessedStanzasCounter,
          previd: this._resumeToken
        }));

        this._c.flush();
      } else if (status === strophe_js.Strophe.Status.ERROR) {
        this.logging && strophe_js.Strophe.debug('SM cleared resume token on error');
        this._resumeToken = undefined;
      }
    },

    /**
    * This method overrides the send method implemented by Strophe.Connection
    * to count outgoing stanzas
    *
    * @method Send
    * @public
    */
    xmlOutput: function (elem) {
      if (strophe_js.Strophe.isTagEqual(elem, 'iq') || strophe_js.Strophe.isTagEqual(elem, 'presence') || strophe_js.Strophe.isTagEqual(elem, 'message')) {
        this._increaseSentStanzasCounter(elem);
      }

      return this._originalXMLOutput.call(this._c, elem);
    },
    _handleEnabled: function (elem) {
      this._isStreamManagementEnabled = true; // FIXME fail if requested, but not enabled

      this._resumeToken = elem.getAttribute('resume') === 'true' && elem.getAttribute('id');

      this._c.resume();

      return true;
    },
    _handleResumeFailed: function (elem) {
      const error = elem && elem.firstElementChild && elem.firstElementChild.tagName;

      this._c._changeConnectStatus(strophe_js.Strophe.Status.ERROR, error, elem);

      this._c._doDisconnect();

      return true;
    },
    _handleResumed: function (elem) {
      // FIXME check if in the correct state
      var handledCount = parseInt(elem.getAttribute('h'));

      this._handleAcknowledgedStanzas(handledCount, this._serverProcesssedStanzasCounter);

      this._resuming = false;
      this._c.do_bind = false; // No need to bind our resource anymore

      this._c.authenticated = true;
      this._c.restored = true;

      if (this._unacknowledgedStanzas.length > 0) {
        this.logging && strophe_js.Strophe.debug('SM Sending unacknowledged stanzas', this._unacknowledgedStanzas);

        for (const stanza of this._unacknowledgedStanzas) {
          this._c.send(stanza);
        }
      } else {
        this.logging && strophe_js.Strophe.debug('SM No unacknowledged stanzas', this._unacknowledgedStanzas);
      }

      this._c._changeConnectStatus(strophe_js.Strophe.Status.CONNECTED, null);

      return true;
    },
    _incomingStanzaHandler: function (elem) {
      if (strophe_js.Strophe.isTagEqual(elem, 'iq') || strophe_js.Strophe.isTagEqual(elem, 'presence') || strophe_js.Strophe.isTagEqual(elem, 'message')) {
        this._increaseReceivedStanzasCounter();

        if (this.autoSendCountOnEveryIncomingStanza) {
          this._answerProcessedStanzas();
        }
      }

      return true;
    },
    _handleAcknowledgedStanzas: function (reportedHandledCount, lastKnownHandledCount) {
      var delta = reportedHandledCount - lastKnownHandledCount;

      if (delta < 0) {
        this._throwError('New reported stanza count lower than previous. New: ' + reportedHandledCount + ' - Previous: ' + lastKnownHandledCount);
      }

      if (delta > this._unacknowledgedStanzas.length) {
        this._throwError('Higher reported acknowledge count than unacknowledged stanzas. Reported Acknowledge Count: ' + delta + ' - Unacknowledge Stanza Count: ' + this._unacknowledgedStanzas.length + ' - New: ' + reportedHandledCount + ' - Previous: ' + lastKnownHandledCount);
      }

      for (var i = 0; i < delta; i++) {
        var stanza = this._unacknowledgedStanzas.shift();

        for (var j = 0; j < this._acknowledgedStanzaListeners.length; j++) {
          this._acknowledgedStanzaListeners[j](stanza);
        }
      }

      if (this.logging && this._unacknowledgedStanzas.length > 0) {
        strophe_js.Strophe.warn('SM Unacknowledged stanzas', this._unacknowledgedStanzas);
      }

      this._serverProcesssedStanzasCounter = reportedHandledCount;

      if (this.requestResponseInterval > 0) {
        this._requestResponseIntervalCount = 0;
      }
    },
    _handleServerRequestHandler: function () {
      this._answerProcessedStanzas();

      return true;
    },
    _handleServerAck: function (elem) {
      var handledCount = parseInt(elem.getAttribute('h'));

      this._handleAcknowledgedStanzas(handledCount, this._serverProcesssedStanzasCounter);

      return true;
    },
    _answerProcessedStanzas: function () {
      if (this._isStreamManagementEnabled) {
        this._c.send(strophe_js.$build('a', {
          xmlns: this._NS,
          h: this._clientProcessedStanzasCounter
        }));
      }
    },
    _increaseSentStanzasCounter: function (elem) {
      if (this._isStreamManagementEnabled) {
        if (this._unacknowledgedStanzas.indexOf(elem) !== -1) {
          return;
        }

        this._unacknowledgedStanzas.push(elem);

        this._clientSentStanzasCounter++;

        if (this.requestResponseInterval > 0) {
          this._requestResponseIntervalCount++;

          if (this._requestResponseIntervalCount === this.requestResponseInterval) {
            // FIXME Can not call send from onIdle.
            setTimeout(() => {
              this.requestAcknowledgement();
            }, 1);
          }
        }
      }
    },
    _increaseReceivedStanzasCounter: function () {
      if (this._isStreamManagementEnabled) {
        this._clientProcessedStanzasCounter++;
      }
    },
    _throwError: function (msg) {
      strophe_js.Strophe.error(msg);
      throw new Error(msg);
    }
  });
});

/***/ }),

/***/ "./node_modules/timers-browserify/main.js":
/*!************************************************!*\
  !*** ./node_modules/timers-browserify/main.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(global) {var scope = typeof global !== "undefined" && global || typeof self !== "undefined" && self || window;
var apply = Function.prototype.apply; // DOM APIs, for completeness

exports.setTimeout = function () {
  return new Timeout(apply.call(setTimeout, scope, arguments), clearTimeout);
};

exports.setInterval = function () {
  return new Timeout(apply.call(setInterval, scope, arguments), clearInterval);
};

exports.clearTimeout = exports.clearInterval = function (timeout) {
  if (timeout) {
    timeout.close();
  }
};

function Timeout(id, clearFn) {
  this._id = id;
  this._clearFn = clearFn;
}

Timeout.prototype.unref = Timeout.prototype.ref = function () {};

Timeout.prototype.close = function () {
  this._clearFn.call(scope, this._id);
}; // Does not start the time, just sets up the members needed.


exports.enroll = function (item, msecs) {
  clearTimeout(item._idleTimeoutId);
  item._idleTimeout = msecs;
};

exports.unenroll = function (item) {
  clearTimeout(item._idleTimeoutId);
  item._idleTimeout = -1;
};

exports._unrefActive = exports.active = function (item) {
  clearTimeout(item._idleTimeoutId);
  var msecs = item._idleTimeout;

  if (msecs >= 0) {
    item._idleTimeoutId = setTimeout(function onTimeout() {
      if (item._onTimeout) item._onTimeout();
    }, msecs);
  }
}; // setimmediate attaches itself to the global object


__webpack_require__(/*! setimmediate */ "./node_modules/setimmediate/setImmediate.js"); // On some exotic environments, it's not clear which object `setimmediate` was
// able to install onto.  Search each possibility in the same order as the
// `setimmediate` library.


exports.setImmediate = typeof self !== "undefined" && self.setImmediate || typeof global !== "undefined" && global.setImmediate || this && this.setImmediate;
exports.clearImmediate = typeof self !== "undefined" && self.clearImmediate || typeof global !== "undefined" && global.clearImmediate || this && this.clearImmediate;
/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js")))

/***/ }),

/***/ "./node_modules/webpack/buildin/amd-options.js":
/*!****************************************!*\
  !*** (webpack)/buildin/amd-options.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/* WEBPACK VAR INJECTION */(function(__webpack_amd_options__) {/* globals __webpack_amd_options__ */
module.exports = __webpack_amd_options__;

/* WEBPACK VAR INJECTION */}.call(this, {}))

/***/ }),

/***/ "./node_modules/webpack/buildin/global.js":
/*!***********************************!*\
  !*** (webpack)/buildin/global.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

var g; // This works in non-strict mode

g = function () {
  return this;
}();

try {
  // This works if eval is allowed (see CSP)
  g = g || new Function("return this")();
} catch (e) {
  // This works if the window reference is available
  if (typeof window === "object") g = window;
} // g can still be undefined, but nothing to do about it...
// We return undefined, instead of nothing here, so it's
// easier to handle this case. if(!global) { ...}


module.exports = g;

/***/ }),

/***/ "./node_modules/webpack/buildin/module.js":
/*!***********************************!*\
  !*** (webpack)/buildin/module.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

module.exports = function (module) {
  if (!module.webpackPolyfill) {
    module.deprecate = function () {};

    module.paths = []; // module.parent = undefined by default

    if (!module.children) module.children = [];
    Object.defineProperty(module, "loaded", {
      enumerable: true,
      get: function () {
        return module.l;
      }
    });
    Object.defineProperty(module, "id", {
      enumerable: true,
      get: function () {
        return module.i;
      }
    });
    module.webpackPolyfill = 1;
  }

  return module;
};

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/adapter_core.js":
/*!************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/adapter_core.js ***!
  \************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _adapter_factory_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./adapter_factory.js */ "./node_modules/webrtc-adapter/src/js/adapter_factory.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */



const adapter = Object(_adapter_factory_js__WEBPACK_IMPORTED_MODULE_0__["adapterFactory"])({
  window
});
/* harmony default export */ __webpack_exports__["default"] = (adapter);

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/adapter_factory.js":
/*!***************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/adapter_factory.js ***!
  \***************************************************************/
/*! exports provided: adapterFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "adapterFactory", function() { return adapterFactory; });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/* harmony import */ var _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./chrome/chrome_shim */ "./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js");
/* harmony import */ var _edge_edge_shim__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./edge/edge_shim */ "./node_modules/webrtc-adapter/src/js/edge/edge_shim.js");
/* harmony import */ var _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./firefox/firefox_shim */ "./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js");
/* harmony import */ var _safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./safari/safari_shim */ "./node_modules/webrtc-adapter/src/js/safari/safari_shim.js");
/* harmony import */ var _common_shim__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./common_shim */ "./node_modules/webrtc-adapter/src/js/common_shim.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
 // Browser shims.





 // Shimming starts here.

function adapterFactory({
  window
} = {}, options = {
  shimChrome: true,
  shimFirefox: true,
  shimEdge: true,
  shimSafari: true
}) {
  // Utils.
  const logging = _utils__WEBPACK_IMPORTED_MODULE_0__["log"];
  const browserDetails = _utils__WEBPACK_IMPORTED_MODULE_0__["detectBrowser"](window);
  const adapter = {
    browserDetails,
    commonShim: _common_shim__WEBPACK_IMPORTED_MODULE_5__,
    extractVersion: _utils__WEBPACK_IMPORTED_MODULE_0__["extractVersion"],
    disableLog: _utils__WEBPACK_IMPORTED_MODULE_0__["disableLog"],
    disableWarnings: _utils__WEBPACK_IMPORTED_MODULE_0__["disableWarnings"]
  }; // Shim browser if found.

  switch (browserDetails.browser) {
    case 'chrome':
      if (!_chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__ || !_chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["shimPeerConnection"] || !options.shimChrome) {
        logging('Chrome shim is not included in this adapter release.');
        return adapter;
      }

      logging('adapter.js shimming chrome.'); // Export to the adapter global object visible in the browser.

      adapter.browserShim = _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__;
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["shimGetUserMedia"](window);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["shimMediaStream"](window);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["shimPeerConnection"](window);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["shimOnTrack"](window);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["shimAddTrackRemoveTrack"](window);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["shimGetSendersWithDtmf"](window);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["shimGetStats"](window);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["shimSenderReceiverGetStats"](window);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__["fixNegotiationNeeded"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimRTCIceCandidate"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimConnectionState"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimMaxMessageSize"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimSendThrowTypeError"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["removeAllowExtmapMixed"](window);
      break;

    case 'firefox':
      if (!_firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__ || !_firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimPeerConnection"] || !options.shimFirefox) {
        logging('Firefox shim is not included in this adapter release.');
        return adapter;
      }

      logging('adapter.js shimming firefox.'); // Export to the adapter global object visible in the browser.

      adapter.browserShim = _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__;
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimGetUserMedia"](window);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimPeerConnection"](window);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimOnTrack"](window);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimRemoveStream"](window);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimSenderGetStats"](window);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimReceiverGetStats"](window);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimRTCDataChannel"](window);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimAddTransceiver"](window);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimCreateOffer"](window);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_3__["shimCreateAnswer"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimRTCIceCandidate"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimConnectionState"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimMaxMessageSize"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimSendThrowTypeError"](window);
      break;

    case 'edge':
      if (!_edge_edge_shim__WEBPACK_IMPORTED_MODULE_2__ || !_edge_edge_shim__WEBPACK_IMPORTED_MODULE_2__["shimPeerConnection"] || !options.shimEdge) {
        logging('MS edge shim is not included in this adapter release.');
        return adapter;
      }

      logging('adapter.js shimming edge.'); // Export to the adapter global object visible in the browser.

      adapter.browserShim = _edge_edge_shim__WEBPACK_IMPORTED_MODULE_2__;
      _edge_edge_shim__WEBPACK_IMPORTED_MODULE_2__["shimGetUserMedia"](window);
      _edge_edge_shim__WEBPACK_IMPORTED_MODULE_2__["shimGetDisplayMedia"](window);
      _edge_edge_shim__WEBPACK_IMPORTED_MODULE_2__["shimPeerConnection"](window);
      _edge_edge_shim__WEBPACK_IMPORTED_MODULE_2__["shimReplaceTrack"](window); // the edge shim implements the full RTCIceCandidate object.

      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimMaxMessageSize"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimSendThrowTypeError"](window);
      break;

    case 'safari':
      if (!_safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__ || !options.shimSafari) {
        logging('Safari shim is not included in this adapter release.');
        return adapter;
      }

      logging('adapter.js shimming safari.'); // Export to the adapter global object visible in the browser.

      adapter.browserShim = _safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__;
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__["shimRTCIceServerUrls"](window);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__["shimCreateOfferLegacy"](window);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__["shimCallbacksAPI"](window);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__["shimLocalStreamsAPI"](window);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__["shimRemoteStreamsAPI"](window);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__["shimTrackEventTransceiver"](window);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_4__["shimGetUserMedia"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimRTCIceCandidate"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimMaxMessageSize"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["shimSendThrowTypeError"](window);
      _common_shim__WEBPACK_IMPORTED_MODULE_5__["removeAllowExtmapMixed"](window);
      break;

    default:
      logging('Unsupported browser!');
      break;
  }

  return adapter;
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js":
/*!******************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js ***!
  \******************************************************************/
/*! exports provided: shimGetUserMedia, shimGetDisplayMedia, shimMediaStream, shimOnTrack, shimGetSendersWithDtmf, shimGetStats, shimSenderReceiverGetStats, shimAddTrackRemoveTrackWithNative, shimAddTrackRemoveTrack, shimPeerConnection, fixNegotiationNeeded */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimMediaStream", function() { return shimMediaStream; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimOnTrack", function() { return shimOnTrack; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimGetSendersWithDtmf", function() { return shimGetSendersWithDtmf; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimGetStats", function() { return shimGetStats; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimSenderReceiverGetStats", function() { return shimSenderReceiverGetStats; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimAddTrackRemoveTrackWithNative", function() { return shimAddTrackRemoveTrackWithNative; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimAddTrackRemoveTrack", function() { return shimAddTrackRemoveTrack; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimPeerConnection", function() { return shimPeerConnection; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "fixNegotiationNeeded", function() { return fixNegotiationNeeded; });
/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ "./node_modules/webrtc-adapter/src/js/utils.js");
/* harmony import */ var _getusermedia__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./getusermedia */ "./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "shimGetUserMedia", function() { return _getusermedia__WEBPACK_IMPORTED_MODULE_1__["shimGetUserMedia"]; });

/* harmony import */ var _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./getdisplaymedia */ "./node_modules/webrtc-adapter/src/js/chrome/getdisplaymedia.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "shimGetDisplayMedia", function() { return _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__["shimGetDisplayMedia"]; });

/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */





function shimMediaStream(window) {
  window.MediaStream = window.MediaStream || window.webkitMediaStream;
}
function shimOnTrack(window) {
  if (typeof window === 'object' && window.RTCPeerConnection && !('ontrack' in window.RTCPeerConnection.prototype)) {
    Object.defineProperty(window.RTCPeerConnection.prototype, 'ontrack', {
      get() {
        return this._ontrack;
      },

      set(f) {
        if (this._ontrack) {
          this.removeEventListener('track', this._ontrack);
        }

        this.addEventListener('track', this._ontrack = f);
      },

      enumerable: true,
      configurable: true
    });
    const origSetRemoteDescription = window.RTCPeerConnection.prototype.setRemoteDescription;

    window.RTCPeerConnection.prototype.setRemoteDescription = function setRemoteDescription() {
      if (!this._ontrackpoly) {
        this._ontrackpoly = e => {
          // onaddstream does not fire when a track is added to an existing
          // stream. But stream.onaddtrack is implemented so we use that.
          e.stream.addEventListener('addtrack', te => {
            let receiver;

            if (window.RTCPeerConnection.prototype.getReceivers) {
              receiver = this.getReceivers().find(r => r.track && r.track.id === te.track.id);
            } else {
              receiver = {
                track: te.track
              };
            }

            const event = new Event('track');
            event.track = te.track;
            event.receiver = receiver;
            event.transceiver = {
              receiver
            };
            event.streams = [e.stream];
            this.dispatchEvent(event);
          });
          e.stream.getTracks().forEach(track => {
            let receiver;

            if (window.RTCPeerConnection.prototype.getReceivers) {
              receiver = this.getReceivers().find(r => r.track && r.track.id === track.id);
            } else {
              receiver = {
                track
              };
            }

            const event = new Event('track');
            event.track = track;
            event.receiver = receiver;
            event.transceiver = {
              receiver
            };
            event.streams = [e.stream];
            this.dispatchEvent(event);
          });
        };

        this.addEventListener('addstream', this._ontrackpoly);
      }

      return origSetRemoteDescription.apply(this, arguments);
    };
  } else {
    // even if RTCRtpTransceiver is in window, it is only used and
    // emitted in unified-plan. Unfortunately this means we need
    // to unconditionally wrap the event.
    _utils_js__WEBPACK_IMPORTED_MODULE_0__["wrapPeerConnectionEvent"](window, 'track', e => {
      if (!e.transceiver) {
        Object.defineProperty(e, 'transceiver', {
          value: {
            receiver: e.receiver
          }
        });
      }

      return e;
    });
  }
}
function shimGetSendersWithDtmf(window) {
  // Overrides addTrack/removeTrack, depends on shimAddTrackRemoveTrack.
  if (typeof window === 'object' && window.RTCPeerConnection && !('getSenders' in window.RTCPeerConnection.prototype) && 'createDTMFSender' in window.RTCPeerConnection.prototype) {
    const shimSenderWithDtmf = function (pc, track) {
      return {
        track,

        get dtmf() {
          if (this._dtmf === undefined) {
            if (track.kind === 'audio') {
              this._dtmf = pc.createDTMFSender(track);
            } else {
              this._dtmf = null;
            }
          }

          return this._dtmf;
        },

        _pc: pc
      };
    }; // augment addTrack when getSenders is not available.


    if (!window.RTCPeerConnection.prototype.getSenders) {
      window.RTCPeerConnection.prototype.getSenders = function getSenders() {
        this._senders = this._senders || [];
        return this._senders.slice(); // return a copy of the internal state.
      };

      const origAddTrack = window.RTCPeerConnection.prototype.addTrack;

      window.RTCPeerConnection.prototype.addTrack = function addTrack(track, stream) {
        let sender = origAddTrack.apply(this, arguments);

        if (!sender) {
          sender = shimSenderWithDtmf(this, track);

          this._senders.push(sender);
        }

        return sender;
      };

      const origRemoveTrack = window.RTCPeerConnection.prototype.removeTrack;

      window.RTCPeerConnection.prototype.removeTrack = function removeTrack(sender) {
        origRemoveTrack.apply(this, arguments);

        const idx = this._senders.indexOf(sender);

        if (idx !== -1) {
          this._senders.splice(idx, 1);
        }
      };
    }

    const origAddStream = window.RTCPeerConnection.prototype.addStream;

    window.RTCPeerConnection.prototype.addStream = function addStream(stream) {
      this._senders = this._senders || [];
      origAddStream.apply(this, [stream]);
      stream.getTracks().forEach(track => {
        this._senders.push(shimSenderWithDtmf(this, track));
      });
    };

    const origRemoveStream = window.RTCPeerConnection.prototype.removeStream;

    window.RTCPeerConnection.prototype.removeStream = function removeStream(stream) {
      this._senders = this._senders || [];
      origRemoveStream.apply(this, [stream]);
      stream.getTracks().forEach(track => {
        const sender = this._senders.find(s => s.track === track);

        if (sender) {
          // remove sender
          this._senders.splice(this._senders.indexOf(sender), 1);
        }
      });
    };
  } else if (typeof window === 'object' && window.RTCPeerConnection && 'getSenders' in window.RTCPeerConnection.prototype && 'createDTMFSender' in window.RTCPeerConnection.prototype && window.RTCRtpSender && !('dtmf' in window.RTCRtpSender.prototype)) {
    const origGetSenders = window.RTCPeerConnection.prototype.getSenders;

    window.RTCPeerConnection.prototype.getSenders = function getSenders() {
      const senders = origGetSenders.apply(this, []);
      senders.forEach(sender => sender._pc = this);
      return senders;
    };

    Object.defineProperty(window.RTCRtpSender.prototype, 'dtmf', {
      get() {
        if (this._dtmf === undefined) {
          if (this.track.kind === 'audio') {
            this._dtmf = this._pc.createDTMFSender(this.track);
          } else {
            this._dtmf = null;
          }
        }

        return this._dtmf;
      }

    });
  }
}
function shimGetStats(window) {
  if (!window.RTCPeerConnection) {
    return;
  }

  const origGetStats = window.RTCPeerConnection.prototype.getStats;

  window.RTCPeerConnection.prototype.getStats = function getStats() {
    const [selector, onSucc, onErr] = arguments; // If selector is a function then we are in the old style stats so just
    // pass back the original getStats format to avoid breaking old users.

    if (arguments.length > 0 && typeof selector === 'function') {
      return origGetStats.apply(this, arguments);
    } // When spec-style getStats is supported, return those when called with
    // either no arguments or the selector argument is null.


    if (origGetStats.length === 0 && (arguments.length === 0 || typeof selector !== 'function')) {
      return origGetStats.apply(this, []);
    }

    const fixChromeStats_ = function (response) {
      const standardReport = {};
      const reports = response.result();
      reports.forEach(report => {
        const standardStats = {
          id: report.id,
          timestamp: report.timestamp,
          type: {
            localcandidate: 'local-candidate',
            remotecandidate: 'remote-candidate'
          }[report.type] || report.type
        };
        report.names().forEach(name => {
          standardStats[name] = report.stat(name);
        });
        standardReport[standardStats.id] = standardStats;
      });
      return standardReport;
    }; // shim getStats with maplike support


    const makeMapStats = function (stats) {
      return new Map(Object.keys(stats).map(key => [key, stats[key]]));
    };

    if (arguments.length >= 2) {
      const successCallbackWrapper_ = function (response) {
        onSucc(makeMapStats(fixChromeStats_(response)));
      };

      return origGetStats.apply(this, [successCallbackWrapper_, selector]);
    } // promise-support


    return new Promise((resolve, reject) => {
      origGetStats.apply(this, [function (response) {
        resolve(makeMapStats(fixChromeStats_(response)));
      }, reject]);
    }).then(onSucc, onErr);
  };
}
function shimSenderReceiverGetStats(window) {
  if (!(typeof window === 'object' && window.RTCPeerConnection && window.RTCRtpSender && window.RTCRtpReceiver)) {
    return;
  } // shim sender stats.


  if (!('getStats' in window.RTCRtpSender.prototype)) {
    const origGetSenders = window.RTCPeerConnection.prototype.getSenders;

    if (origGetSenders) {
      window.RTCPeerConnection.prototype.getSenders = function getSenders() {
        const senders = origGetSenders.apply(this, []);
        senders.forEach(sender => sender._pc = this);
        return senders;
      };
    }

    const origAddTrack = window.RTCPeerConnection.prototype.addTrack;

    if (origAddTrack) {
      window.RTCPeerConnection.prototype.addTrack = function addTrack() {
        const sender = origAddTrack.apply(this, arguments);
        sender._pc = this;
        return sender;
      };
    }

    window.RTCRtpSender.prototype.getStats = function getStats() {
      const sender = this;
      return this._pc.getStats().then(result =>
      /* Note: this will include stats of all senders that
       *   send a track with the same id as sender.track as
       *   it is not possible to identify the RTCRtpSender.
       */
      _utils_js__WEBPACK_IMPORTED_MODULE_0__["filterStats"](result, sender.track, true));
    };
  } // shim receiver stats.


  if (!('getStats' in window.RTCRtpReceiver.prototype)) {
    const origGetReceivers = window.RTCPeerConnection.prototype.getReceivers;

    if (origGetReceivers) {
      window.RTCPeerConnection.prototype.getReceivers = function getReceivers() {
        const receivers = origGetReceivers.apply(this, []);
        receivers.forEach(receiver => receiver._pc = this);
        return receivers;
      };
    }

    _utils_js__WEBPACK_IMPORTED_MODULE_0__["wrapPeerConnectionEvent"](window, 'track', e => {
      e.receiver._pc = e.srcElement;
      return e;
    });

    window.RTCRtpReceiver.prototype.getStats = function getStats() {
      const receiver = this;
      return this._pc.getStats().then(result => _utils_js__WEBPACK_IMPORTED_MODULE_0__["filterStats"](result, receiver.track, false));
    };
  }

  if (!('getStats' in window.RTCRtpSender.prototype && 'getStats' in window.RTCRtpReceiver.prototype)) {
    return;
  } // shim RTCPeerConnection.getStats(track).


  const origGetStats = window.RTCPeerConnection.prototype.getStats;

  window.RTCPeerConnection.prototype.getStats = function getStats() {
    if (arguments.length > 0 && arguments[0] instanceof window.MediaStreamTrack) {
      const track = arguments[0];
      let sender;
      let receiver;
      let err;
      this.getSenders().forEach(s => {
        if (s.track === track) {
          if (sender) {
            err = true;
          } else {
            sender = s;
          }
        }
      });
      this.getReceivers().forEach(r => {
        if (r.track === track) {
          if (receiver) {
            err = true;
          } else {
            receiver = r;
          }
        }

        return r.track === track;
      });

      if (err || sender && receiver) {
        return Promise.reject(new DOMException('There are more than one sender or receiver for the track.', 'InvalidAccessError'));
      } else if (sender) {
        return sender.getStats();
      } else if (receiver) {
        return receiver.getStats();
      }

      return Promise.reject(new DOMException('There is no sender or receiver for the track.', 'InvalidAccessError'));
    }

    return origGetStats.apply(this, arguments);
  };
}
function shimAddTrackRemoveTrackWithNative(window) {
  // shim addTrack/removeTrack with native variants in order to make
  // the interactions with legacy getLocalStreams behave as in other browsers.
  // Keeps a mapping stream.id => [stream, rtpsenders...]
  window.RTCPeerConnection.prototype.getLocalStreams = function getLocalStreams() {
    this._shimmedLocalStreams = this._shimmedLocalStreams || {};
    return Object.keys(this._shimmedLocalStreams).map(streamId => this._shimmedLocalStreams[streamId][0]);
  };

  const origAddTrack = window.RTCPeerConnection.prototype.addTrack;

  window.RTCPeerConnection.prototype.addTrack = function addTrack(track, stream) {
    if (!stream) {
      return origAddTrack.apply(this, arguments);
    }

    this._shimmedLocalStreams = this._shimmedLocalStreams || {};
    const sender = origAddTrack.apply(this, arguments);

    if (!this._shimmedLocalStreams[stream.id]) {
      this._shimmedLocalStreams[stream.id] = [stream, sender];
    } else if (this._shimmedLocalStreams[stream.id].indexOf(sender) === -1) {
      this._shimmedLocalStreams[stream.id].push(sender);
    }

    return sender;
  };

  const origAddStream = window.RTCPeerConnection.prototype.addStream;

  window.RTCPeerConnection.prototype.addStream = function addStream(stream) {
    this._shimmedLocalStreams = this._shimmedLocalStreams || {};
    stream.getTracks().forEach(track => {
      const alreadyExists = this.getSenders().find(s => s.track === track);

      if (alreadyExists) {
        throw new DOMException('Track already exists.', 'InvalidAccessError');
      }
    });
    const existingSenders = this.getSenders();
    origAddStream.apply(this, arguments);
    const newSenders = this.getSenders().filter(newSender => existingSenders.indexOf(newSender) === -1);
    this._shimmedLocalStreams[stream.id] = [stream].concat(newSenders);
  };

  const origRemoveStream = window.RTCPeerConnection.prototype.removeStream;

  window.RTCPeerConnection.prototype.removeStream = function removeStream(stream) {
    this._shimmedLocalStreams = this._shimmedLocalStreams || {};
    delete this._shimmedLocalStreams[stream.id];
    return origRemoveStream.apply(this, arguments);
  };

  const origRemoveTrack = window.RTCPeerConnection.prototype.removeTrack;

  window.RTCPeerConnection.prototype.removeTrack = function removeTrack(sender) {
    this._shimmedLocalStreams = this._shimmedLocalStreams || {};

    if (sender) {
      Object.keys(this._shimmedLocalStreams).forEach(streamId => {
        const idx = this._shimmedLocalStreams[streamId].indexOf(sender);

        if (idx !== -1) {
          this._shimmedLocalStreams[streamId].splice(idx, 1);
        }

        if (this._shimmedLocalStreams[streamId].length === 1) {
          delete this._shimmedLocalStreams[streamId];
        }
      });
    }

    return origRemoveTrack.apply(this, arguments);
  };
}
function shimAddTrackRemoveTrack(window) {
  if (!window.RTCPeerConnection) {
    return;
  }

  const browserDetails = _utils_js__WEBPACK_IMPORTED_MODULE_0__["detectBrowser"](window); // shim addTrack and removeTrack.

  if (window.RTCPeerConnection.prototype.addTrack && browserDetails.version >= 65) {
    return shimAddTrackRemoveTrackWithNative(window);
  } // also shim pc.getLocalStreams when addTrack is shimmed
  // to return the original streams.


  const origGetLocalStreams = window.RTCPeerConnection.prototype.getLocalStreams;

  window.RTCPeerConnection.prototype.getLocalStreams = function getLocalStreams() {
    const nativeStreams = origGetLocalStreams.apply(this);
    this._reverseStreams = this._reverseStreams || {};
    return nativeStreams.map(stream => this._reverseStreams[stream.id]);
  };

  const origAddStream = window.RTCPeerConnection.prototype.addStream;

  window.RTCPeerConnection.prototype.addStream = function addStream(stream) {
    this._streams = this._streams || {};
    this._reverseStreams = this._reverseStreams || {};
    stream.getTracks().forEach(track => {
      const alreadyExists = this.getSenders().find(s => s.track === track);

      if (alreadyExists) {
        throw new DOMException('Track already exists.', 'InvalidAccessError');
      }
    }); // Add identity mapping for consistency with addTrack.
    // Unless this is being used with a stream from addTrack.

    if (!this._reverseStreams[stream.id]) {
      const newStream = new window.MediaStream(stream.getTracks());
      this._streams[stream.id] = newStream;
      this._reverseStreams[newStream.id] = stream;
      stream = newStream;
    }

    origAddStream.apply(this, [stream]);
  };

  const origRemoveStream = window.RTCPeerConnection.prototype.removeStream;

  window.RTCPeerConnection.prototype.removeStream = function removeStream(stream) {
    this._streams = this._streams || {};
    this._reverseStreams = this._reverseStreams || {};
    origRemoveStream.apply(this, [this._streams[stream.id] || stream]);
    delete this._reverseStreams[this._streams[stream.id] ? this._streams[stream.id].id : stream.id];
    delete this._streams[stream.id];
  };

  window.RTCPeerConnection.prototype.addTrack = function addTrack(track, stream) {
    if (this.signalingState === 'closed') {
      throw new DOMException('The RTCPeerConnection\'s signalingState is \'closed\'.', 'InvalidStateError');
    }

    const streams = [].slice.call(arguments, 1);

    if (streams.length !== 1 || !streams[0].getTracks().find(t => t === track)) {
      // this is not fully correct but all we can manage without
      // [[associated MediaStreams]] internal slot.
      throw new DOMException('The adapter.js addTrack polyfill only supports a single ' + ' stream which is associated with the specified track.', 'NotSupportedError');
    }

    const alreadyExists = this.getSenders().find(s => s.track === track);

    if (alreadyExists) {
      throw new DOMException('Track already exists.', 'InvalidAccessError');
    }

    this._streams = this._streams || {};
    this._reverseStreams = this._reverseStreams || {};
    const oldStream = this._streams[stream.id];

    if (oldStream) {
      // this is using odd Chrome behaviour, use with caution:
      // https://bugs.chromium.org/p/webrtc/issues/detail?id=7815
      // Note: we rely on the high-level addTrack/dtmf shim to
      // create the sender with a dtmf sender.
      oldStream.addTrack(track); // Trigger ONN async.

      Promise.resolve().then(() => {
        this.dispatchEvent(new Event('negotiationneeded'));
      });
    } else {
      const newStream = new window.MediaStream([track]);
      this._streams[stream.id] = newStream;
      this._reverseStreams[newStream.id] = stream;
      this.addStream(newStream);
    }

    return this.getSenders().find(s => s.track === track);
  }; // replace the internal stream id with the external one and
  // vice versa.


  function replaceInternalStreamId(pc, description) {
    let sdp = description.sdp;
    Object.keys(pc._reverseStreams || []).forEach(internalId => {
      const externalStream = pc._reverseStreams[internalId];
      const internalStream = pc._streams[externalStream.id];
      sdp = sdp.replace(new RegExp(internalStream.id, 'g'), externalStream.id);
    });
    return new RTCSessionDescription({
      type: description.type,
      sdp
    });
  }

  function replaceExternalStreamId(pc, description) {
    let sdp = description.sdp;
    Object.keys(pc._reverseStreams || []).forEach(internalId => {
      const externalStream = pc._reverseStreams[internalId];
      const internalStream = pc._streams[externalStream.id];
      sdp = sdp.replace(new RegExp(externalStream.id, 'g'), internalStream.id);
    });
    return new RTCSessionDescription({
      type: description.type,
      sdp
    });
  }

  ['createOffer', 'createAnswer'].forEach(function (method) {
    const nativeMethod = window.RTCPeerConnection.prototype[method];
    const methodObj = {
      [method]() {
        const args = arguments;
        const isLegacyCall = arguments.length && typeof arguments[0] === 'function';

        if (isLegacyCall) {
          return nativeMethod.apply(this, [description => {
            const desc = replaceInternalStreamId(this, description);
            args[0].apply(null, [desc]);
          }, err => {
            if (args[1]) {
              args[1].apply(null, err);
            }
          }, arguments[2]]);
        }

        return nativeMethod.apply(this, arguments).then(description => replaceInternalStreamId(this, description));
      }

    };
    window.RTCPeerConnection.prototype[method] = methodObj[method];
  });
  const origSetLocalDescription = window.RTCPeerConnection.prototype.setLocalDescription;

  window.RTCPeerConnection.prototype.setLocalDescription = function setLocalDescription() {
    if (!arguments.length || !arguments[0].type) {
      return origSetLocalDescription.apply(this, arguments);
    }

    arguments[0] = replaceExternalStreamId(this, arguments[0]);
    return origSetLocalDescription.apply(this, arguments);
  }; // TODO: mangle getStats: https://w3c.github.io/webrtc-stats/#dom-rtcmediastreamstats-streamidentifier


  const origLocalDescription = Object.getOwnPropertyDescriptor(window.RTCPeerConnection.prototype, 'localDescription');
  Object.defineProperty(window.RTCPeerConnection.prototype, 'localDescription', {
    get() {
      const description = origLocalDescription.get.apply(this);

      if (description.type === '') {
        return description;
      }

      return replaceInternalStreamId(this, description);
    }

  });

  window.RTCPeerConnection.prototype.removeTrack = function removeTrack(sender) {
    if (this.signalingState === 'closed') {
      throw new DOMException('The RTCPeerConnection\'s signalingState is \'closed\'.', 'InvalidStateError');
    } // We can not yet check for sender instanceof RTCRtpSender
    // since we shim RTPSender. So we check if sender._pc is set.


    if (!sender._pc) {
      throw new DOMException('Argument 1 of RTCPeerConnection.removeTrack ' + 'does not implement interface RTCRtpSender.', 'TypeError');
    }

    const isLocal = sender._pc === this;

    if (!isLocal) {
      throw new DOMException('Sender was not created by this connection.', 'InvalidAccessError');
    } // Search for the native stream the senders track belongs to.


    this._streams = this._streams || {};
    let stream;
    Object.keys(this._streams).forEach(streamid => {
      const hasTrack = this._streams[streamid].getTracks().find(track => sender.track === track);

      if (hasTrack) {
        stream = this._streams[streamid];
      }
    });

    if (stream) {
      if (stream.getTracks().length === 1) {
        // if this is the last track of the stream, remove the stream. This
        // takes care of any shimmed _senders.
        this.removeStream(this._reverseStreams[stream.id]);
      } else {
        // relying on the same odd chrome behaviour as above.
        stream.removeTrack(sender.track);
      }

      this.dispatchEvent(new Event('negotiationneeded'));
    }
  };
}
function shimPeerConnection(window) {
  const browserDetails = _utils_js__WEBPACK_IMPORTED_MODULE_0__["detectBrowser"](window);

  if (!window.RTCPeerConnection && window.webkitRTCPeerConnection) {
    // very basic support for old versions.
    window.RTCPeerConnection = window.webkitRTCPeerConnection;
  }

  if (!window.RTCPeerConnection) {
    return;
  }

  const addIceCandidateNullSupported = window.RTCPeerConnection.prototype.addIceCandidate.length === 0; // shim implicit creation of RTCSessionDescription/RTCIceCandidate

  if (browserDetails.version < 53) {
    ['setLocalDescription', 'setRemoteDescription', 'addIceCandidate'].forEach(function (method) {
      const nativeMethod = window.RTCPeerConnection.prototype[method];
      const methodObj = {
        [method]() {
          arguments[0] = new (method === 'addIceCandidate' ? window.RTCIceCandidate : window.RTCSessionDescription)(arguments[0]);
          return nativeMethod.apply(this, arguments);
        }

      };
      window.RTCPeerConnection.prototype[method] = methodObj[method];
    });
  } // support for addIceCandidate(null or undefined)


  const nativeAddIceCandidate = window.RTCPeerConnection.prototype.addIceCandidate;

  window.RTCPeerConnection.prototype.addIceCandidate = function addIceCandidate() {
    if (!addIceCandidateNullSupported && !arguments[0]) {
      if (arguments[1]) {
        arguments[1].apply(null);
      }

      return Promise.resolve();
    } // Firefox 68+ emits and processes {candidate: "", ...}, ignore
    // in older versions. Native support planned for Chrome M77.


    if (browserDetails.version < 78 && arguments[0] && arguments[0].candidate === '') {
      return Promise.resolve();
    }

    return nativeAddIceCandidate.apply(this, arguments);
  };
}
function fixNegotiationNeeded(window) {
  _utils_js__WEBPACK_IMPORTED_MODULE_0__["wrapPeerConnectionEvent"](window, 'negotiationneeded', e => {
    const pc = e.target;

    if (pc.signalingState !== 'stable') {
      return;
    }

    return e;
  });
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/chrome/getdisplaymedia.js":
/*!**********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/chrome/getdisplaymedia.js ***!
  \**********************************************************************/
/*! exports provided: shimGetDisplayMedia */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimGetDisplayMedia", function() { return shimGetDisplayMedia; });
/*
 *  Copyright (c) 2018 The adapter.js project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */


function shimGetDisplayMedia(window, getSourceId) {
  if (window.navigator.mediaDevices && 'getDisplayMedia' in window.navigator.mediaDevices) {
    return;
  }

  if (!window.navigator.mediaDevices) {
    return;
  } // getSourceId is a function that returns a promise resolving with
  // the sourceId of the screen/window/tab to be shared.


  if (typeof getSourceId !== 'function') {
    console.error('shimGetDisplayMedia: getSourceId argument is not ' + 'a function');
    return;
  }

  window.navigator.mediaDevices.getDisplayMedia = function getDisplayMedia(constraints) {
    return getSourceId(constraints).then(sourceId => {
      const widthSpecified = constraints.video && constraints.video.width;
      const heightSpecified = constraints.video && constraints.video.height;
      const frameRateSpecified = constraints.video && constraints.video.frameRate;
      constraints.video = {
        mandatory: {
          chromeMediaSource: 'desktop',
          chromeMediaSourceId: sourceId,
          maxFrameRate: frameRateSpecified || 3
        }
      };

      if (widthSpecified) {
        constraints.video.mandatory.maxWidth = widthSpecified;
      }

      if (heightSpecified) {
        constraints.video.mandatory.maxHeight = heightSpecified;
      }

      return window.navigator.mediaDevices.getUserMedia(constraints);
    });
  };
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js":
/*!*******************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js ***!
  \*******************************************************************/
/*! exports provided: shimGetUserMedia */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimGetUserMedia", function() { return shimGetUserMedia; });
/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ "./node_modules/webrtc-adapter/src/js/utils.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */



const logging = _utils_js__WEBPACK_IMPORTED_MODULE_0__["log"];
function shimGetUserMedia(window) {
  const navigator = window && window.navigator;

  if (!navigator.mediaDevices) {
    return;
  }

  const browserDetails = _utils_js__WEBPACK_IMPORTED_MODULE_0__["detectBrowser"](window);

  const constraintsToChrome_ = function (c) {
    if (typeof c !== 'object' || c.mandatory || c.optional) {
      return c;
    }

    const cc = {};
    Object.keys(c).forEach(key => {
      if (key === 'require' || key === 'advanced' || key === 'mediaSource') {
        return;
      }

      const r = typeof c[key] === 'object' ? c[key] : {
        ideal: c[key]
      };

      if (r.exact !== undefined && typeof r.exact === 'number') {
        r.min = r.max = r.exact;
      }

      const oldname_ = function (prefix, name) {
        if (prefix) {
          return prefix + name.charAt(0).toUpperCase() + name.slice(1);
        }

        return name === 'deviceId' ? 'sourceId' : name;
      };

      if (r.ideal !== undefined) {
        cc.optional = cc.optional || [];
        let oc = {};

        if (typeof r.ideal === 'number') {
          oc[oldname_('min', key)] = r.ideal;
          cc.optional.push(oc);
          oc = {};
          oc[oldname_('max', key)] = r.ideal;
          cc.optional.push(oc);
        } else {
          oc[oldname_('', key)] = r.ideal;
          cc.optional.push(oc);
        }
      }

      if (r.exact !== undefined && typeof r.exact !== 'number') {
        cc.mandatory = cc.mandatory || {};
        cc.mandatory[oldname_('', key)] = r.exact;
      } else {
        ['min', 'max'].forEach(mix => {
          if (r[mix] !== undefined) {
            cc.mandatory = cc.mandatory || {};
            cc.mandatory[oldname_(mix, key)] = r[mix];
          }
        });
      }
    });

    if (c.advanced) {
      cc.optional = (cc.optional || []).concat(c.advanced);
    }

    return cc;
  };

  const shimConstraints_ = function (constraints, func) {
    if (browserDetails.version >= 61) {
      return func(constraints);
    }

    constraints = JSON.parse(JSON.stringify(constraints));

    if (constraints && typeof constraints.audio === 'object') {
      const remap = function (obj, a, b) {
        if (a in obj && !(b in obj)) {
          obj[b] = obj[a];
          delete obj[a];
        }
      };

      constraints = JSON.parse(JSON.stringify(constraints));
      remap(constraints.audio, 'autoGainControl', 'googAutoGainControl');
      remap(constraints.audio, 'noiseSuppression', 'googNoiseSuppression');
      constraints.audio = constraintsToChrome_(constraints.audio);
    }

    if (constraints && typeof constraints.video === 'object') {
      // Shim facingMode for mobile & surface pro.
      let face = constraints.video.facingMode;
      face = face && (typeof face === 'object' ? face : {
        ideal: face
      });
      const getSupportedFacingModeLies = browserDetails.version < 66;

      if (face && (face.exact === 'user' || face.exact === 'environment' || face.ideal === 'user' || face.ideal === 'environment') && !(navigator.mediaDevices.getSupportedConstraints && navigator.mediaDevices.getSupportedConstraints().facingMode && !getSupportedFacingModeLies)) {
        delete constraints.video.facingMode;
        let matches;

        if (face.exact === 'environment' || face.ideal === 'environment') {
          matches = ['back', 'rear'];
        } else if (face.exact === 'user' || face.ideal === 'user') {
          matches = ['front'];
        }

        if (matches) {
          // Look for matches in label, or use last cam for back (typical).
          return navigator.mediaDevices.enumerateDevices().then(devices => {
            devices = devices.filter(d => d.kind === 'videoinput');
            let dev = devices.find(d => matches.some(match => d.label.toLowerCase().includes(match)));

            if (!dev && devices.length && matches.includes('back')) {
              dev = devices[devices.length - 1]; // more likely the back cam
            }

            if (dev) {
              constraints.video.deviceId = face.exact ? {
                exact: dev.deviceId
              } : {
                ideal: dev.deviceId
              };
            }

            constraints.video = constraintsToChrome_(constraints.video);
            logging('chrome: ' + JSON.stringify(constraints));
            return func(constraints);
          });
        }
      }

      constraints.video = constraintsToChrome_(constraints.video);
    }

    logging('chrome: ' + JSON.stringify(constraints));
    return func(constraints);
  };

  const shimError_ = function (e) {
    if (browserDetails.version >= 64) {
      return e;
    }

    return {
      name: {
        PermissionDeniedError: 'NotAllowedError',
        PermissionDismissedError: 'NotAllowedError',
        InvalidStateError: 'NotAllowedError',
        DevicesNotFoundError: 'NotFoundError',
        ConstraintNotSatisfiedError: 'OverconstrainedError',
        TrackStartError: 'NotReadableError',
        MediaDeviceFailedDueToShutdown: 'NotAllowedError',
        MediaDeviceKillSwitchOn: 'NotAllowedError',
        TabCaptureError: 'AbortError',
        ScreenCaptureError: 'AbortError',
        DeviceCaptureError: 'AbortError'
      }[e.name] || e.name,
      message: e.message,
      constraint: e.constraint || e.constraintName,

      toString() {
        return this.name + (this.message && ': ') + this.message;
      }

    };
  };

  const getUserMedia_ = function (constraints, onSuccess, onError) {
    shimConstraints_(constraints, c => {
      navigator.webkitGetUserMedia(c, onSuccess, e => {
        if (onError) {
          onError(shimError_(e));
        }
      });
    });
  };

  navigator.getUserMedia = getUserMedia_.bind(navigator); // Even though Chrome 45 has navigator.mediaDevices and a getUserMedia
  // function which returns a Promise, it does not accept spec-style
  // constraints.

  if (navigator.mediaDevices.getUserMedia) {
    const origGetUserMedia = navigator.mediaDevices.getUserMedia.bind(navigator.mediaDevices);

    navigator.mediaDevices.getUserMedia = function (cs) {
      return shimConstraints_(cs, c => origGetUserMedia(c).then(stream => {
        if (c.audio && !stream.getAudioTracks().length || c.video && !stream.getVideoTracks().length) {
          stream.getTracks().forEach(track => {
            track.stop();
          });
          throw new DOMException('', 'NotFoundError');
        }

        return stream;
      }, e => Promise.reject(shimError_(e))));
    };
  }
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/common_shim.js":
/*!***********************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/common_shim.js ***!
  \***********************************************************/
/*! exports provided: shimRTCIceCandidate, shimMaxMessageSize, shimSendThrowTypeError, shimConnectionState, removeAllowExtmapMixed */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimRTCIceCandidate", function() { return shimRTCIceCandidate; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimMaxMessageSize", function() { return shimMaxMessageSize; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimSendThrowTypeError", function() { return shimSendThrowTypeError; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimConnectionState", function() { return shimConnectionState; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "removeAllowExtmapMixed", function() { return removeAllowExtmapMixed; });
/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! sdp */ "./node_modules/sdp/sdp.js");
/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(sdp__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/*
 *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */




function shimRTCIceCandidate(window) {
  // foundation is arbitrarily chosen as an indicator for full support for
  // https://w3c.github.io/webrtc-pc/#rtcicecandidate-interface
  if (!window.RTCIceCandidate || window.RTCIceCandidate && 'foundation' in window.RTCIceCandidate.prototype) {
    return;
  }

  const NativeRTCIceCandidate = window.RTCIceCandidate;

  window.RTCIceCandidate = function RTCIceCandidate(args) {
    // Remove the a= which shouldn't be part of the candidate string.
    if (typeof args === 'object' && args.candidate && args.candidate.indexOf('a=') === 0) {
      args = JSON.parse(JSON.stringify(args));
      args.candidate = args.candidate.substr(2);
    }

    if (args.candidate && args.candidate.length) {
      // Augment the native candidate with the parsed fields.
      const nativeCandidate = new NativeRTCIceCandidate(args);
      const parsedCandidate = sdp__WEBPACK_IMPORTED_MODULE_0___default.a.parseCandidate(args.candidate);
      const augmentedCandidate = Object.assign(nativeCandidate, parsedCandidate); // Add a serializer that does not serialize the extra attributes.

      augmentedCandidate.toJSON = function toJSON() {
        return {
          candidate: augmentedCandidate.candidate,
          sdpMid: augmentedCandidate.sdpMid,
          sdpMLineIndex: augmentedCandidate.sdpMLineIndex,
          usernameFragment: augmentedCandidate.usernameFragment
        };
      };

      return augmentedCandidate;
    }

    return new NativeRTCIceCandidate(args);
  };

  window.RTCIceCandidate.prototype = NativeRTCIceCandidate.prototype; // Hook up the augmented candidate in onicecandidate and
  // addEventListener('icecandidate', ...)

  _utils__WEBPACK_IMPORTED_MODULE_1__["wrapPeerConnectionEvent"](window, 'icecandidate', e => {
    if (e.candidate) {
      Object.defineProperty(e, 'candidate', {
        value: new window.RTCIceCandidate(e.candidate),
        writable: 'false'
      });
    }

    return e;
  });
}
function shimMaxMessageSize(window) {
  if (!window.RTCPeerConnection) {
    return;
  }

  const browserDetails = _utils__WEBPACK_IMPORTED_MODULE_1__["detectBrowser"](window);

  if (!('sctp' in window.RTCPeerConnection.prototype)) {
    Object.defineProperty(window.RTCPeerConnection.prototype, 'sctp', {
      get() {
        return typeof this._sctp === 'undefined' ? null : this._sctp;
      }

    });
  }

  const sctpInDescription = function (description) {
    if (!description || !description.sdp) {
      return false;
    }

    const sections = sdp__WEBPACK_IMPORTED_MODULE_0___default.a.splitSections(description.sdp);
    sections.shift();
    return sections.some(mediaSection => {
      const mLine = sdp__WEBPACK_IMPORTED_MODULE_0___default.a.parseMLine(mediaSection);
      return mLine && mLine.kind === 'application' && mLine.protocol.indexOf('SCTP') !== -1;
    });
  };

  const getRemoteFirefoxVersion = function (description) {
    // TODO: Is there a better solution for detecting Firefox?
    const match = description.sdp.match(/mozilla...THIS_IS_SDPARTA-(\d+)/);

    if (match === null || match.length < 2) {
      return -1;
    }

    const version = parseInt(match[1], 10); // Test for NaN (yes, this is ugly)

    return version !== version ? -1 : version;
  };

  const getCanSendMaxMessageSize = function (remoteIsFirefox) {
    // Every implementation we know can send at least 64 KiB.
    // Note: Although Chrome is technically able to send up to 256 KiB, the
    //       data does not reach the other peer reliably.
    //       See: https://bugs.chromium.org/p/webrtc/issues/detail?id=8419
    let canSendMaxMessageSize = 65536;

    if (browserDetails.browser === 'firefox') {
      if (browserDetails.version < 57) {
        if (remoteIsFirefox === -1) {
          // FF < 57 will send in 16 KiB chunks using the deprecated PPID
          // fragmentation.
          canSendMaxMessageSize = 16384;
        } else {
          // However, other FF (and RAWRTC) can reassemble PPID-fragmented
          // messages. Thus, supporting ~2 GiB when sending.
          canSendMaxMessageSize = 2147483637;
        }
      } else if (browserDetails.version < 60) {
        // Currently, all FF >= 57 will reset the remote maximum message size
        // to the default value when a data channel is created at a later
        // stage. :(
        // See: https://bugzilla.mozilla.org/show_bug.cgi?id=1426831
        canSendMaxMessageSize = browserDetails.version === 57 ? 65535 : 65536;
      } else {
        // FF >= 60 supports sending ~2 GiB
        canSendMaxMessageSize = 2147483637;
      }
    }

    return canSendMaxMessageSize;
  };

  const getMaxMessageSize = function (description, remoteIsFirefox) {
    // Note: 65536 bytes is the default value from the SDP spec. Also,
    //       every implementation we know supports receiving 65536 bytes.
    let maxMessageSize = 65536; // FF 57 has a slightly incorrect default remote max message size, so
    // we need to adjust it here to avoid a failure when sending.
    // See: https://bugzilla.mozilla.org/show_bug.cgi?id=1425697

    if (browserDetails.browser === 'firefox' && browserDetails.version === 57) {
      maxMessageSize = 65535;
    }

    const match = sdp__WEBPACK_IMPORTED_MODULE_0___default.a.matchPrefix(description.sdp, 'a=max-message-size:');

    if (match.length > 0) {
      maxMessageSize = parseInt(match[0].substr(19), 10);
    } else if (browserDetails.browser === 'firefox' && remoteIsFirefox !== -1) {
      // If the maximum message size is not present in the remote SDP and
      // both local and remote are Firefox, the remote peer can receive
      // ~2 GiB.
      maxMessageSize = 2147483637;
    }

    return maxMessageSize;
  };

  const origSetRemoteDescription = window.RTCPeerConnection.prototype.setRemoteDescription;

  window.RTCPeerConnection.prototype.setRemoteDescription = function setRemoteDescription() {
    this._sctp = null; // Chrome decided to not expose .sctp in plan-b mode.
    // As usual, adapter.js has to do an 'ugly worakaround'
    // to cover up the mess.

    if (browserDetails.browser === 'chrome' && browserDetails.version >= 76) {
      const {
        sdpSemantics
      } = this.getConfiguration();

      if (sdpSemantics === 'plan-b') {
        Object.defineProperty(this, 'sctp', {
          get() {
            return typeof this._sctp === 'undefined' ? null : this._sctp;
          },

          enumerable: true,
          configurable: true
        });
      }
    }

    if (sctpInDescription(arguments[0])) {
      // Check if the remote is FF.
      const isFirefox = getRemoteFirefoxVersion(arguments[0]); // Get the maximum message size the local peer is capable of sending

      const canSendMMS = getCanSendMaxMessageSize(isFirefox); // Get the maximum message size of the remote peer.

      const remoteMMS = getMaxMessageSize(arguments[0], isFirefox); // Determine final maximum message size

      let maxMessageSize;

      if (canSendMMS === 0 && remoteMMS === 0) {
        maxMessageSize = Number.POSITIVE_INFINITY;
      } else if (canSendMMS === 0 || remoteMMS === 0) {
        maxMessageSize = Math.max(canSendMMS, remoteMMS);
      } else {
        maxMessageSize = Math.min(canSendMMS, remoteMMS);
      } // Create a dummy RTCSctpTransport object and the 'maxMessageSize'
      // attribute.


      const sctp = {};
      Object.defineProperty(sctp, 'maxMessageSize', {
        get() {
          return maxMessageSize;
        }

      });
      this._sctp = sctp;
    }

    return origSetRemoteDescription.apply(this, arguments);
  };
}
function shimSendThrowTypeError(window) {
  if (!(window.RTCPeerConnection && 'createDataChannel' in window.RTCPeerConnection.prototype)) {
    return;
  } // Note: Although Firefox >= 57 has a native implementation, the maximum
  //       message size can be reset for all data channels at a later stage.
  //       See: https://bugzilla.mozilla.org/show_bug.cgi?id=1426831


  function wrapDcSend(dc, pc) {
    const origDataChannelSend = dc.send;

    dc.send = function send() {
      const data = arguments[0];
      const length = data.length || data.size || data.byteLength;

      if (dc.readyState === 'open' && pc.sctp && length > pc.sctp.maxMessageSize) {
        throw new TypeError('Message too large (can send a maximum of ' + pc.sctp.maxMessageSize + ' bytes)');
      }

      return origDataChannelSend.apply(dc, arguments);
    };
  }

  const origCreateDataChannel = window.RTCPeerConnection.prototype.createDataChannel;

  window.RTCPeerConnection.prototype.createDataChannel = function createDataChannel() {
    const dataChannel = origCreateDataChannel.apply(this, arguments);
    wrapDcSend(dataChannel, this);
    return dataChannel;
  };

  _utils__WEBPACK_IMPORTED_MODULE_1__["wrapPeerConnectionEvent"](window, 'datachannel', e => {
    wrapDcSend(e.channel, e.target);
    return e;
  });
}
/* shims RTCConnectionState by pretending it is the same as iceConnectionState.
 * See https://bugs.chromium.org/p/webrtc/issues/detail?id=6145#c12
 * for why this is a valid hack in Chrome. In Firefox it is slightly incorrect
 * since DTLS failures would be hidden. See
 * https://bugzilla.mozilla.org/show_bug.cgi?id=1265827
 * for the Firefox tracking bug.
 */

function shimConnectionState(window) {
  if (!window.RTCPeerConnection || 'connectionState' in window.RTCPeerConnection.prototype) {
    return;
  }

  const proto = window.RTCPeerConnection.prototype;
  Object.defineProperty(proto, 'connectionState', {
    get() {
      return {
        completed: 'connected',
        checking: 'connecting'
      }[this.iceConnectionState] || this.iceConnectionState;
    },

    enumerable: true,
    configurable: true
  });
  Object.defineProperty(proto, 'onconnectionstatechange', {
    get() {
      return this._onconnectionstatechange || null;
    },

    set(cb) {
      if (this._onconnectionstatechange) {
        this.removeEventListener('connectionstatechange', this._onconnectionstatechange);
        delete this._onconnectionstatechange;
      }

      if (cb) {
        this.addEventListener('connectionstatechange', this._onconnectionstatechange = cb);
      }
    },

    enumerable: true,
    configurable: true
  });
  ['setLocalDescription', 'setRemoteDescription'].forEach(method => {
    const origMethod = proto[method];

    proto[method] = function () {
      if (!this._connectionstatechangepoly) {
        this._connectionstatechangepoly = e => {
          const pc = e.target;

          if (pc._lastConnectionState !== pc.connectionState) {
            pc._lastConnectionState = pc.connectionState;
            const newEvent = new Event('connectionstatechange', e);
            pc.dispatchEvent(newEvent);
          }

          return e;
        };

        this.addEventListener('iceconnectionstatechange', this._connectionstatechangepoly);
      }

      return origMethod.apply(this, arguments);
    };
  });
}
function removeAllowExtmapMixed(window) {
  /* remove a=extmap-allow-mixed for Chrome < M71 */
  if (!window.RTCPeerConnection) {
    return;
  }

  const browserDetails = _utils__WEBPACK_IMPORTED_MODULE_1__["detectBrowser"](window);

  if (browserDetails.browser === 'chrome' && browserDetails.version >= 71) {
    return;
  }

  const nativeSRD = window.RTCPeerConnection.prototype.setRemoteDescription;

  window.RTCPeerConnection.prototype.setRemoteDescription = function setRemoteDescription(desc) {
    if (desc && desc.sdp && desc.sdp.indexOf('\na=extmap-allow-mixed') !== -1) {
      desc.sdp = desc.sdp.split('\n').filter(line => {
        return line.trim() !== 'a=extmap-allow-mixed';
      }).join('\n');
    }

    return nativeSRD.apply(this, arguments);
  };
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/edge/edge_shim.js":
/*!**************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/edge/edge_shim.js ***!
  \**************************************************************/
/*! exports provided: shimGetUserMedia, shimGetDisplayMedia, shimPeerConnection, shimReplaceTrack */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimPeerConnection", function() { return shimPeerConnection; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimReplaceTrack", function() { return shimReplaceTrack; });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/* harmony import */ var _filtericeservers__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./filtericeservers */ "./node_modules/webrtc-adapter/src/js/edge/filtericeservers.js");
/* harmony import */ var rtcpeerconnection_shim__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! rtcpeerconnection-shim */ "./node_modules/rtcpeerconnection-shim/rtcpeerconnection.js");
/* harmony import */ var rtcpeerconnection_shim__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(rtcpeerconnection_shim__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _getusermedia__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./getusermedia */ "./node_modules/webrtc-adapter/src/js/edge/getusermedia.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "shimGetUserMedia", function() { return _getusermedia__WEBPACK_IMPORTED_MODULE_3__["shimGetUserMedia"]; });

/* harmony import */ var _getdisplaymedia__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./getdisplaymedia */ "./node_modules/webrtc-adapter/src/js/edge/getdisplaymedia.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "shimGetDisplayMedia", function() { return _getdisplaymedia__WEBPACK_IMPORTED_MODULE_4__["shimGetDisplayMedia"]; });

/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */







function shimPeerConnection(window) {
  const browserDetails = _utils__WEBPACK_IMPORTED_MODULE_0__["detectBrowser"](window);

  if (window.RTCIceGatherer) {
    if (!window.RTCIceCandidate) {
      window.RTCIceCandidate = function RTCIceCandidate(args) {
        return args;
      };
    }

    if (!window.RTCSessionDescription) {
      window.RTCSessionDescription = function RTCSessionDescription(args) {
        return args;
      };
    } // this adds an additional event listener to MediaStrackTrack that signals
    // when a tracks enabled property was changed. Workaround for a bug in
    // addStream, see below. No longer required in 15025+


    if (browserDetails.version < 15025) {
      const origMSTEnabled = Object.getOwnPropertyDescriptor(window.MediaStreamTrack.prototype, 'enabled');
      Object.defineProperty(window.MediaStreamTrack.prototype, 'enabled', {
        set(value) {
          origMSTEnabled.set.call(this, value);
          const ev = new Event('enabled');
          ev.enabled = value;
          this.dispatchEvent(ev);
        }

      });
    }
  } // ORTC defines the DTMF sender a bit different.
  // https://github.com/w3c/ortc/issues/714


  if (window.RTCRtpSender && !('dtmf' in window.RTCRtpSender.prototype)) {
    Object.defineProperty(window.RTCRtpSender.prototype, 'dtmf', {
      get() {
        if (this._dtmf === undefined) {
          if (this.track.kind === 'audio') {
            this._dtmf = new window.RTCDtmfSender(this);
          } else if (this.track.kind === 'video') {
            this._dtmf = null;
          }
        }

        return this._dtmf;
      }

    });
  } // Edge currently only implements the RTCDtmfSender, not the
  // RTCDTMFSender alias. See http://draft.ortc.org/#rtcdtmfsender2*


  if (window.RTCDtmfSender && !window.RTCDTMFSender) {
    window.RTCDTMFSender = window.RTCDtmfSender;
  }

  const RTCPeerConnectionShim = rtcpeerconnection_shim__WEBPACK_IMPORTED_MODULE_2___default()(window, browserDetails.version);

  window.RTCPeerConnection = function RTCPeerConnection(config) {
    if (config && config.iceServers) {
      config.iceServers = Object(_filtericeservers__WEBPACK_IMPORTED_MODULE_1__["filterIceServers"])(config.iceServers, browserDetails.version);
      _utils__WEBPACK_IMPORTED_MODULE_0__["log"]('ICE servers after filtering:', config.iceServers);
    }

    return new RTCPeerConnectionShim(config);
  };

  window.RTCPeerConnection.prototype = RTCPeerConnectionShim.prototype;
}
function shimReplaceTrack(window) {
  // ORTC has replaceTrack -- https://github.com/w3c/ortc/issues/614
  if (window.RTCRtpSender && !('replaceTrack' in window.RTCRtpSender.prototype)) {
    window.RTCRtpSender.prototype.replaceTrack = window.RTCRtpSender.prototype.setTrack;
  }
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/edge/filtericeservers.js":
/*!*********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/edge/filtericeservers.js ***!
  \*********************************************************************/
/*! exports provided: filterIceServers */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "filterIceServers", function() { return filterIceServers; });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/*
 *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */


 // Edge does not like
// 1) stun: filtered after 14393 unless ?transport=udp is present
// 2) turn: that does not have all of turn:host:port?transport=udp
// 3) turn: with ipv6 addresses
// 4) turn: occurring muliple times

function filterIceServers(iceServers, edgeVersion) {
  let hasTurn = false;
  iceServers = JSON.parse(JSON.stringify(iceServers));
  return iceServers.filter(server => {
    if (server && (server.urls || server.url)) {
      var urls = server.urls || server.url;

      if (server.url && !server.urls) {
        _utils__WEBPACK_IMPORTED_MODULE_0__["deprecated"]('RTCIceServer.url', 'RTCIceServer.urls');
      }

      const isString = typeof urls === 'string';

      if (isString) {
        urls = [urls];
      }

      urls = urls.filter(url => {
        // filter STUN unconditionally.
        if (url.indexOf('stun:') === 0) {
          return false;
        }

        const validTurn = url.startsWith('turn') && !url.startsWith('turn:[') && url.includes('transport=udp');

        if (validTurn && !hasTurn) {
          hasTurn = true;
          return true;
        }

        return validTurn && !hasTurn;
      });
      delete server.url;
      server.urls = isString ? urls[0] : urls;
      return !!urls.length;
    }
  });
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/edge/getdisplaymedia.js":
/*!********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/edge/getdisplaymedia.js ***!
  \********************************************************************/
/*! exports provided: shimGetDisplayMedia */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimGetDisplayMedia", function() { return shimGetDisplayMedia; });
/*
 *  Copyright (c) 2018 The adapter.js project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */


function shimGetDisplayMedia(window) {
  if (!('getDisplayMedia' in window.navigator)) {
    return;
  }

  if (!window.navigator.mediaDevices) {
    return;
  }

  if (window.navigator.mediaDevices && 'getDisplayMedia' in window.navigator.mediaDevices) {
    return;
  }

  window.navigator.mediaDevices.getDisplayMedia = window.navigator.getDisplayMedia.bind(window.navigator);
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/edge/getusermedia.js":
/*!*****************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/edge/getusermedia.js ***!
  \*****************************************************************/
/*! exports provided: shimGetUserMedia */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimGetUserMedia", function() { return shimGetUserMedia; });
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */


function shimGetUserMedia(window) {
  const navigator = window && window.navigator;

  const shimError_ = function (e) {
    return {
      name: {
        PermissionDeniedError: 'NotAllowedError'
      }[e.name] || e.name,
      message: e.message,
      constraint: e.constraint,

      toString() {
        return this.name;
      }

    };
  }; // getUserMedia error shim.


  const origGetUserMedia = navigator.mediaDevices.getUserMedia.bind(navigator.mediaDevices);

  navigator.mediaDevices.getUserMedia = function (c) {
    return origGetUserMedia(c).catch(e => Promise.reject(shimError_(e)));
  };
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js":
/*!********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js ***!
  \********************************************************************/
/*! exports provided: shimGetUserMedia, shimGetDisplayMedia, shimOnTrack, shimPeerConnection, shimSenderGetStats, shimReceiverGetStats, shimRemoveStream, shimRTCDataChannel, shimAddTransceiver, shimCreateOffer, shimCreateAnswer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimOnTrack", function() { return shimOnTrack; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimPeerConnection", function() { return shimPeerConnection; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimSenderGetStats", function() { return shimSenderGetStats; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimReceiverGetStats", function() { return shimReceiverGetStats; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimRemoveStream", function() { return shimRemoveStream; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimRTCDataChannel", function() { return shimRTCDataChannel; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimAddTransceiver", function() { return shimAddTransceiver; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimCreateOffer", function() { return shimCreateOffer; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimCreateAnswer", function() { return shimCreateAnswer; });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/* harmony import */ var _getusermedia__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./getusermedia */ "./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "shimGetUserMedia", function() { return _getusermedia__WEBPACK_IMPORTED_MODULE_1__["shimGetUserMedia"]; });

/* harmony import */ var _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./getdisplaymedia */ "./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "shimGetDisplayMedia", function() { return _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__["shimGetDisplayMedia"]; });

/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */





function shimOnTrack(window) {
  if (typeof window === 'object' && window.RTCTrackEvent && 'receiver' in window.RTCTrackEvent.prototype && !('transceiver' in window.RTCTrackEvent.prototype)) {
    Object.defineProperty(window.RTCTrackEvent.prototype, 'transceiver', {
      get() {
        return {
          receiver: this.receiver
        };
      }

    });
  }
}
function shimPeerConnection(window) {
  const browserDetails = _utils__WEBPACK_IMPORTED_MODULE_0__["detectBrowser"](window);

  if (typeof window !== 'object' || !(window.RTCPeerConnection || window.mozRTCPeerConnection)) {
    return; // probably media.peerconnection.enabled=false in about:config
  }

  if (!window.RTCPeerConnection && window.mozRTCPeerConnection) {
    // very basic support for old versions.
    window.RTCPeerConnection = window.mozRTCPeerConnection;
  }

  if (browserDetails.version < 53) {
    // shim away need for obsolete RTCIceCandidate/RTCSessionDescription.
    ['setLocalDescription', 'setRemoteDescription', 'addIceCandidate'].forEach(function (method) {
      const nativeMethod = window.RTCPeerConnection.prototype[method];
      const methodObj = {
        [method]() {
          arguments[0] = new (method === 'addIceCandidate' ? window.RTCIceCandidate : window.RTCSessionDescription)(arguments[0]);
          return nativeMethod.apply(this, arguments);
        }

      };
      window.RTCPeerConnection.prototype[method] = methodObj[method];
    });
  } // support for addIceCandidate(null or undefined)
  // as well as ignoring {sdpMid, candidate: ""}


  if (browserDetails.version < 68) {
    const nativeAddIceCandidate = window.RTCPeerConnection.prototype.addIceCandidate;

    window.RTCPeerConnection.prototype.addIceCandidate = function addIceCandidate() {
      if (!arguments[0]) {
        if (arguments[1]) {
          arguments[1].apply(null);
        }

        return Promise.resolve();
      } // Firefox 68+ emits and processes {candidate: "", ...}, ignore
      // in older versions.


      if (arguments[0] && arguments[0].candidate === '') {
        return Promise.resolve();
      }

      return nativeAddIceCandidate.apply(this, arguments);
    };
  }

  const modernStatsTypes = {
    inboundrtp: 'inbound-rtp',
    outboundrtp: 'outbound-rtp',
    candidatepair: 'candidate-pair',
    localcandidate: 'local-candidate',
    remotecandidate: 'remote-candidate'
  };
  const nativeGetStats = window.RTCPeerConnection.prototype.getStats;

  window.RTCPeerConnection.prototype.getStats = function getStats() {
    const [selector, onSucc, onErr] = arguments;
    return nativeGetStats.apply(this, [selector || null]).then(stats => {
      if (browserDetails.version < 53 && !onSucc) {
        // Shim only promise getStats with spec-hyphens in type names
        // Leave callback version alone; misc old uses of forEach before Map
        try {
          stats.forEach(stat => {
            stat.type = modernStatsTypes[stat.type] || stat.type;
          });
        } catch (e) {
          if (e.name !== 'TypeError') {
            throw e;
          } // Avoid TypeError: "type" is read-only, in old versions. 34-43ish


          stats.forEach((stat, i) => {
            stats.set(i, Object.assign({}, stat, {
              type: modernStatsTypes[stat.type] || stat.type
            }));
          });
        }
      }

      return stats;
    }).then(onSucc, onErr);
  };
}
function shimSenderGetStats(window) {
  if (!(typeof window === 'object' && window.RTCPeerConnection && window.RTCRtpSender)) {
    return;
  }

  if (window.RTCRtpSender && 'getStats' in window.RTCRtpSender.prototype) {
    return;
  }

  const origGetSenders = window.RTCPeerConnection.prototype.getSenders;

  if (origGetSenders) {
    window.RTCPeerConnection.prototype.getSenders = function getSenders() {
      const senders = origGetSenders.apply(this, []);
      senders.forEach(sender => sender._pc = this);
      return senders;
    };
  }

  const origAddTrack = window.RTCPeerConnection.prototype.addTrack;

  if (origAddTrack) {
    window.RTCPeerConnection.prototype.addTrack = function addTrack() {
      const sender = origAddTrack.apply(this, arguments);
      sender._pc = this;
      return sender;
    };
  }

  window.RTCRtpSender.prototype.getStats = function getStats() {
    return this.track ? this._pc.getStats(this.track) : Promise.resolve(new Map());
  };
}
function shimReceiverGetStats(window) {
  if (!(typeof window === 'object' && window.RTCPeerConnection && window.RTCRtpSender)) {
    return;
  }

  if (window.RTCRtpSender && 'getStats' in window.RTCRtpReceiver.prototype) {
    return;
  }

  const origGetReceivers = window.RTCPeerConnection.prototype.getReceivers;

  if (origGetReceivers) {
    window.RTCPeerConnection.prototype.getReceivers = function getReceivers() {
      const receivers = origGetReceivers.apply(this, []);
      receivers.forEach(receiver => receiver._pc = this);
      return receivers;
    };
  }

  _utils__WEBPACK_IMPORTED_MODULE_0__["wrapPeerConnectionEvent"](window, 'track', e => {
    e.receiver._pc = e.srcElement;
    return e;
  });

  window.RTCRtpReceiver.prototype.getStats = function getStats() {
    return this._pc.getStats(this.track);
  };
}
function shimRemoveStream(window) {
  if (!window.RTCPeerConnection || 'removeStream' in window.RTCPeerConnection.prototype) {
    return;
  }

  window.RTCPeerConnection.prototype.removeStream = function removeStream(stream) {
    _utils__WEBPACK_IMPORTED_MODULE_0__["deprecated"]('removeStream', 'removeTrack');
    this.getSenders().forEach(sender => {
      if (sender.track && stream.getTracks().includes(sender.track)) {
        this.removeTrack(sender);
      }
    });
  };
}
function shimRTCDataChannel(window) {
  // rename DataChannel to RTCDataChannel (native fix in FF60):
  // https://bugzilla.mozilla.org/show_bug.cgi?id=1173851
  if (window.DataChannel && !window.RTCDataChannel) {
    window.RTCDataChannel = window.DataChannel;
  }
}
function shimAddTransceiver(window) {
  // https://github.com/webrtcHacks/adapter/issues/998#issuecomment-516921647
  // Firefox ignores the init sendEncodings options passed to addTransceiver
  // https://bugzilla.mozilla.org/show_bug.cgi?id=1396918
  if (!(typeof window === 'object' && window.RTCPeerConnection)) {
    return;
  }

  const origAddTransceiver = window.RTCPeerConnection.prototype.addTransceiver;

  if (origAddTransceiver) {
    window.RTCPeerConnection.prototype.addTransceiver = function addTransceiver() {
      this.setParametersPromises = [];
      const initParameters = arguments[1];
      const shouldPerformCheck = initParameters && 'sendEncodings' in initParameters;

      if (shouldPerformCheck) {
        // If sendEncodings params are provided, validate grammar
        initParameters.sendEncodings.forEach(encodingParam => {
          if ('rid' in encodingParam) {
            const ridRegex = /^[a-z0-9]{0,16}$/i;

            if (!ridRegex.test(encodingParam.rid)) {
              throw new TypeError('Invalid RID value provided.');
            }
          }

          if ('scaleResolutionDownBy' in encodingParam) {
            if (!(parseFloat(encodingParam.scaleResolutionDownBy) >= 1.0)) {
              throw new RangeError('scale_resolution_down_by must be >= 1.0');
            }
          }

          if ('maxFramerate' in encodingParam) {
            if (!(parseFloat(encodingParam.maxFramerate) >= 0)) {
              throw new RangeError('max_framerate must be >= 0.0');
            }
          }
        });
      }

      const transceiver = origAddTransceiver.apply(this, arguments);

      if (shouldPerformCheck) {
        // Check if the init options were applied. If not we do this in an
        // asynchronous way and save the promise reference in a global object.
        // This is an ugly hack, but at the same time is way more robust than
        // checking the sender parameters before and after the createOffer
        // Also note that after the createoffer we are not 100% sure that
        // the params were asynchronously applied so we might miss the
        // opportunity to recreate offer.
        const {
          sender
        } = transceiver;
        const params = sender.getParameters();

        if (!('encodings' in params)) {
          params.encodings = initParameters.sendEncodings;
          this.setParametersPromises.push(sender.setParameters(params).catch(() => {}));
        }
      }

      return transceiver;
    };
  }
}
function shimCreateOffer(window) {
  // https://github.com/webrtcHacks/adapter/issues/998#issuecomment-516921647
  // Firefox ignores the init sendEncodings options passed to addTransceiver
  // https://bugzilla.mozilla.org/show_bug.cgi?id=1396918
  if (!(typeof window === 'object' && window.RTCPeerConnection)) {
    return;
  }

  const origCreateOffer = window.RTCPeerConnection.prototype.createOffer;

  window.RTCPeerConnection.prototype.createOffer = function createOffer() {
    if (this.setParametersPromises && this.setParametersPromises.length) {
      return Promise.all(this.setParametersPromises).then(() => {
        return origCreateOffer.apply(this, arguments);
      }).finally(() => {
        this.setParametersPromises = [];
      });
    }

    return origCreateOffer.apply(this, arguments);
  };
}
function shimCreateAnswer(window) {
  // https://github.com/webrtcHacks/adapter/issues/998#issuecomment-516921647
  // Firefox ignores the init sendEncodings options passed to addTransceiver
  // https://bugzilla.mozilla.org/show_bug.cgi?id=1396918
  if (!(typeof window === 'object' && window.RTCPeerConnection)) {
    return;
  }

  const origCreateAnswer = window.RTCPeerConnection.prototype.createAnswer;

  window.RTCPeerConnection.prototype.createAnswer = function createAnswer() {
    if (this.setParametersPromises && this.setParametersPromises.length) {
      return Promise.all(this.setParametersPromises).then(() => {
        return origCreateAnswer.apply(this, arguments);
      }).finally(() => {
        this.setParametersPromises = [];
      });
    }

    return origCreateAnswer.apply(this, arguments);
  };
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js":
/*!***********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js ***!
  \***********************************************************************/
/*! exports provided: shimGetDisplayMedia */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimGetDisplayMedia", function() { return shimGetDisplayMedia; });
/*
 *  Copyright (c) 2018 The adapter.js project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */


function shimGetDisplayMedia(window, preferredMediaSource) {
  if (window.navigator.mediaDevices && 'getDisplayMedia' in window.navigator.mediaDevices) {
    return;
  }

  if (!window.navigator.mediaDevices) {
    return;
  }

  window.navigator.mediaDevices.getDisplayMedia = function getDisplayMedia(constraints) {
    if (!(constraints && constraints.video)) {
      const err = new DOMException('getDisplayMedia without video ' + 'constraints is undefined');
      err.name = 'NotFoundError'; // from https://heycam.github.io/webidl/#idl-DOMException-error-names

      err.code = 8;
      return Promise.reject(err);
    }

    if (constraints.video === true) {
      constraints.video = {
        mediaSource: preferredMediaSource
      };
    } else {
      constraints.video.mediaSource = preferredMediaSource;
    }

    return window.navigator.mediaDevices.getUserMedia(constraints);
  };
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js":
/*!********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js ***!
  \********************************************************************/
/*! exports provided: shimGetUserMedia */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimGetUserMedia", function() { return shimGetUserMedia; });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */



function shimGetUserMedia(window) {
  const browserDetails = _utils__WEBPACK_IMPORTED_MODULE_0__["detectBrowser"](window);
  const navigator = window && window.navigator;
  const MediaStreamTrack = window && window.MediaStreamTrack;

  navigator.getUserMedia = function (constraints, onSuccess, onError) {
    // Replace Firefox 44+'s deprecation warning with unprefixed version.
    _utils__WEBPACK_IMPORTED_MODULE_0__["deprecated"]('navigator.getUserMedia', 'navigator.mediaDevices.getUserMedia');
    navigator.mediaDevices.getUserMedia(constraints).then(onSuccess, onError);
  };

  if (!(browserDetails.version > 55 && 'autoGainControl' in navigator.mediaDevices.getSupportedConstraints())) {
    const remap = function (obj, a, b) {
      if (a in obj && !(b in obj)) {
        obj[b] = obj[a];
        delete obj[a];
      }
    };

    const nativeGetUserMedia = navigator.mediaDevices.getUserMedia.bind(navigator.mediaDevices);

    navigator.mediaDevices.getUserMedia = function (c) {
      if (typeof c === 'object' && typeof c.audio === 'object') {
        c = JSON.parse(JSON.stringify(c));
        remap(c.audio, 'autoGainControl', 'mozAutoGainControl');
        remap(c.audio, 'noiseSuppression', 'mozNoiseSuppression');
      }

      return nativeGetUserMedia(c);
    };

    if (MediaStreamTrack && MediaStreamTrack.prototype.getSettings) {
      const nativeGetSettings = MediaStreamTrack.prototype.getSettings;

      MediaStreamTrack.prototype.getSettings = function () {
        const obj = nativeGetSettings.apply(this, arguments);
        remap(obj, 'mozAutoGainControl', 'autoGainControl');
        remap(obj, 'mozNoiseSuppression', 'noiseSuppression');
        return obj;
      };
    }

    if (MediaStreamTrack && MediaStreamTrack.prototype.applyConstraints) {
      const nativeApplyConstraints = MediaStreamTrack.prototype.applyConstraints;

      MediaStreamTrack.prototype.applyConstraints = function (c) {
        if (this.kind === 'audio' && typeof c === 'object') {
          c = JSON.parse(JSON.stringify(c));
          remap(c, 'autoGainControl', 'mozAutoGainControl');
          remap(c, 'noiseSuppression', 'mozNoiseSuppression');
        }

        return nativeApplyConstraints.apply(this, [c]);
      };
    }
  }
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/safari/safari_shim.js":
/*!******************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/safari/safari_shim.js ***!
  \******************************************************************/
/*! exports provided: shimLocalStreamsAPI, shimRemoteStreamsAPI, shimCallbacksAPI, shimGetUserMedia, shimConstraints, shimRTCIceServerUrls, shimTrackEventTransceiver, shimCreateOfferLegacy */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimLocalStreamsAPI", function() { return shimLocalStreamsAPI; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimRemoteStreamsAPI", function() { return shimRemoteStreamsAPI; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimCallbacksAPI", function() { return shimCallbacksAPI; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimGetUserMedia", function() { return shimGetUserMedia; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimConstraints", function() { return shimConstraints; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimRTCIceServerUrls", function() { return shimRTCIceServerUrls; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimTrackEventTransceiver", function() { return shimTrackEventTransceiver; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "shimCreateOfferLegacy", function() { return shimCreateOfferLegacy; });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */



function shimLocalStreamsAPI(window) {
  if (typeof window !== 'object' || !window.RTCPeerConnection) {
    return;
  }

  if (!('getLocalStreams' in window.RTCPeerConnection.prototype)) {
    window.RTCPeerConnection.prototype.getLocalStreams = function getLocalStreams() {
      if (!this._localStreams) {
        this._localStreams = [];
      }

      return this._localStreams;
    };
  }

  if (!('addStream' in window.RTCPeerConnection.prototype)) {
    const _addTrack = window.RTCPeerConnection.prototype.addTrack;

    window.RTCPeerConnection.prototype.addStream = function addStream(stream) {
      if (!this._localStreams) {
        this._localStreams = [];
      }

      if (!this._localStreams.includes(stream)) {
        this._localStreams.push(stream);
      } // Try to emulate Chrome's behaviour of adding in audio-video order.
      // Safari orders by track id.


      stream.getAudioTracks().forEach(track => _addTrack.call(this, track, stream));
      stream.getVideoTracks().forEach(track => _addTrack.call(this, track, stream));
    };

    window.RTCPeerConnection.prototype.addTrack = function addTrack(track) {
      const stream = arguments[1];

      if (stream) {
        if (!this._localStreams) {
          this._localStreams = [stream];
        } else if (!this._localStreams.includes(stream)) {
          this._localStreams.push(stream);
        }
      }

      return _addTrack.apply(this, arguments);
    };
  }

  if (!('removeStream' in window.RTCPeerConnection.prototype)) {
    window.RTCPeerConnection.prototype.removeStream = function removeStream(stream) {
      if (!this._localStreams) {
        this._localStreams = [];
      }

      const index = this._localStreams.indexOf(stream);

      if (index === -1) {
        return;
      }

      this._localStreams.splice(index, 1);

      const tracks = stream.getTracks();
      this.getSenders().forEach(sender => {
        if (tracks.includes(sender.track)) {
          this.removeTrack(sender);
        }
      });
    };
  }
}
function shimRemoteStreamsAPI(window) {
  if (typeof window !== 'object' || !window.RTCPeerConnection) {
    return;
  }

  if (!('getRemoteStreams' in window.RTCPeerConnection.prototype)) {
    window.RTCPeerConnection.prototype.getRemoteStreams = function getRemoteStreams() {
      return this._remoteStreams ? this._remoteStreams : [];
    };
  }

  if (!('onaddstream' in window.RTCPeerConnection.prototype)) {
    Object.defineProperty(window.RTCPeerConnection.prototype, 'onaddstream', {
      get() {
        return this._onaddstream;
      },

      set(f) {
        if (this._onaddstream) {
          this.removeEventListener('addstream', this._onaddstream);
          this.removeEventListener('track', this._onaddstreampoly);
        }

        this.addEventListener('addstream', this._onaddstream = f);
        this.addEventListener('track', this._onaddstreampoly = e => {
          e.streams.forEach(stream => {
            if (!this._remoteStreams) {
              this._remoteStreams = [];
            }

            if (this._remoteStreams.includes(stream)) {
              return;
            }

            this._remoteStreams.push(stream);

            const event = new Event('addstream');
            event.stream = stream;
            this.dispatchEvent(event);
          });
        });
      }

    });
    const origSetRemoteDescription = window.RTCPeerConnection.prototype.setRemoteDescription;

    window.RTCPeerConnection.prototype.setRemoteDescription = function setRemoteDescription() {
      const pc = this;

      if (!this._onaddstreampoly) {
        this.addEventListener('track', this._onaddstreampoly = function (e) {
          e.streams.forEach(stream => {
            if (!pc._remoteStreams) {
              pc._remoteStreams = [];
            }

            if (pc._remoteStreams.indexOf(stream) >= 0) {
              return;
            }

            pc._remoteStreams.push(stream);

            const event = new Event('addstream');
            event.stream = stream;
            pc.dispatchEvent(event);
          });
        });
      }

      return origSetRemoteDescription.apply(pc, arguments);
    };
  }
}
function shimCallbacksAPI(window) {
  if (typeof window !== 'object' || !window.RTCPeerConnection) {
    return;
  }

  const prototype = window.RTCPeerConnection.prototype;
  const origCreateOffer = prototype.createOffer;
  const origCreateAnswer = prototype.createAnswer;
  const setLocalDescription = prototype.setLocalDescription;
  const setRemoteDescription = prototype.setRemoteDescription;
  const addIceCandidate = prototype.addIceCandidate;

  prototype.createOffer = function createOffer(successCallback, failureCallback) {
    const options = arguments.length >= 2 ? arguments[2] : arguments[0];
    const promise = origCreateOffer.apply(this, [options]);

    if (!failureCallback) {
      return promise;
    }

    promise.then(successCallback, failureCallback);
    return Promise.resolve();
  };

  prototype.createAnswer = function createAnswer(successCallback, failureCallback) {
    const options = arguments.length >= 2 ? arguments[2] : arguments[0];
    const promise = origCreateAnswer.apply(this, [options]);

    if (!failureCallback) {
      return promise;
    }

    promise.then(successCallback, failureCallback);
    return Promise.resolve();
  };

  let withCallback = function (description, successCallback, failureCallback) {
    const promise = setLocalDescription.apply(this, [description]);

    if (!failureCallback) {
      return promise;
    }

    promise.then(successCallback, failureCallback);
    return Promise.resolve();
  };

  prototype.setLocalDescription = withCallback;

  withCallback = function (description, successCallback, failureCallback) {
    const promise = setRemoteDescription.apply(this, [description]);

    if (!failureCallback) {
      return promise;
    }

    promise.then(successCallback, failureCallback);
    return Promise.resolve();
  };

  prototype.setRemoteDescription = withCallback;

  withCallback = function (candidate, successCallback, failureCallback) {
    const promise = addIceCandidate.apply(this, [candidate]);

    if (!failureCallback) {
      return promise;
    }

    promise.then(successCallback, failureCallback);
    return Promise.resolve();
  };

  prototype.addIceCandidate = withCallback;
}
function shimGetUserMedia(window) {
  const navigator = window && window.navigator;

  if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
    // shim not needed in Safari 12.1
    const mediaDevices = navigator.mediaDevices;

    const _getUserMedia = mediaDevices.getUserMedia.bind(mediaDevices);

    navigator.mediaDevices.getUserMedia = constraints => {
      return _getUserMedia(shimConstraints(constraints));
    };
  }

  if (!navigator.getUserMedia && navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
    navigator.getUserMedia = function getUserMedia(constraints, cb, errcb) {
      navigator.mediaDevices.getUserMedia(constraints).then(cb, errcb);
    }.bind(navigator);
  }
}
function shimConstraints(constraints) {
  if (constraints && constraints.video !== undefined) {
    return Object.assign({}, constraints, {
      video: _utils__WEBPACK_IMPORTED_MODULE_0__["compactObject"](constraints.video)
    });
  }

  return constraints;
}
function shimRTCIceServerUrls(window) {
  // migrate from non-spec RTCIceServer.url to RTCIceServer.urls
  const OrigPeerConnection = window.RTCPeerConnection;

  window.RTCPeerConnection = function RTCPeerConnection(pcConfig, pcConstraints) {
    if (pcConfig && pcConfig.iceServers) {
      const newIceServers = [];

      for (let i = 0; i < pcConfig.iceServers.length; i++) {
        let server = pcConfig.iceServers[i];

        if (!server.hasOwnProperty('urls') && server.hasOwnProperty('url')) {
          _utils__WEBPACK_IMPORTED_MODULE_0__["deprecated"]('RTCIceServer.url', 'RTCIceServer.urls');
          server = JSON.parse(JSON.stringify(server));
          server.urls = server.url;
          delete server.url;
          newIceServers.push(server);
        } else {
          newIceServers.push(pcConfig.iceServers[i]);
        }
      }

      pcConfig.iceServers = newIceServers;
    }

    return new OrigPeerConnection(pcConfig, pcConstraints);
  };

  window.RTCPeerConnection.prototype = OrigPeerConnection.prototype; // wrap static methods. Currently just generateCertificate.

  if ('generateCertificate' in window.RTCPeerConnection) {
    Object.defineProperty(window.RTCPeerConnection, 'generateCertificate', {
      get() {
        return OrigPeerConnection.generateCertificate;
      }

    });
  }
}
function shimTrackEventTransceiver(window) {
  // Add event.transceiver member over deprecated event.receiver
  if (typeof window === 'object' && window.RTCTrackEvent && 'receiver' in window.RTCTrackEvent.prototype && !('transceiver' in window.RTCTrackEvent.prototype)) {
    Object.defineProperty(window.RTCTrackEvent.prototype, 'transceiver', {
      get() {
        return {
          receiver: this.receiver
        };
      }

    });
  }
}
function shimCreateOfferLegacy(window) {
  const origCreateOffer = window.RTCPeerConnection.prototype.createOffer;

  window.RTCPeerConnection.prototype.createOffer = function createOffer(offerOptions) {
    if (offerOptions) {
      if (typeof offerOptions.offerToReceiveAudio !== 'undefined') {
        // support bit values
        offerOptions.offerToReceiveAudio = !!offerOptions.offerToReceiveAudio;
      }

      const audioTransceiver = this.getTransceivers().find(transceiver => transceiver.receiver.track.kind === 'audio');

      if (offerOptions.offerToReceiveAudio === false && audioTransceiver) {
        if (audioTransceiver.direction === 'sendrecv') {
          if (audioTransceiver.setDirection) {
            audioTransceiver.setDirection('sendonly');
          } else {
            audioTransceiver.direction = 'sendonly';
          }
        } else if (audioTransceiver.direction === 'recvonly') {
          if (audioTransceiver.setDirection) {
            audioTransceiver.setDirection('inactive');
          } else {
            audioTransceiver.direction = 'inactive';
          }
        }
      } else if (offerOptions.offerToReceiveAudio === true && !audioTransceiver) {
        this.addTransceiver('audio');
      }

      if (typeof offerOptions.offerToReceiveVideo !== 'undefined') {
        // support bit values
        offerOptions.offerToReceiveVideo = !!offerOptions.offerToReceiveVideo;
      }

      const videoTransceiver = this.getTransceivers().find(transceiver => transceiver.receiver.track.kind === 'video');

      if (offerOptions.offerToReceiveVideo === false && videoTransceiver) {
        if (videoTransceiver.direction === 'sendrecv') {
          if (videoTransceiver.setDirection) {
            videoTransceiver.setDirection('sendonly');
          } else {
            videoTransceiver.direction = 'sendonly';
          }
        } else if (videoTransceiver.direction === 'recvonly') {
          if (videoTransceiver.setDirection) {
            videoTransceiver.setDirection('inactive');
          } else {
            videoTransceiver.direction = 'inactive';
          }
        }
      } else if (offerOptions.offerToReceiveVideo === true && !videoTransceiver) {
        this.addTransceiver('video');
      }
    }

    return origCreateOffer.apply(this, arguments);
  };
}

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/utils.js":
/*!*****************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/utils.js ***!
  \*****************************************************/
/*! exports provided: extractVersion, wrapPeerConnectionEvent, disableLog, disableWarnings, log, deprecated, detectBrowser, compactObject, walkStats, filterStats */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "extractVersion", function() { return extractVersion; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "wrapPeerConnectionEvent", function() { return wrapPeerConnectionEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "disableLog", function() { return disableLog; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "disableWarnings", function() { return disableWarnings; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "log", function() { return log; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "deprecated", function() { return deprecated; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "detectBrowser", function() { return detectBrowser; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "compactObject", function() { return compactObject; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "walkStats", function() { return walkStats; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "filterStats", function() { return filterStats; });
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */

/* eslint-env node */


let logDisabled_ = true;
let deprecationWarnings_ = true;
/**
 * Extract browser version out of the provided user agent string.
 *
 * @param {!string} uastring userAgent string.
 * @param {!string} expr Regular expression used as match criteria.
 * @param {!number} pos position in the version string to be returned.
 * @return {!number} browser version.
 */

function extractVersion(uastring, expr, pos) {
  const match = uastring.match(expr);
  return match && match.length >= pos && parseInt(match[pos], 10);
} // Wraps the peerconnection event eventNameToWrap in a function
// which returns the modified event object (or false to prevent
// the event).

function wrapPeerConnectionEvent(window, eventNameToWrap, wrapper) {
  if (!window.RTCPeerConnection) {
    return;
  }

  const proto = window.RTCPeerConnection.prototype;
  const nativeAddEventListener = proto.addEventListener;

  proto.addEventListener = function (nativeEventName, cb) {
    if (nativeEventName !== eventNameToWrap) {
      return nativeAddEventListener.apply(this, arguments);
    }

    const wrappedCallback = e => {
      const modifiedEvent = wrapper(e);

      if (modifiedEvent) {
        cb(modifiedEvent);
      }
    };

    this._eventMap = this._eventMap || {};
    this._eventMap[cb] = wrappedCallback;
    return nativeAddEventListener.apply(this, [nativeEventName, wrappedCallback]);
  };

  const nativeRemoveEventListener = proto.removeEventListener;

  proto.removeEventListener = function (nativeEventName, cb) {
    if (nativeEventName !== eventNameToWrap || !this._eventMap || !this._eventMap[cb]) {
      return nativeRemoveEventListener.apply(this, arguments);
    }

    const unwrappedCb = this._eventMap[cb];
    delete this._eventMap[cb];
    return nativeRemoveEventListener.apply(this, [nativeEventName, unwrappedCb]);
  };

  Object.defineProperty(proto, 'on' + eventNameToWrap, {
    get() {
      return this['_on' + eventNameToWrap];
    },

    set(cb) {
      if (this['_on' + eventNameToWrap]) {
        this.removeEventListener(eventNameToWrap, this['_on' + eventNameToWrap]);
        delete this['_on' + eventNameToWrap];
      }

      if (cb) {
        this.addEventListener(eventNameToWrap, this['_on' + eventNameToWrap] = cb);
      }
    },

    enumerable: true,
    configurable: true
  });
}
function disableLog(bool) {
  if (typeof bool !== 'boolean') {
    return new Error('Argument type: ' + typeof bool + '. Please use a boolean.');
  }

  logDisabled_ = bool;
  return bool ? 'adapter.js logging disabled' : 'adapter.js logging enabled';
}
/**
 * Disable or enable deprecation warnings
 * @param {!boolean} bool set to true to disable warnings.
 */

function disableWarnings(bool) {
  if (typeof bool !== 'boolean') {
    return new Error('Argument type: ' + typeof bool + '. Please use a boolean.');
  }

  deprecationWarnings_ = !bool;
  return 'adapter.js deprecation warnings ' + (bool ? 'disabled' : 'enabled');
}
function log() {
  if (typeof window === 'object') {
    if (logDisabled_) {
      return;
    }

    if (typeof console !== 'undefined' && typeof console.log === 'function') {
      console.log.apply(console, arguments);
    }
  }
}
/**
 * Shows a deprecation warning suggesting the modern and spec-compatible API.
 */

function deprecated(oldMethod, newMethod) {
  if (!deprecationWarnings_) {
    return;
  }

  console.warn(oldMethod + ' is deprecated, please use ' + newMethod + ' instead.');
}
/**
 * Browser detector.
 *
 * @return {object} result containing browser and version
 *     properties.
 */

function detectBrowser(window) {
  const {
    navigator
  } = window; // Returned result object.

  const result = {
    browser: null,
    version: null
  }; // Fail early if it's not a browser

  if (typeof window === 'undefined' || !window.navigator) {
    result.browser = 'Not a browser.';
    return result;
  }

  if (navigator.mozGetUserMedia) {
    // Firefox.
    result.browser = 'firefox';
    result.version = extractVersion(navigator.userAgent, /Firefox\/(\d+)\./, 1);
  } else if (navigator.webkitGetUserMedia || window.isSecureContext === false && window.webkitRTCPeerConnection && !window.RTCIceGatherer) {
    // Chrome, Chromium, Webview, Opera.
    // Version matches Chrome/WebRTC version.
    // Chrome 74 removed webkitGetUserMedia on http as well so we need the
    // more complicated fallback to webkitRTCPeerConnection.
    result.browser = 'chrome';
    result.version = extractVersion(navigator.userAgent, /Chrom(e|ium)\/(\d+)\./, 2);
  } else if (navigator.mediaDevices && navigator.userAgent.match(/Edge\/(\d+).(\d+)$/)) {
    // Edge.
    result.browser = 'edge';
    result.version = extractVersion(navigator.userAgent, /Edge\/(\d+).(\d+)$/, 2);
  } else if (window.RTCPeerConnection && navigator.userAgent.match(/AppleWebKit\/(\d+)\./)) {
    // Safari.
    result.browser = 'safari';
    result.version = extractVersion(navigator.userAgent, /AppleWebKit\/(\d+)\./, 1);
    result.supportsUnifiedPlan = window.RTCRtpTransceiver && 'currentDirection' in window.RTCRtpTransceiver.prototype;
  } else {
    // Default fallthrough: not supported.
    result.browser = 'Not a supported browser.';
    return result;
  }

  return result;
}
/**
 * Checks if something is an object.
 *
 * @param {*} val The something you want to check.
 * @return true if val is an object, false otherwise.
 */

function isObject(val) {
  return Object.prototype.toString.call(val) === '[object Object]';
}
/**
 * Remove all empty objects and undefined values
 * from a nested object -- an enhanced and vanilla version
 * of Lodash's `compact`.
 */


function compactObject(data) {
  if (!isObject(data)) {
    return data;
  }

  return Object.keys(data).reduce(function (accumulator, key) {
    const isObj = isObject(data[key]);
    const value = isObj ? compactObject(data[key]) : data[key];
    const isEmptyObject = isObj && !Object.keys(value).length;

    if (value === undefined || isEmptyObject) {
      return accumulator;
    }

    return Object.assign(accumulator, {
      [key]: value
    });
  }, {});
}
/* iterates the stats graph recursively. */

function walkStats(stats, base, resultSet) {
  if (!base || resultSet.has(base.id)) {
    return;
  }

  resultSet.set(base.id, base);
  Object.keys(base).forEach(name => {
    if (name.endsWith('Id')) {
      walkStats(stats, stats.get(base[name]), resultSet);
    } else if (name.endsWith('Ids')) {
      base[name].forEach(id => {
        walkStats(stats, stats.get(id), resultSet);
      });
    }
  });
}
/* filter getStats for a sender/receiver track. */

function filterStats(result, track, outbound) {
  const streamStatsType = outbound ? 'outbound-rtp' : 'inbound-rtp';
  const filteredResult = new Map();

  if (track === null) {
    return filteredResult;
  }

  const trackStats = [];
  result.forEach(value => {
    if (value.type === 'track' && value.trackIdentifier === track.id) {
      trackStats.push(value);
    }
  });
  trackStats.forEach(trackStat => {
    result.forEach(stats => {
      if (stats.type === streamStatsType && stats.trackId === trackStat.id) {
        walkStats(result, stats, filteredResult);
      }
    });
  });
  return filteredResult;
}

/***/ }),

/***/ "./service/RTC/CameraFacingMode.js":
/*!*****************************************!*\
  !*** ./service/RTC/CameraFacingMode.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * The possible camera facing modes. For now support only 'user' and
 * 'environment' because 'left' and 'right' are not used anywhere in our
 * projects at the time of this writing. For more information please refer to
 * https://w3c.github.io/mediacapture-main/getusermedia.html
 * #def-constraint-facingMode.
 *
 * @enum {string}
 */
const CameraFacingMode = {
  /**
   * The mode which specifies the environment-facing camera.
   */
  ENVIRONMENT: 'environment',

  /**
   * The mode which specifies the user-facing camera.
   */
  USER: 'user'
};
module.exports = CameraFacingMode;

/***/ }),

/***/ "./service/RTC/MediaType.js":
/*!**********************************!*\
  !*** ./service/RTC/MediaType.js ***!
  \**********************************/
/*! exports provided: AUDIO, PRESENTER, VIDEO */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AUDIO", function() { return AUDIO; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PRESENTER", function() { return PRESENTER; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VIDEO", function() { return VIDEO; });
/**
 * The audio type.
 */
const AUDIO = 'audio';
/**
 * The presenter type.
 */

const PRESENTER = 'presenter';
/**
 * The video type.
 */

const VIDEO = 'video';

/***/ }),

/***/ "./service/RTC/RTCEvents.js":
/*!**********************************!*\
  !*** ./service/RTC/RTCEvents.js ***!
  \**********************************/
/*! no static exports found */
/***/ (function(module, exports) {

const RTCEvents = {
  /**
   * Indicates error while create answer call.
   */
  CREATE_ANSWER_FAILED: 'rtc.create_answer_failed',

  /**
   * Indicates error while create offer call.
   */
  CREATE_OFFER_FAILED: 'rtc.create_offer_failed',
  DATA_CHANNEL_OPEN: 'rtc.data_channel_open',
  ENDPOINT_CONN_STATUS_CHANGED: 'rtc.endpoint_conn_status_changed',
  DOMINANT_SPEAKER_CHANGED: 'rtc.dominant_speaker_changed',
  LASTN_ENDPOINT_CHANGED: 'rtc.lastn_endpoint_changed',

  /**
   * Event emitted when the user granted a permission for the camera / mic.
   * Used to keep track of the granted permissions on browsers which don't
   * support the Permissions API.
   */
  GRANTED_PERMISSIONS: 'rtc.granted_permissions',
  IS_SELECTED_CHANGED: 'rtc.is_selected_change',

  /**
   * Event emitted when {@link RTC.setLastN} method is called to update with
   * the new value set.
   * The first argument is the value passed to {@link RTC.setLastN}.
   */
  LASTN_VALUE_CHANGED: 'rtc.lastn_value_changed',

  /**
   * Event emitted when ssrc for a local track is extracted and stored
   * in {@link TraceablePeerConnection}.
   * @param {JitsiLocalTrack} track which ssrc was updated
   * @param {string} ssrc that was stored
   */
  LOCAL_TRACK_SSRC_UPDATED: 'rtc.local_track_ssrc_updated',
  TRACK_ATTACHED: 'rtc.track_attached',

  /**
   * Event fired when we remote track is added to the conference.
   * 1st event argument is the added <tt>JitsiRemoteTrack</tt> instance.
   **/
  REMOTE_TRACK_ADDED: 'rtc.remote_track_added',
  // FIXME get rid of this event in favour of NO_DATA_FROM_SOURCE event
  // (currently implemented for local tracks only)
  REMOTE_TRACK_MUTE: 'rtc.remote_track_mute',

  /**
   * Indicates that the remote track has been removed from the conference.
   * 1st event argument is the removed {@link JitsiRemoteTrack} instance.
   */
  REMOTE_TRACK_REMOVED: 'rtc.remote_track_removed',
  // FIXME get rid of this event in favour of NO_DATA_FROM_SOURCE event
  // (currently implemented for local tracks only)
  REMOTE_TRACK_UNMUTE: 'rtc.remote_track_unmute',

  /**
   * Indicates error while set local description.
   */
  SET_LOCAL_DESCRIPTION_FAILED: 'rtc.set_local_description_failed',

  /**
   * Indicates error while set remote description.
   */
  SET_REMOTE_DESCRIPTION_FAILED: 'rtc.set_remote_description_failed',
  AUDIO_OUTPUT_DEVICE_CHANGED: 'rtc.audio_output_device_changed',
  DEVICE_LIST_CHANGED: 'rtc.device_list_changed',

  /**
   * Indicates that the list with available devices will change.
   */
  DEVICE_LIST_WILL_CHANGE: 'rtc.device_list_will_change',
  DEVICE_LIST_AVAILABLE: 'rtc.device_list_available',

  /**
   * Indicates that a message from another participant is received on
   * data channel.
   */
  ENDPOINT_MESSAGE_RECEIVED: 'rtc.endpoint_message_received',

  /**
   * Designates an event indicating that the local ICE username fragment of
   * the jingle session has changed.
   * The first argument of the vent is <tt>TraceablePeerConnection</tt> which
   * is the source of the event.
   * The second argument is the actual "ufrag" string.
   */
  LOCAL_UFRAG_CHANGED: 'rtc.local_ufrag_changed',

  /**
   * Designates an event indicating that the local ICE username fragment of
   * the jingle session has changed.
   * The first argument of the vent is <tt>TraceablePeerConnection</tt> which
   * is the source of the event.
   * The second argument is the actual "ufrag" string.
   */
  REMOTE_UFRAG_CHANGED: 'rtc.remote_ufrag_changed'
};
module.exports = RTCEvents;

/***/ }),

/***/ "./service/RTC/Resolutions.js":
/*!************************************!*\
  !*** ./service/RTC/Resolutions.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports) {

const Resolutions = {
  '1080': {
    width: 1920,
    height: 1080,
    order: 8
  },
  'fullhd': {
    width: 1920,
    height: 1080,
    order: 8
  },
  '720': {
    width: 1280,
    height: 720,
    order: 7
  },
  'hd': {
    width: 1280,
    height: 720,
    order: 7
  },
  '960': {
    width: 960,
    height: 720,
    order: 6
  },
  '540': {
    width: 960,
    height: 540,
    order: 5
  },
  'qhd': {
    width: 960,
    height: 540,
    order: 5
  },
  // 16:9 resolution first.
  '360': {
    width: 640,
    height: 360,
    order: 4
  },
  '640': {
    width: 640,
    height: 480,
    order: 3
  },
  'vga': {
    width: 640,
    height: 480,
    order: 3
  },
  // 16:9 resolution first.
  '180': {
    width: 320,
    height: 180,
    order: 2
  },
  '320': {
    width: 320,
    height: 240,
    order: 1
  }
};
module.exports = Resolutions;

/***/ }),

/***/ "./service/RTC/SignalingEvents.js":
/*!****************************************!*\
  !*** ./service/RTC/SignalingEvents.js ***!
  \****************************************/
/*! exports provided: PEER_MUTED_CHANGED, PEER_VIDEO_TYPE_CHANGED */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PEER_MUTED_CHANGED", function() { return PEER_MUTED_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PEER_VIDEO_TYPE_CHANGED", function() { return PEER_VIDEO_TYPE_CHANGED; });
/**
 * Event triggered when participant's muted status changes.
 * @param {string} endpointId the track owner's identifier (MUC nickname)
 * @param {MediaType} mediaType "audio" or "video"
 * @param {boolean} isMuted the new muted state
 */
const PEER_MUTED_CHANGED = 'signaling.peerMuted';
/**
 * Event triggered when participant's video type changes.
 * @param {string} endpointId the video owner's ID (MUC nickname)
 * @param {VideoType} videoType the new value
 */

const PEER_VIDEO_TYPE_CHANGED = 'signaling.peerVideoType';

/***/ }),

/***/ "./service/RTC/SignalingLayer.js":
/*!***************************************!*\
  !*** ./service/RTC/SignalingLayer.js ***!
  \***************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return SignalingLayer; });
/* harmony import */ var _modules_util_Listenable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../modules/util/Listenable */ "./modules/util/Listenable.js");

/**
 * An object that carries the info about specific media type advertised by
 * participant in the signaling channel.
 * @typedef {Object} PeerMediaInfo
 * @property {boolean} muted indicates if the media is currently muted
 * @property {VideoType|undefined} videoType the type of the video if applicable
 */

/**
 * Interface used to expose the information carried over the signaling channel
 * which is not available to the RTC module in the media SDP.
 *
 * @interface SignalingLayer
 */

class SignalingLayer extends _modules_util_Listenable__WEBPACK_IMPORTED_MODULE_0__["default"] {
  /**
   * Obtains the endpoint ID for given SSRC.
   * @param {number} ssrc the SSRC number.
   * @return {string|null} the endpoint ID for given media SSRC.
   */
  getSSRCOwner(ssrc) {
    // eslint-disable-line no-unused-vars
    throw new Error('not implemented');
  }
  /**
   * Obtains the info about given media advertised in the MUC presence of
   * the participant identified by the given MUC JID.
   * @param {string} owner the MUC jid of the participant for whom
   * {@link PeerMediaInfo} will be obtained.
   * @param {MediaType} mediaType the type of the media for which presence
   * info will be obtained.
   * @return {PeerMediaInfo|null} presenceInfo an object with media presence
   * info or <tt>null</tt> either if there is no presence available for given
   * JID or if the media type given is invalid.
   */


  getPeerMediaInfo(owner, mediaType) {
    // eslint-disable-line no-unused-vars
    throw new Error('not implemented');
  }

}

/***/ }),

/***/ "./service/RTC/VideoType.js":
/*!**********************************!*\
  !*** ./service/RTC/VideoType.js ***!
  \**********************************/
/*! no static exports found */
/***/ (function(module, exports) {

/* global module */

/**
 * Enumeration of the video types
 * @type {{CAMERA: string, DESKTOP: string}}
 */
const VideoType = {
  /**
   * The camera video type.
   */
  CAMERA: 'camera',

  /**
   * The desktop video type.
   */
  DESKTOP: 'desktop'
};
module.exports = VideoType;

/***/ }),

/***/ "./service/authentication/AuthenticationEvents.js":
/*!********************************************************!*\
  !*** ./service/authentication/AuthenticationEvents.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

const AuthenticationEvents = {
  /**
   * Event callback arguments:
   * function(authenticationEnabled, userIdentity)
   * authenticationEnabled - indicates whether authentication has been enabled
   *                         in this session
   * userIdentity - if user has been logged in then it contains user name. If
   *                contains 'null' or 'undefined' then user is not logged in.
   */
  IDENTITY_UPDATED: 'authentication.identity_updated'
};
module.exports = AuthenticationEvents;

/***/ }),

/***/ "./service/connectivity/ConnectionQualityEvents.js":
/*!*********************************************************!*\
  !*** ./service/connectivity/ConnectionQualityEvents.js ***!
  \*********************************************************/
/*! exports provided: LOCAL_STATS_UPDATED, REMOTE_STATS_UPDATED */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LOCAL_STATS_UPDATED", function() { return LOCAL_STATS_UPDATED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "REMOTE_STATS_UPDATED", function() { return REMOTE_STATS_UPDATED; });
/**
 * Indicates that the local connection statistics were updated.
 */
const LOCAL_STATS_UPDATED = 'cq.local_stats_updated';
/**
 * Indicates that the connection statistics for a particular remote participant
 * were updated.
 */

const REMOTE_STATS_UPDATED = 'cq.remote_stats_updated';

/***/ }),

/***/ "./service/e2eping/E2ePingEvents.js":
/*!******************************************!*\
  !*** ./service/e2eping/E2ePingEvents.js ***!
  \******************************************/
/*! exports provided: E2E_RTT_CHANGED */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "E2E_RTT_CHANGED", function() { return E2E_RTT_CHANGED; });
/**
 * Indicates that the end-to-end round-trip-time for a participant has changed.
 */
const E2E_RTT_CHANGED = 'e2eping.e2e_rtt_changed';

/***/ }),

/***/ "./service/statistics/AnalyticsEvents.js":
/*!***********************************************!*\
  !*** ./service/statistics/AnalyticsEvents.js ***!
  \***********************************************/
/*! exports provided: TYPE_OPERATIONAL, TYPE_PAGE, TYPE_TRACK, TYPE_UI, ACTION_JINGLE_RESTART, ACTION_JINGLE_SA_TIMEOUT, ACTION_JINGLE_SI_RECEIVED, ACTION_JINGLE_SI_TIMEOUT, ACTION_JINGLE_TERMINATE, ACTION_JINGLE_TR_RECEIVED, ACTION_JINGLE_TR_SUCCESS, ACTION_P2P_DECLINED, ACTION_P2P_ESTABLISHED, ACTION_P2P_FAILED, ACTION_P2P_SWITCH_TO_JVB, AVAILABLE_DEVICE, CONNECTION_DISCONNECTED, FEEDBACK, ICE_DURATION, ICE_ESTABLISHMENT_DURATION_DIFF, ICE_STATE_CHANGED, NO_BYTES_SENT, TRACK_UNMUTED, createBridgeDownEvent, createConnectionFailedEvent, createConferenceEvent, createConnectionStageReachedEvent, createE2eRttEvent, createFocusLeftEvent, createGetUserMediaEvent, createParticipantConnectionStatusEvent, createJingleEvent, createNoDataFromSourceEvent, createP2PEvent, createRemotelyMutedEvent, createRtpStatsEvent, createRttByRegionEvent, createTransportStatsEvent, createAudioOutputProblemEvent, createBridgeChannelClosedEvent, createTtfmEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TYPE_OPERATIONAL", function() { return TYPE_OPERATIONAL; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TYPE_PAGE", function() { return TYPE_PAGE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TYPE_TRACK", function() { return TYPE_TRACK; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TYPE_UI", function() { return TYPE_UI; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_JINGLE_RESTART", function() { return ACTION_JINGLE_RESTART; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_JINGLE_SA_TIMEOUT", function() { return ACTION_JINGLE_SA_TIMEOUT; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_JINGLE_SI_RECEIVED", function() { return ACTION_JINGLE_SI_RECEIVED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_JINGLE_SI_TIMEOUT", function() { return ACTION_JINGLE_SI_TIMEOUT; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_JINGLE_TERMINATE", function() { return ACTION_JINGLE_TERMINATE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_JINGLE_TR_RECEIVED", function() { return ACTION_JINGLE_TR_RECEIVED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_JINGLE_TR_SUCCESS", function() { return ACTION_JINGLE_TR_SUCCESS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_P2P_DECLINED", function() { return ACTION_P2P_DECLINED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_P2P_ESTABLISHED", function() { return ACTION_P2P_ESTABLISHED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_P2P_FAILED", function() { return ACTION_P2P_FAILED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ACTION_P2P_SWITCH_TO_JVB", function() { return ACTION_P2P_SWITCH_TO_JVB; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AVAILABLE_DEVICE", function() { return AVAILABLE_DEVICE; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_DISCONNECTED", function() { return CONNECTION_DISCONNECTED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "FEEDBACK", function() { return FEEDBACK; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ICE_DURATION", function() { return ICE_DURATION; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ICE_ESTABLISHMENT_DURATION_DIFF", function() { return ICE_ESTABLISHMENT_DURATION_DIFF; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ICE_STATE_CHANGED", function() { return ICE_STATE_CHANGED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NO_BYTES_SENT", function() { return NO_BYTES_SENT; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TRACK_UNMUTED", function() { return TRACK_UNMUTED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createBridgeDownEvent", function() { return createBridgeDownEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createConnectionFailedEvent", function() { return createConnectionFailedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createConferenceEvent", function() { return createConferenceEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createConnectionStageReachedEvent", function() { return createConnectionStageReachedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createE2eRttEvent", function() { return createE2eRttEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createFocusLeftEvent", function() { return createFocusLeftEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createGetUserMediaEvent", function() { return createGetUserMediaEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createParticipantConnectionStatusEvent", function() { return createParticipantConnectionStatusEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createJingleEvent", function() { return createJingleEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createNoDataFromSourceEvent", function() { return createNoDataFromSourceEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createP2PEvent", function() { return createP2PEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createRemotelyMutedEvent", function() { return createRemotelyMutedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createRtpStatsEvent", function() { return createRtpStatsEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createRttByRegionEvent", function() { return createRttByRegionEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createTransportStatsEvent", function() { return createTransportStatsEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createAudioOutputProblemEvent", function() { return createAudioOutputProblemEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createBridgeChannelClosedEvent", function() { return createBridgeChannelClosedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createTtfmEvent", function() { return createTtfmEvent; });
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

/**
 * This class exports constants and factory methods related to the analytics
 * API provided by AnalyticsAdapter. In order for entries in a database to be
 * somewhat easily traceable back to the code which produced them, events sent
 * through analytics should be defined here.
 *
 * Since the AnalyticsAdapter API can be used in different ways, for some events
 * it is more convenient to just define the event name as a constant. For other
 * events a factory function is easier.
 *
 * A general approach for adding a new event:
 * 1. Determine the event type: track, UI, page, or operational. If in doubt use
 * operational.
 * 2. Determine whether the event is related to other existing events, and
 * which fields are desired to be set: name, action, actionSubject, source.
 * 3. If the name is sufficient (the other fields are not important), use a
 * constant. Otherwise use a factory function.
 *
 * Note that the AnalyticsAdapter uses the events passed to its functions for
 * its own purposes, and might modify them. Because of this, factory functions
 * should create new objects.
 *
 */

/**
 * The constant which identifies an event of type "operational".
 * @type {string}
 */
const TYPE_OPERATIONAL = 'operational';
/**
 * The constant which identifies an event of type "page".
 * @type {string}
 */

const TYPE_PAGE = 'page';
/**
 * The constant which identifies an event of type "track".
 * @type {string}
 */

const TYPE_TRACK = 'track';
/**
 * The constant which identifies an event of type "ui".
 * @type {string}
 */

const TYPE_UI = 'ui';
/**
 * The "action" value for Jingle events which indicates that the Jingle session
 * was restarted (TODO: verify/fix the documentation)
 * @type {string}
 */

const ACTION_JINGLE_RESTART = 'restart';
/**
 * The "action" value for Jingle events which indicates that a session-accept
 * timed out (TODO: verify/fix the documentation)
 * @type {string}
 */

const ACTION_JINGLE_SA_TIMEOUT = 'session-accept.timeout';
/**
 * The "action" value for Jingle events which indicates that a session-initiate
 * was received.
 * @type {string}
 */

const ACTION_JINGLE_SI_RECEIVED = 'session-initiate.received';
/**
 * The "action" value for Jingle events which indicates that a session-initiate
 * not arrived within a timeout (the value is specified in
 * the {@link JingleSessionPC}.
 * @type {string}
 */

const ACTION_JINGLE_SI_TIMEOUT = 'session-initiate.timeout';
/**
 * A constant for the "terminate" action for Jingle events. TODO: verify/fix
 * the documentation)
 * @type {string}
 */

const ACTION_JINGLE_TERMINATE = 'terminate';
/**
 * The "action" value for Jingle events which indicates that a transport-replace
 * was received.
 * @type {string}
 */

const ACTION_JINGLE_TR_RECEIVED = 'transport-replace.received';
/**
 * The "action" value for Jingle events which indicates that a transport-replace
 * succeeded (TODO: verify/fix the documentation)
 * @type {string}
 */

const ACTION_JINGLE_TR_SUCCESS = 'transport-replace.success';
/**
 * The "action" value for P2P events which indicates that P2P session initiate message has been rejected by the client
 * because the mandatory requirements were not met.
 * @type {string}
 */

const ACTION_P2P_DECLINED = 'decline';
/**
 * The "action" value for P2P events which indicates that a connection was
 * established (TODO: verify/fix the documentation)
 * @type {string}
 */

const ACTION_P2P_ESTABLISHED = 'established';
/**
 * The "action" value for P2P events which indicates that something failed.
 * @type {string}
 */

const ACTION_P2P_FAILED = 'failed';
/**
 * The "action" value for P2P events which indicates that a switch to
 * jitsi-videobridge happened.
 * @type {string}
 */

const ACTION_P2P_SWITCH_TO_JVB = 'switch.to.jvb';
/**
 * The name of an event which indicates an available device. We send one such
 * event per available device once when the available devices are first known,
 * and every time that they change
 * @type {string}
 *
 * Properties:
 *      audio_input_device_count: the number of audio input devices available at
 *          the time the event was sent.
 *      audio_output_device_count: the number of audio output devices available
 *          at the time the event was sent.
 *      video_input_device_count: the number of video input devices available at
 *          the time the event was sent.
 *      video_output_device_count: the number of video output devices available
 *          at the time the event was sent.
 *      device_id: an identifier of the device described in this event.
 *      device_group_id:
 *      device_kind: one of 'audioinput', 'audiooutput', 'videoinput' or
 *          'videooutput'.
 *      device_label: a string which describes the device.
 */

const AVAILABLE_DEVICE = 'available.device';
/**
 * This appears to be fired only in certain cases when the XMPP connection
 * disconnects (and it was intentional?). It is currently never observed to
 * fire in production.
 *
 * TODO: document
 *
 * Properties:
 *      message: an error message
 */

const CONNECTION_DISCONNECTED = 'connection.disconnected';
/**
 * Indicates that the user of the application provided feedback in terms of a
 * rating (an integer from 1 to 5) and an optional comment.
 * Properties:
 *      value: the user's rating (an integer from 1 to 5)
 *      comment: the user's comment
 */

const FEEDBACK = 'feedback';
/**
 * Indicates the duration of a particular phase of the ICE connectivity
 * establishment.
 *
 * Properties:
 *      phase: the ICE phase (e.g. 'gathering', 'checking', 'establishment')
 *      value: the duration in milliseconds.
 *      p2p: whether the associated ICE connection is p2p or towards a
 *          jitsi-videobridge
 *      initiator: whether the local Jingle peer is the initiator or responder
 *          in the Jingle session. XXX we probably actually care about the ICE
 *          role (controlling vs controlled), and we assume that this correlates
 *          with the Jingle initiator.
 */

const ICE_DURATION = 'ice.duration';
/**
 * Indicates the difference in milliseconds between the ICE establishment time
 * for the P2P and JVB connections (e.g. a value of 10 would indicate that the
 * P2P connection took 10ms more than JVB connection to establish).
 *
 * Properties:
 *      value: the difference in establishment durations in milliseconds.
 *
 */

const ICE_ESTABLISHMENT_DURATION_DIFF = 'ice.establishment.duration.diff';
/**
 * Indicates that the ICE state has changed.
 *
 * Properties:
 *      state: the ICE state which was entered (e.g. 'checking', 'connected',
 *          'completed', etc).
 *      value: the time in milliseconds (as reported by
 *          window.performance.now()) that the state change occurred.
 *      p2p: whether the associated ICE connection is p2p or towards a
 *          jitsi-videobridge
 *      signalingState: The signaling state of the associated PeerConnection
 *      reconnect: whether the associated Jingle session is in the process of
 *          reconnecting (or is it ICE? TODO: verify/fix the documentation)
 */

const ICE_STATE_CHANGED = 'ice.state.changed';
/**
 * Indicates that no bytes have been sent for the track.
 *
 * Properties:
 *      mediaType: the media type of the local track ('audio' or 'video').
 */

const NO_BYTES_SENT = 'track.no-bytes-sent';
/**
 * Indicates that a track was unmuted (?).
 *
 * Properties:
 *      mediaType: the media type of the local track ('audio' or 'video').
 *      trackType: the type of the track ('local' or 'remote').
 *      value: TODO: document
 */

const TRACK_UNMUTED = 'track.unmuted';
/**
 * Creates an operational event which indicates that we have received a
 * "bridge down" event from jicofo.
 */

const createBridgeDownEvent = function () {
  const bridgeDown = 'bridge.down';
  return {
    action: bridgeDown,
    actionSubject: bridgeDown,
    type: TYPE_OPERATIONAL
  };
};
/**
 * Creates an event which indicates that the XMPP connection failed
 * @param errorType TODO
 * @param errorMessage TODO
 * @param detail connection failed details.
 */

const createConnectionFailedEvent = function (errorType, errorMessage, details) {
  return {
    type: TYPE_OPERATIONAL,
    action: 'connection.failed',
    attributes: _objectSpread({
      'error_type': errorType,
      'error_message': errorMessage
    }, details)
  };
};
/**
 * Creates a conference event.
 *
 * @param {string} action - The action of the event.
 * @param {Object} attributes - The attributes to be added to the event.
 * @returns {{type: string, source: string, action: string, attributes: object}}
 */

function createConferenceEvent(action, attributes) {
  return {
    action,
    attributes,
    source: 'conference',
    type: TYPE_OPERATIONAL
  };
}
/**
 * Creates an operational event which indicates that a particular connection
 * stage was reached (i.e. the XMPP connection transitioned to the "connected"
 * state).
 *
 * @param stage the stage which was reached
 * @param attributes additional attributes for the event. This should be an
 * object with a "value" property indicating a timestamp in milliseconds
 * relative to the beginning of the document's lifetime.
 *
 */

const createConnectionStageReachedEvent = function (stage, attributes) {
  const action = 'connection.stage.reached';
  return {
    action,
    actionSubject: stage,
    attributes,
    source: action,
    type: TYPE_OPERATIONAL
  };
};
/**
 * Creates an operational event for the end-to-end round trip time to a
 * specific remote participant.
 * @param participantId the ID of the remote participant.
 * @param region the region of the remote participant
 * @param rtt the rtt
 */

const createE2eRttEvent = function (participantId, region, rtt) {
  const attributes = {
    'participant_id': participantId,
    region,
    rtt
  };
  return {
    attributes,
    name: 'e2e_rtt',
    type: TYPE_OPERATIONAL
  };
};
/**
 * Creates an event which indicates that the focus has left the MUC.
 */

const createFocusLeftEvent = function () {
  const action = 'focus.left';
  return {
    action,
    actionSubject: action,
    type: TYPE_OPERATIONAL
  };
};
/**
 * Creates an event related to a getUserMedia call.
 *
 * @param action the type of the result that the event represents: 'error',
 * 'success', 'warning', etc.
 * @param attributes the attributes to attach to the event.
 * @returns {{type: string, source: string, name: string}}
 */

const createGetUserMediaEvent = function (action, attributes = {}) {
  return {
    type: TYPE_OPERATIONAL,
    source: 'get.user.media',
    action,
    attributes
  };
};
/**
 * Creates an event related to remote participant connection status changes.
 *
 * @param attributes the attributes to attach to the event.
 * @returns {{type: string, source: string, name: string}}
 */

const createParticipantConnectionStatusEvent = function (attributes = {}) {
  const action = 'duration';
  return {
    type: TYPE_OPERATIONAL,
    source: 'peer.conn.status',
    action,
    attributes
  };
};
/**
 * Creates an event for a Jingle-related event.
 * @param action the action of the event
 * @param attributes attributes to add to the event.
 */

const createJingleEvent = function (action, attributes = {}) {
  return {
    type: TYPE_OPERATIONAL,
    action,
    source: 'jingle',
    attributes
  };
};
/**
 * Creates an event which indicates that a local track was not able to read
 * data from its source (a camera or a microphone).
 *
 * @param mediaType {String} the media type of the local track ('audio' or
 * 'video').
 */

const createNoDataFromSourceEvent = function (mediaType, value) {
  return {
    attributes: {
      'media_type': mediaType,
      value
    },
    action: 'track.no.data.from.source',
    type: TYPE_OPERATIONAL
  };
};
/**
 * Creates an event for a p2p-related event.
 * @param action the action of the event
 * @param attributes attributes to add to the event.
 */

const createP2PEvent = function (action, attributes = {}) {
  return {
    type: TYPE_OPERATIONAL,
    action,
    source: 'p2p',
    attributes
  };
};
/**
 * Indicates that we received a remote command to mute.
 */

const createRemotelyMutedEvent = function () {
  return {
    type: TYPE_OPERATIONAL,
    action: 'remotely.muted'
  };
};
/**
 * Creates an event which contains RTP statistics such as RTT and packet loss.
 *
 * All average RTP stats are currently reported under 1 event name, but with
 * different properties that allows to distinguish between a P2P call, a
 * call relayed through TURN or the JVB, and multiparty vs 1:1.
 *
 * The structure of the event is:
 *
 * {
 *      p2p: true,
 *      conferenceSize: 2,
 *      localCandidateType: "relay",
 *      remoteCandidateType: "relay",
 *      transportType: "udp",
 *
 *      // Average RTT of 200ms
 *      "rtt.avg": 200,
 *      "rtt.samples": "[100, 200, 300]",
 *
 *      // Average packet loss of 10%
 *      "packet.loss.avg": 10,
 *      "packet.loss.samples": '[5, 10, 15]'
 *
 *      // Difference in milliseconds in the end-to-end RTT between p2p and jvb.
 *      // The e2e RTT through jvb is 15ms shorter:
 *      "rtt.diff": 15,
 *
 *      // End-to-end RTT through JVB is ms.
 *      "end2end.rtt.avg" = 100
 * }
 *
 * Note that the value of the "samples" properties are (JSON encoded) strings,
 * and not JSON arrays, as events' attributes can not be nested. The samples are
 * currently included for debug purposes only and can be removed anytime soon
 * from the structure.
 *
 * Also note that not all of values are present in each event, as values are
 * obtained and calculated as part of different process/event pipe. For example
 * {@link ConnectionAvgStats} instances are doing the reports for each
 * {@link TraceablePeerConnection} and work independently from the main stats
 * pipe.
 */

const createRtpStatsEvent = function (attributes) {
  return {
    type: TYPE_OPERATIONAL,
    action: 'rtp.stats',
    attributes
  };
};
/**
 * Creates an event which contains the round trip time (RTT) to a set of
 * regions.
 *
 * @param attributes
 * @returns {{type: string, action: string, attributes: *}}
 */

const createRttByRegionEvent = function (attributes) {
  return {
    type: TYPE_OPERATIONAL,
    action: 'rtt.by.region',
    attributes
  };
};
/**
 * Creates an event which contains the local and remote ICE candidate types
 * for the transport that is currently selected.
 *
 * @param attributes
 * @returns {{type: string, action: string, attributes: *}}
 */

const createTransportStatsEvent = function (attributes) {
  return {
    type: TYPE_OPERATIONAL,
    action: 'transport.stats',
    attributes
  };
};
/**
 * Creates an event which contains information about the audio output problem (the user id of the affected participant,
 * the local audio levels and the remote audio levels that triggered the event).
 *
 * @param {string} userID - The user id of the affected participant.
 * @param {*} localAudioLevels - The local audio levels.
 * @param {*} remoteAudioLevels - The audio levels received from the participant.
 */

function createAudioOutputProblemEvent(userID, localAudioLevels, remoteAudioLevels) {
  return {
    type: TYPE_OPERATIONAL,
    action: 'audio.output.problem',
    attributes: {
      userID,
      localAudioLevels,
      remoteAudioLevels
    }
  };
}
/**
 * Creates an event which contains an information related to the bridge channel close event.
 *
 * @param {string} code - A code from {@link https://developer.mozilla.org/en-US/docs/Web/API/CloseEvent}
 * @param {string} reason - A string which describes the reason for closing the bridge channel.
 * @returns {{type: string, action: string, attributes: { code: string, reason: string }}}
 */

const createBridgeChannelClosedEvent = function (code, reason) {
  return {
    type: TYPE_OPERATIONAL,
    action: 'bridge-channel.error',
    attributes: {
      code,
      reason
    }
  };
};
/**
 * Creates an event which indicates the Time To First Media (TTFM).
 * It is measured in milliseconds relative to the beginning of the document's
 * lifetime (i.e. the origin used by window.performance.now()), and it excludes
 * the following:
 * 1. The delay due to getUserMedia()
 * 2. The period between the MUC being joined and the reception of the Jingle
 * session-initiate from jicofo. This is because jicofo will not start a Jingle
 * session until there are at least 2 participants in the room.
 *
 * @param attributes the attributes to add to the event. Currently used fields:
 *      mediaType: the media type of the local track ('audio' or 'video').
 *      muted: whether the track has ever been muted (?)
 *      value: the TTMF in milliseconds.
 */

const createTtfmEvent = function (attributes) {
  return createConnectionStageReachedEvent('ttfm', attributes);
};

/***/ }),

/***/ "./service/statistics/Events.js":
/*!**************************************!*\
  !*** ./service/statistics/Events.js ***!
  \**************************************/
/*! exports provided: AUDIO_LEVEL, BEFORE_DISPOSED, BYTE_SENT_STATS, CONNECTION_STATS */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AUDIO_LEVEL", function() { return AUDIO_LEVEL; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "BEFORE_DISPOSED", function() { return BEFORE_DISPOSED; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "BYTE_SENT_STATS", function() { return BYTE_SENT_STATS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CONNECTION_STATS", function() { return CONNECTION_STATS; });
/**
 * Notifies about audio level in RTP statistics by SSRC.
 *
 * @param ssrc - The synchronization source identifier (SSRC) of the
 * endpoint/participant whose audio level is being reported.
 * @param {number} audioLevel - The audio level of <tt>ssrc</tt> according to
 * RTP statistics.
 * @param {boolean} isLocal - <tt>true</tt> if <tt>ssrc</tt> identifies the
 * local endpoint/participant; otherwise, <tt>false</tt>.
 */
const AUDIO_LEVEL = 'statistics.audioLevel';
/**
 * An event fired just before the statistics module gets disposes and it's
 * the last chance to submit some logs that will end up in stats services like
 * CallStats (if enabled).
 */

const BEFORE_DISPOSED = 'statistics.before_disposed';
/**
 * An event carrying all statistics by ssrc.
 */

const BYTE_SENT_STATS = 'statistics.byte_sent_stats';
/**
 * An event carrying connection statistics.
 *
 * @param {object} connectionStats - The connection statistics carried by the
 * event such as <tt>bandwidth</tt>, <tt>bitrate</tt>, <tt>packetLoss</tt>,
 * <tt>resolution</tt>, and <tt>transport</tt>.
 */

const CONNECTION_STATS = 'statistics.connectionstats';

/***/ }),

/***/ "./service/statistics/constants.js":
/*!*****************************************!*\
  !*** ./service/statistics/constants.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

const Constants = {
  LOCAL_JID: 'local'
};
module.exports = Constants;

/***/ }),

/***/ "./service/xmpp/XMPPEvents.js":
/*!************************************!*\
  !*** ./service/xmpp/XMPPEvents.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports) {

const XMPPEvents = {
  /**
   * Indicates error while adding ice candidate.
   */
  ADD_ICE_CANDIDATE_FAILED: 'xmpp.add_ice_candidate_failed',
  // Designates an event indicating that the focus has asked us to mute our
  // audio.
  AUDIO_MUTED_BY_FOCUS: 'xmpp.audio_muted_by_focus',
  AUTHENTICATION_REQUIRED: 'xmpp.authentication_required',
  BRIDGE_DOWN: 'xmpp.bridge_down',

  /**
   * Triggered when 'session-accept' is received from the responder.
   */
  CALL_ACCEPTED: 'xmpp.callaccepted.jingle',
  // Designates an event indicating that an offer (e.g. Jingle
  // session-initiate) was received.
  CALL_INCOMING: 'xmpp.callincoming.jingle',
  // Triggered when Jicofo kills our media session, this can happen while
  // we're still in the MUC, when it decides to terminate the media session.
  // For example when the session is idle for too long, because we're the only
  // person in the conference room.
  CALL_ENDED: 'xmpp.callended.jingle',
  CHAT_ERROR_RECEIVED: 'xmpp.chat_error_received',
  // The conference properties (as advertised by jicofo) have changed
  CONFERENCE_PROPERTIES_CHANGED: 'xmpp.conference_properties_changed',

  /**
   * This event is triggered when the ICE connects for the first time.
   */
  CONNECTION_ESTABLISHED: 'xmpp.connection.connected',
  // Designates an event indicating that the connection to the XMPP server
  // failed.
  CONNECTION_FAILED: 'xmpp.connection.failed',
  // Designates an event indicating that the media (ICE) connection was
  // interrupted. This should go to the RTC module.
  CONNECTION_INTERRUPTED: 'xmpp.connection.interrupted',
  // Designates an event indicating that the media (ICE) connection was
  // restored. This should go to the RTC module.
  CONNECTION_RESTORED: 'xmpp.connection.restored',
  // Designates an event indicating that the media (ICE) connection failed.
  // This should go to the RTC module.
  CONNECTION_ICE_FAILED: 'xmpp.connection.ice.failed',

  /**
   * Designates an event indicating connection status changes.
   */
  CONNECTION_STATUS_CHANGED: 'xmpp.connection.status.changed',
  // Designates an event indicating that the display name of a participant
  // has changed.
  DISPLAY_NAME_CHANGED: 'xmpp.display_name_changed',

  /**
   * Chat room instance have been added to Strophe.emuc plugin.
   */
  EMUC_ROOM_ADDED: 'xmpp.emuc_room_added',

  /**
   * Chat room instance have been removed from Strophe.emuc plugin.
   */
  EMUC_ROOM_REMOVED: 'xmpp.emuc_room_removed',
  ETHERPAD: 'xmpp.etherpad',
  FOCUS_DISCONNECTED: 'xmpp.focus_disconnected',
  FOCUS_LEFT: 'xmpp.focus_left',
  GRACEFUL_SHUTDOWN: 'xmpp.graceful_shutdown',

  /**
   * Event fired when 'transport-replace' Jingle message has been received,
   * before the new offer is set on the PeerConnection.
   */
  ICE_RESTARTING: 'rtc.ice_restarting',

  /**
   * Event fired after the 'transport-replace' message has been processed
   * and the new offer has been set successfully.
   */
  ICE_RESTART_SUCCESS: 'rtc.ice_restart_success',

  /**
   * Designates an event indicating that we were kicked from the XMPP MUC.
   * @param {boolean} isSelfPresence - whether it is for local participant
   * or another participant.
   * @param {string} actorJid - the jid of the participant who was initator
   * of the kick.
   * @param {?string} participantJid - when it is not a kick for local participant,
   * this is the jid of the participant which was kicked.
   */
  KICKED: 'xmpp.kicked',
  // Designates an event indicating that our role in the XMPP MUC has changed.
  LOCAL_ROLE_CHANGED: 'xmpp.localrole_changed',

  /**
   * Event fired when the unique meeting id is set.
   */
  MEETING_ID_SET: 'xmpp.meeting_id_set',
  // Designates an event indicating that an XMPP message in the MUC was
  // received.
  MESSAGE_RECEIVED: 'xmpp.message_received',
  // Designates an event indicating that a private XMPP message in the MUC was
  // received.
  PRIVATE_MESSAGE_RECEIVED: 'xmpp.private_message_received',
  // Designates an event indicating that a bot participant type had changed
  MUC_MEMBER_BOT_TYPE_CHANGED: 'xmpp.muc_member_bot_type_changed',
  // Designates an event indicating that the XMPP MUC was destroyed.
  MUC_DESTROYED: 'xmpp.muc_destroyed',
  // Designates an event indicating that we have joined the XMPP MUC.
  MUC_JOINED: 'xmpp.muc_joined',
  // Designates an event indicating that a participant joined the XMPP MUC.
  MUC_MEMBER_JOINED: 'xmpp.muc_member_joined',
  // Designates an event indicating that a participant left the XMPP MUC.
  MUC_MEMBER_LEFT: 'xmpp.muc_member_left',
  // Designates an event indicating that local participant left the muc
  MUC_LEFT: 'xmpp.muc_left',
  // Designates an event indicating that the MUC role of a participant has
  // changed.
  MUC_ROLE_CHANGED: 'xmpp.muc_role_changed',
  // Designates an event indicating that the MUC has been locked or unlocked.
  MUC_LOCK_CHANGED: 'xmpp.muc_lock_changed',
  // Designates an event indicating that a participant in the XMPP MUC has
  // advertised that they have audio muted (or unmuted).
  PARTICIPANT_AUDIO_MUTED: 'xmpp.audio_muted',
  // Designates an event indicating that a participant in the XMPP MUC has
  // advertised that they have video muted (or unmuted).
  PARTICIPANT_VIDEO_MUTED: 'xmpp.video_muted',
  // Designates an event indicating that the video type (e.g. 'camera' or
  // 'screen') for a participant has changed.
  // Note: currently this event fires every time we receive presence from
  // someone (regardless of whether or not the "video type" changed).
  PARTICIPANT_VIDEO_TYPE_CHANGED: 'xmpp.video_type',

  /**
   * Indicates that the features of the participant has been changed.
   */
  PARTCIPANT_FEATURES_CHANGED: 'xmpp.partcipant_features_changed',
  PASSWORD_REQUIRED: 'xmpp.password_required',
  PEERCONNECTION_READY: 'xmpp.peerconnection_ready',

  /**
   * Indicates that phone number changed.
   */
  PHONE_NUMBER_CHANGED: 'conference.phoneNumberChanged',
  PRESENCE_RECEIVED: 'xmpp.presence_received',
  PRESENCE_STATUS: 'xmpp.presence_status',
  PROMPT_FOR_LOGIN: 'xmpp.prompt_for_login',
  // xmpp is connected and obtained user media
  READY_TO_JOIN: 'xmpp.ready_to_join',

  /**
   * Indicates that recording state changed.
   */
  RECORDER_STATE_CHANGED: 'xmpp.recorderStateChanged',
  // Designates an event indicating that we received statistics from a
  // participant in the MUC.
  REMOTE_STATS: 'xmpp.remote_stats',

  /**
   * Indicates that the offer / answer renegotiation has failed.
   */
  RENEGOTIATION_FAILED: 'xmpp.renegotiation_failed',
  RESERVATION_ERROR: 'xmpp.room_reservation_error',
  ROOM_CONNECT_ERROR: 'xmpp.room_connect_error',
  ROOM_CONNECT_NOT_ALLOWED_ERROR: 'xmpp.room_connect_error.not_allowed',
  ROOM_JOIN_ERROR: 'xmpp.room_join_error',

  /**
   * Indicates that max users limit has been reached.
   */
  ROOM_MAX_USERS_ERROR: 'xmpp.room_max_users_error',
  // Designates an event indicating that we sent an XMPP message to the MUC.
  SENDING_CHAT_MESSAGE: 'xmpp.sending_chat_message',
  // Designates an event indicating that we sent a private XMPP message to
  // a specific user of the muc.
  SENDING_PRIVATE_CHAT_MESSAGE: 'xmpp.sending_private_chat_message',

  /**
   * Event fired when we do not get our 'session-accept' acknowledged by
   * Jicofo. It most likely means that there is serious problem with our
   * connection or XMPP server and we should reload the conference.
   *
   * We have seen that to happen in BOSH requests race condition when the BOSH
   * request table containing the 'session-accept' was discarded by Prosody.
   * Jicofo does send the RESULT immediately without any condition, so missing
   * packets means that most likely it has never seen our IQ.
   */
  SESSION_ACCEPT_TIMEOUT: 'xmpp.session_accept_timeout',

  /**
   * Event fired when speaker stats update message is received.
   */
  SPEAKER_STATS_RECEIVED: 'xmpp.speaker_stats_received',

  /**
   * Event fired when conference creation timestamp is received.
   */
  CONFERENCE_TIMESTAMP_RECEIVED: 'xmpp.conference_timestamp_received',
  // Designates an event indicating that we should join the conference with
  // audio and/or video muted.
  START_MUTED_FROM_FOCUS: 'xmpp.start_muted_from_focus',
  // Designates an event indicating that the subject of the XMPP MUC has
  // changed.
  SUBJECT_CHANGED: 'xmpp.subject_changed',
  // FIXME: how does it belong to XMPP ? - it's detected by the PeerConnection
  // suspending detected
  SUSPEND_DETECTED: 'xmpp.suspend_detected',

  /**
   * Notifies for transcription status changes. The event provides the
   * following parameters to its listeners:
   *
   * @param {String} status - The new status.
   */
  TRANSCRIPTION_STATUS_CHANGED: 'xmpp.transcription_status_changed',

  /**
   * Event fired when 'transport-info' with new ICE candidates is received.
   */
  TRANSPORT_INFO: 'xmpp.transportinfo.jingle',

  /**
   * Indicates that video SIP GW state changed.
   *
   * @param {VideoSIPGWConstants} status - Any of the following statuses:
   * STATUS_BUSY, STATUS_AVAILABLE or STATUS_UNDEFINED.
   */
  VIDEO_SIP_GW_AVAILABILITY_CHANGED: 'xmpp.videoSIPGWAvailabilityChanged',

  /**
   * Indicates that video SIP GW Session state changed.
   * The statuses are any of the following statuses:
   * STATE_ON, STATE_OFF, STATE_PENDING, STATE_RETRYING, STATE_FAILED.
   * {@see VideoSIPGWConstants}
   *
   * @param {options} event - {address, oldState, newState, displayName}.
   */
  VIDEO_SIP_GW_SESSION_STATE_CHANGED: 'xmpp.videoSIPGWSessionStateChanged',
  // Designates an event indicating that the local ICE connection state has
  // changed.
  ICE_CONNECTION_STATE_CHANGED: 'xmpp.ice_connection_state_changed',

  /**
   * Event which is emitted when the body in an XMPP message in the MUC
   * contains JSON
   */
  JSON_MESSAGE_RECEIVED: 'xmmp.json_message_received'
};
module.exports = XMPPEvents;

/***/ })

/******/ });
});
//# sourceMappingURL=lib-jitsi-meet.js.map